{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f0f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b94190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import math\n",
    "from torch import nn  # nn module contains CrossEntropyLoss\n",
    "from torch import optim  # optim module contains SGD and lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cb628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'D', 'E', 'F', 'G']\n",
      "[[0], [1], [2], [3], [4], [5]]\n",
      "[[1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1]]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "songString = \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\"\n",
    "notes=list(unique(list(songString)))\n",
    "print(notes)\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5]]\n",
    "print(chord)\n",
    "DaisyBell=list()\n",
    "DaisyBellMatrix=[]\n",
    "for note in list(songString):\n",
    "    row=[0]*6\n",
    "    row[notes.index(note)]=1\n",
    "    DaisyBellMatrix.append(row)\n",
    "    DaisyBell.append(chord[notes.index(note)])\n",
    "print(DaisyBell)\n",
    "print(len(DaisyBell))\n",
    "DaisyBellMatrix=numpy.array(DaisyBellMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b05238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [1], [1], [5], [5], [5], [4], [4], [4], [4], [2], [2], [5], [1], [1], [4], [4], [2], [2], [2], [0], [0], [4], [4], [1], [1], [2], [1], [1], [5], [5], [5], [5], [5], [4], [4], [3], [3], [2], [2], [1]]\n"
     ]
    }
   ],
   "source": [
    "HotDogsongString = \"AACCGGGFFFFDDGCCFFDDDAAFFCCDCCGGGGGFFEEDDC\"\n",
    "notes=list(unique(list(HotDogsongString)))\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5]]\n",
    "HotDog=list()\n",
    "HotDogMatrix=[]\n",
    "for note in list(HotDogsongString):\n",
    "    row=[0]*6\n",
    "    row[notes.index(note)]=1\n",
    "    HotDogMatrix.append(row)\n",
    "    HotDog.append(chord[notes.index(note)])\n",
    "print(HotDog)\n",
    "HotDogMatrix=numpy.array(HotDogMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34b4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [4],\n",
       " [4],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [5],\n",
       " [1],\n",
       " [1],\n",
       " [4],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [2],\n",
       " [0],\n",
       " [0],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [1],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [4],\n",
       " [3],\n",
       " [3],\n",
       " [2],\n",
       " [2],\n",
       " [1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HotDog#DaisyBell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54b2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d282f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [0], [4], [3], [2], [1], [2], [3], [4], [0], [4], [3], [2], [1], [2], [3], [4], [0], [4], [3], [2], [1], [2], [3], [4], [0], [4], [3], [2], [1], [2], [3], [4], [0], [4]]\n"
     ]
    }
   ],
   "source": [
    "song3 = \"CDEGAGEDCDEGAGEDCDEGAGEDCDEGAGEDCDEGAG\"\n",
    "notes=list(unique(list(song3)))\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5]]\n",
    "song=list()\n",
    "songMatrix=[]\n",
    "for note in list(song3):\n",
    "    row=[0]*6\n",
    "    row[notes.index(note)]=1\n",
    "    songMatrix.append(row)\n",
    "    song.append(chord[notes.index(note)])\n",
    "print(song)\n",
    "songMatrix=numpy.array(songMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090a12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the songs in a list\n",
    "#songs = [DaisyBell, HotDog, song]\n",
    "songs = [DaisyBell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac1fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, song_index, bptt=42):\n",
    "    data=[]\n",
    "    target=[]\n",
    "    for pos in range(i,i+bptt):\n",
    "        data.append(source[song_index][pos%len(source[song_index])])\n",
    "        target+=source[song_index][(pos+1)%len(source[song_index])]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330c2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [[1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1]]\n",
      "output [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1]\n",
      "[1, 5, 5, 0]\n",
      "\n",
      "\n",
      "input [[1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1]]\n",
      "output [5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1]\n",
      "[5, 5, 0, 0]\n",
      "\n",
      "\n",
      "input [[5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1]]\n",
      "output [5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5]\n",
      "[5, 0, 0, 5]\n",
      "\n",
      "\n",
      "input [[5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5]]\n",
      "output [0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5]\n",
      "[0, 0, 5, 4]\n",
      "\n",
      "\n",
      "input [[0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5]]\n",
      "output [0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0]\n",
      "[0, 5, 4, 4]\n",
      "\n",
      "\n",
      "input [[0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0]]\n",
      "output [5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0]\n",
      "[5, 4, 4, 3]\n",
      "\n",
      "\n",
      "input [[5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0]]\n",
      "output [4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5]\n",
      "[4, 4, 3, 3]\n",
      "\n",
      "\n",
      "input [[4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5]]\n",
      "output [4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4]\n",
      "[4, 3, 3, 2]\n",
      "\n",
      "\n",
      "input [[4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4]]\n",
      "output [3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4]\n",
      "[3, 3, 2, 2]\n",
      "\n",
      "\n",
      "input [[3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4]]\n",
      "output [3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3]\n",
      "[3, 2, 2, 1]\n",
      "\n",
      "\n",
      "input [[3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3]]\n",
      "output [2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3]\n",
      "[2, 2, 1, 5]\n",
      "\n",
      "\n",
      "input [[2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3]]\n",
      "output [2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2]\n",
      "[2, 1, 5, 5]\n",
      "\n",
      "\n",
      "input [[2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2]]\n",
      "output [1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2]\n",
      "[1, 5, 5, 4]\n",
      "\n",
      "\n",
      "input [[1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2]]\n",
      "output [5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1]\n",
      "[5, 5, 4, 4]\n",
      "\n",
      "\n",
      "input [[5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1]]\n",
      "output [5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5]\n",
      "[5, 4, 4, 3]\n",
      "\n",
      "\n",
      "input [[5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5]]\n",
      "output [4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5]\n",
      "[4, 4, 3, 3]\n",
      "\n",
      "\n",
      "input [[4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5]]\n",
      "output [4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4]\n",
      "[4, 3, 3, 2]\n",
      "\n",
      "\n",
      "input [[4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4]]\n",
      "output [3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4]\n",
      "[3, 3, 2, 5]\n",
      "\n",
      "\n",
      "input [[3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4]]\n",
      "output [3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3]\n",
      "[3, 2, 5, 5]\n",
      "\n",
      "\n",
      "input [[3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3]]\n",
      "output [2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3]\n",
      "[2, 5, 5, 4]\n",
      "\n",
      "\n",
      "input [[2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3]]\n",
      "output [5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2]\n",
      "[5, 5, 4, 4]\n",
      "\n",
      "\n",
      "input [[5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2]]\n",
      "output [5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5]\n",
      "[5, 4, 4, 3]\n",
      "\n",
      "\n",
      "input [[5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5]]\n",
      "output [4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5]\n",
      "[4, 4, 3, 3]\n",
      "\n",
      "\n",
      "input [[4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5]]\n",
      "output [4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4]\n",
      "[4, 3, 3, 2]\n",
      "\n",
      "\n",
      "input [[4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4]]\n",
      "output [3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4]\n",
      "[3, 3, 2, 1]\n",
      "\n",
      "\n",
      "input [[3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4]]\n",
      "output [3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3]\n",
      "[3, 2, 1, 1]\n",
      "\n",
      "\n",
      "input [[3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3]]\n",
      "output [2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3]\n",
      "[2, 1, 1, 5]\n",
      "\n",
      "\n",
      "input [[2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3]]\n",
      "output [1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2]\n",
      "[1, 1, 5, 5]\n",
      "\n",
      "\n",
      "input [[1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2]]\n",
      "output [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1]\n",
      "[1, 5, 5, 0]\n",
      "\n",
      "\n",
      "input [[1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1]]\n",
      "output [5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1]\n",
      "[5, 5, 0, 0]\n",
      "\n",
      "\n",
      "input [[5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1]]\n",
      "output [5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5]\n",
      "[5, 0, 0, 5]\n",
      "\n",
      "\n",
      "input [[5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5]]\n",
      "output [0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5]\n",
      "[0, 0, 5, 4]\n",
      "\n",
      "\n",
      "input [[0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5]]\n",
      "output [0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0]\n",
      "[0, 5, 4, 4]\n",
      "\n",
      "\n",
      "input [[0], [5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0]]\n",
      "output [5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0]\n",
      "[5, 4, 4, 3]\n",
      "\n",
      "\n",
      "input [[5], [4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0]]\n",
      "output [4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5]\n",
      "[4, 4, 3, 3]\n",
      "\n",
      "\n",
      "input [[4], [4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5]]\n",
      "output [4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4]\n",
      "[4, 3, 3, 2]\n",
      "\n",
      "\n",
      "input [[4], [3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4]]\n",
      "output [3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4]\n",
      "[3, 3, 2, 2]\n",
      "\n",
      "\n",
      "input [[3], [3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4]]\n",
      "output [3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3]\n",
      "[3, 2, 2, 1]\n",
      "\n",
      "\n",
      "input [[3], [2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3]]\n",
      "output [2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3]\n",
      "[2, 2, 1, 1]\n",
      "\n",
      "\n",
      "input [[2], [2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3]]\n",
      "output [2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2]\n",
      "[2, 1, 1, 1]\n",
      "\n",
      "\n",
      "input [[2], [1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2]]\n",
      "output [1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2]\n",
      "[1, 1, 1, 5]\n",
      "\n",
      "\n",
      "input [[1], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2], [1], [5], [5], [4], [4], [3], [3], [2], [5], [5], [4], [4], [3], [3], [2], [1], [1], [5], [5], [0], [0], [5], [4], [4], [3], [3], [2], [2]]\n",
      "output [1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1]\n",
      "[1, 1, 5, 5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bptt=42\n",
    "for i in range(42):\n",
    "    d,t=get_batch(songs,i,0)\n",
    "    print(f\"input {d}\")\n",
    "    print(f\"output {t}\")\n",
    "    print(t[:4])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d38c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, d_model, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout), nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor, verbose=False) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        if verbose:\n",
    "            print(src.shape)\n",
    "            figure()\n",
    "            imshow(src.detach().numpy().reshape((42,20)))\n",
    "        src = self.pos_encoder(src)\n",
    "        if verbose:\n",
    "            print(src.shape)\n",
    "            figure()\n",
    "            imshow(src.detach().numpy().reshape((42,20)))\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        #print(output.shape)\n",
    "        #self.retainer=output[-1].copy()\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "            figure()\n",
    "            imshow(output.detach().numpy().reshape((42,20)))\n",
    "        output = self.decoder(output)\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "            figure()\n",
    "            imshow(output.detach().numpy().reshape((42,6)))\n",
    "        return output\n",
    "\n",
    "        \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b455867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (encoder): Embedding(6, 64)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# I generated this part not sure if its right\n",
    "model = TransformerModel(ntoken=6, d_model=64, nhead=4, d_hid=256, nlayers=2, dropout=0.2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5344ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  6.8156e-01,  ...,  1.0000e+00,\n",
       "                         1.3335e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.9748e-01,  ...,  1.0000e+00,\n",
       "                         2.6670e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.5625e-01, -2.9254e-01,  6.4315e-01,  ...,  6.3049e-01,\n",
       "                         6.1813e-01,  7.8608e-01]],\n",
       "              \n",
       "                      [[ 2.7050e-01, -9.6272e-01, -5.1133e-02,  ...,  6.3036e-01,\n",
       "                         6.1823e-01,  7.8599e-01]],\n",
       "              \n",
       "                      [[-6.6395e-01, -7.4778e-01, -7.1816e-01,  ...,  6.3022e-01,\n",
       "                         6.1834e-01,  7.8591e-01]]])),\n",
       "             ('encoder.weight',\n",
       "              tensor([[ 0.0579, -0.0096, -0.0636,  0.0155,  0.0797, -0.0264,  0.0029,  0.0844,\n",
       "                       -0.0049,  0.0075, -0.0038,  0.0222, -0.0319, -0.0940,  0.0465, -0.0739,\n",
       "                       -0.0592,  0.0763, -0.0789, -0.0797, -0.0498,  0.0660,  0.0241, -0.0455,\n",
       "                        0.0111, -0.0680, -0.0105,  0.0755, -0.0568,  0.0898, -0.0170,  0.0612,\n",
       "                        0.0444, -0.0817, -0.0237, -0.0792,  0.0262,  0.0036,  0.0114,  0.0397,\n",
       "                       -0.0875, -0.0627, -0.0040, -0.0517, -0.0190,  0.0454,  0.0320, -0.0737,\n",
       "                       -0.0557, -0.0026,  0.0514, -0.0151,  0.0608,  0.0435,  0.0615, -0.0355,\n",
       "                       -0.0441, -0.0310,  0.0776,  0.0900, -0.0952, -0.0291, -0.0500,  0.0242],\n",
       "                      [-0.0072, -0.0083, -0.0505,  0.0542,  0.0998, -0.0374, -0.0499,  0.0715,\n",
       "                        0.0224, -0.0290,  0.0409,  0.0041, -0.0637, -0.0972,  0.0310,  0.0579,\n",
       "                        0.0688, -0.0181,  0.0926, -0.0168,  0.0762, -0.0076, -0.0098,  0.0842,\n",
       "                        0.0821, -0.0537,  0.0104, -0.0229,  0.0124,  0.0897,  0.0761,  0.0870,\n",
       "                        0.0569,  0.0927,  0.0336, -0.0388, -0.0751,  0.0295, -0.0001, -0.0714,\n",
       "                       -0.0663,  0.0601,  0.0759,  0.0834,  0.0549,  0.0532,  0.0442, -0.0177,\n",
       "                        0.0782, -0.0318, -0.0728, -0.0999, -0.0792, -0.0401, -0.0075,  0.0817,\n",
       "                        0.0694,  0.0923, -0.0914, -0.0356, -0.0455,  0.0214, -0.0569,  0.0683],\n",
       "                      [-0.0145,  0.0729, -0.0288, -0.0069, -0.0679,  0.0846,  0.0217,  0.0988,\n",
       "                        0.0172,  0.0520, -0.0473, -0.0545,  0.0981, -0.0854, -0.0756, -0.0985,\n",
       "                       -0.0212,  0.0626, -0.0607,  0.0160, -0.0322,  0.0530, -0.0204, -0.0251,\n",
       "                       -0.0452, -0.0265,  0.0705, -0.0934,  0.0248, -0.0704,  0.0367,  0.0582,\n",
       "                        0.0940, -0.0923,  0.0325,  0.0480,  0.0382,  0.0595, -0.0589,  0.0867,\n",
       "                       -0.0236, -0.0807,  0.0063, -0.0076, -0.0517, -0.0809, -0.0773,  0.0411,\n",
       "                        0.0583, -0.0175,  0.0478,  0.0672, -0.0093, -0.0624,  0.0423,  0.0233,\n",
       "                        0.0795,  0.0881, -0.0376,  0.0926, -0.0390, -0.0520, -0.0887, -0.0472],\n",
       "                      [-0.0235, -0.0922, -0.0738, -0.0929, -0.0765,  0.0043, -0.0562, -0.0708,\n",
       "                       -0.0188,  0.0029,  0.0188,  0.0015, -0.0855,  0.0417, -0.0757,  0.0837,\n",
       "                       -0.0565,  0.0389, -0.0560, -0.0397, -0.0208, -0.0054,  0.0552, -0.0910,\n",
       "                        0.0406, -0.0350,  0.0298, -0.0904,  0.0895,  0.0087,  0.0347,  0.0165,\n",
       "                        0.0504,  0.0521,  0.0090,  0.0306,  0.0800,  0.0264,  0.0583,  0.0030,\n",
       "                       -0.0795, -0.0191,  0.0394,  0.0758, -0.0509, -0.0344,  0.0236, -0.0342,\n",
       "                       -0.0809,  0.0876, -0.0714, -0.0090, -0.0267, -0.0022,  0.0218,  0.0703,\n",
       "                        0.0471, -0.0170, -0.0235,  0.0887, -0.0333, -0.0785, -0.0479,  0.0497],\n",
       "                      [-0.0841, -0.0903,  0.0692, -0.0438,  0.0737,  0.0257,  0.0192, -0.0652,\n",
       "                        0.0103,  0.0693,  0.0058,  0.0583,  0.0963, -0.0290, -0.0252, -0.0733,\n",
       "                        0.0321,  0.0587,  0.0735, -0.0870, -0.0670, -0.0762,  0.0954,  0.0790,\n",
       "                        0.0346,  0.0791, -0.0864, -0.0804, -0.0735, -0.0683, -0.0173,  0.0760,\n",
       "                       -0.0808, -0.0648,  0.0528, -0.0878, -0.0330, -0.0423, -0.0243, -0.0088,\n",
       "                        0.0514, -0.0765,  0.0825, -0.0099,  0.0551,  0.0703, -0.0396, -0.0548,\n",
       "                       -0.0743, -0.0335, -0.0416,  0.0452, -0.0668, -0.0111, -0.0904,  0.0295,\n",
       "                       -0.0364, -0.0120,  0.0745, -0.0192, -0.0744,  0.0366, -0.0915, -0.0399],\n",
       "                      [ 0.0634, -0.0865,  0.0737,  0.0568,  0.0612, -0.0693,  0.0533,  0.0527,\n",
       "                        0.0102, -0.0859,  0.0888,  0.0988,  0.0390,  0.0271,  0.0801, -0.0725,\n",
       "                        0.0478,  0.0867,  0.0491, -0.0694,  0.0868, -0.0830,  0.0292, -0.0842,\n",
       "                       -0.0730,  0.0358, -0.0854,  0.0960,  0.0863, -0.0986, -0.0839,  0.0785,\n",
       "                       -0.0086, -0.0784, -0.0559, -0.0574,  0.0786,  0.0916, -0.0750, -0.0070,\n",
       "                        0.0708,  0.0382,  0.0414, -0.0310,  0.0434, -0.0900, -0.0187, -0.0811,\n",
       "                        0.0005,  0.0237, -0.0907,  0.0060, -0.0559, -0.0466, -0.0041, -0.0412,\n",
       "                        0.0943, -0.0392, -0.0502, -0.0558,  0.0771, -0.0265, -0.0800, -0.0566]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0911,  0.1134,  0.0738,  ...,  0.0152, -0.0313,  0.0678],\n",
       "                      [-0.0831,  0.0428, -0.0731,  ...,  0.1233,  0.0086,  0.1109],\n",
       "                      [-0.0977,  0.0615,  0.0579,  ..., -0.0896,  0.1046,  0.0313],\n",
       "                      ...,\n",
       "                      [-0.1158,  0.0808, -0.0685,  ...,  0.0844,  0.0893, -0.1514],\n",
       "                      [-0.0894, -0.0097, -0.1512,  ..., -0.1141,  0.0464, -0.1501],\n",
       "                      [ 0.1156,  0.0047, -0.0243,  ..., -0.0238, -0.0308, -0.0102]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0724,  0.0607,  0.0626,  ..., -0.1204, -0.0604,  0.1066],\n",
       "                      [ 0.0837,  0.0234, -0.0338,  ..., -0.0727,  0.0696, -0.0946],\n",
       "                      [-0.0180,  0.0126,  0.0679,  ..., -0.1011, -0.0704,  0.1120],\n",
       "                      ...,\n",
       "                      [ 0.0953, -0.0815, -0.0335,  ..., -0.0405,  0.0808, -0.0139],\n",
       "                      [ 0.0637, -0.0301, -0.0248,  ...,  0.0269,  0.0986,  0.0296],\n",
       "                      [-0.0496,  0.1248, -0.1025,  ...,  0.0029, -0.0757,  0.0152]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.0493,  0.0265,  0.0353,  ...,  0.0460,  0.0433, -0.0225],\n",
       "                      [-0.0160,  0.0531, -0.0417,  ...,  0.0420,  0.0393,  0.1099],\n",
       "                      [-0.0699, -0.0081,  0.0441,  ..., -0.0182, -0.0883,  0.1091],\n",
       "                      ...,\n",
       "                      [-0.0867, -0.1142, -0.0499,  ...,  0.1080,  0.0106,  0.0421],\n",
       "                      [ 0.0278, -0.1058,  0.1072,  ...,  0.0615, -0.0209,  0.1069],\n",
       "                      [ 0.0971, -0.0128, -0.0647,  ...,  0.0490,  0.0446, -0.0581]])),\n",
       "             ('transformer_encoder.layers.0.linear1.bias',\n",
       "              tensor([-0.1082,  0.0510, -0.1084, -0.0624,  0.1056,  0.0977,  0.0422, -0.1168,\n",
       "                       0.0118,  0.0247,  0.0511, -0.0885,  0.1189,  0.0740,  0.0230,  0.0224,\n",
       "                       0.0866, -0.1041, -0.0021,  0.1045, -0.1123,  0.0755, -0.0660, -0.1028,\n",
       "                      -0.0500,  0.0949, -0.1026,  0.0754, -0.0045,  0.0986, -0.0735,  0.0815,\n",
       "                      -0.0714, -0.0226, -0.0400, -0.0722, -0.0436, -0.0781, -0.0291, -0.0556,\n",
       "                      -0.0868, -0.0869, -0.0261,  0.0126,  0.0974,  0.0098, -0.0976, -0.0314,\n",
       "                      -0.0112,  0.1039, -0.0815,  0.0779,  0.0798,  0.0303,  0.0541,  0.0794,\n",
       "                       0.0259, -0.0360,  0.0551, -0.0301, -0.0693,  0.0143, -0.0208, -0.0415,\n",
       "                      -0.0223,  0.0700,  0.0353,  0.0775, -0.0210,  0.0920,  0.0518,  0.0450,\n",
       "                       0.0042, -0.1114,  0.0546,  0.1041, -0.0496,  0.1155, -0.1039,  0.0946,\n",
       "                      -0.0108, -0.0659,  0.1070,  0.0525,  0.0471,  0.1032,  0.1003, -0.1040,\n",
       "                      -0.0535,  0.1187, -0.0438,  0.0835,  0.0250, -0.0058,  0.0373, -0.0465,\n",
       "                       0.0867,  0.0389,  0.1009,  0.0137,  0.1188, -0.0557, -0.0756,  0.0360,\n",
       "                      -0.0629,  0.0580,  0.1242,  0.0149,  0.0043,  0.0080,  0.1094,  0.0885,\n",
       "                      -0.0424, -0.1056, -0.0653, -0.0068,  0.0856, -0.0320, -0.0928, -0.0622,\n",
       "                      -0.0674, -0.0932,  0.0833,  0.0885,  0.0192, -0.0012, -0.0963,  0.0610,\n",
       "                      -0.0569,  0.1226, -0.0740,  0.0954, -0.0537,  0.1196,  0.0613,  0.0246,\n",
       "                       0.0488, -0.0695, -0.1144, -0.0153, -0.1005, -0.0139,  0.0898, -0.0831,\n",
       "                      -0.1208,  0.0833,  0.0763,  0.0576,  0.1101, -0.0887, -0.0532,  0.0552,\n",
       "                       0.0268,  0.0378, -0.0630, -0.0348,  0.0983, -0.0543,  0.0133, -0.0385,\n",
       "                       0.1005,  0.0366, -0.1077, -0.0652, -0.0728, -0.0562,  0.0240, -0.0851,\n",
       "                      -0.0568, -0.0166,  0.0180, -0.1124,  0.0461,  0.0778,  0.0966,  0.0812,\n",
       "                      -0.0106,  0.0041, -0.0841,  0.0204,  0.0331, -0.0427,  0.0360,  0.0722,\n",
       "                       0.0750, -0.0270,  0.0752, -0.0024, -0.1079,  0.1237, -0.0164, -0.0565,\n",
       "                       0.0447,  0.0399,  0.1031,  0.0963,  0.1243,  0.0074,  0.0204, -0.0332,\n",
       "                      -0.0977, -0.0065, -0.0291, -0.0153,  0.1021, -0.0661,  0.1194,  0.0017,\n",
       "                      -0.0384,  0.0486,  0.1092,  0.1139,  0.0957, -0.1036,  0.0323,  0.1065,\n",
       "                      -0.0290,  0.0789,  0.0377, -0.0734, -0.0652, -0.0318,  0.0241,  0.0754,\n",
       "                       0.1240,  0.1083,  0.0935, -0.0721,  0.0968,  0.1076, -0.0789,  0.0460,\n",
       "                       0.1016, -0.0861,  0.0465,  0.0141,  0.0055, -0.0551, -0.0898,  0.0612,\n",
       "                       0.0794, -0.0620, -0.0328,  0.0874,  0.0633,  0.0402, -0.0557,  0.0770,\n",
       "                      -0.0947, -0.0704, -0.0115, -0.0301,  0.1181, -0.0237, -0.0332, -0.0829])),\n",
       "             ('transformer_encoder.layers.0.linear2.weight',\n",
       "              tensor([[-0.0253,  0.0077,  0.0247,  ...,  0.0625, -0.0124,  0.0375],\n",
       "                      [ 0.0397, -0.0391, -0.0041,  ...,  0.0083, -0.0127,  0.0555],\n",
       "                      [ 0.0473,  0.0040,  0.0179,  ...,  0.0447, -0.0234,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0403, -0.0119,  0.0092,  ..., -0.0374, -0.0610, -0.0353],\n",
       "                      [ 0.0354, -0.0261, -0.0564,  ..., -0.0548,  0.0183,  0.0257],\n",
       "                      [ 0.0381, -0.0259,  0.0338,  ...,  0.0310, -0.0609,  0.0448]])),\n",
       "             ('transformer_encoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0289,  0.0101,  0.0246,  0.0274, -0.0420,  0.0575, -0.0409, -0.0204,\n",
       "                       0.0548, -0.0510, -0.0316,  0.0547, -0.0388,  0.0296, -0.0576,  0.0315,\n",
       "                       0.0173,  0.0330, -0.0351,  0.0438,  0.0143, -0.0338,  0.0315,  0.0427,\n",
       "                      -0.0251, -0.0244,  0.0455, -0.0496,  0.0002,  0.0168, -0.0576,  0.0295,\n",
       "                      -0.0564, -0.0217,  0.0524,  0.0533, -0.0289,  0.0507,  0.0490, -0.0620,\n",
       "                      -0.0321, -0.0603, -0.0133,  0.0471, -0.0444,  0.0288, -0.0033, -0.0038,\n",
       "                      -0.0034, -0.0150,  0.0434, -0.0505, -0.0078, -0.0369,  0.0451, -0.0372,\n",
       "                       0.0010, -0.0198, -0.0208,  0.0113, -0.0434,  0.0304, -0.0559, -0.0219])),\n",
       "             ('transformer_encoder.layers.0.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.0911,  0.1134,  0.0738,  ...,  0.0152, -0.0313,  0.0678],\n",
       "                      [-0.0831,  0.0428, -0.0731,  ...,  0.1233,  0.0086,  0.1109],\n",
       "                      [-0.0977,  0.0615,  0.0579,  ..., -0.0896,  0.1046,  0.0313],\n",
       "                      ...,\n",
       "                      [-0.1158,  0.0808, -0.0685,  ...,  0.0844,  0.0893, -0.1514],\n",
       "                      [-0.0894, -0.0097, -0.1512,  ..., -0.1141,  0.0464, -0.1501],\n",
       "                      [ 0.1156,  0.0047, -0.0243,  ..., -0.0238, -0.0308, -0.0102]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0724,  0.0607,  0.0626,  ..., -0.1204, -0.0604,  0.1066],\n",
       "                      [ 0.0837,  0.0234, -0.0338,  ..., -0.0727,  0.0696, -0.0946],\n",
       "                      [-0.0180,  0.0126,  0.0679,  ..., -0.1011, -0.0704,  0.1120],\n",
       "                      ...,\n",
       "                      [ 0.0953, -0.0815, -0.0335,  ..., -0.0405,  0.0808, -0.0139],\n",
       "                      [ 0.0637, -0.0301, -0.0248,  ...,  0.0269,  0.0986,  0.0296],\n",
       "                      [-0.0496,  0.1248, -0.1025,  ...,  0.0029, -0.0757,  0.0152]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.0493,  0.0265,  0.0353,  ...,  0.0460,  0.0433, -0.0225],\n",
       "                      [-0.0160,  0.0531, -0.0417,  ...,  0.0420,  0.0393,  0.1099],\n",
       "                      [-0.0699, -0.0081,  0.0441,  ..., -0.0182, -0.0883,  0.1091],\n",
       "                      ...,\n",
       "                      [-0.0867, -0.1142, -0.0499,  ...,  0.1080,  0.0106,  0.0421],\n",
       "                      [ 0.0278, -0.1058,  0.1072,  ...,  0.0615, -0.0209,  0.1069],\n",
       "                      [ 0.0971, -0.0128, -0.0647,  ...,  0.0490,  0.0446, -0.0581]])),\n",
       "             ('transformer_encoder.layers.1.linear1.bias',\n",
       "              tensor([-0.1082,  0.0510, -0.1084, -0.0624,  0.1056,  0.0977,  0.0422, -0.1168,\n",
       "                       0.0118,  0.0247,  0.0511, -0.0885,  0.1189,  0.0740,  0.0230,  0.0224,\n",
       "                       0.0866, -0.1041, -0.0021,  0.1045, -0.1123,  0.0755, -0.0660, -0.1028,\n",
       "                      -0.0500,  0.0949, -0.1026,  0.0754, -0.0045,  0.0986, -0.0735,  0.0815,\n",
       "                      -0.0714, -0.0226, -0.0400, -0.0722, -0.0436, -0.0781, -0.0291, -0.0556,\n",
       "                      -0.0868, -0.0869, -0.0261,  0.0126,  0.0974,  0.0098, -0.0976, -0.0314,\n",
       "                      -0.0112,  0.1039, -0.0815,  0.0779,  0.0798,  0.0303,  0.0541,  0.0794,\n",
       "                       0.0259, -0.0360,  0.0551, -0.0301, -0.0693,  0.0143, -0.0208, -0.0415,\n",
       "                      -0.0223,  0.0700,  0.0353,  0.0775, -0.0210,  0.0920,  0.0518,  0.0450,\n",
       "                       0.0042, -0.1114,  0.0546,  0.1041, -0.0496,  0.1155, -0.1039,  0.0946,\n",
       "                      -0.0108, -0.0659,  0.1070,  0.0525,  0.0471,  0.1032,  0.1003, -0.1040,\n",
       "                      -0.0535,  0.1187, -0.0438,  0.0835,  0.0250, -0.0058,  0.0373, -0.0465,\n",
       "                       0.0867,  0.0389,  0.1009,  0.0137,  0.1188, -0.0557, -0.0756,  0.0360,\n",
       "                      -0.0629,  0.0580,  0.1242,  0.0149,  0.0043,  0.0080,  0.1094,  0.0885,\n",
       "                      -0.0424, -0.1056, -0.0653, -0.0068,  0.0856, -0.0320, -0.0928, -0.0622,\n",
       "                      -0.0674, -0.0932,  0.0833,  0.0885,  0.0192, -0.0012, -0.0963,  0.0610,\n",
       "                      -0.0569,  0.1226, -0.0740,  0.0954, -0.0537,  0.1196,  0.0613,  0.0246,\n",
       "                       0.0488, -0.0695, -0.1144, -0.0153, -0.1005, -0.0139,  0.0898, -0.0831,\n",
       "                      -0.1208,  0.0833,  0.0763,  0.0576,  0.1101, -0.0887, -0.0532,  0.0552,\n",
       "                       0.0268,  0.0378, -0.0630, -0.0348,  0.0983, -0.0543,  0.0133, -0.0385,\n",
       "                       0.1005,  0.0366, -0.1077, -0.0652, -0.0728, -0.0562,  0.0240, -0.0851,\n",
       "                      -0.0568, -0.0166,  0.0180, -0.1124,  0.0461,  0.0778,  0.0966,  0.0812,\n",
       "                      -0.0106,  0.0041, -0.0841,  0.0204,  0.0331, -0.0427,  0.0360,  0.0722,\n",
       "                       0.0750, -0.0270,  0.0752, -0.0024, -0.1079,  0.1237, -0.0164, -0.0565,\n",
       "                       0.0447,  0.0399,  0.1031,  0.0963,  0.1243,  0.0074,  0.0204, -0.0332,\n",
       "                      -0.0977, -0.0065, -0.0291, -0.0153,  0.1021, -0.0661,  0.1194,  0.0017,\n",
       "                      -0.0384,  0.0486,  0.1092,  0.1139,  0.0957, -0.1036,  0.0323,  0.1065,\n",
       "                      -0.0290,  0.0789,  0.0377, -0.0734, -0.0652, -0.0318,  0.0241,  0.0754,\n",
       "                       0.1240,  0.1083,  0.0935, -0.0721,  0.0968,  0.1076, -0.0789,  0.0460,\n",
       "                       0.1016, -0.0861,  0.0465,  0.0141,  0.0055, -0.0551, -0.0898,  0.0612,\n",
       "                       0.0794, -0.0620, -0.0328,  0.0874,  0.0633,  0.0402, -0.0557,  0.0770,\n",
       "                      -0.0947, -0.0704, -0.0115, -0.0301,  0.1181, -0.0237, -0.0332, -0.0829])),\n",
       "             ('transformer_encoder.layers.1.linear2.weight',\n",
       "              tensor([[-0.0253,  0.0077,  0.0247,  ...,  0.0625, -0.0124,  0.0375],\n",
       "                      [ 0.0397, -0.0391, -0.0041,  ...,  0.0083, -0.0127,  0.0555],\n",
       "                      [ 0.0473,  0.0040,  0.0179,  ...,  0.0447, -0.0234,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0403, -0.0119,  0.0092,  ..., -0.0374, -0.0610, -0.0353],\n",
       "                      [ 0.0354, -0.0261, -0.0564,  ..., -0.0548,  0.0183,  0.0257],\n",
       "                      [ 0.0381, -0.0259,  0.0338,  ...,  0.0310, -0.0609,  0.0448]])),\n",
       "             ('transformer_encoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0289,  0.0101,  0.0246,  0.0274, -0.0420,  0.0575, -0.0409, -0.0204,\n",
       "                       0.0548, -0.0510, -0.0316,  0.0547, -0.0388,  0.0296, -0.0576,  0.0315,\n",
       "                       0.0173,  0.0330, -0.0351,  0.0438,  0.0143, -0.0338,  0.0315,  0.0427,\n",
       "                      -0.0251, -0.0244,  0.0455, -0.0496,  0.0002,  0.0168, -0.0576,  0.0295,\n",
       "                      -0.0564, -0.0217,  0.0524,  0.0533, -0.0289,  0.0507,  0.0490, -0.0620,\n",
       "                      -0.0321, -0.0603, -0.0133,  0.0471, -0.0444,  0.0288, -0.0033, -0.0038,\n",
       "                      -0.0034, -0.0150,  0.0434, -0.0505, -0.0078, -0.0369,  0.0451, -0.0372,\n",
       "                       0.0010, -0.0198, -0.0208,  0.0113, -0.0434,  0.0304, -0.0559, -0.0219])),\n",
       "             ('transformer_encoder.layers.1.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.weight',\n",
       "              tensor([[ 0.0022, -0.0607,  0.0976,  0.0104, -0.0317,  0.0439,  0.0597, -0.0001,\n",
       "                       -0.0140, -0.0698, -0.0659,  0.0020, -0.0772,  0.0822,  0.0969,  0.0805,\n",
       "                       -0.0366, -0.0033,  0.0292, -0.0370, -0.0543, -0.0484, -0.0185,  0.0647,\n",
       "                       -0.0836, -0.0929, -0.0724,  0.0169,  0.0403,  0.0300,  0.0321,  0.0854,\n",
       "                       -0.0241, -0.0097,  0.0661,  0.0286,  0.0714,  0.0846, -0.0182, -0.0513,\n",
       "                        0.0513, -0.0690, -0.0344,  0.0374, -0.0023,  0.0892, -0.0775,  0.0428,\n",
       "                       -0.0978,  0.0846, -0.0915, -0.0593,  0.0317,  0.0099,  0.0655,  0.0470,\n",
       "                        0.0665, -0.0889,  0.0286,  0.0440, -0.0985,  0.0365,  0.0231,  0.0150],\n",
       "                      [-0.0679,  0.0448,  0.0143,  0.0115,  0.0971,  0.0118, -0.0505,  0.0019,\n",
       "                       -0.0718,  0.0157, -0.0358,  0.0111,  0.0798,  0.0752, -0.0917, -0.0361,\n",
       "                       -0.0657,  0.0599,  0.0315, -0.0897,  0.0862, -0.0586,  0.0793,  0.0703,\n",
       "                        0.0503,  0.0765,  0.0693, -0.0002,  0.0094, -0.0786,  0.0623, -0.0642,\n",
       "                        0.0246,  0.0094, -0.0327,  0.0454,  0.0557, -0.0372, -0.0799, -0.0577,\n",
       "                       -0.0106, -0.0646, -0.0345,  0.0927, -0.0811, -0.0013,  0.0004, -0.0923,\n",
       "                        0.0100, -0.0301, -0.0214,  0.0611,  0.0871, -0.0536, -0.0149,  0.0876,\n",
       "                       -0.0404, -0.0496, -0.0186,  0.0491,  0.0167, -0.0748,  0.0878, -0.0282],\n",
       "                      [ 0.0101, -0.0633, -0.0307, -0.0613, -0.0832,  0.0773, -0.0518,  0.0388,\n",
       "                        0.0255,  0.0105,  0.0763, -0.0352, -0.0680,  0.0352, -0.0557,  0.0714,\n",
       "                       -0.0337, -0.0018, -0.0529, -0.0631,  0.0582, -0.0025,  0.0281, -0.0513,\n",
       "                       -0.0308, -0.0139, -0.0121, -0.0986, -0.0036,  0.0007,  0.0209, -0.0432,\n",
       "                       -0.0379,  0.0631, -0.0760, -0.0778, -0.0478, -0.0062, -0.0553,  0.0959,\n",
       "                       -0.0445,  0.0974,  0.0362,  0.0513, -0.0492,  0.0700,  0.0024,  0.0866,\n",
       "                       -0.0099, -0.0612,  0.0143, -0.0320,  0.0016, -0.0003,  0.0102, -0.0598,\n",
       "                       -0.0328, -0.0677, -0.0165, -0.0988,  0.0942, -0.0728, -0.0483,  0.0496],\n",
       "                      [ 0.0993,  0.0542,  0.0335,  0.0884, -0.0390, -0.0263, -0.0168,  0.0312,\n",
       "                        0.0981, -0.0176, -0.0590,  0.0654, -0.0909,  0.0117,  0.0726, -0.0105,\n",
       "                       -0.0267, -0.0554, -0.0267, -0.0270,  0.0365,  0.0591,  0.0557,  0.0988,\n",
       "                        0.0525, -0.0776,  0.0202, -0.0273,  0.0865,  0.0027,  0.0696, -0.0657,\n",
       "                        0.0235,  0.0422, -0.0203, -0.0983, -0.0821, -0.0656, -0.0858,  0.0902,\n",
       "                       -0.0271, -0.0427,  0.0503, -0.0716, -0.0418,  0.0593, -0.0821, -0.0748,\n",
       "                       -0.0815, -0.0309,  0.0465,  0.0920,  0.0034,  0.0488,  0.0136, -0.0270,\n",
       "                        0.0735, -0.0713,  0.0556, -0.0281, -0.0266, -0.0711, -0.0932,  0.0621],\n",
       "                      [ 0.0834, -0.0445, -0.0356,  0.0127, -0.0959,  0.0366, -0.0953, -0.0656,\n",
       "                       -0.0883,  0.0337,  0.0493,  0.0904,  0.0685,  0.0201, -0.0282, -0.0845,\n",
       "                       -0.0301, -0.0622,  0.0575, -0.1000, -0.0451,  0.0329, -0.0231, -0.0203,\n",
       "                       -0.0835,  0.0482,  0.0582, -0.0952,  0.0311, -0.0871,  0.0903,  0.0597,\n",
       "                        0.0409,  0.0269, -0.0173,  0.0899,  0.0419,  0.0583, -0.0039,  0.0222,\n",
       "                        0.0613,  0.0224,  0.0283,  0.0263,  0.0242,  0.0339,  0.0434,  0.0192,\n",
       "                       -0.0560, -0.0618,  0.0430, -0.0804, -0.0257, -0.0278,  0.0152,  0.0652,\n",
       "                        0.0973,  0.0211,  0.0600,  0.0034, -0.0404, -0.0387,  0.0374,  0.0877],\n",
       "                      [-0.0823,  0.0196, -0.0470, -0.0959, -0.0410, -0.0384, -0.0989, -0.0940,\n",
       "                        0.0592, -0.0669, -0.0657, -0.0842,  0.0458,  0.0227, -0.0980, -0.0933,\n",
       "                        0.0222, -0.0700, -0.0766,  0.0779, -0.0679, -0.0043,  0.0434, -0.0904,\n",
       "                       -0.0421,  0.0662, -0.0849,  0.0296, -0.0912, -0.0833,  0.0336, -0.0397,\n",
       "                        0.0283,  0.0256,  0.0299, -0.0309, -0.0667, -0.0325, -0.0262,  0.0288,\n",
       "                       -0.0278, -0.0622, -0.0506, -0.0316,  0.0389, -0.0256,  0.0507,  0.0144,\n",
       "                        0.0814, -0.0660,  0.0841,  0.0343, -0.0089,  0.0878, -0.0654,  0.0673,\n",
       "                       -0.0488,  0.0158, -0.0101, -0.0917,  0.0525, -0.0206, -0.0170,  0.0010]])),\n",
       "             ('decoder.bias', tensor([0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cd21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50eafb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.84 | Training Perplexity: 6.29\n",
      "| End of epoch   1 | Validation Loss: 1.82 | Validation Perplexity:     6.20\n",
      "Training Loss: 1.82 | Training Perplexity: 6.20\n",
      "| End of epoch   2 | Validation Loss: 1.81 | Validation Perplexity:     6.10\n",
      "Training Loss: 1.81 | Training Perplexity: 6.10\n",
      "| End of epoch   3 | Validation Loss: 1.79 | Validation Perplexity:     6.02\n",
      "Training Loss: 1.79 | Training Perplexity: 6.02\n",
      "| End of epoch   4 | Validation Loss: 1.78 | Validation Perplexity:     5.93\n",
      "Training Loss: 1.78 | Training Perplexity: 5.93\n",
      "| End of epoch   5 | Validation Loss: 1.77 | Validation Perplexity:     5.85\n",
      "Training Loss: 1.77 | Training Perplexity: 5.85\n",
      "| End of epoch   6 | Validation Loss: 1.75 | Validation Perplexity:     5.78\n",
      "Training Loss: 1.75 | Training Perplexity: 5.78\n",
      "| End of epoch   7 | Validation Loss: 1.74 | Validation Perplexity:     5.70\n",
      "Training Loss: 1.74 | Training Perplexity: 5.70\n",
      "| End of epoch   8 | Validation Loss: 1.73 | Validation Perplexity:     5.63\n",
      "Training Loss: 1.73 | Training Perplexity: 5.63\n",
      "| End of epoch   9 | Validation Loss: 1.72 | Validation Perplexity:     5.56\n",
      "Training Loss: 1.72 | Training Perplexity: 5.56\n",
      "| End of epoch  10 | Validation Loss: 1.70 | Validation Perplexity:     5.50\n",
      "Training Loss: 1.70 | Training Perplexity: 5.50\n",
      "| End of epoch  11 | Validation Loss: 1.69 | Validation Perplexity:     5.43\n",
      "Training Loss: 1.69 | Training Perplexity: 5.43\n",
      "| End of epoch  12 | Validation Loss: 1.68 | Validation Perplexity:     5.37\n",
      "Training Loss: 1.68 | Training Perplexity: 5.37\n",
      "| End of epoch  13 | Validation Loss: 1.67 | Validation Perplexity:     5.31\n",
      "Training Loss: 1.67 | Training Perplexity: 5.31\n",
      "| End of epoch  14 | Validation Loss: 1.66 | Validation Perplexity:     5.24\n",
      "Training Loss: 1.66 | Training Perplexity: 5.24\n",
      "| End of epoch  15 | Validation Loss: 1.64 | Validation Perplexity:     5.18\n",
      "Training Loss: 1.64 | Training Perplexity: 5.18\n",
      "| End of epoch  16 | Validation Loss: 1.63 | Validation Perplexity:     5.11\n",
      "Training Loss: 1.63 | Training Perplexity: 5.11\n",
      "| End of epoch  17 | Validation Loss: 1.62 | Validation Perplexity:     5.05\n",
      "Training Loss: 1.62 | Training Perplexity: 5.05\n",
      "| End of epoch  18 | Validation Loss: 1.61 | Validation Perplexity:     4.98\n",
      "Training Loss: 1.61 | Training Perplexity: 4.98\n",
      "| End of epoch  19 | Validation Loss: 1.59 | Validation Perplexity:     4.92\n",
      "Training Loss: 1.59 | Training Perplexity: 4.92\n",
      "| End of epoch  20 | Validation Loss: 1.58 | Validation Perplexity:     4.85\n",
      "Training Loss: 1.58 | Training Perplexity: 4.85\n",
      "| End of epoch  21 | Validation Loss: 1.56 | Validation Perplexity:     4.78\n",
      "Training Loss: 1.56 | Training Perplexity: 4.78\n",
      "| End of epoch  22 | Validation Loss: 1.55 | Validation Perplexity:     4.71\n",
      "Training Loss: 1.55 | Training Perplexity: 4.71\n",
      "| End of epoch  23 | Validation Loss: 1.54 | Validation Perplexity:     4.64\n",
      "Training Loss: 1.54 | Training Perplexity: 4.64\n",
      "| End of epoch  24 | Validation Loss: 1.52 | Validation Perplexity:     4.58\n",
      "Training Loss: 1.52 | Training Perplexity: 4.58\n",
      "| End of epoch  25 | Validation Loss: 1.51 | Validation Perplexity:     4.51\n",
      "Training Loss: 1.51 | Training Perplexity: 4.51\n",
      "| End of epoch  26 | Validation Loss: 1.49 | Validation Perplexity:     4.44\n",
      "Training Loss: 1.49 | Training Perplexity: 4.44\n",
      "| End of epoch  27 | Validation Loss: 1.47 | Validation Perplexity:     4.37\n",
      "Training Loss: 1.47 | Training Perplexity: 4.37\n",
      "| End of epoch  28 | Validation Loss: 1.46 | Validation Perplexity:     4.30\n",
      "Training Loss: 1.46 | Training Perplexity: 4.30\n",
      "| End of epoch  29 | Validation Loss: 1.44 | Validation Perplexity:     4.23\n",
      "Training Loss: 1.44 | Training Perplexity: 4.23\n",
      "| End of epoch  30 | Validation Loss: 1.43 | Validation Perplexity:     4.16\n",
      "Training Loss: 1.43 | Training Perplexity: 4.16\n",
      "| End of epoch  31 | Validation Loss: 1.41 | Validation Perplexity:     4.09\n",
      "Training Loss: 1.41 | Training Perplexity: 4.09\n",
      "| End of epoch  32 | Validation Loss: 1.39 | Validation Perplexity:     4.02\n",
      "Training Loss: 1.39 | Training Perplexity: 4.02\n",
      "| End of epoch  33 | Validation Loss: 1.38 | Validation Perplexity:     3.96\n",
      "Training Loss: 1.38 | Training Perplexity: 3.96\n",
      "| End of epoch  34 | Validation Loss: 1.36 | Validation Perplexity:     3.89\n",
      "Training Loss: 1.36 | Training Perplexity: 3.89\n",
      "| End of epoch  35 | Validation Loss: 1.34 | Validation Perplexity:     3.82\n",
      "Training Loss: 1.34 | Training Perplexity: 3.82\n",
      "| End of epoch  36 | Validation Loss: 1.32 | Validation Perplexity:     3.76\n",
      "Training Loss: 1.32 | Training Perplexity: 3.76\n",
      "| End of epoch  37 | Validation Loss: 1.31 | Validation Perplexity:     3.69\n",
      "Training Loss: 1.31 | Training Perplexity: 3.69\n",
      "| End of epoch  38 | Validation Loss: 1.29 | Validation Perplexity:     3.63\n",
      "Training Loss: 1.29 | Training Perplexity: 3.63\n",
      "| End of epoch  39 | Validation Loss: 1.27 | Validation Perplexity:     3.57\n",
      "Training Loss: 1.27 | Training Perplexity: 3.57\n",
      "| End of epoch  40 | Validation Loss: 1.25 | Validation Perplexity:     3.51\n",
      "Training Loss: 1.25 | Training Perplexity: 3.51\n",
      "| End of epoch  41 | Validation Loss: 1.24 | Validation Perplexity:     3.45\n",
      "Training Loss: 1.24 | Training Perplexity: 3.45\n",
      "| End of epoch  42 | Validation Loss: 1.22 | Validation Perplexity:     3.39\n",
      "Training Loss: 1.22 | Training Perplexity: 3.39\n",
      "| End of epoch  43 | Validation Loss: 1.21 | Validation Perplexity:     3.34\n",
      "Training Loss: 1.21 | Training Perplexity: 3.34\n",
      "| End of epoch  44 | Validation Loss: 1.19 | Validation Perplexity:     3.29\n",
      "Training Loss: 1.19 | Training Perplexity: 3.29\n",
      "| End of epoch  45 | Validation Loss: 1.17 | Validation Perplexity:     3.24\n",
      "Training Loss: 1.17 | Training Perplexity: 3.24\n",
      "| End of epoch  46 | Validation Loss: 1.16 | Validation Perplexity:     3.19\n",
      "Training Loss: 1.16 | Training Perplexity: 3.19\n",
      "| End of epoch  47 | Validation Loss: 1.14 | Validation Perplexity:     3.14\n",
      "Training Loss: 1.14 | Training Perplexity: 3.14\n",
      "| End of epoch  48 | Validation Loss: 1.13 | Validation Perplexity:     3.09\n",
      "Training Loss: 1.13 | Training Perplexity: 3.09\n",
      "| End of epoch  49 | Validation Loss: 1.11 | Validation Perplexity:     3.05\n",
      "Training Loss: 1.11 | Training Perplexity: 3.05\n",
      "| End of epoch  50 | Validation Loss: 1.10 | Validation Perplexity:     3.01\n",
      "Training Loss: 1.10 | Training Perplexity: 3.01\n",
      "| End of epoch  51 | Validation Loss: 1.09 | Validation Perplexity:     2.96\n",
      "Training Loss: 1.09 | Training Perplexity: 2.96\n",
      "| End of epoch  52 | Validation Loss: 1.07 | Validation Perplexity:     2.92\n",
      "Training Loss: 1.07 | Training Perplexity: 2.92\n",
      "| End of epoch  53 | Validation Loss: 1.06 | Validation Perplexity:     2.89\n",
      "Training Loss: 1.06 | Training Perplexity: 2.89\n",
      "| End of epoch  54 | Validation Loss: 1.05 | Validation Perplexity:     2.85\n",
      "Training Loss: 1.05 | Training Perplexity: 2.85\n",
      "| End of epoch  55 | Validation Loss: 1.03 | Validation Perplexity:     2.81\n",
      "Training Loss: 1.03 | Training Perplexity: 2.81\n",
      "| End of epoch  56 | Validation Loss: 1.02 | Validation Perplexity:     2.78\n",
      "Training Loss: 1.02 | Training Perplexity: 2.78\n",
      "| End of epoch  57 | Validation Loss: 1.01 | Validation Perplexity:     2.75\n",
      "Training Loss: 1.01 | Training Perplexity: 2.75\n",
      "| End of epoch  58 | Validation Loss: 1.00 | Validation Perplexity:     2.71\n",
      "Training Loss: 1.00 | Training Perplexity: 2.71\n",
      "| End of epoch  59 | Validation Loss: 0.99 | Validation Perplexity:     2.68\n",
      "Training Loss: 0.99 | Training Perplexity: 2.68\n",
      "| End of epoch  60 | Validation Loss: 0.97 | Validation Perplexity:     2.65\n",
      "Training Loss: 0.97 | Training Perplexity: 2.65\n",
      "| End of epoch  61 | Validation Loss: 0.96 | Validation Perplexity:     2.62\n",
      "Training Loss: 0.96 | Training Perplexity: 2.62\n",
      "| End of epoch  62 | Validation Loss: 0.95 | Validation Perplexity:     2.59\n",
      "Training Loss: 0.95 | Training Perplexity: 2.59\n",
      "| End of epoch  63 | Validation Loss: 0.94 | Validation Perplexity:     2.56\n",
      "Training Loss: 0.94 | Training Perplexity: 2.56\n",
      "| End of epoch  64 | Validation Loss: 0.93 | Validation Perplexity:     2.54\n",
      "Training Loss: 0.93 | Training Perplexity: 2.54\n",
      "| End of epoch  65 | Validation Loss: 0.92 | Validation Perplexity:     2.51\n",
      "Training Loss: 0.92 | Training Perplexity: 2.51\n",
      "| End of epoch  66 | Validation Loss: 0.91 | Validation Perplexity:     2.48\n",
      "Training Loss: 0.91 | Training Perplexity: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pnb9p7_n30s29gprj1gbqbbm0000gn/T/ipykernel_67881/1964148146.py:41: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  avg_loss = total_loss / sum(len(song) for song in songs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| End of epoch  67 | Validation Loss: 0.90 | Validation Perplexity:     2.46\n",
      "Training Loss: 0.90 | Training Perplexity: 2.46\n",
      "| End of epoch  68 | Validation Loss: 0.89 | Validation Perplexity:     2.43\n",
      "Training Loss: 0.89 | Training Perplexity: 2.43\n",
      "| End of epoch  69 | Validation Loss: 0.88 | Validation Perplexity:     2.41\n",
      "Training Loss: 0.88 | Training Perplexity: 2.41\n",
      "| End of epoch  70 | Validation Loss: 0.87 | Validation Perplexity:     2.38\n",
      "Training Loss: 0.87 | Training Perplexity: 2.38\n",
      "| End of epoch  71 | Validation Loss: 0.86 | Validation Perplexity:     2.36\n",
      "Training Loss: 0.86 | Training Perplexity: 2.36\n",
      "| End of epoch  72 | Validation Loss: 0.85 | Validation Perplexity:     2.34\n",
      "Training Loss: 0.85 | Training Perplexity: 2.34\n",
      "| End of epoch  73 | Validation Loss: 0.84 | Validation Perplexity:     2.31\n",
      "Training Loss: 0.84 | Training Perplexity: 2.31\n",
      "| End of epoch  74 | Validation Loss: 0.83 | Validation Perplexity:     2.29\n",
      "Training Loss: 0.83 | Training Perplexity: 2.29\n",
      "| End of epoch  75 | Validation Loss: 0.82 | Validation Perplexity:     2.27\n",
      "Training Loss: 0.82 | Training Perplexity: 2.27\n",
      "| End of epoch  76 | Validation Loss: 0.81 | Validation Perplexity:     2.25\n",
      "Training Loss: 0.81 | Training Perplexity: 2.25\n",
      "| End of epoch  77 | Validation Loss: 0.80 | Validation Perplexity:     2.23\n",
      "Training Loss: 0.80 | Training Perplexity: 2.23\n",
      "| End of epoch  78 | Validation Loss: 0.79 | Validation Perplexity:     2.20\n",
      "Training Loss: 0.79 | Training Perplexity: 2.20\n",
      "| End of epoch  79 | Validation Loss: 0.78 | Validation Perplexity:     2.18\n",
      "Training Loss: 0.78 | Training Perplexity: 2.18\n",
      "| End of epoch  80 | Validation Loss: 0.77 | Validation Perplexity:     2.16\n",
      "Training Loss: 0.77 | Training Perplexity: 2.16\n",
      "| End of epoch  81 | Validation Loss: 0.76 | Validation Perplexity:     2.14\n",
      "Training Loss: 0.76 | Training Perplexity: 2.14\n",
      "| End of epoch  82 | Validation Loss: 0.75 | Validation Perplexity:     2.12\n",
      "Training Loss: 0.75 | Training Perplexity: 2.12\n",
      "| End of epoch  83 | Validation Loss: 0.74 | Validation Perplexity:     2.10\n",
      "Training Loss: 0.74 | Training Perplexity: 2.10\n",
      "| End of epoch  84 | Validation Loss: 0.73 | Validation Perplexity:     2.08\n",
      "Training Loss: 0.73 | Training Perplexity: 2.08\n",
      "| End of epoch  85 | Validation Loss: 0.72 | Validation Perplexity:     2.06\n",
      "Training Loss: 0.72 | Training Perplexity: 2.06\n",
      "| End of epoch  86 | Validation Loss: 0.71 | Validation Perplexity:     2.04\n",
      "Training Loss: 0.71 | Training Perplexity: 2.04\n",
      "| End of epoch  87 | Validation Loss: 0.70 | Validation Perplexity:     2.02\n",
      "Training Loss: 0.70 | Training Perplexity: 2.02\n",
      "| End of epoch  88 | Validation Loss: 0.69 | Validation Perplexity:     2.00\n",
      "Training Loss: 0.69 | Training Perplexity: 2.00\n",
      "| End of epoch  89 | Validation Loss: 0.68 | Validation Perplexity:     1.98\n",
      "Training Loss: 0.68 | Training Perplexity: 1.98\n",
      "| End of epoch  90 | Validation Loss: 0.67 | Validation Perplexity:     1.96\n",
      "Training Loss: 0.67 | Training Perplexity: 1.96\n",
      "| End of epoch  91 | Validation Loss: 0.66 | Validation Perplexity:     1.94\n",
      "Training Loss: 0.66 | Training Perplexity: 1.94\n",
      "| End of epoch  92 | Validation Loss: 0.65 | Validation Perplexity:     1.92\n",
      "Training Loss: 0.65 | Training Perplexity: 1.92\n",
      "| End of epoch  93 | Validation Loss: 0.64 | Validation Perplexity:     1.90\n",
      "Training Loss: 0.64 | Training Perplexity: 1.90\n",
      "| End of epoch  94 | Validation Loss: 0.63 | Validation Perplexity:     1.88\n",
      "Training Loss: 0.63 | Training Perplexity: 1.88\n",
      "| End of epoch  95 | Validation Loss: 0.62 | Validation Perplexity:     1.86\n",
      "Training Loss: 0.62 | Training Perplexity: 1.86\n",
      "| End of epoch  96 | Validation Loss: 0.61 | Validation Perplexity:     1.84\n",
      "Training Loss: 0.61 | Training Perplexity: 1.84\n",
      "| End of epoch  97 | Validation Loss: 0.60 | Validation Perplexity:     1.82\n",
      "Training Loss: 0.60 | Training Perplexity: 1.82\n",
      "| End of epoch  98 | Validation Loss: 0.59 | Validation Perplexity:     1.81\n",
      "Training Loss: 0.59 | Training Perplexity: 1.81\n",
      "| End of epoch  99 | Validation Loss: 0.58 | Validation Perplexity:     1.79\n",
      "Training Loss: 0.58 | Training Perplexity: 1.79\n",
      "| End of epoch 100 | Validation Loss: 0.57 | Validation Perplexity:     1.77\n",
      "Training Loss: 0.57 | Training Perplexity: 1.77\n",
      "| End of epoch 101 | Validation Loss: 0.56 | Validation Perplexity:     1.75\n",
      "Training Loss: 0.56 | Training Perplexity: 1.75\n",
      "| End of epoch 102 | Validation Loss: 0.55 | Validation Perplexity:     1.73\n",
      "Training Loss: 0.55 | Training Perplexity: 1.73\n",
      "| End of epoch 103 | Validation Loss: 0.54 | Validation Perplexity:     1.72\n",
      "Training Loss: 0.54 | Training Perplexity: 1.72\n",
      "| End of epoch 104 | Validation Loss: 0.53 | Validation Perplexity:     1.70\n",
      "Training Loss: 0.53 | Training Perplexity: 1.70\n",
      "| End of epoch 105 | Validation Loss: 0.52 | Validation Perplexity:     1.68\n",
      "Training Loss: 0.52 | Training Perplexity: 1.68\n",
      "| End of epoch 106 | Validation Loss: 0.51 | Validation Perplexity:     1.67\n",
      "Training Loss: 0.51 | Training Perplexity: 1.67\n",
      "| End of epoch 107 | Validation Loss: 0.50 | Validation Perplexity:     1.65\n",
      "Training Loss: 0.50 | Training Perplexity: 1.65\n",
      "| End of epoch 108 | Validation Loss: 0.49 | Validation Perplexity:     1.64\n",
      "Training Loss: 0.49 | Training Perplexity: 1.64\n",
      "| End of epoch 109 | Validation Loss: 0.48 | Validation Perplexity:     1.62\n",
      "Training Loss: 0.48 | Training Perplexity: 1.62\n",
      "| End of epoch 110 | Validation Loss: 0.47 | Validation Perplexity:     1.61\n",
      "Training Loss: 0.47 | Training Perplexity: 1.61\n",
      "| End of epoch 111 | Validation Loss: 0.47 | Validation Perplexity:     1.59\n",
      "Training Loss: 0.47 | Training Perplexity: 1.59\n",
      "| End of epoch 112 | Validation Loss: 0.46 | Validation Perplexity:     1.58\n",
      "Training Loss: 0.46 | Training Perplexity: 1.58\n",
      "| End of epoch 113 | Validation Loss: 0.45 | Validation Perplexity:     1.56\n",
      "Training Loss: 0.45 | Training Perplexity: 1.56\n",
      "| End of epoch 114 | Validation Loss: 0.44 | Validation Perplexity:     1.55\n",
      "Training Loss: 0.44 | Training Perplexity: 1.55\n",
      "| End of epoch 115 | Validation Loss: 0.43 | Validation Perplexity:     1.54\n",
      "Training Loss: 0.43 | Training Perplexity: 1.54\n",
      "| End of epoch 116 | Validation Loss: 0.42 | Validation Perplexity:     1.52\n",
      "Training Loss: 0.42 | Training Perplexity: 1.52\n",
      "| End of epoch 117 | Validation Loss: 0.41 | Validation Perplexity:     1.51\n",
      "Training Loss: 0.41 | Training Perplexity: 1.51\n",
      "| End of epoch 118 | Validation Loss: 0.40 | Validation Perplexity:     1.50\n",
      "Training Loss: 0.40 | Training Perplexity: 1.50\n",
      "| End of epoch 119 | Validation Loss: 0.39 | Validation Perplexity:     1.48\n",
      "Training Loss: 0.39 | Training Perplexity: 1.48\n",
      "| End of epoch 120 | Validation Loss: 0.39 | Validation Perplexity:     1.47\n",
      "Training Loss: 0.39 | Training Perplexity: 1.47\n",
      "| End of epoch 121 | Validation Loss: 0.38 | Validation Perplexity:     1.46\n",
      "Training Loss: 0.38 | Training Perplexity: 1.46\n",
      "| End of epoch 122 | Validation Loss: 0.37 | Validation Perplexity:     1.45\n",
      "Training Loss: 0.37 | Training Perplexity: 1.45\n",
      "| End of epoch 123 | Validation Loss: 0.36 | Validation Perplexity:     1.44\n",
      "Training Loss: 0.36 | Training Perplexity: 1.44\n",
      "| End of epoch 124 | Validation Loss: 0.35 | Validation Perplexity:     1.43\n",
      "Training Loss: 0.35 | Training Perplexity: 1.43\n",
      "| End of epoch 125 | Validation Loss: 0.35 | Validation Perplexity:     1.41\n",
      "Training Loss: 0.35 | Training Perplexity: 1.41\n",
      "| End of epoch 126 | Validation Loss: 0.34 | Validation Perplexity:     1.40\n",
      "Training Loss: 0.34 | Training Perplexity: 1.40\n",
      "| End of epoch 127 | Validation Loss: 0.33 | Validation Perplexity:     1.39\n",
      "Training Loss: 0.33 | Training Perplexity: 1.39\n",
      "| End of epoch 128 | Validation Loss: 0.32 | Validation Perplexity:     1.38\n",
      "Training Loss: 0.32 | Training Perplexity: 1.38\n",
      "| End of epoch 129 | Validation Loss: 0.32 | Validation Perplexity:     1.37\n",
      "Training Loss: 0.32 | Training Perplexity: 1.37\n",
      "| End of epoch 130 | Validation Loss: 0.31 | Validation Perplexity:     1.36\n",
      "Training Loss: 0.31 | Training Perplexity: 1.36\n",
      "| End of epoch 131 | Validation Loss: 0.30 | Validation Perplexity:     1.35\n",
      "Training Loss: 0.30 | Training Perplexity: 1.35\n",
      "| End of epoch 132 | Validation Loss: 0.30 | Validation Perplexity:     1.34\n",
      "Training Loss: 0.30 | Training Perplexity: 1.34\n",
      "| End of epoch 133 | Validation Loss: 0.29 | Validation Perplexity:     1.34\n",
      "Training Loss: 0.29 | Training Perplexity: 1.34\n",
      "| End of epoch 134 | Validation Loss: 0.28 | Validation Perplexity:     1.33\n",
      "Training Loss: 0.28 | Training Perplexity: 1.33\n",
      "| End of epoch 135 | Validation Loss: 0.28 | Validation Perplexity:     1.32\n",
      "Training Loss: 0.28 | Training Perplexity: 1.32\n",
      "| End of epoch 136 | Validation Loss: 0.27 | Validation Perplexity:     1.31\n",
      "Training Loss: 0.27 | Training Perplexity: 1.31\n",
      "| End of epoch 137 | Validation Loss: 0.26 | Validation Perplexity:     1.30\n",
      "Training Loss: 0.26 | Training Perplexity: 1.30\n",
      "| End of epoch 138 | Validation Loss: 0.26 | Validation Perplexity:     1.29\n",
      "Training Loss: 0.26 | Training Perplexity: 1.29\n",
      "| End of epoch 139 | Validation Loss: 0.25 | Validation Perplexity:     1.29\n",
      "Training Loss: 0.25 | Training Perplexity: 1.29\n",
      "| End of epoch 140 | Validation Loss: 0.25 | Validation Perplexity:     1.28\n",
      "Training Loss: 0.25 | Training Perplexity: 1.28\n",
      "| End of epoch 141 | Validation Loss: 0.24 | Validation Perplexity:     1.27\n",
      "Training Loss: 0.24 | Training Perplexity: 1.27\n",
      "| End of epoch 142 | Validation Loss: 0.23 | Validation Perplexity:     1.26\n",
      "Training Loss: 0.23 | Training Perplexity: 1.26\n",
      "| End of epoch 143 | Validation Loss: 0.23 | Validation Perplexity:     1.26\n",
      "Training Loss: 0.23 | Training Perplexity: 1.26\n",
      "| End of epoch 144 | Validation Loss: 0.22 | Validation Perplexity:     1.25\n",
      "Training Loss: 0.22 | Training Perplexity: 1.25\n",
      "| End of epoch 145 | Validation Loss: 0.22 | Validation Perplexity:     1.24\n",
      "Training Loss: 0.22 | Training Perplexity: 1.24\n",
      "| End of epoch 146 | Validation Loss: 0.21 | Validation Perplexity:     1.24\n",
      "Training Loss: 0.21 | Training Perplexity: 1.24\n",
      "| End of epoch 147 | Validation Loss: 0.21 | Validation Perplexity:     1.23\n",
      "Training Loss: 0.21 | Training Perplexity: 1.23\n",
      "| End of epoch 148 | Validation Loss: 0.20 | Validation Perplexity:     1.22\n",
      "Training Loss: 0.20 | Training Perplexity: 1.22\n",
      "| End of epoch 149 | Validation Loss: 0.20 | Validation Perplexity:     1.22\n",
      "Training Loss: 0.20 | Training Perplexity: 1.22\n",
      "| End of epoch 150 | Validation Loss: 0.19 | Validation Perplexity:     1.21\n",
      "Training Loss: 0.19 | Training Perplexity: 1.21\n",
      "| End of epoch 151 | Validation Loss: 0.19 | Validation Perplexity:     1.21\n",
      "Training Loss: 0.19 | Training Perplexity: 1.21\n",
      "| End of epoch 152 | Validation Loss: 0.18 | Validation Perplexity:     1.20\n",
      "Training Loss: 0.18 | Training Perplexity: 1.20\n",
      "| End of epoch 153 | Validation Loss: 0.18 | Validation Perplexity:     1.20\n",
      "Training Loss: 0.18 | Training Perplexity: 1.20\n",
      "| End of epoch 154 | Validation Loss: 0.17 | Validation Perplexity:     1.19\n",
      "Training Loss: 0.17 | Training Perplexity: 1.19\n",
      "| End of epoch 155 | Validation Loss: 0.17 | Validation Perplexity:     1.18\n",
      "Training Loss: 0.17 | Training Perplexity: 1.18\n",
      "| End of epoch 156 | Validation Loss: 0.17 | Validation Perplexity:     1.18\n",
      "Training Loss: 0.17 | Training Perplexity: 1.18\n",
      "| End of epoch 157 | Validation Loss: 0.16 | Validation Perplexity:     1.17\n",
      "Training Loss: 0.16 | Training Perplexity: 1.17\n",
      "| End of epoch 158 | Validation Loss: 0.16 | Validation Perplexity:     1.17\n",
      "Training Loss: 0.16 | Training Perplexity: 1.17\n",
      "| End of epoch 159 | Validation Loss: 0.15 | Validation Perplexity:     1.16\n",
      "Training Loss: 0.15 | Training Perplexity: 1.16\n",
      "| End of epoch 160 | Validation Loss: 0.15 | Validation Perplexity:     1.16\n",
      "Training Loss: 0.15 | Training Perplexity: 1.16\n",
      "| End of epoch 161 | Validation Loss: 0.14 | Validation Perplexity:     1.15\n",
      "Training Loss: 0.14 | Training Perplexity: 1.15\n",
      "| End of epoch 162 | Validation Loss: 0.14 | Validation Perplexity:     1.15\n",
      "Training Loss: 0.14 | Training Perplexity: 1.15\n",
      "| End of epoch 163 | Validation Loss: 0.14 | Validation Perplexity:     1.14\n",
      "Training Loss: 0.14 | Training Perplexity: 1.14\n",
      "| End of epoch 164 | Validation Loss: 0.13 | Validation Perplexity:     1.14\n",
      "Training Loss: 0.13 | Training Perplexity: 1.14\n",
      "| End of epoch 165 | Validation Loss: 0.13 | Validation Perplexity:     1.14\n",
      "Training Loss: 0.13 | Training Perplexity: 1.14\n",
      "| End of epoch 166 | Validation Loss: 0.12 | Validation Perplexity:     1.13\n",
      "Training Loss: 0.12 | Training Perplexity: 1.13\n",
      "| End of epoch 167 | Validation Loss: 0.12 | Validation Perplexity:     1.13\n",
      "Training Loss: 0.12 | Training Perplexity: 1.13\n",
      "| End of epoch 168 | Validation Loss: 0.12 | Validation Perplexity:     1.12\n",
      "Training Loss: 0.12 | Training Perplexity: 1.12\n",
      "| End of epoch 169 | Validation Loss: 0.11 | Validation Perplexity:     1.12\n",
      "Training Loss: 0.11 | Training Perplexity: 1.12\n",
      "| End of epoch 170 | Validation Loss: 0.11 | Validation Perplexity:     1.11\n",
      "Training Loss: 0.11 | Training Perplexity: 1.11\n",
      "| End of epoch 171 | Validation Loss: 0.11 | Validation Perplexity:     1.11\n",
      "Training Loss: 0.11 | Training Perplexity: 1.11\n",
      "| End of epoch 172 | Validation Loss: 0.10 | Validation Perplexity:     1.11\n",
      "Training Loss: 0.10 | Training Perplexity: 1.11\n",
      "| End of epoch 173 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "Training Loss: 0.10 | Training Perplexity: 1.10\n",
      "| End of epoch 174 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "Training Loss: 0.10 | Training Perplexity: 1.10\n",
      "| End of epoch 175 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "Training Loss: 0.09 | Training Perplexity: 1.10\n",
      "| End of epoch 176 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "Training Loss: 0.09 | Training Perplexity: 1.10\n",
      "| End of epoch 177 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "Training Loss: 0.09 | Training Perplexity: 1.09\n",
      "| End of epoch 178 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "Training Loss: 0.09 | Training Perplexity: 1.09\n",
      "| End of epoch 179 | Validation Loss: 0.08 | Validation Perplexity:     1.09\n",
      "Training Loss: 0.08 | Training Perplexity: 1.09\n",
      "| End of epoch 180 | Validation Loss: 0.08 | Validation Perplexity:     1.09\n",
      "Training Loss: 0.08 | Training Perplexity: 1.09\n",
      "| End of epoch 181 | Validation Loss: 0.08 | Validation Perplexity:     1.08\n",
      "Training Loss: 0.08 | Training Perplexity: 1.08\n",
      "| End of epoch 182 | Validation Loss: 0.08 | Validation Perplexity:     1.08\n",
      "Training Loss: 0.08 | Training Perplexity: 1.08\n",
      "| End of epoch 183 | Validation Loss: 0.08 | Validation Perplexity:     1.08\n",
      "Training Loss: 0.08 | Training Perplexity: 1.08\n",
      "| End of epoch 184 | Validation Loss: 0.07 | Validation Perplexity:     1.08\n",
      "Training Loss: 0.07 | Training Perplexity: 1.08\n",
      "| End of epoch 185 | Validation Loss: 0.07 | Validation Perplexity:     1.08\n",
      "Training Loss: 0.07 | Training Perplexity: 1.08\n",
      "| End of epoch 186 | Validation Loss: 0.07 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.07 | Training Perplexity: 1.07\n",
      "| End of epoch 187 | Validation Loss: 0.07 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.07 | Training Perplexity: 1.07\n",
      "| End of epoch 188 | Validation Loss: 0.07 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.07 | Training Perplexity: 1.07\n",
      "| End of epoch 189 | Validation Loss: 0.07 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.07 | Training Perplexity: 1.07\n",
      "| End of epoch 190 | Validation Loss: 0.07 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.07 | Training Perplexity: 1.07\n",
      "| End of epoch 191 | Validation Loss: 0.06 | Validation Perplexity:     1.07\n",
      "Training Loss: 0.06 | Training Perplexity: 1.07\n",
      "| End of epoch 192 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 193 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 194 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 195 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 196 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 197 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 198 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 199 | Validation Loss: 0.06 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.06 | Training Perplexity: 1.06\n",
      "| End of epoch 200 | Validation Loss: 0.05 | Validation Perplexity:     1.06\n",
      "Training Loss: 0.05 | Training Perplexity: 1.06\n",
      "| End of epoch 201 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 202 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 203 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 204 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 205 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 206 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 207 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 208 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 209 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 210 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 211 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 212 | Validation Loss: 0.05 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.05 | Training Perplexity: 1.05\n",
      "| End of epoch 213 | Validation Loss: 0.04 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.04 | Training Perplexity: 1.05\n",
      "| End of epoch 214 | Validation Loss: 0.04 | Validation Perplexity:     1.05\n",
      "Training Loss: 0.04 | Training Perplexity: 1.05\n",
      "| End of epoch 215 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 216 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 217 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 218 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 219 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 220 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 221 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 222 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 223 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 224 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 225 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 226 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 227 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 228 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 229 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 230 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 231 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 232 | Validation Loss: 0.04 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.04 | Training Perplexity: 1.04\n",
      "| End of epoch 233 | Validation Loss: 0.03 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.03 | Training Perplexity: 1.04\n",
      "| End of epoch 234 | Validation Loss: 0.03 | Validation Perplexity:     1.04\n",
      "Training Loss: 0.03 | Training Perplexity: 1.04\n",
      "| End of epoch 235 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 236 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 237 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 238 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 239 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 240 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 241 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 242 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 243 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 244 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 245 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 246 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 247 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 248 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 249 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 250 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 251 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 252 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 253 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 254 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 255 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 256 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 257 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 258 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 259 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 260 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 261 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 262 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 263 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 264 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 265 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 266 | Validation Loss: 0.03 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.03 | Training Perplexity: 1.03\n",
      "| End of epoch 267 | Validation Loss: 0.02 | Validation Perplexity:     1.03\n",
      "Training Loss: 0.02 | Training Perplexity: 1.03\n",
      "| End of epoch 268 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 269 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 270 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 271 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 272 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 273 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 274 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 275 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 276 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 277 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 278 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 279 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 280 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 281 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 282 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 283 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 284 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 285 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 286 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 287 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 288 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 289 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 290 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 291 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 292 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 293 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 294 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 295 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 296 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 297 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 298 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 299 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 300 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 301 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 302 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 303 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 304 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 305 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 306 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 307 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 308 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 309 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 310 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 311 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 312 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 313 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 314 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 315 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 316 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 317 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 318 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 319 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 320 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 321 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 322 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 323 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 324 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 325 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 326 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 327 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 328 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 329 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 330 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 331 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 332 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 333 | Validation Loss: 0.02 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.02 | Training Perplexity: 1.02\n",
      "| End of epoch 334 | Validation Loss: 0.01 | Validation Perplexity:     1.02\n",
      "Training Loss: 0.01 | Training Perplexity: 1.02\n",
      "| End of epoch 335 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 336 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 337 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 338 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 339 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 340 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 341 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 342 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 343 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 344 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 345 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 346 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 347 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 348 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 349 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 350 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 351 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 352 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 353 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 354 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 355 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 356 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 357 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 358 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 359 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 360 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 361 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 362 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 363 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 364 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 365 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 366 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 367 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 368 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 369 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 370 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 371 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 372 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 373 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 374 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 375 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 376 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 377 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 378 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 379 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 380 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 381 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 382 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 383 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 384 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 385 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 386 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 387 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 388 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 389 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 390 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 391 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 392 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 393 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 394 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 395 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 396 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 397 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 398 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 399 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 400 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 401 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 402 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 403 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 404 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 405 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 406 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 407 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 408 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 409 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 410 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 411 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 412 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 413 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 414 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 415 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 416 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 417 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 418 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 419 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 420 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 421 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 422 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 423 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 424 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 425 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 426 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 427 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 428 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 429 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 430 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 431 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 432 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 433 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 434 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 435 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 436 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 437 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 438 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 439 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 440 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 441 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 442 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 443 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 444 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 445 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 446 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 447 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 448 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 449 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 450 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 451 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 452 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 453 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 454 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 455 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 456 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 457 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 458 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 459 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 460 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 461 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 462 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 463 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 464 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 465 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 466 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 467 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 468 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 469 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 470 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 471 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 472 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 473 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 474 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 475 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 476 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 477 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 478 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 479 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 480 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 481 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 482 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 483 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 484 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 485 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 486 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 487 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 488 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 489 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 490 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 491 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 492 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 493 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 494 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 495 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 496 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 497 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 498 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 499 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 500 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 501 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 502 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 503 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 504 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 505 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 506 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 507 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 508 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 509 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 510 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 511 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 512 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 513 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 514 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 515 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 516 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 517 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 518 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 519 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 520 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 521 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 522 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 523 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 524 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 525 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 526 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 527 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 528 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 529 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 530 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 531 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 532 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 533 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 534 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 535 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 536 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 537 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 538 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 539 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 540 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 541 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 542 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 543 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 544 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 545 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 546 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 547 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 548 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 549 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 550 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 551 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 552 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 553 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 554 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 555 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 556 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 557 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 558 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 559 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 560 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 561 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 562 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 563 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 564 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 565 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 566 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 567 | Validation Loss: 0.01 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.01 | Training Perplexity: 1.01\n",
      "| End of epoch 568 | Validation Loss: 0.00 | Validation Perplexity:     1.01\n",
      "Training Loss: 0.00 | Training Perplexity: 1.01\n",
      "| End of epoch 569 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 570 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 571 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 572 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 573 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 574 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 575 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 576 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 577 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 578 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 579 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 580 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 581 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 582 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 583 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 584 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 585 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 586 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 587 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 588 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 589 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 590 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 591 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 592 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 593 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 594 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 595 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 596 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 597 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 598 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 599 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 600 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 601 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 602 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 603 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 604 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 605 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 606 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 607 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 608 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 609 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 610 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 611 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 612 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 613 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 614 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 615 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 616 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 617 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 618 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 619 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 620 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 621 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 622 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 623 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 624 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 625 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 626 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 627 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 628 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 629 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 630 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 631 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 632 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 633 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 634 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 635 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 636 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 637 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 638 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 639 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 640 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 641 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 642 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 643 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 644 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 645 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 646 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 647 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 648 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 649 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 650 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 651 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 652 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 653 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 654 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 655 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 656 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 657 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 658 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 659 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 660 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 661 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 662 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 663 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 664 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 665 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 666 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 667 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 668 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 669 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 670 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 671 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 672 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 673 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 674 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 675 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 676 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 677 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 678 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 679 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 680 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 681 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 682 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 683 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 684 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 685 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 686 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 687 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 688 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 689 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 690 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 691 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 692 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 693 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 694 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 695 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 696 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 697 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 698 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 699 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 700 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 701 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 702 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 703 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 704 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 705 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 706 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 707 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 708 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 709 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 710 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 711 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 712 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 713 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 714 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 715 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 716 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 717 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 718 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 719 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 720 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 721 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 722 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 723 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 724 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 725 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 726 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 727 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 728 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 729 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 730 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 731 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 732 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 733 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 734 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 735 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 736 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 737 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 738 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 739 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 740 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 741 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 742 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 743 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 744 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 745 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 746 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 747 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 748 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 749 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 750 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 751 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 752 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 753 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 754 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 755 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 756 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 757 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 758 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 759 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 760 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 761 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 762 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 763 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 764 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 765 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 766 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 767 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 768 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 769 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 770 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 771 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 772 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 773 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 774 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 775 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 776 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 777 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 778 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 779 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 780 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 781 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 782 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 783 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 784 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 785 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 786 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 787 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 788 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 789 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 790 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 791 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 792 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 793 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 794 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 795 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 796 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 797 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 798 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 799 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 800 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 801 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 802 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 803 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 804 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 805 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 806 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 807 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 808 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 809 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 810 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 811 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 812 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 813 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 814 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 815 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 816 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 817 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 818 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 819 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 820 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 821 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 822 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 823 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 824 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 825 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 826 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 827 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 828 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 829 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 830 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 831 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 832 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 833 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 834 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 835 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 836 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 837 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 838 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 839 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 840 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 841 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 842 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 843 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 844 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 845 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 846 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 847 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 848 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 849 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 850 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 851 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 852 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 853 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 854 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 855 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 856 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 857 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 858 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 859 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 860 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 861 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 862 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 863 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 864 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 865 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 866 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 867 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 868 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 869 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 870 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 871 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 872 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 873 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 874 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 875 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 876 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 877 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 878 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 879 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 880 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 881 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 882 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 883 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 884 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 885 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 886 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 887 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 888 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 889 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 890 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 891 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 892 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 893 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 894 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 895 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 896 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 897 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 898 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 899 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 900 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 901 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 902 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 903 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 904 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 905 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 906 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 907 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 908 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 909 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 910 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 911 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 912 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 913 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 914 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 915 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 916 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 917 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 918 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 919 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 920 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 921 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 922 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 923 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 924 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 925 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 926 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 927 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 928 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 929 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 930 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 931 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 932 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 933 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 934 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 935 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 936 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 937 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 938 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 939 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 940 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 941 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 942 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 943 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 944 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 945 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 946 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 947 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 948 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 949 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 950 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 951 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 952 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 953 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 954 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 955 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 956 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 957 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 958 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 959 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 960 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 961 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 962 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 963 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 964 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 965 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 966 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 967 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 968 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 969 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 970 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 971 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 972 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 973 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 974 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 975 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 976 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 977 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 978 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 979 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 980 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 981 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 982 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 983 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 984 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 985 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 986 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 987 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 988 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 989 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 990 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 991 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 992 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 993 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 994 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 995 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 996 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 997 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 998 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 999 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1000 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1001 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1002 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1003 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1004 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1005 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1006 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1007 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1008 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1009 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1010 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1011 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1012 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1013 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1014 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1015 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1016 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1017 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1018 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1019 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1020 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1021 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1022 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1023 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1024 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1025 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1026 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1027 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1028 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1029 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1030 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1031 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1032 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1033 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1034 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1035 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1036 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1037 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1038 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1039 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1040 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1041 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1042 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1043 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1044 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1045 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1046 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1047 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1048 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1049 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1050 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1051 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1052 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1053 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1054 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1055 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1056 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1057 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1058 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1059 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1060 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1061 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1062 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1063 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1064 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1065 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1066 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1067 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1068 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1069 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1070 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1071 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1072 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1073 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1074 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1075 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1076 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1077 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1078 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1079 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1080 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1081 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1082 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1083 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1084 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1085 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1086 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1087 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1088 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1089 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1090 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1091 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1092 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1093 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1094 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1095 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1096 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1097 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1098 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1099 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1100 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1101 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1102 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1103 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1104 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1105 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1106 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1107 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1108 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1109 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1110 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1111 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1112 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1113 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1114 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1115 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1116 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1117 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1118 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1119 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1120 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1121 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1122 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1123 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1124 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1125 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1126 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1127 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1128 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1129 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1130 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1131 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1132 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1133 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1134 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1135 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1136 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1137 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1138 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1139 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1140 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1141 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1142 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1143 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1144 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1145 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1146 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1147 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1148 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1149 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1150 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1151 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1152 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1153 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1154 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1155 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1156 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1157 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1158 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1159 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1160 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1161 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1162 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1163 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1164 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1165 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1166 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1167 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1168 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1169 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1170 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1171 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1172 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1173 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1174 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1175 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1176 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1177 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1178 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1179 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1180 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1181 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1182 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1183 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1184 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1185 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1186 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1187 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1188 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1189 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1190 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1191 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1192 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1193 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1194 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1195 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1196 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1197 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1198 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1199 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1200 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1201 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1202 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1203 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1204 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1205 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1206 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1207 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1208 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1209 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1210 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1211 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1212 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1213 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1214 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1215 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1216 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1217 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1218 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1219 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1220 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1221 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1222 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1223 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1224 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1225 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1226 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1227 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1228 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1229 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1230 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1231 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1232 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1233 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1234 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1235 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1236 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1237 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1238 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1239 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1240 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1241 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1242 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1243 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1244 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1245 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1246 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1247 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1248 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1249 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1250 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1251 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1252 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1253 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1254 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1255 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1256 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1257 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1258 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1259 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1260 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1261 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1262 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1263 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1264 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1265 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1266 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1267 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1268 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1269 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1270 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1271 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1272 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1273 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1274 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1275 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1276 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1277 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1278 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1279 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1280 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1281 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1282 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1283 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1284 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1285 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1286 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1287 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1288 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1289 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1290 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1291 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1292 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1293 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1294 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1295 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1296 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1297 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1298 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1299 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1300 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1301 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1302 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1303 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1304 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1305 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1306 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1307 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1308 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1309 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1310 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1311 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1312 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1313 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1314 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1315 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1316 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1317 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1318 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1319 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1320 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1321 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1322 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1323 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1324 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1325 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1326 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1327 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1328 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1329 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1330 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1331 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1332 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1333 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1334 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1335 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1336 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1337 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1338 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1339 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1340 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1341 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1342 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1343 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1344 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1345 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1346 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1347 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1348 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1349 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1350 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1351 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1352 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1353 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1354 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1355 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1356 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1357 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1358 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1359 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1360 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1361 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1362 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1363 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1364 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1365 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1366 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1367 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1368 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1369 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1370 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1371 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1372 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1373 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1374 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1375 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1376 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1377 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1378 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1379 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1380 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1381 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1382 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1383 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1384 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1385 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1386 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1387 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1388 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1389 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1390 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1391 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1392 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1393 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1394 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1395 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1396 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1397 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1398 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1399 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1400 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1401 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1402 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1403 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1404 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1405 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1406 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1407 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1408 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1409 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1410 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1411 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1412 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1413 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1414 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1415 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1416 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1417 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1418 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1419 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1420 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1421 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1422 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1423 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1424 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1425 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1426 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1427 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1428 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1429 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1430 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1431 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1432 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1433 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1434 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1435 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1436 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1437 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1438 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1439 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1440 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1441 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1442 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1443 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1444 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1445 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1446 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1447 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1448 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1449 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1450 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1451 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1452 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1453 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1454 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1455 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1456 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1457 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1458 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1459 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1460 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1461 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1462 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1463 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1464 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1465 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1466 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1467 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1468 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1469 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1470 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1471 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1472 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1473 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1474 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1475 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1476 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1477 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1478 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1479 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1480 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1481 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1482 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1483 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1484 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1485 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1486 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1487 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1488 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1489 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1490 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1491 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1492 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1493 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1494 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1495 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1496 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1497 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1498 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1499 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1500 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1501 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1502 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1503 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1504 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1505 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1506 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1507 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1508 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1509 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1510 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1511 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1512 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1513 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1514 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1515 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1516 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1517 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1518 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1519 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1520 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1521 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1522 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1523 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1524 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1525 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1526 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1527 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1528 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1529 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1530 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1531 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1532 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1533 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1534 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1535 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1536 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1537 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1538 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1539 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1540 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1541 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1542 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1543 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1544 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1545 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1546 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1547 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1548 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1549 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1550 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1551 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1552 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1553 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1554 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1555 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1556 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1557 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1558 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1559 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1560 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1561 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1562 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1563 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1564 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1565 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1566 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1567 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1568 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1569 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1570 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1571 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1572 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1573 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1574 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1575 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1576 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1577 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1578 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1579 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1580 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1581 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1582 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1583 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1584 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1585 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1586 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1587 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1588 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1589 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1590 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1591 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1592 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1593 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1594 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1595 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1596 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1597 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1598 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1599 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1600 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1601 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1602 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1603 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1604 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1605 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1606 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1607 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1608 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1609 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1610 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1611 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1612 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1613 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1614 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1615 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1616 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1617 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1618 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1619 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1620 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1621 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1622 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1623 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1624 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1625 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1626 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1627 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1628 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1629 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1630 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1631 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1632 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1633 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1634 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1635 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1636 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1637 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1638 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1639 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1640 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1641 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1642 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1643 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1644 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1645 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1646 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1647 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1648 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1649 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1650 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1651 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1652 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1653 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1654 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1655 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1656 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1657 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1658 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1659 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1660 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1661 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1662 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1663 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1664 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1665 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1666 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1667 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1668 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1669 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1670 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1671 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1672 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1673 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1674 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1675 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1676 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1677 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1678 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1679 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1680 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1681 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1682 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1683 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1684 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1685 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1686 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1687 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1688 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1689 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1690 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1691 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1692 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1693 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1694 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1695 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1696 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1697 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1698 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1699 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1700 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1701 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1702 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1703 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1704 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1705 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1706 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1707 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1708 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1709 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1710 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1711 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1712 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1713 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1714 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1715 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1716 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1717 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1718 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1719 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1720 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1721 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1722 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1723 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1724 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1725 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1726 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1727 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1728 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1729 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1730 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1731 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1732 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1733 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1734 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1735 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1736 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1737 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1738 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1739 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1740 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1741 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1742 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1743 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1744 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1745 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1746 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1747 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1748 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1749 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1750 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1751 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1752 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1753 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1754 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1755 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1756 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1757 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1758 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1759 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1760 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1761 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1762 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1763 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1764 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1765 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1766 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1767 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1768 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1769 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1770 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1771 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1772 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1773 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1774 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1775 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1776 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1777 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1778 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1779 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1780 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1781 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1782 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1783 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1784 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1785 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1786 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1787 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1788 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1789 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1790 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1791 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1792 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1793 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1794 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1795 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1796 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1797 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1798 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1799 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1800 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1801 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1802 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1803 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1804 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1805 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1806 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1807 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1808 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1809 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1810 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1811 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1812 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1813 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1814 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1815 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1816 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1817 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1818 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1819 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1820 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1821 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1822 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1823 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1824 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1825 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1826 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1827 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1828 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1829 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1830 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1831 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1832 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1833 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1834 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1835 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1836 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1837 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1838 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1839 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1840 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1841 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1842 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1843 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1844 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1845 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1846 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1847 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1848 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1849 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1850 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1851 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1852 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1853 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1854 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1855 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1856 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1857 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1858 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1859 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1860 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1861 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1862 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1863 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1864 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1865 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1866 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1867 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1868 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1869 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1870 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1871 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1872 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1873 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1874 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1875 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1876 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1877 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1878 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1879 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1880 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1881 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1882 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1883 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1884 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1885 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1886 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1887 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1888 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1889 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1890 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1891 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1892 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1893 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1894 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1895 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1896 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1897 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1898 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1899 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1900 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1901 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1902 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1903 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1904 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1905 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1906 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1907 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1908 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1909 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1910 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1911 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1912 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1913 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1914 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1915 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1916 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1917 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1918 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1919 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1920 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1921 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1922 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1923 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1924 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1925 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1926 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1927 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1928 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1929 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1930 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1931 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1932 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1933 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1934 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1935 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1936 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1937 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1938 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1939 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1940 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1941 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1942 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1943 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1944 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1945 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1946 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1947 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1948 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1949 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1950 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1951 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1952 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1953 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1954 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1955 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1956 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1957 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1958 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1959 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1960 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1961 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1962 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1963 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1964 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1965 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1966 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1967 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1968 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1969 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1970 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1971 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1972 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1973 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1974 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1975 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1976 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1977 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1978 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1979 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1980 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1981 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1982 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1983 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1984 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1985 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1986 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1987 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1988 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1989 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1990 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1991 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1992 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1993 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1994 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1995 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1996 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1997 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1998 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 1999 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n",
      "Training Loss: 0.00 | Training Perplexity: 1.00\n",
      "| End of epoch 2000 | Validation Loss: 0.00 | Validation Perplexity:     1.00\n"
     ]
    }
   ],
   "source": [
    "def train(model, songs, optimizer, criterion, bptt=42, device='cpu'):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    total_items = 0\n",
    "\n",
    "    for song_index, song in enumerate(songs):\n",
    "        for i in range(0, len(song) - 1, bptt):\n",
    "            data, targets = get_batch(songs, i, song_index, bptt)\n",
    "            data_tensor = torch.tensor(data, dtype=torch.long).to(device)\n",
    "            targets_tensor = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "            src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data_tensor, src_mask)\n",
    "            loss = criterion(output.view(-1, ntokens), targets_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * data_tensor.size(0)\n",
    "            total_items += data_tensor.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_items\n",
    "    ppl = math.exp(avg_loss)\n",
    "    print(f'Training Loss: {avg_loss:.2f} | Training Perplexity: {ppl:.2f}')\n",
    "\n",
    "\n",
    "def evaluate(model, songs, criterion, bptt=42, device='cpu'):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for song_index, song in enumerate(songs):\n",
    "            for i in range(0, len(song) - 1, bptt):\n",
    "                data, targets = get_batch(songs, i, song_index, bptt)\n",
    "                data_tensor = torch.tensor(data, dtype=torch.long).to(device)\n",
    "                targets_tensor = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "                src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "                output = model(data_tensor, src_mask)\n",
    "                total_loss += len(data) * criterion(output.view(-1, ntokens), targets_tensor).item()\n",
    "\n",
    "    avg_loss = total_loss / sum(len(song) for song in songs)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# Parameters setup\n",
    "bptt: int = 42  # sequence length\n",
    "ntokens = 6 # number of unique notes\n",
    "emsize = 20 # embedding dimension\n",
    "nhid = 20 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.0 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "epochs = 2000 # The number of epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, songs, optimizer, criterion)\n",
    "    # Evaluate on the validation dataset\n",
    "    val_loss = evaluate(model, songs, criterion)  # Replace `songs` with your validation dataset if available\n",
    "    \n",
    "    # Calculate and print the validation perplexity\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    print(f'| End of epoch {epoch:3d} | Validation Loss: {val_loss:.2f} | Validation Perplexity: {val_ppl:8.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ecd203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for song 1, index 0: 1.00\n",
      "target notes:    [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1]\n",
      "predicted notes: [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 1: 0.48\n",
      "target notes:    [5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1]\n",
      "predicted notes: [1, 5, 5, 5, 0, 4, 3, 4, 3, 2, 1, 1, 5, 5, 5, 4, 4, 3, 3, 5, 5, 5, 4, 4, 3, 3, 1, 1, 1, 4, 5, 3, 3, 5, 4, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 2: 0.21\n",
      "target notes:    [5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5]\n",
      "predicted notes: [0, 0, 3, 3, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2, 2, 4, 2, 3, 5, 5, 5, 5, 4, 3, 3, 3, 3, 1, 4, 4, 3, 3, 0, 4, 4, 4, 3, 3, 3, 4, 1, 1]\n",
      "Accuracy for song 1, index 3: 0.21\n",
      "target notes:    [0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5]\n",
      "predicted notes: [0, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 3, 4, 2, 2, 2, 2, 0, 0, 0, 2, 5, 4, 3, 1, 3, 3, 4, 4, 0, 3, 3, 3, 0, 4, 4, 3, 3, 3, 3, 1, 4]\n",
      "Accuracy for song 1, index 4: 0.26\n",
      "target notes:    [0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0]\n",
      "predicted notes: [3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 4, 3, 2, 2, 2, 1, 4, 3, 3, 2, 4, 4, 1, 3, 3, 4, 4, 0, 0, 4, 3, 3, 3, 4, 4, 2, 3, 3, 2, 1, 1]\n",
      "Accuracy for song 1, index 5: 0.40\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0]\n",
      "predicted notes: [3, 3, 3, 3, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 1, 4, 4, 3, 3, 2, 4, 1, 4, 5, 4, 4, 0, 5, 4, 3, 3, 3, 2, 1, 1, 5, 5, 2, 2, 1, 2]\n",
      "Accuracy for song 1, index 6: 0.29\n",
      "target notes:    [4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5]\n",
      "predicted notes: [0, 2, 2, 2, 2, 5, 1, 4, 4, 2, 2, 2, 2, 2, 1, 5, 5, 5, 2, 2, 2, 1, 5, 1, 1, 4, 0, 1, 1, 4, 3, 3, 3, 5, 1, 5, 5, 5, 1, 2, 2, 2]\n",
      "Accuracy for song 1, index 7: 0.21\n",
      "target notes:    [4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4]\n",
      "predicted notes: [1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 5, 5, 5, 2, 2, 1, 5, 5, 1, 1, 4, 4, 1, 1, 4, 3, 3, 2, 1, 5, 1, 4, 4, 4, 2, 2, 1]\n",
      "Accuracy for song 1, index 8: 0.17\n",
      "target notes:    [3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4]\n",
      "predicted notes: [1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 5, 5, 5, 1, 1, 5, 4, 4, 1, 4, 4, 3, 3, 3, 5, 1, 4, 4, 4, 1, 1, 1, 1]\n",
      "Accuracy for song 1, index 9: 0.17\n",
      "target notes:    [3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 5, 5, 1, 1, 5, 4, 4, 4, 4, 4, 4, 1, 3, 3, 5, 1, 4, 4, 0, 4, 1, 1, 3]\n",
      "Accuracy for song 1, index 10: 0.33\n",
      "target notes:    [2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 1, 1, 1, 1, 1, 4, 4, 1, 5, 5, 5, 1, 5, 5, 4, 3, 3, 3, 4, 1, 1, 3, 0, 5, 1, 4, 0, 0, 4, 2, 3, 3]\n",
      "Accuracy for song 1, index 11: 0.38\n",
      "target notes:    [2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [1, 1, 5, 5, 0, 3, 4, 5, 5, 1, 4, 3, 1, 5, 2, 4, 1, 5, 5, 5, 5, 5, 5, 4, 3, 3, 3, 3, 1, 1, 5, 3, 5, 5, 5, 0, 0, 4, 3, 2, 3, 3]\n",
      "Accuracy for song 1, index 12: 0.43\n",
      "target notes:    [1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2]\n",
      "predicted notes: [1, 1, 5, 0, 3, 3, 3, 5, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 3, 5, 5, 5, 5, 4, 3, 2, 3, 3, 1]\n",
      "Accuracy for song 1, index 13: 0.48\n",
      "target notes:    [5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1]\n",
      "predicted notes: [1, 5, 5, 2, 2, 2, 2, 1, 5, 5, 2, 2, 2, 2, 1, 5, 5, 5, 5, 5, 5, 4, 4, 4, 3, 3, 1, 1, 1, 1, 5, 4, 5, 5, 5, 4, 3, 3, 3, 3, 1, 1]\n",
      "Accuracy for song 1, index 14: 0.43\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5]\n",
      "predicted notes: [0, 0, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 1, 1, 5, 5, 5, 0, 0, 5, 4, 4, 3, 3, 4, 1, 1, 1, 1, 4, 4, 3, 0, 4, 4, 3, 3, 3, 2, 1, 1]\n",
      "Accuracy for song 1, index 15: 0.38\n",
      "target notes:    [4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5]\n",
      "predicted notes: [0, 2, 2, 2, 2, 5, 4, 4, 2, 2, 2, 2, 1, 1, 5, 5, 5, 0, 3, 4, 0, 4, 4, 3, 1, 1, 1, 1, 1, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3, 2, 1, 1]\n",
      "Accuracy for song 1, index 16: 0.36\n",
      "target notes:    [4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4]\n",
      "predicted notes: [1, 5, 5, 5, 5, 5, 1, 5, 5, 2, 2, 1, 1, 5, 5, 5, 5, 5, 4, 2, 5, 4, 4, 1, 1, 4, 1, 1, 1, 4, 0, 3, 4, 4, 4, 4, 3, 3, 3, 4, 1, 4]\n",
      "Accuracy for song 1, index 17: 0.21\n",
      "target notes:    [3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4]\n",
      "predicted notes: [1, 1, 5, 1, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 5, 5, 5, 4, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 5, 0, 3, 3, 5, 4, 4, 3, 3, 4, 1, 1, 3]\n",
      "Accuracy for song 1, index 18: 0.36\n",
      "target notes:    [3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3]\n",
      "predicted notes: [1, 1, 1, 1, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 5, 4, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 3, 3, 3, 4, 1, 1, 5, 4, 1, 2, 3]\n",
      "Accuracy for song 1, index 19: 0.38\n",
      "target notes:    [2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3]\n",
      "predicted notes: [1, 1, 1, 5, 5, 5, 2, 5, 1, 1, 1, 1, 1, 5, 5, 1, 4, 3, 3, 2, 5, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 3, 3, 2, 1, 1, 5, 1, 1, 2, 1, 4]\n",
      "Accuracy for song 1, index 20: 0.36\n",
      "target notes:    [5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [1, 1, 5, 0, 2, 2, 2, 1, 1, 1, 1, 2, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 4, 4, 4, 3, 5, 4, 4, 3, 3, 3, 5, 1, 5, 5, 4, 2, 2, 2, 2]\n",
      "Accuracy for song 1, index 21: 0.21\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5]\n",
      "predicted notes: [0, 0, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 3, 4, 2, 2, 2, 3, 5, 5, 5, 5, 4, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3, 5, 5, 4, 4, 3, 3, 2, 2, 1]\n",
      "Accuracy for song 1, index 22: 0.26\n",
      "target notes:    [4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5]\n",
      "predicted notes: [0, 2, 2, 2, 2, 5, 5, 4, 2, 2, 2, 3, 3, 2, 2, 2, 2, 5, 5, 5, 5, 5, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 5, 4, 4, 3, 3, 3, 2, 1, 1]\n",
      "Accuracy for song 1, index 23: 0.26\n",
      "target notes:    [4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4]\n",
      "predicted notes: [1, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 3, 2, 5, 2, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 3, 4, 4, 3, 4, 3, 0, 5, 4, 4, 3, 3, 3, 1, 1, 1]\n",
      "Accuracy for song 1, index 24: 0.26\n",
      "target notes:    [3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4]\n",
      "predicted notes: [1, 1, 5, 1, 5, 5, 1, 1, 5, 5, 1, 3, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 3, 2, 3, 4, 1, 1, 3, 5, 5, 5, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 25: 0.36\n",
      "target notes:    [3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 3, 3, 2, 5, 1, 5, 5, 5, 5, 5, 5, 5, 4, 3, 3, 3, 3, 1, 1, 5, 0, 0, 2, 5, 4, 3, 2, 4, 2, 2, 1]\n",
      "Accuracy for song 1, index 26: 0.38\n",
      "target notes:    [2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 3, 3, 3, 1, 1, 5, 4, 4, 5, 5, 5, 5, 4, 4, 3, 3, 3, 1, 1, 1, 1, 0, 3, 2, 4, 4, 1, 4, 4, 2, 3, 3]\n",
      "Accuracy for song 1, index 27: 0.43\n",
      "target notes:    [1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [1, 1, 5, 0, 3, 5, 5, 4, 3, 3, 3, 3, 1, 1, 5, 4, 4, 4, 4, 4, 5, 4, 4, 4, 3, 3, 1, 1, 1, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 2, 3, 3]\n",
      "Accuracy for song 1, index 28: 0.60\n",
      "target notes:    [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1]\n",
      "predicted notes: [1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 5, 4, 4, 0, 5, 5, 4, 4, 3, 3, 1, 1, 1, 4, 4, 3, 3, 3, 3, 1, 4, 4, 3, 3, 2, 3, 1]\n",
      "Accuracy for song 1, index 29: 0.43\n",
      "target notes:    [5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1]\n",
      "predicted notes: [1, 5, 5, 5, 0, 4, 3, 4, 3, 2, 1, 1, 5, 5, 5, 5, 4, 0, 0, 5, 5, 4, 4, 3, 4, 4, 1, 1, 4, 4, 3, 3, 3, 1, 5, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 30: 0.33\n",
      "target notes:    [5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5]\n",
      "predicted notes: [0, 0, 3, 3, 3, 3, 3, 2, 2, 1, 1, 2, 5, 2, 2, 4, 0, 3, 3, 3, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 2, 5, 5, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 31: 0.26\n",
      "target notes:    [0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5]\n",
      "predicted notes: [0, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 2, 5, 2, 5, 5, 0, 3, 3, 3, 2, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 3, 0, 5, 5, 4, 3, 3, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 32: 0.33\n",
      "target notes:    [0, 5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0]\n",
      "predicted notes: [3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 4, 4, 0, 5, 4, 3, 3, 3, 2, 5, 1, 4, 4, 4, 3, 4, 4, 4, 3, 3, 0, 2, 4, 2, 3, 3, 3, 2, 1, 1]\n",
      "Accuracy for song 1, index 33: 0.33\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0]\n",
      "predicted notes: [3, 3, 3, 3, 2, 2, 2, 1, 2, 1, 2, 4, 4, 3, 0, 4, 4, 3, 3, 2, 5, 5, 4, 4, 4, 3, 3, 4, 4, 1, 5, 3, 3, 2, 4, 2, 5, 0, 2, 2, 1, 2]\n",
      "Accuracy for song 1, index 34: 0.29\n",
      "target notes:    [4, 4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5]\n",
      "predicted notes: [0, 2, 2, 2, 2, 5, 1, 4, 1, 1, 2, 2, 3, 3, 4, 4, 4, 3, 3, 5, 5, 5, 4, 4, 3, 3, 3, 2, 1, 1, 5, 3, 2, 2, 2, 5, 5, 2, 4, 2, 2, 2]\n",
      "Accuracy for song 1, index 35: 0.38\n",
      "target notes:    [4, 3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4]\n",
      "predicted notes: [1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 5, 1, 5, 4, 4, 3, 5, 5, 5, 1, 4, 4, 3, 3, 2, 1, 1, 1, 3, 3, 3, 2, 1, 5, 5, 5, 2, 2, 2, 1]\n",
      "Accuracy for song 1, index 36: 0.29\n",
      "target notes:    [3, 3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4]\n",
      "predicted notes: [1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 5, 5, 4, 4, 5, 5, 5, 5, 5, 4, 4, 3, 3, 1, 1, 1, 4, 3, 3, 3, 1, 5, 5, 5, 5, 2, 2, 1, 1]\n",
      "Accuracy for song 1, index 37: 0.24\n",
      "target notes:    [3, 2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 4, 1, 1, 5, 5, 5, 5, 1, 4, 3, 1, 1, 1, 1, 4, 3, 3, 1, 5, 5, 1, 1, 5, 4, 1, 1, 3]\n",
      "Accuracy for song 1, index 38: 0.29\n",
      "target notes:    [2, 2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3]\n",
      "predicted notes: [1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 3, 2, 3, 1, 1, 1, 5, 5, 5, 5, 5, 4, 4, 1, 1, 1, 1, 1, 4, 3, 1, 5, 5, 1, 4, 0, 4, 1, 2, 1, 3]\n",
      "Accuracy for song 1, index 39: 0.29\n",
      "target notes:    [2, 1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [1, 1, 5, 5, 5, 4, 4, 5, 5, 4, 3, 3, 3, 2, 5, 5, 4, 4, 5, 2, 5, 4, 4, 4, 4, 1, 2, 1, 4, 3, 1, 3, 2, 5, 4, 0, 0, 4, 2, 2, 3, 3]\n",
      "Accuracy for song 1, index 40: 0.38\n",
      "target notes:    [1, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2]\n",
      "predicted notes: [1, 1, 5, 5, 0, 4, 5, 5, 4, 3, 3, 3, 3, 1, 1, 5, 4, 4, 3, 2, 2, 4, 4, 4, 4, 3, 3, 3, 4, 1, 5, 3, 0, 4, 5, 0, 4, 3, 2, 3, 3, 1]\n",
      "Accuracy for song 1, index 41: 0.64\n",
      "target notes:    [1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1, 5, 5, 4, 4, 3, 3, 2, 5, 5, 4, 4, 3, 3, 2, 1, 1, 5, 5, 0, 0, 5, 4, 4, 3, 3, 2, 2, 1]\n",
      "predicted notes: [1, 5, 5, 0, 0, 5, 5, 4, 3, 3, 3, 2, 1, 1, 5, 4, 4, 3, 3, 3, 2, 5, 4, 4, 3, 3, 2, 2, 1, 1, 5, 0, 0, 5, 5, 4, 3, 3, 2, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i ,song in enumerate(songs):\n",
    "    for j in range(bptt):\n",
    "        data,target=get_batch(songs,j, i)\n",
    "        # Convert the input notes to a tensor and add an extra dimension\n",
    "\n",
    "        # Create a mask for the input\n",
    "        src_mask = generate_square_subsequent_mask(len(data)).to(device)\n",
    "\n",
    "        # Run the model on the input tensor\n",
    "        output = model(torch.tensor(data,dtype=torch.long),src_mask)\n",
    "\n",
    "        # Detach the output from the computation graph and convert to numpy array\n",
    "        output_array = output.detach().numpy()\n",
    "\n",
    "        # Get the predicted notes by finding the index of the maximum value in each output vector\n",
    "        predicted_notes = np.argmax(output_array, axis=-1)\n",
    "\n",
    "        predicted_notes_list = [note for sublist in predicted_notes for note in sublist]  # Flattening the list\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(np.array(predicted_notes_list) == np.array(target))\n",
    "        print(f'Accuracy for song {i + 1}, index {j}: {accuracy:.2f}')\n",
    "        print(f'target notes:    {target}')\n",
    "        print(f'predicted notes: {predicted_notes_list}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
