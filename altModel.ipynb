{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0111566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be541e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4ab0c",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530360a",
   "metadata": {},
   "source": [
    "## getTrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00a7c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 41) (168, 41) (168,)\n"
     ]
    }
   ],
   "source": [
    "def getTrainingData(songStrings,nrOfSongs):\n",
    "    notes=list(\"ABCDEFGH\")\n",
    "    chord=[[0],\n",
    "           [1],\n",
    "           [2],\n",
    "           [3],\n",
    "           [4],\n",
    "           [5],\n",
    "           [6],\n",
    "           [7]]\n",
    "    source=[]\n",
    "    target=[]\n",
    "    song=[]\n",
    "    for s in range(nrOfSongs):\n",
    "        for i in range(42):\n",
    "            sentence=[]\n",
    "            answer=[]\n",
    "            song.append(s)\n",
    "            for j in range(41):\n",
    "                sentence.append(chord[notes.index(songStrings[s][(i+j)%42])][0])\n",
    "                answer.append(chord[notes.index(songStrings[s][(i+j+1)%42])][0])\n",
    "            source.append(sentence)\n",
    "            target.append(answer)\n",
    "    return numpy.array(source),numpy.array(target),numpy.array(song)\n",
    "\n",
    "songStrings = numpy.array([\n",
    "    \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "\n",
    "I,O,S=getTrainingData(songStrings,4)\n",
    "print(I.shape,O.shape,S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ca66102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songStrings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6219c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d6a3f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c09937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 41)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f34d66c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5\n",
      " 4 4 3 3] [2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5 4\n",
      " 4 3 3 2]\n",
      "[2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5 4\n",
      " 4 3 3 2] [6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5 4 4\n",
      " 3 3 2 2]\n",
      "[6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5 4 4\n",
      " 3 3 2 2] [6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5 4 4 3\n",
      " 3 2 2 2]\n",
      "[3 2 2 2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6\n",
      " 5 5 4 4] [2 2 2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5\n",
      " 5 4 4 3]\n",
      "[2 2 2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5\n",
      " 5 4 4 3] [2 2 6 6 0 0 6 5 5 4 4 3 3 2 6 6 5 5 4 4 3 6 6 5 5 4 4 3 2 2 6 6 0 0 6 5 5\n",
      " 4 4 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(I[0].flatten(),O[0].flatten())\n",
    "print(I[1].flatten(),O[1].flatten())\n",
    "print(I[2].flatten(),O[2].flatten())\n",
    "\n",
    "print(I[-2].flatten(),O[-2].flatten())\n",
    "print(I[-1].flatten(),O[-1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4301f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 41) (42, 41) (42,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getTrainingData(songStrings, nrOfSongs):\n",
    "    notes = list(\"ABCDEFGH\")\n",
    "    nrOfNotes = len(songStrings[0])  # Assuming all songs are the same length\n",
    "    source = []\n",
    "    target = []\n",
    "    song = []\n",
    "    \n",
    "    for s in range(nrOfSongs):\n",
    "        indices = [notes.index(note) for note in songStrings[s]]\n",
    "        for i in range(nrOfNotes):\n",
    "            # Create sequences by shifting manually\n",
    "            sentence = indices[i:] + indices[:i]  # Wrap around to create circular shift\n",
    "            source.append(sentence[:-1])  # Exclude the last to form the source sequence\n",
    "            target.append(sentence[1:])   # Start from the second element to form the target sequence\n",
    "            song.append(s)\n",
    "    \n",
    "    return np.array(source), np.array(target), np.array(song)\n",
    "\n",
    "# Convert songStrings to a NumPy array for efficient indexing\n",
    "songStrings = np.array([\n",
    "    #\"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "\n",
    "I, O, S = getTrainingData(songStrings, 1)\n",
    "print(I.shape, O.shape, S.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd3e0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4] [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "[1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5] [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "[2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0] [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "[3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1] [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "[4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2] [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "[2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0] [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "[3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1] [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "[4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2] [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "[5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3] [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(I[0].flatten(),O[0].flatten())\n",
    "print(I[1].flatten(),O[1].flatten())\n",
    "print(I[2].flatten(),O[2].flatten())\n",
    "print(I[3].flatten(),O[3].flatten())\n",
    "print(I[4].flatten(),O[4].flatten())\n",
    "\n",
    "print(I[-4].flatten(),O[-4].flatten())\n",
    "print(I[-3].flatten(),O[-3].flatten())\n",
    "print(I[-2].flatten(),O[-2].flatten())\n",
    "print(I[-1].flatten(),O[-1].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2caa821",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3541090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntokens, emsize, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(emsize, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntokens, emsize)\n",
    "        self.emsize = emsize\n",
    "        self.decoder = nn.Linear(emsize, ntokens)\n",
    "        self.ntokens=ntokens\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src,verbose=False):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.emsize)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        self.store=output.detach().numpy().copy()\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Parameters\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 20  # embedding dimension\n",
    "nhead = 4  # number of heads in the nn.MultiheadAttention\n",
    "d_hid = 20  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer\n",
    "dropout = 0.03  # dropout probability\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d22cd1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c81051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, source, target):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "        tgt = target.transpose(0, 1)  # Same adjustment for the target\n",
    "        \n",
    "        output = model(src)  # Compute the output\n",
    "        \n",
    "        # The output is [sequence_length, batch_size, ntokens]. Get the most likely token predictions\n",
    "        predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "        #print(predictions)\n",
    "        correct += (predictions == tgt).sum().item()  # Count how many predictions match the target\n",
    "        total += tgt.numel()  # Total number of predictions\n",
    "        \n",
    "    accuracy = correct / total  # Calculate the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1cf6f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aad73e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_24832\\4185048613.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  source = torch.tensor(source, dtype=torch.long)\n",
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_24832\\4185048613.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long)\n",
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_24832\\1989781991.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  source = torch.tensor(source, dtype=torch.long)\n",
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_24832\\1989781991.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0124\n",
      "acc: 0.13893728222996515\n",
      "Epoch 101, Loss: 0.0085\n",
      "acc: 0.4880952380952381\n",
      "Epoch 201, Loss: 0.0051\n",
      "acc: 0.6672473867595818\n",
      "Epoch 301, Loss: 0.0026\n",
      "acc: 0.8549651567944251\n",
      "Epoch 401, Loss: 0.0014\n",
      "acc: 0.9208768873403019\n",
      "Epoch 501, Loss: 0.0009\n",
      "acc: 0.9465737514518002\n",
      "Epoch 601, Loss: 0.0007\n",
      "acc: 0.9590592334494773\n",
      "Epoch 701, Loss: 0.0006\n",
      "acc: 0.962979094076655\n",
      "Epoch 801, Loss: 0.0008\n",
      "acc: 0.9532520325203252\n",
      "Epoch 901, Loss: 0.0006\n",
      "acc: 0.9658826945412311\n",
      "Epoch 1001, Loss: 0.0005\n",
      "acc: 0.9679152148664344\n",
      "Epoch 1101, Loss: 0.0005\n",
      "acc: 0.9693670150987224\n",
      "Epoch 1201, Loss: 0.0005\n",
      "acc: 0.9700929152148664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26acb19e110>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(model, source, target, num_epochs=1000, learning_rate=1e-3):\n",
    "    W=[]\n",
    "    model.train()  # Set the model to training mode\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Assuming source and target are numpy arrays of shape (sentences, 41) and need to be converted to tensors\n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    target = torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Here, we assume batching is handled externally, and source is directly fed into the model\n",
    "        optimizer.zero_grad()  # Clear the gradients of all optimized tensors\n",
    "        \n",
    "        # Adjust for PyTorch expecting (sequence_length, batch_size), so we transpose source and target\n",
    "        src = source.transpose(0, 1)  # Now shape [41, sentences]\n",
    "        tgt = target.transpose(0, 1)  # Now shape [41, sentences]\n",
    "        \n",
    "        output = model(src)  # Forward pass: compute the output of the model\n",
    "        \n",
    "        # Output is [sequence_length, batch_size, ntokens], target is [sequence_length, batch_size]\n",
    "        # Flatten output to [sequence_length*batch_size, ntokens] for compatibility with CrossEntropyLoss\n",
    "        output_flat = output.view(-1, model.ntokens)\n",
    "        tgt_flat = tgt.reshape(-1)\n",
    "        \n",
    "        loss = criterion(output_flat, tgt_flat)  # Compute the loss\n",
    "        loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # Perform a single optimization step (parameter update)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / src.size(1)  # average loss per sentence\n",
    "        if epoch % 100 ==0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n",
    "            W.append(test(model,source,target))\n",
    "            print(\"acc:\",W[-1])\n",
    "        if  W[-1]>0.97:\n",
    "            break    \n",
    "    return W\n",
    "# Example usage\n",
    "# Assuming `model` is your model instance, and `source`, `target` are your data tensors\n",
    "\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 20  # embedding dimension\n",
    "nhead = 4  # number of heads in the nn.MultiheadAttention\n",
    "d_hid = 20  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer\n",
    "dropout = 0.00  # dropout probability\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "nrOfSongs=4\n",
    "source,target,songs=getTrainingData(songStrings,nrOfSongs)\n",
    "\n",
    "W=train(model, torch.tensor(source), torch.tensor(target),num_epochs=5000)\n",
    "plot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe46ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.store[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3b48b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "source,target,songs=getTrainingData(songStrings,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab522d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53df64cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 41)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fab037e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e30a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pnb9p7_n30s29gprj1gbqbbm0000gn/T/ipykernel_969/1989781991.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  source = torch.tensor(source, dtype=torch.long)\n",
      "/var/folders/87/pnb9p7_n30s29gprj1gbqbbm0000gn/T/ipykernel_969/1989781991.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9700929152148664"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,torch.tensor(source),torch.tensor(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1b48ea28",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[201], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming you have a `model` instance and a sentence represented as a list of token indices\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# token_indices = [1, 2, 3, 2, 1, 2, 3, ...]\u001b[39;00m\n\u001b[0;32m     19\u001b[0m who\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m\n\u001b[1;32m---> 20\u001b[0m predicted_token_index \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_next_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwho\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted next token index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_token_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(target[who][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[201], line 8\u001b[0m, in \u001b[0;36mpredict_next_token\u001b[1;34m(model, token_indices, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(token_indices, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape [sequence_length, 1] to match expected input\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get model output for the entire sequence\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Assuming output is [sequence_length, 1, ntokens] and we're interested in the last token's prediction\u001b[39;00m\n\u001b[0;32m     11\u001b[0m last_token_logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Get logits for the last token\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[194], line 19\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, x, verbose)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,verbose\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(numpy\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)))\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "def predict_next_token(model, token_indices,verbose=False):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    \n",
    "    # Convert the list of token indices to a PyTorch tensor and add a batch dimension\n",
    "    src = torch.tensor(token_indices, dtype=torch.long).unsqueeze(1)  # Shape [sequence_length, 1] to match expected input\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(src,verbose)  # Get model output for the entire sequence\n",
    "\n",
    "    # Assuming output is [sequence_length, 1, ntokens] and we're interested in the last token's prediction\n",
    "    last_token_logits = output[-1, 0, :]  # Get logits for the last token\n",
    "    predicted_token_index = last_token_logits.argmax().item()  # Find the index of the max log-probability\n",
    "    \n",
    "    return predicted_token_index\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a `model` instance and a sentence represented as a list of token indices\n",
    "# token_indices = [1, 2, 3, 2, 1, 2, 3, ...]\n",
    "who=34\n",
    "source[who]\n",
    "predicted_token_index = predict_next_token(model, source[who],verbose=True)\n",
    "print(f'Predicted next token index: {predicted_token_index}')\n",
    "print(target[who][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f967708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "1 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "2 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "3 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "4 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "5 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "6 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "7 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "8 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "9 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "10 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "11 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "12 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "13 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "14 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "15 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "16 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "17 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "18 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "19 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "20 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "21 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "22 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "23 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "24 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "25 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "26 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "27 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "28 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "29 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "30 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "31 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "32 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "33 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "34 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "35 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "36 0\n",
      "source [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0\n",
      " 1 2 3 4]\n",
      "37 0\n",
      "source [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 5]\n",
      "38 0\n",
      "source [2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2\n",
      " 3 4 5 0]\n",
      "39 0\n",
      "source [3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
      " 4 5 0 1]\n",
      "40 0\n",
      "source [4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
      " 5 0 1 2]\n",
      "41 0\n",
      "source [5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\n",
      " 0 1 2 3]\n",
      "42 1\n",
      "source [0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0\n",
      " 3 5 0 1]\n",
      "43 1\n",
      "source [1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3\n",
      " 5 0 1 4]\n",
      "44 1\n",
      "source [0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5\n",
      " 0 1 4 0]\n",
      "45 1\n",
      "source [2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0\n",
      " 1 4 0 1]\n",
      "46 1\n",
      "source [0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1\n",
      " 4 0 1 0]\n",
      "47 1\n",
      "source [3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4\n",
      " 0 1 0 2]\n",
      "48 1\n",
      "source [0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0\n",
      " 1 0 2 0]\n",
      "49 1\n",
      "source [4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1\n",
      " 0 2 0 3]\n",
      "50 1\n",
      "source [0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0\n",
      " 2 0 3 0]\n",
      "51 1\n",
      "source [5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2\n",
      " 0 3 0 4]\n",
      "52 1\n",
      "source [0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0\n",
      " 3 0 4 0]\n",
      "53 1\n",
      "source [1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3\n",
      " 0 4 0 5]\n",
      "54 1\n",
      "source [4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0\n",
      " 4 0 5 0]\n",
      "55 1\n",
      "source [5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4\n",
      " 0 5 0 1]\n",
      "56 1\n",
      "source [0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0\n",
      " 5 0 1 4]\n",
      "57 1\n",
      "source [3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5\n",
      " 0 1 4 5]\n",
      "58 1\n",
      "source [4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0\n",
      " 1 4 5 0]\n",
      "59 1\n",
      "source [2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1\n",
      " 4 5 0 3]\n",
      "60 1\n",
      "source [1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4\n",
      " 5 0 3 4]\n",
      "61 1\n",
      "source [0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5\n",
      " 0 3 4 2]\n",
      "62 1\n",
      "source [1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0\n",
      " 3 4 2 1]\n",
      "63 1\n",
      "source [2 5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3\n",
      " 4 2 1 0]\n",
      "64 1\n",
      "source [5 4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4\n",
      " 2 1 0 1]\n",
      "65 1\n",
      "source [4 3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2\n",
      " 1 0 1 2]\n",
      "66 1\n",
      "source [3 4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1\n",
      " 0 1 2 5]\n",
      "67 1\n",
      "source [4 5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0\n",
      " 1 2 5 4]\n",
      "68 1\n",
      "source [5 0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1\n",
      " 2 5 4 3]\n",
      "69 1\n",
      "source [0 1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2\n",
      " 5 4 3 4]\n",
      "70 1\n",
      "source [1 2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5\n",
      " 4 3 4 5]\n",
      "71 1\n",
      "source [2 0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4\n",
      " 3 4 5 0]\n",
      "72 1\n",
      "source [0 3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3\n",
      " 4 5 0 1]\n",
      "73 1\n",
      "source [3 4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4\n",
      " 5 0 1 2]\n",
      "74 1\n",
      "source [4 1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5\n",
      " 0 1 2 0]\n",
      "75 1\n",
      "source [1 0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0\n",
      " 1 2 0 3]\n",
      "76 1\n",
      "source [0 2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1\n",
      " 2 0 3 4]\n",
      "77 1\n",
      "source [2 0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2\n",
      " 0 3 4 1]\n",
      "78 1\n",
      "source [0 3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0\n",
      " 3 4 1 0]\n",
      "79 1\n",
      "source [3 5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3\n",
      " 4 1 0 2]\n",
      "80 1\n",
      "source [5 0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4\n",
      " 1 0 2 0]\n",
      "81 1\n",
      "source [0 1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1\n",
      " 0 2 0 3]\n",
      "82 1\n",
      "source [1 4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0\n",
      " 2 0 3 5]\n",
      "83 1\n",
      "source [4 0 1 0 2 0 3 0 4 0 5 0 1 4 5 0 3 4 2 1 0 1 2 5 4 3 4 5 0 1 2 0 3 4 1 0 2\n",
      " 0 3 5 0]\n",
      "84 2\n",
      "source [3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1\n",
      " 5 3 0 5]\n",
      "85 2\n",
      "source [1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5\n",
      " 3 0 5 1]\n",
      "86 2\n",
      "source [2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3\n",
      " 0 5 1 3]\n",
      "87 2\n",
      "source [0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0\n",
      " 5 1 3 1]\n",
      "88 2\n",
      "source [2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5\n",
      " 1 3 1 2]\n",
      "89 2\n",
      "source [1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1\n",
      " 3 1 2 0]\n",
      "90 2\n",
      "source [2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3\n",
      " 1 2 0 2]\n",
      "91 2\n",
      "source [5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1\n",
      " 2 0 2 1]\n",
      "92 2\n",
      "source [5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2\n",
      " 0 2 1 2]\n",
      "93 2\n",
      "source [3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0\n",
      " 2 1 2 5]\n",
      "94 2\n",
      "source [2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2\n",
      " 1 2 5 5]\n",
      "95 2\n",
      "source [4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1\n",
      " 2 5 5 3]\n",
      "96 2\n",
      "source [5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2\n",
      " 5 5 3 2]\n",
      "97 2\n",
      "source [5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5\n",
      " 5 3 2 4]\n",
      "98 2\n",
      "source [4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5\n",
      " 3 2 4 5]\n",
      "99 2\n",
      "source [5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3\n",
      " 2 4 5 5]\n",
      "100 2\n",
      "source [2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2\n",
      " 4 5 5 4]\n",
      "101 2\n",
      "source [3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4\n",
      " 5 5 4 5]\n",
      "102 2\n",
      "source [3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5\n",
      " 5 4 5 2]\n",
      "103 2\n",
      "source [4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5\n",
      " 4 5 2 3]\n",
      "104 2\n",
      "source [5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4\n",
      " 5 2 3 3]\n",
      "105 2\n",
      "source [4 1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5\n",
      " 2 3 3 4]\n",
      "106 2\n",
      "source [1 4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2\n",
      " 3 3 4 5]\n",
      "107 2\n",
      "source [4 0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3\n",
      " 3 4 5 4]\n",
      "108 2\n",
      "source [0 2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3\n",
      " 4 5 4 1]\n",
      "109 2\n",
      "source [2 5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4\n",
      " 5 4 1 4]\n",
      "110 2\n",
      "source [5 4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5\n",
      " 4 1 4 0]\n",
      "111 2\n",
      "source [4 2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4\n",
      " 1 4 0 2]\n",
      "112 2\n",
      "source [2 1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1\n",
      " 4 0 2 5]\n",
      "113 2\n",
      "source [1 1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4\n",
      " 0 2 5 4]\n",
      "114 2\n",
      "source [1 1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0\n",
      " 2 5 4 2]\n",
      "115 2\n",
      "source [1 2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2\n",
      " 5 4 2 1]\n",
      "116 2\n",
      "source [2 1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5\n",
      " 4 2 1 1]\n",
      "117 2\n",
      "source [1 4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4\n",
      " 2 1 1 1]\n",
      "118 2\n",
      "source [4 2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2\n",
      " 1 1 1 2]\n",
      "119 2\n",
      "source [2 1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1\n",
      " 1 1 2 1]\n",
      "120 2\n",
      "source [1 5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1\n",
      " 1 2 1 4]\n",
      "121 2\n",
      "source [5 3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1\n",
      " 2 1 4 2]\n",
      "122 2\n",
      "source [3 0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2\n",
      " 1 4 2 1]\n",
      "123 2\n",
      "source [0 5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1\n",
      " 4 2 1 5]\n",
      "124 2\n",
      "source [5 1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4\n",
      " 2 1 5 3]\n",
      "125 2\n",
      "source [1 3 1 2 0 2 1 2 5 5 3 2 4 5 5 4 5 2 3 3 4 5 4 1 4 0 2 5 4 2 1 1 1 2 1 4 2\n",
      " 1 5 3 0]\n",
      "126 3\n",
      "source [0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0\n",
      " 5 5 0 3]\n",
      "127 3\n",
      "source [1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5\n",
      " 5 0 3 1]\n",
      "128 3\n",
      "source [4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5\n",
      " 0 3 1 0]\n",
      "129 3\n",
      "source [1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0\n",
      " 3 1 0 1]\n",
      "130 3\n",
      "source [2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3\n",
      " 1 0 1 4]\n",
      "131 3\n",
      "source [0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1\n",
      " 0 1 4 1]\n",
      "132 3\n",
      "source [4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0\n",
      " 1 4 1 2]\n",
      "133 3\n",
      "source [5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1\n",
      " 4 1 2 0]\n",
      "134 3\n",
      "source [2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4\n",
      " 1 2 0 4]\n",
      "135 3\n",
      "source [3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1\n",
      " 2 0 4 5]\n",
      "136 3\n",
      "source [5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2\n",
      " 0 4 5 2]\n",
      "137 3\n",
      "source [5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0\n",
      " 4 5 2 3]\n",
      "138 3\n",
      "source [1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4\n",
      " 5 2 3 5]\n",
      "139 3\n",
      "source [2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5\n",
      " 2 3 5 5]\n",
      "140 3\n",
      "source [1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2\n",
      " 3 5 5 1]\n",
      "141 3\n",
      "source [3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3\n",
      " 5 5 1 2]\n",
      "142 3\n",
      "source [1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5\n",
      " 5 1 2 1]\n",
      "143 3\n",
      "source [1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5\n",
      " 1 2 1 3]\n",
      "144 3\n",
      "source [1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1\n",
      " 2 1 3 1]\n",
      "145 3\n",
      "source [2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2\n",
      " 1 3 1 1]\n",
      "146 3\n",
      "source [4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1\n",
      " 3 1 1 1]\n",
      "147 3\n",
      "source [3 2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3\n",
      " 1 1 1 2]\n",
      "148 3\n",
      "source [2 1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1\n",
      " 1 1 2 4]\n",
      "149 3\n",
      "source [1 5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1\n",
      " 1 2 4 3]\n",
      "150 3\n",
      "source [5 1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1\n",
      " 2 4 3 2]\n",
      "151 3\n",
      "source [1 5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2\n",
      " 4 3 2 1]\n",
      "152 3\n",
      "source [5 5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4\n",
      " 3 2 1 5]\n",
      "153 3\n",
      "source [5 4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3\n",
      " 2 1 5 1]\n",
      "154 3\n",
      "source [4 2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2\n",
      " 1 5 1 5]\n",
      "155 3\n",
      "source [2 1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1\n",
      " 5 1 5 5]\n",
      "156 3\n",
      "source [1 2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5\n",
      " 1 5 5 4]\n",
      "157 3\n",
      "source [2 4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1\n",
      " 5 5 4 2]\n",
      "158 3\n",
      "source [4 1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5\n",
      " 5 4 2 1]\n",
      "159 3\n",
      "source [1 2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5\n",
      " 4 2 1 2]\n",
      "160 3\n",
      "source [2 0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4\n",
      " 2 1 2 4]\n",
      "161 3\n",
      "source [0 0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2\n",
      " 1 2 4 1]\n",
      "162 3\n",
      "source [0 5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1\n",
      " 2 4 1 2]\n",
      "163 3\n",
      "source [5 5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2\n",
      " 4 1 2 0]\n",
      "164 3\n",
      "source [5 0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4\n",
      " 1 2 0 0]\n",
      "165 3\n",
      "source [0 3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1\n",
      " 2 0 0 5]\n",
      "166 3\n",
      "source [3 1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2\n",
      " 0 0 5 5]\n",
      "167 3\n",
      "source [1 0 1 4 1 2 0 4 5 2 3 5 5 1 2 1 3 1 1 1 2 4 3 2 1 5 1 5 5 4 2 1 2 4 1 2 0\n",
      " 0 5 5 0]\n"
     ]
    }
   ],
   "source": [
    "    for i in range(len(songs)):\n",
    "        print(i,songs[i])\n",
    "        print(\"source\",source[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a6589",
   "metadata": {},
   "source": [
    "## Transformer  shrinkingDecompositionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5626ff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 168)\n",
      "(20, 168)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def symbolEntropy(D,base=2):\n",
    "    value,counts = numpy.unique(D, return_counts=True)\n",
    "    return entropy(counts,base=base)\n",
    "\n",
    "def computeTransmissionHfast(I,H,O,maskC,maskNC,iMult=2,oMult=2):\n",
    "    #print(\"I H O\",I.shape,H.shape,O.shape)\n",
    "    B=numpy.bitwise_and(H,maskNC)\n",
    "    IB=(B*iMult)+I\n",
    "    AB=H#numpy.bitwise_and(H,maskC+maskNC)\n",
    "    BO=(B*oMult)+O\n",
    "    IAB=(AB*iMult)+I\n",
    "    IBO=(B*(iMult*oMult))+(I*oMult)+O\n",
    "    ABO=(AB*oMult)+O\n",
    "    IABO=(AB*(iMult*oMult))+(I*oMult)+O\n",
    "    hB=symbolEntropy(B, base=2)\n",
    "    hIB=symbolEntropy(IB, base=2)\n",
    "    hAB=symbolEntropy(AB, base=2)\n",
    "    hBO=symbolEntropy(BO, base=2)\n",
    "    hIAB=symbolEntropy(IAB, base=2)\n",
    "    hIBO=symbolEntropy(IBO, base=2)\n",
    "    hABO=symbolEntropy(ABO, base=2)\n",
    "    hIABO=symbolEntropy(IABO, base=2)\n",
    "    #-H(B)+H(IB)+H(AB)+H(BO)-H(IAB)-H(IBO)-H(ABO)+H(IABO)\n",
    "    #print(hB,hIB,hAB,hBO,hIAB,hIBO,hABO,hIABO)\n",
    "    return-hB+hIB+hAB+hBO-hIAB-hIBO-hABO+hIABO\n",
    "\n",
    "def singleShrinkingDecompositionInformation(I,H,O,width,iMult=2,oMult=2):\n",
    "    nodes=list(range(width))\n",
    "    cols=[]\n",
    "    colh=[]\n",
    "    while len(nodes)>0:\n",
    "        infos=[]\n",
    "        for node in nodes:\n",
    "            subset=copy.deepcopy(nodes)\n",
    "            subset.remove(node)\n",
    "            maskA=0\n",
    "            for s in subset:\n",
    "                maskA+=1*(2**s)\n",
    "            maskA=int(maskA)\n",
    "            maskB=numpy.bitwise_and(numpy.bitwise_not(maskA),((2**width)-1))\n",
    "            h=computeTransmissionHfast(I,H,O,maskA,maskB,iMult=iMult,oMult=oMult)\n",
    "            infos.append(h)\n",
    "        nodeToDrop=nodes[infos.index(max(infos))]\n",
    "        nodes.remove(nodeToDrop)\n",
    "        cols.append(copy.deepcopy(nodes))\n",
    "        colh.append(max(infos))\n",
    "    return cols,colh\n",
    "\n",
    "def getAllIOH(model,source,target,songs,width=20):\n",
    "    I=[]\n",
    "    O=[]\n",
    "    H=[]\n",
    "    for i in range(len(songs)):\n",
    "        I.append(songs[i])\n",
    "        predicted_token_index = predict_next_token(model, source[i])\n",
    "        if predicted_token_index==target[i][-1]:\n",
    "            O.append(songs[i])\n",
    "        else:\n",
    "            O.append((songs[i]+1)%max(songs))\n",
    "        H.append(list(model.store[-1].flatten()))\n",
    "    H=numpy.array(H).transpose()\n",
    "    print(H.shape)\n",
    "    imshow(H)\n",
    "    B=numpy.zeros(H.shape)\n",
    "    clusterNr=2\n",
    "    for i in range(B.shape[0]):\n",
    "        a=H[i].reshape(-1, 1)\n",
    "        if len(numpy.unique(a))==1:\n",
    "            who=numpy.random.randint(len(a))\n",
    "            a[who]=1-a[who]\n",
    "        kmeans = KMeans(n_clusters=clusterNr,n_init=10).fit(a)\n",
    "        B[i]=kmeans.labels_\n",
    "    print(B.shape)\n",
    "    H=numpy.zeros((H.shape[1]))\n",
    "    for i in range(width):\n",
    "        H+=B[i]*(clusterNr**i)\n",
    "    H=H.astype((int))\n",
    "    return numpy.array(I),numpy.array(O),H\n",
    "\n",
    "def shrinkingDecompositionInformation(model,source,target,songs,numbers=[0,1,2,3],width=20):\n",
    "    allI,allO,H=getAllIOH(model,source,target,songs,width=width)\n",
    "    collectorSet=dict()\n",
    "    collectorH=dict()\n",
    "    for number in numbers:\n",
    "        I=(1*(songs==number)).astype(int)\n",
    "        O=(1*(allO==number)).astype(int)\n",
    "        s,h=singleShrinkingDecompositionInformation(I,H,O,width)\n",
    "        collectorSet[number]=s\n",
    "        collectorH[number]=h\n",
    "    return collectorSet,collectorH\n",
    "\n",
    "def removalIntoVec(res,width,H):\n",
    "    V=numpy.zeros(width)\n",
    "    #for i,r in enumerate(res):\n",
    "    #    for e in r:\n",
    "    #        V[e]+=H[0]-H[i]\n",
    "    fullSet=list(range(width))\n",
    "    nRes=copy.deepcopy(res)\n",
    "    nRes.insert(0,fullSet)\n",
    "    nodeList=[]\n",
    "    for i in range(width):\n",
    "        removedNode=list(set(nRes[i])-set(nRes[i+1]))[0]\n",
    "        nodeList.append(removedNode)\n",
    "    for i,node in enumerate(nodeList):\n",
    "        V[node]=H[0]-H[i]\n",
    "    #V=sqrt(V)\n",
    "    if V.sum()==0:\n",
    "        return V\n",
    "    return V#/V.max()\n",
    "\n",
    "def removalIntoMatrix(res,width,H):\n",
    "    M=[]\n",
    "    for i in range(len(res)):\n",
    "        M.append(removalIntoVec(res[i],width,H[i]))\n",
    "    return numpy.array(M)\n",
    "\n",
    "s,h=shrinkingDecompositionInformation(model,source,target,songs,numbers=list(range(5)),width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ffa17e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M=removalIntoMatrix(s,20,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14a24130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n"
     ]
    }
   ],
   "source": [
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0966474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993386655816854 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAACnCAYAAABNThUqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAS70lEQVR4nO3df2zV1f3H8ddtobelu70otS1dkR9GZONHtzFoCvFHpCkwNotbFAyZyJwjrjUQtgSJSiX+URRjnEgKWQTG2BBNBOKPYEpHcToQQlHBmQZZgzXQMlm4twVbSO/5/tX79dL2llvOue29PB/JTei95/N+n8Pp5/bVT297PcYYIwAAAAtSBnoCAAAgeRAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGDNkHg2C4VCOnPmjHw+nzweTzxbAwCAfjLGqLW1Vfn5+UpJiX5NIq7B4syZMxo1alQ8WwIAAEuamppUUFAQdUxcg4XP55Mkbd++XcOGDYtna+ueeuopp/VPnTrltL4kPfDAA857LFq0yHmPV1991XmP//3vf07r/+c//3FaX5IWLlzovEdOTo7zHk8//bTzHi+//LLT+vfcc4/T+pJ06dIl5z1mzJjhvMeOHTuc97jrrruc1l+/fr3T+pI0btw4p/W//fZbLVu2LPx1PJq4BouuH38MGzZMmZmZ8WxtXWpqqtP68fhRUVpamvMe8djnoUOHOu8xZIjbU6WvS4s2eL1e5z3S09Od94iHjIwMp/Wv5cn5esXjcyoe4vFNaFZWltP68TgvXH/OdrmWr03J8ZkHAAAGBYIFAACwhmABAACsIVgAAABrCBYAAMAaggUAALCmX8Fiw4YNGjNmjNLT01VUVKTDhw/bnhcAAEhAMQeLnTt3asWKFaqsrFR9fb0KCws1e/ZsnTt3zsX8AABAAok5WLz00kt67LHHtGTJEv3whz/Uxo0bNWzYMG3evNnF/AAAQAKJKVhcvnxZR48eVUlJyf8XSElRSUmJDh482G18R0eHgsFgxA0AACSvmILFN998o87OTuXm5kbcn5ubq+bm5m7jq6qq5Pf7wzfegAwAgOTm9LdCVq1apUAgEL41NTW5bAcAAAZYTO+slJ2drdTUVLW0tETc39LSory8vG7jvV5vXN74CAAADA4xXbFIS0vT1KlTVVtbG74vFAqptrZWxcXF1icHAAASS8zvBb1ixQotXrxYP/3pTzV9+nS9/PLLunjxopYsWeJifgAAIIHEHCwWLFig//73v1q9erWam5v1ox/9SHv37u32gk4AAHDjiTlYSFJFRYUqKipszwUAACQ43isEAABYQ7AAAADWECwAAIA1BAsAAGCNxxhj4tUsGAzK7/fr1KlT8vl8zvqUlpY6q93l5z//udP658+fd1pfkqqrq533WLdunfMeZWVlznu0t7c7rf/88887rS9Jb731lvMe8fic2rNnj/Me27Ztc1r/e9/7ntP6kpSamuq8x9133+28xxdffOG8x44dO5zWv3DhgtP6knT//fc77yFJgUBAWVlZUcdwxQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGCNxxhj4tUsGAzK7/frlVdeUUZGhrM+S5cudVa7y5tvvum0fnp6utP6krRgwQLnPdra2pz3OHnypPMev//9753WP3/+vNP6kvTCCy847zFx4kTnPVasWOG8x4gRI5zWX7x4sdP6kpSXl+e8R3t7u/Mes2bNct6joqLCaf0lS5Y4rS9Jt9xyi/MekhQIBJSVlRV1DFcsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUxBYuqqipNmzZNPp9POTk5mj9/vhoaGlzNDQAAJJiYgsWBAwdUXl6uQ4cOqaamRleuXFFpaakuXrzoan4AACCBDIll8N69eyM+3rp1q3JycnT06FHddddd3cZ3dHSoo6Mj/HEwGOznNAEAQCK4rtdYBAIBSdLNN9/c4+NVVVXy+/3h26hRo66nHQAAGOT6HSxCoZCWL1+umTNnatKkST2OWbVqlQKBQPjW1NTU74kCAIDBL6YfhXxXeXm5Tpw4oQ8//LDXMV6vV16vt78tAABAgulXsKioqNA777yjDz74QAUFBbbnBAAAElRMwcIYoyeeeEK7du1SXV2dxo4d62peAAAgAcUULMrLy/X3v/9de/bskc/nU3NzsyTJ7/crIyPDyQQBAEDiiOnFm9XV1QoEArrnnns0cuTI8G3nzp2u5gcAABJIzD8KAQAA6A3vFQIAAKwhWAAAAGsIFgAAwBqCBQAAsKbff3nzeowfP16ZmZnO6p89e9ZZ7S5PPfWU0/rbtm1zWl+SsrOznfdoa2tz3mPIEPefxk888YTT+qWlpU7rS1JOTo7zHvF4P6ClS5c67/H22287rT9t2jSn9SXpr3/9q/MexcXFznt8+umnznt89dVXTuv/6U9/clpfktrb253WDwaD1/wcwhULAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANR5jjIlXs2AwKL/fH692AADAokAgoKysrKhjuGIBAACsIVgAAABrCBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsOa6gsXatWvl8Xi0fPlyS9MBAACJrN/B4siRI9q0aZOmTJlicz4AACCB9StYtLW1adGiRfrzn/+sm266yfacAABAgupXsCgvL9e8efNUUlISdVxHR4eCwWDEDQAAJK8hsR7w+uuvq76+XkeOHOlzbFVVldasWdOviQEAgMQT0xWLpqYmLVu2TH/729+Unp7e5/hVq1YpEAiEb01NTf2eKAAAGPxietv03bt36/7771dqamr4vs7OTnk8HqWkpKijoyPisavxtukAACSua3nb9Jh+FDJr1iwdP3484r4lS5ZowoQJWrlyZdRQAQAAkl9MwcLn82nSpEkR92VmZmrEiBHd7gcAADce/vImAACwJqbXWFwvXmMBAEDiupbXWHDFAgAAWEOwAAAA1hAsAACANQQLAABgTVyDRRxfJwoAACy7lq/jcQ0Wra2t8WwHAAAsupav43H9ddNQKKQzZ87I5/PJ4/Fc0zHBYFCjRo1SU1NTn7/ikkxYN+u+EbBu1n0jSIZ1G2PU2tqq/Px8paREvyYR87ubXo+UlBQVFBT069isrKyE3ZDrwbpvLKz7xsK6byyJvu5r/TtUvHgTAABYQ7AAAADWDPpg4fV6VVlZKa/XO9BTiSvWzbpvBKybdd8IbrR1x/XFmwAAILkN+isWAAAgcRAsAACANQQLAABgDcECAABYQ7AAAADWDIpgsWHDBo0ZM0bp6ekqKirS4cOHo45/8803NWHCBKWnp2vy5Ml677334jRTO6qqqjRt2jT5fD7l5ORo/vz5amhoiHrM1q1b5fF4Im7p6elxmrEdzz77bLc1TJgwIeoxib7XkjRmzJhu6/Z4PCovL+9xfKLu9QcffKBf/OIXys/Pl8fj0e7duyMeN8Zo9erVGjlypDIyMlRSUqKTJ0/2WTfW54d4i7buK1euaOXKlZo8ebIyMzOVn5+vhx9+WGfOnIlasz/nSrz1td+PPPJItzXMmTOnz7qJvN+SejzXPR6P1q1b12vNRNjvWAx4sNi5c6dWrFihyspK1dfXq7CwULNnz9a5c+d6HP+vf/1LDz30kB599FEdO3ZM8+fP1/z583XixIk4z7z/Dhw4oPLych06dEg1NTW6cuWKSktLdfHixajHZWVl6ezZs+Hb6dOn4zRjeyZOnBixhg8//LDXscmw15J05MiRiDXX1NRIkh544IFej0nEvb548aIKCwu1YcOGHh9/4YUX9Morr2jjxo36+OOPlZmZqdmzZ6u9vb3XmrE+PwyEaOu+dOmS6uvr9cwzz6i+vl5vvfWWGhoadN999/VZN5ZzZSD0td+SNGfOnIg17NixI2rNRN9vSRHrPXv2rDZv3iyPx6Nf/epXUesO9v2OiRlg06dPN+Xl5eGPOzs7TX5+vqmqqupx/IMPPmjmzZsXcV9RUZFZunSp03m6dO7cOSPJHDhwoNcxW7ZsMX6/P36TcqCystIUFhZe8/hk3GtjjFm2bJm57bbbTCgU6vHxZNhrSWbXrl3hj0OhkMnLyzPr1q0L33fhwgXj9XrNjh07eq0T6/PDQLt63T05fPiwkWROnz7d65hYz5WB1tO6Fy9ebMrKymKqk4z7XVZWZu69996oYxJtv/syoFcsLl++rKNHj6qkpCR8X0pKikpKSnTw4MEejzl48GDEeEmaPXt2r+MTQSAQkCTdfPPNUce1tbVp9OjRGjVqlMrKyvT555/HY3pWnTx5Uvn5+Ro3bpwWLVqkr776qtexybjXly9f1vbt2/Wb3/wm6jv8JsNef1djY6Oam5sj9tPv96uoqKjX/ezP80MiCAQC8ng8Gj58eNRxsZwrg1VdXZ1ycnJ0xx136PHHH9f58+d7HZuM+93S0qJ3331Xjz76aJ9jk2G/uwxosPjmm2/U2dmp3NzciPtzc3PV3Nzc4zHNzc0xjR/sQqGQli9frpkzZ2rSpEm9jrvjjju0efNm7dmzR9u3b1coFNKMGTP09ddfx3G216eoqEhbt27V3r17VV1drcbGRt15551qbW3tcXyy7bUk7d69WxcuXNAjjzzS65hk2Ourde1ZLPvZn+eHwa69vV0rV67UQw89FPVdLmM9VwajOXPmaNu2baqtrdXzzz+vAwcOaO7cuers7OxxfDLu91/+8hf5fD798pe/jDouGfb7u+L6tunorry8XCdOnOjz52nFxcUqLi4Ofzxjxgz94Ac/0KZNm/Tcc8+5nqYVc+fODf97ypQpKioq0ujRo/XGG29cU6JPBq+99prmzp2r/Pz8Xsckw16juytXrujBBx+UMUbV1dVRxybDubJw4cLwvydPnqwpU6botttuU11dnWbNmjWAM4ufzZs3a9GiRX2++DoZ9vu7BvSKRXZ2tlJTU9XS0hJxf0tLi/Ly8no8Ji8vL6bxg1lFRYXeeecd7d+/XwUFBTEdO3ToUP34xz/Wl19+6Wh27g0fPlzjx4/vdQ3JtNeSdPr0ae3bt0+//e1vYzouGfa6a89i2c/+PD8MVl2h4vTp06qpqYl6taInfZ0riWDcuHHKzs7udQ3JtN+S9M9//lMNDQ0xn+9S4u/3gAaLtLQ0TZ06VbW1teH7QqGQamtrI75j+67i4uKI8ZJUU1PT6/jByBijiooK7dq1S//4xz80duzYmGt0dnbq+PHjGjlypIMZxkdbW5tOnTrV6xqSYa+/a8uWLcrJydG8efNiOi4Z9nrs2LHKy8uL2M9gMKiPP/641/3sz/PDYNQVKk6ePKl9+/ZpxIgRMdfo61xJBF9//bXOnz/f6xqSZb+7vPbaa5o6daoKCwtjPjbh93ugXz36+uuvG6/Xa7Zu3Wr+/e9/m9/97ndm+PDhprm52RhjzK9//Wvz5JNPhsd/9NFHZsiQIebFF180X3zxhamsrDRDhw41x48fH6glxOzxxx83fr/f1NXVmbNnz4Zvly5dCo+5et1r1qwx77//vjl16pQ5evSoWbhwoUlPTzeff/75QCyhX/7whz+Yuro609jYaD766CNTUlJisrOzzblz54wxybnXXTo7O82tt95qVq5c2e2xZNnr1tZWc+zYMXPs2DEjybz00kvm2LFj4d9+WLt2rRk+fLjZs2eP+eyzz0xZWZkZO3as+fbbb8M17r33XrN+/frwx309PwwG0dZ9+fJlc99995mCggLzySefRJzvHR0d4RpXr7uvc2UwiLbu1tZW88c//tEcPHjQNDY2mn379pmf/OQn5vbbbzft7e3hGsm2310CgYAZNmyYqa6u7rFGIu53LAY8WBhjzPr1682tt95q0tLSzPTp082hQ4fCj919991m8eLFEePfeOMNM378eJOWlmYmTpxo3n333TjP+PpI6vG2ZcuW8Jir1718+fLw/1Fubq752c9+Zurr6+M/+euwYMECM3LkSJOWlma+//3vmwULFpgvv/wy/Hgy7nWX999/30gyDQ0N3R5Llr3ev39/j5/XXWsLhULmmWeeMbm5ucbr9ZpZs2Z1+/8YPXq0qaysjLgv2vPDYBBt3Y2Njb2e7/v37w/XuHrdfZ0rg0G0dV+6dMmUlpaaW265xQwdOtSMHj3aPPbYY90CQrLtd5dNmzaZjIwMc+HChR5rJOJ+x8JjjDFOL4kAAIAbxoD/5U0AAJA8CBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACw5v8AGNwPaEDMjHgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(M,cmap=\"gray\")\n",
    "print(M.max(),M.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86b71e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3139788132777146 0.28518808249275135\n"
     ]
    }
   ],
   "source": [
    "print(M.mean(),M.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f544301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe4530b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 168)\n",
      "(20, 168)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAABqCAYAAAAcLTOKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAADg3ElEQVR4nOz9aay2W3rXif3WdA/PuPd+5zPXqclVZZcLbFeZQOgmTQTu/oCbRIJPEJDyIQK++JsVwEIosQSKZKFGoCB1BFFHQXxolAgFWnF3GkibGM921anx1BneeY/PeE9ryIdr3c/ep8qYQrHdhuwlbb3n7OF+7nvda63ruv7X//pfKqWUuB2343bcjttxO27H7fhdGvp/7Bu4HbfjdtyO23E7bsf/f41b5+N23I7bcTtux+24Hb+r49b5uB2343bcjttxO27H7+q4dT5ux+24HbfjdtyO2/G7Om6dj9txO27H7bgdt+N2/K6OW+fjdtyO23E7bsftuB2/q+PW+bgdt+N23I7bcTtux+/quHU+bsftuB2343bcjtvxuzpunY/bcTtux+24Hbfjdvyujlvn43bcjttxO27H7bgdv6vjd8z5+Nt/+2/z1ltvUVUVX/rSl/j5n//536mPuh2343bcjttxO27Hv0dD/U70dvmH//Af8mf+zJ/h7/7dv8uXvvQlfuZnfoZ/9I/+EV/72te4f//+b/m3MUaePn3KfD5HKfXbfWu343bcjttxO27H7fgdGCklNpsNr7zyClr/W7CN9DswvvjFL6a/8Bf+wuH/QwjplVdeST/90z/9b/3bDz/8MAG3X7dft1+3X7dft1+3X/8efn344Yf/Vltv+W0efd/zi7/4i/zkT/7k4Xtaa/7oH/2j/NzP/dx3/X7XdXRdd/j/lIGY/80/++N8I7zJV7/9CHNlCbPA5G7DrOw4vZjj3i+x+48iI7YBt0uQ4OqziR/84W/xen3Jv3r5Fi/fu4PqFfFo4Ohkh1KJy6dLqqcWPeQLKFAR7E6u4yew+uGeP/6ZL+OT5l98+Db9kxlJJ/SdjuPlnn1X0H44o3qpZdrzdfQAbpuwLewfKPSXrvhjr7/Du/u7/PJ7r6NPC8IkUt5pWE5aLlZT1Ic1bnXjmRSYVq5jBlh9Ej72pQ/4geVTfuHiDd579wFmrwkLz/zOntJ5zl4uKD8oMN31NUjg9nKdaOHiC4E//PmvMncd//Lp26w/WKCSguOO4+M9vTdsn8ypnhlUvDE3IT9TA91S0X5xy3/6ia9w3k/5V+99jPSiIhYJe6fheN5wtauIH8woLj76TLqHYpswHYQC+rkiFvLfYZKILhHLiJp6tI3oD2vu/GqkPh/o55b22BBKCIXCTyBZ6E8i5v4eV0TanSNtCvAKu1fYnXx+ez/gHuyxNhGCIgZF8AZ1WlKeaaKB9vWB+69csR8c/ZeXHH09MUwVl7/P8/lPfcDpfsbZr97n6OvQzxSrz3nuv3bJ+dWM6b+uOf5mzzAx7B4Z+gVEC7FKJANmp5g+T7hNwteK9q7CV7Ju67OEaRPrj2mKH77k03de8ksfvE79SxOq8yTzfS8RC6hOFYv3A6aNXHzGMfy+LdNJx+rdY05+XWH6xOWnFeXnVpTOc/WVO9z5jYTuE/v7huYuJJdkrqsASWFXBreReQqVfI6KYLcKuwOV5P3rkIhG4acQSohlor/rcfMOpRPGJLRONLsC/bTCrRUomYdkEn6WMA8aZrMWoxNWB4xK7PqC3a4keA3nJbP3NG6X0F4+kwTJgC8VycD2LZh+3yXzsuPD9+8y/5pDD7D6rOeHv/9dHpSb6zMpGn7j4hEvzhfE1lJ96Jh/kEDB7qGiuxsJk8jbn3jOf/bw13Eq0MSCLlrea+7w377zGepvFYRJgk9s+b4HL3n/6gT/c8ecvDPga01zTzPMFKGAYZGIVcStNIt3oT7zXH7Kcfd//oQff/Qr/JMXP8D7P/869XPF7vXEW194zOeOnvH/fvE2q1+/Q7FSdHcS5s0tk6rn8smSxdcstkls3obFZy84rvY8vlrSnk5QgwadQMscT+/v+My9F1gVeW99zOnlnBQUMWjwGoLCrg12I3PZPfTUd/cErxnOa9xKo3pFsZJ9OkwUm48Hiod7nAssq5Z52XHZ1Lx4doS5krl3G4VpoTuC9IkdD0/WbLqS1WpCagzu0rL4FpRXkeaeZvMx8PNAcWaYvwduF1m/Zei/f8/Rcs/Z4yMW79h8Fiv6uZwfxQrqswDA2Rc0n/iRDzgqGn756av4D2boAMMyUBy1uCJwZ7rjlemaQnnulDvuuw3bUPJz5x/jw9Nj/GDQ5wVupWXtv9Hw5v0LOm85Xc3odwXKRSazjlnZoVSiMIFCyz0oJQf/uqs4u5wT9ha7skw/UFRXkX6u2N9XhElCD6BbhYrgFwn/sMNVA3fmez5/8oyTYksbHXtfMiRFHy37UOCj5ryZcrmf4L2iv6xxlwYVIJYQyghG3j82QlTYK3uwJ8nIV6gS5SfX/KFXvs2QFO9t73C6ndEPhm5donbZJVB5PdWB118955PLl5Q6MDUdten5sDnhl1++xnpdk3qN3ll0p4htywf/+7/OfD7/Llv/neO33fk4OzsjhMCDBw8+8v0HDx7w1a9+9bt+/6d/+qf5a3/tr33X93+9+zhX6QRtJ6iJRk8D1XygrgIPpz37B4kYNbuLmvJJgWnBeihjREUoe827zWtc6RPWcYGuKpRVqJmmXnQUJuCmLe1bFu8N3YsJ1XOD6cE1iTIm7KDYtiW/0b4NgFdzdF2SbMLOEvW8p5pHmkVD/2lL2zp4UlNeKIwWB6aIiTBortoTfqX7JFd9hTIT1MSiJ5Fy4aknnvuzgf1dRYia3aqieFrIwR+gTBEToRw0HzavEKopZ36OLisUGj0bqBc9tUuYSUf7asB7Q3M2oXpqMT3YLlGkBB7KXvG17k0mcaBJS3RdAqDnUC86JkA5b+g/Yek6S3g+oXqp5YDZJ8qQUF6xay2/1n6C1luimaInDlVGikWgng8U88D+uGEIhmZXYJ5UuJXCAo6ECxEamO7lnQ+1pj1RhAq6k4Q+3nE83/NCG3ZdTb+G7g40rw3oiScOGvrs9CkIwREa0I3B7bQYrgFMkJ/HkBi8I4xeokmARpcWNdVoA7o2hHJCpKCINdP9wKAMu67ieXiAt5rwluHy2JKKRHkSoK7RQ0k6rgh3C7o7is0XPA/fuKAbLLumxPeGYW/Yzy12pwh1orsboIoMCZqgxElc9Dy6P2CqEsqaMpTUfYSk8U7hy4SeKJhHKBPpxHD34Yp7k44v94p2U6N78K96XrsXqK1n86nIxbRGBYWfB/R8EKe0s+i+QHmFU4YiQdIQ54l4FFBBoZTBBIgO9vcT4cjL3OX7JYGJBXE7AQ3eJtAJNWhModFTRagS/iiSyoCdeB7d6TmpWiIKHwWava8bJnaF1YF3V3d58vAEtTeYraa8UugBuqNEfy+gqsB02fCxk4bKDmyUZ13UKK+Yv9Zx9yhQG8M3tvd5vFrSDZb9ukI1DhvBP4Krh6CCorhSLJ+Br+GD+6/yzv09WiWe7JdcNBMu1hNmj2ccvx/olpqz1xxb20Nd4V8p2VKRlDjARgOFOGTUUZyCGaQhYkrDmb/Lvx4+y3vr1zl6WrF8rycdVdQLy2fvXvLOkNhMKkyjYBG592DFo+mOd+uKy2mJ6jUsB+y0YK8tfXPM4pnD9LB5O3L/06csio7SepSuCEAZC6ZaE4ImRnFAUlKEE0XvNUSFDpZuU6F7zeRSU17JfvELaO+J42h1wq8qPNAAzwHlFdVeoQdxYvyjRO8SqUjgprzsSooi8NbHdkxcz7de3qWNM9I57F9LLL//greOLvjlb76JfeyYtJ69dbi7Da8e97jpnrMHM3aDluBHixManlRYK3vbWvj25lWqamB+Eijur+WsDoYQFWCJxYQL7dAkXvbwTp+NTG14+OpA5xMXs5J+bUGDKhTPWof3htAWuFYTVcJNEw+Pd+yGgmdXx3SNQ5vEZNJRFwOp0szvQUyB7UVJaAu8S8RaoaeJVIJ/EDh6tOZo0tAMjvW+IoSadSr5V6sFRiWcDUyLHq0S67Zi25QSLEVNQpG0whQOXcneUW+2fPHNxxQ68GsvH7F5PkcFRXw1MHw8kLzGPiuoXyq8gsEEJgvNRPe8decxTgWedkf8P7/9KfyHFclAXA6U056iCMwWmlBP6VQi6ZpGJQpj+Gy1og9bVn3N89Wcri1Q+Sz/XigTv+3Ox7/r+Mmf/El+4id+4vD/6/Wa119/ncv9hFa5g2FBJ7SOGB05KTreWHRYFfnV9ArDS4dp5TBUAbSXqHq3F6M69FYip7yAjY44EziqGia2pw+GX2leJ50a+Z0k10gGTKu42tcAxMGglNyP1gmbr3Ov3jGxPS+aOe9ePYRLmVYVQQ8J0ydUY7jYTWg6Jwe3AlRCK7mfiet5dbaiMp6v2Aesz04OL+fmM+33jotiQtc5QSsUKCXetzOBWdGxKFpiUvzK8BrppYFe5kb7BEphGsV6V9EWljDkvFy+JZOvc1LvmdmOq77mnc2rpJy/U1GuoweFaTQX+xrvjURUeW5UfqZaBx5MNlTG8/7mmOfnpXjiSaJZcQ4Spg3yfDNLtAY/KIY5EmWVLZfTnv7IEY2ivR84eWXFyaThqqm5Wk+IQRF7A51GBXk+24DyHByQpMH0Ct8Zkk/ieOgEMUcGWr4AQtSEoLADmDaStEJ3hl1boHWinHWEyqN0pCw9MfsyY2Q+TBXzB1v+8MNvcdFPeefyAaumojWJoddEpwl1xCwHyqrHmMikGDA6UlnP1AlslaJCeTB9RPlrZC0piFbmMRSJWdFzVOwpKs8wT5hOQR2Yup6Z6zhZ7jjNxqesBiZVT0qKNTUxz5kKeZ6sXJ8ykAZNNBpQRAth6bn7aEWI6uBQxcGg1hbTKDHCTvaNCrKPksmoRx0opj2TqueoalgUDT4a+mjw0XBc7nmrPmduWmoz0AfDtilpVhUqOkynGE4iR4/WLOuWRdlyp9yhVeJkuqc5ccRgOJo0lFocpE1fslpPiJ0RR6ZR2aiKAxYGjVuVlFcR0yq2W8dpNwPg+WbOelsT1gXz80T9skfFAt1o+mAA8HWiXyqIss5UlGc+jPyeopO56TrHi2ZO2Djqy0hxusPuS6yKnNgttc0QbJIIdl503Cl37OcFvbcMg8E5ibZ9MOjGUF3I+bL5GLy5uOTV6oqrYcJqqOijRef9rFUiJkU0GcqUoxHvDf1lhd0adA9uC8UmEZwgksNcHkgH0Fst+79XaC/3qbIDGioIdSRNQ95EiqFxWBt5OF3zen3Jti95Np9iOoVfRD5xcsYXFo95Z/4QcOg+ohKUNrBwLcXcc1LvCVHTR8MQDH0wnO4cobYkDSom+m1B8Ib7d9Z89vgFpfE83h/xcjcjJgno9oMDoPeW3huMjiyqjqMqB0e9Yx9U3lyKvnGkQWP2GtOKc6VVYmY7Om/pO0daF3gXaU1Eq4RSiTrv47YuCJUjlILqjmeLng78/geP+dzsKV/evsIvDa+x8wV9b2l3haCQpWeYGKyJbPYl3aYUm5HRrdEmjPtrPmv4j06+TqUGnuyWbOIcApiJ597xhm6wrM+OMa0syi5qDJGJ6XmjOONVd8m33AP+RfE2PiowCVMG5pOOwnoKE4hJExMM0aBVxKnIw2rNRPec9nNC1FyaSFDXWYx/2/htdz7u3r2LMYYXL1585PsvXrzg4cOH3/X7ZVlSluV3fX/1fI5eFJjFgD4OTKuBk0nD1Pas+opn64Usmm2JqvJLUQrtxRMHiGcl69JBEbF3OrSJLKYty7LF6shFM+G99hjvDakz+GmGm4OCqMX56BS7F1MwCVUF7P0GYyMn8x2LssVHzfPdnF1X0HUynf0iYXokItCaUCnsRnP1bAE2oqces+yoi8DJdM+yaNn5gm9fndANjmZfgEsMS0hGnse3imhAXRRcNRaKiDnu0DoyrXtO6j2FCay7iierJT5ohsZhJonogKTQQQyY8tC9nNC5iCoj9l6LNpGjWcOibAE43U/5dnvCMBg5SOaJUOW5QRNKMI1i83wOJqErj5l3VC5wZ7ZnXsgm/XB9TNM7utaRTGJYJmKh0F4T3HhSG1AwTBXdCYQ6MZx47k4apq5jWndcLiui1aRaDrchGErruXO0JSbF1aZmGCoIEItEfyQbtLhSFGv5nPYeqGWPNRF/VlGeihEZlpH2zR5lI7NFy/GkwZrA6sGUy08WRCfRe+gcWkesC7haDHgImt1QEjojzsdEUIKhdXxre5eYlBjbsmVVV7xgga8tqojUk47KeUJUbJqSGDVaR07NVLJle4ufKJoTK/PdyprSg6Q8glO4reKb33jEt6r7pF6j5hG/gGrWU2QjvOsK0qqACNEFjicNMSnWmxqzMxJBNmCbRCiyc2ijvK9jcZaSk/Xvg0apxLTuoIamK+j2BhWVpGZ6hYoyX/2dgJpI6mxSDlgTqYqBQnuciqx9zdPtgnawHNUTMcLFjtN2xmZf0TUOdGK44xmSAhdZr2s2u4qT5Y6jYk+pAtuuZLiQyP2pP6LzFqMjpxdzOCsxg/qIE6p6Lc6qVyRHTpco1KD48OpI5uZyglo7XKNIGroTxzBV6E5xejnH90acvJjTfnNJF44Oom40Ksh6aNFEB2Fd8D4n6Fazu6+IZkm/hKfbBT979VnevzxG9xwM/EUzoTCBi2ZC2zrioOn3jl2oISjKlYaUSFph9/CV0wc8ro4orcfllEBMCmsiRqdrJzkpukGcGZJCTwd8EaHTuK2FC3E2TAd2p4guMcwTqQoor7Frjdpn5CvccLhyQMWg0XuL7hVNUKzvVMRKMSs6woOOXe0wJ2KkLv2EqhjYvqbwk4L9w8SDumFqO9pg2fYlQxS0JiYl6y+jbioldK9Qe0P0mhdxyWpXY7IzYI3MQRsE3Y5RMXRWnFGbMHcT9ycb9hQMgyHtBPmwi57JpKNpCtKZo7yUNElMipNiTx8N2gSCltRdShCSwg+W9WZC9Io0aMIy4SfpI8693zm+enWfjS9Z9xXWROpqoGkKQpfP2qDYJIVWiWFbYK6sOLcetJd7MR2YRtbzarLk/+y+RGU9F/sac9STgiLsLc+v7qCCwnWK7kgRS3GinrVLTvsZv3T1OruhpAsWHzTxgaRPrQ20g6UdLOumOtjlEUGry4HXj664V2457Wacbqa0+4K4/y2cg+8Yv+3OR1EU/NAP/RA/+7M/y4//+I8DUsHysz/7s/zFv/gXv+frHP+qYf8px9s/+ow/dPdbDMmw9SVDMvzc5mNsv3pMcaUwy4S/P6DKwH7jGGZyKNgGjt7RgObyBwL/8We/ypv1OftQsI8FO1/y1Wf30V+bSR7uTiQ87AjAMHcMCy1w9BomzwzDVNH+SM//8vt+mVJ79jkn/Hh/xDtPXqV+z2EcDPc96fWWrtf4icNtNWqAyVOFedewf2g5+Z8858de+QpDMuyDXOfXLl7l6psnVC81Zp4Y7nnUPU+zs/iZxbSST118Q6OD4urTmh/+0rt8//wpbXQ0wdHEgn9x8Tb9V5bYncIcJ+K9nmQj+0XBMNfoQXL4R7+hic6w+v0d/+mnvsxdtz3MzVk34ysfPKL6RiWoyt1AfLUlBIWfFvRLScFUZzD7wNCdKMyPbvmTH/tVALahpIuWb27ucf7+MfVjg54k/L1AfL1laAx+4rCNGKlhGaCIuMnA/eMNR1VDZQaOi+ZwiBqdaHox/ikpNl3Bq4s1n18+YaJ7/vvTT/L17UPwhrAIMB0gKcJXa+pzQVZWn7R85rXnWBV555tv8/rP7kla8e7/ouR//SP/grtuw5P+mNN+ztYXfOsHPGdvzAhBE/YWVo5gE9X9LY/mGxrveHq+JKwLVK8IRZK0UZ0Y1iW/rl5hOWv4nz78Fj8wfcypn/OVo1c4bWdyOCp5tqfbJZcvFuitySiXHFZFlDRTdyLvrDoT7o+voV9INFa/TNz9NVBBc/oFh/7iFXdnO+ZFx8x19NGyW9VM3zcQYbc0fGYpgcEHz0+ozmVdFatEuY74SrFDUdYD1gbKky2F9YSoxYkcLKXzfOz4nDeml3ywO+aXr95CeYPpoLiS1Nz2NcXbX3zC/+rV/4Hnfskvrd/grJ1R6MDE9lgduGgnnH5wjFsZPjz2hDcVDyYb3rs6oT2rMXtNvNfz2U8/5qTc8YtPX8d/dYHZK07fcry1vKA2AxdXUxZft7htYphXbOcVKJjshKOkEoRS0nkx5769NpDAV4n9Q0FEzF6z/vYRysPkXFNejVwTxfpNS7TgdhDeneCiBCYqgi8TvLXjY/cuebGZsfv2kvI88ynuJHF6A9SPLSpYQgVXn4lclgnw7J8c8d88PcKsDdVO3r1pFOcXM7ZNSdc40qpADYrySlO/TOKkJHm2aKA6U7S/fsQLB/5Bz4MHK4psfCvrDwirVZE+Gl4OM3zrUCZy52TLW8sLXu7nPL16xOxxQg1QXoHdQ79U+Ddbvu+1F1y2Nc/fv4PyBh3UNScMrlMjrWb6gaa8TOxeKzh9OOPtmeOt2QWvf+YSgD5amuD49u4O92dbTr+UGILhzfmWzx09Y2kbzrspF7sJfWcPBjElcRJln8j9leeGpME2FrurSBq2b0aqNzdondhtKlg7Oc9XmmINvoJVNXD/wZYrXdPvHfUzi58mpo9a/qPXvsk7Vw/54J0px1/3bF8xDJ+HT0+eU+qBr5X3GYwgqClqSXNvSorHBfVK0d1NVN93xVvHl3z74oT260vcRqGi4Vl/j6fFXcyi57W7VzyYdXw7nBA3tSCI1hAKS1BQX2gmzwX1LteB6rRHDeEw5clolu+V7H/tHlcTxeZzA7/vM+/hk+Gdf/UxHv1cABIXn1bsPuahiJQm8o3Le+zagvDOnMW7cp50X9rzxz/zFba+4DdOH7FaCWpozxxuK3NuOzC98Hq+/Omah/dWXO1qmqcz7Eaj2u/dV/gdSbv8xE/8BH/2z/5ZfviHf5gvfvGL/MzP/Ay73Y4/9+f+3Pd8jdlTT/+q4vXpFX909mVehjnf7B6yCjU+aKpzRf0ykYwiveFZzBrWqsb7ktgpbKOZnEZUgKvPKL4w/4AvVO/z4XCHd7v7vAR86zh6LiSgYa4oph3GRLZRMUSH7qA6V0yfB7qFoTeRPzz/Gk553uvv8bg/4bleoDeG6dOEnyra+wKD9d6wHwQ9sVuFewrTlx4/cdyp9/zR2Zc5j1Pe7R5w5gUeLC8006dyGPpXA4v5nq0pGbwiFJqq09QXEbeNbN40fHr2gj8y+wrP/RHf7B6w8jV9b6leKopNwtdgaoHZ1wmGUKA7TbFSTF9EolOsgB+dfYtX3CXv9Xf5oL9LExxpZ5k8E4Jqf6yYzlpSUmy9ZkBg9volzJ4GwFCUPX9k/hXa6PhG/5CzYc43uYe7kmfqThT9w8RivmfvCjovEXWcBmb3dxxPGk6qPZ9dPON+saaLjk2oGJIhVAqfDJ237IaCfe/wwVCZgc/UT7ljtnx18oCva0HWdOU5XogLvnEVdifOR1KWt2dnaJX4evtx7Nc+RDlH0m/yny9+mVes4ufaI35BfYy9LZjZnqt5zVVf8/WnD0hrSyoTRiWOqz2qq4leo/cSjSUjqE10El3365K9C9wvNnyh/JCXdoYh8axYEpOiiQVDNLzYz1Gtxm0Uus8po5CdjCOJqPWgcU3CNoloNaEQhGW2S8x+/Rlpt6d881MsZzs+d/ScIWli0vTRklpDcSWGahsUD8sVOofodi+Ih9sn7D6C0pAUzgYmZc+j6ZqH9YatL/jG1T0uuik4uFdt+ezkqaT3nPCsVBCeU7UK7B9aPrd8xp+eX/L14TErP6GPFqsiZSaZtt7iVobyTJGUZXWvprKefVsI3N0okk58bvmMT1XPeef8Ic1aUV4murvmwBeJraE6T1RXgWEr6zsp4TnZVp6zW2iSVmBz2qDPaSKb8FNyWhJso9E9VOeJ+iISnKK5q+gX+Xd6DukbMkqfNNw/2vIjJ+/zK/o1vqaWQqYuM3m3jpiNwW2gWMv+Vnc67p9suFhNiU9rzF5hOoXpx7SvIjaWNinSXoIPPQgJdPZUyMZ+aujm+YzZJyaDIjrYVo7m2KHKhMupYa0SpfGCOkWLUpC85GyPq4bPL57wbXuXD6uHOS0KdJJeDRUUledzy2d8WBzzojoiGUMkoZTiO7P7yiuKVWL60jPMHe1gGZLmjtvxqfo5J2bLN7uH/MLqTbZDydR1vPXwnFJ7ajNwYndoJehF31mG1qKdeDkpp9ZVlPdhekiNfG51lpi8DCQDw8LiXzXisLQGu5WAqbyE6iIxTGE1GKa2owkOBo3dQdKKqhj47OQpF/2ExwOU5x39rKZPihO7ZeVqnAmSBlGJBMSooDOUl4rJy0ioNY/mG/5nd7/KPw2f41tqmd+tQgVDtIleOdyDwEm54319LHt/n1M8vaytYgX1ecTuI+WLPfqDZ6S2QxUFFA5lLfZqSv2sYlgUbN5yfHx2xpAM32jeZvbOBWjF6q172EWPKwQN3TYl7brkzntw7+cvaF6bs/khzY/Ov8kLv+Trl/eJvUE18kzVmaTJi23EdEJcbx8WrGcV7b7AbjTFWhG6710e43fE+fhTf+pPcXp6yl/9q3+V58+f84UvfIF/+k//6XeRUH+rcfkpx7BM/Pr5I/6L8J/gk6b1jj4a1uuaSczkOAdlOTAreyFrJkUcNHvtiMagPSTn+b8//zw/V32cPhra4NgNBewsSSmSkQN+Ug6U1hPmmkYn/KDZJYefWGGx95b/8vkfwqpIGyx9tLzYzjG9QLPRAi4xLXtKp/FLw1Ba+tqyiZbuxNGdJN6/POa/cNfP5JPm5WqG8desZFsEFpVAk+uoiYOmsY6kDabT+Gnkn7/8BN/a3Ts8Ux8M/aagzsTB5KAuB6Zlj59p9kAYDDscoZRUB1Hxf33+RWZOYM42OK7aGt1ouYZRpCIyLYWl5ReGzkWG1rBNln5h8TPYbSb83Wd/BOAwN49Xy0xGEydGlYFZ2QsEHDS+NrgiHPKkEcWVnzAkwy6UnHVT2uBYdxXnuwneG4beEhoDUfErreO0mVHbQSDqaU+sNEpHdm1BjAo/TVx8pkRFCNPAl68eyXPME9s/+HHGk/NnXv4nHLmGnS9pgmNImr0vaIOjCxZjA/1MIo7V5ZR/vX5T/jAq4vEAQQmcO2QOQKNRO80uTvjvjj7Fytec9nO+ub7LKsOYI0v+6mqK3eiDURumgIZQJmKZSDbRLxPrtwTKDxUMM+GsbF/TmB9+BdMlhpni/Wd3eLGaUzpPVQz4YFCdGKiUQG0sP/vi08LUV7B7VZxvu9PYfU4PVJH9vqTrLd1gOWtmtN5yfjEjrQqubMV/332CX529SjdYlIm0rwyo1hCtpjuyDPPEvz57k79mW170C37j4hGX+xqlhCulVGK1mYBNDHNZI/t1xYedZbgqqS81toFhXvLzZ2/yZHrExdWUWZuJhnvFty/vcFFPUZ1UP/UzTb9Q9EtJUeog7wIlc+YniUyTknWpIEwiqfaQFKqXKg8VIJSa7kQiakk5pux8KDHMUfhg2ouzsG1LnnVLhmiIy4EmOKJLpElAFZEAtPcMfqrolwmlE91gCUFLumqs5qmRdEYEd2ZJWgjjppHP1R7aI4OKhn6u6I/IUX9Gebz8btMUDON+6SW9qExEmSSVLxuH3RhimTg7mXA2zOiiJU4Du1fcAeYfneAQFM/aJduhpJj0dHeFrCooRN5EAVg59JAruSaO7gj6bckvvHidwgb+P+4tnA6suoqL9RQ/GMpq4Gwu+9iZQGWE+/LV0weEZzVFI07VUEVQ4Fol91QKN6xfimOigqZcy3uNLuFcoLCebjbgo9xnshpfCw8jtpb/9smn2HcOe2EPDuOmqXjSH8uZepRYfWJCeyJz+k/OPs95O+XqaoreWpJOhNYQdMJkTkxwwtX64OKY/5f9NC+3M8I00t7T6E7hdnn9WcuH50es2oqudbI+DddVkwn6OeweaHSv6Y7mFI8mqCCptmQy5y/K2vS1BEHvrB8Kv8cm2jePSFqcZ1d4Sae0jjAYGDShVPT3p/QLQ2oU/2L1aU7bGS9eLCmeO1SQddmdCMo1zA3KS/WR2Wu2L2aoQezfME1Ec5P09FuP3xGRsf9fxnq9Zrlc8gf+8V/itL9H/PaUYq3wdcLPE7GIuJWhfqEwrRCtHn3hOW8tzg8EtphLlBrv6Lzl6YsjivdLdKfws4SfySIuzwzVac6bfc7zg595n0XR0EeLj5qYFHtf0AXLtis5+/CI+okVAzFPhGlEDYrqhUCM/VLRf2HHF998H+BwLz4adr5gCIaz7ZT223PKc+FNDPNIrCJ2K8/ktonta7D4fed85s7zHL1KlDc+U4iax2dHmG/X2J0Y2GEupVbuUlO/kAN0/anIJz//IffrzUfmpg2Oxjtab3n++ITqsSyyYZYI8wgBqpcSTYZKsfnBji9+8tsU2h/mxkcj8xssq6Zi9f6S6oUhWRgWUQiVjaZ+oSlWieaeQv/+Fb//0YeHZxrnxieZa+Dw71Vbc3Y1kzxoa7Br4SaYVjavGgl+MZGUYv2pyKd/8AMe1Bu+fP6Q0ydH4BVmOXBytMXoyPnVjOGqlHzxJFBMenFQXtZUL8XQtK8OHD3cYE085Mhvjs22xn55yvLdSLdUXP7QwKfffsYQrwnF3aakfregPpVNun+UhOTYaMpzjduL0xxKcVhNC8UaTJdo7yj2bwSYSdooZUKsm/TcO9pSWc+uLzJLXiL/FCUfzpOa+XtSatvcVbT3IslAcaUpL5EDaiJGODqIr7W8/egMpwPbvqQZHL03bK4msLaoeB3F6F5RXkhEq+L1/Ld3FP2PbPnDb32L1VDxzYu7bLY1vrXYlwLXfmdonEZbVSX8MpKKiGo0bq0xncJtYPIiYtvE9pFh8/FImEaq55b5twXN2D3U7N6IxDLhVpryXNZ8ey/R3xN42VWequ4xmQxodKLzhs3TOfVTK4fq2y2ffO0lSiUumgm7tkApqIuB2okRHKIWEnJUNF3B0Ft8a3HPhQ8wzGB4u+H+3fWBsG11ZAiG/eDwQf7eBy0VC0l4FynBsC2wZw7bCrcilImkoTzXzD9IuCbKes1OVHNHs3uU05Ungcm9HUpB9/WFlFMPsHlDs3sjkEyiem6ZPE+oXPE1Eh8h0zMmivUP9PzgJz8koni8WrLe1hL1XjrsNhvqV1qOjnYUNjAr+gM5dtyvT1ZLtl87pjqV+ehe7SkXHd2uwL4ssHuF7sVJuiltANAtoX0YSNWNHE6C6onj+GuC9PqJpp+JE9IvFN2xrOH0qOUTj05RKvH1L7/GnV8WB/3i++He979kVvQMQc7PBILCBEPXOcLjCfXzXMW3E1SxW2iufqjnBz/xIY13fHBxTLsWwqfqtThbXuF2Ct1dz+NY7GA6IeT7iaK9mw7IV3HcUpUDm8cL7vyiZvrSs7tvWb+NcA0nETMf0CbgO0vaW5S/RtgAkouoIgriMvJ3gsa9cEyeCudq/yjRP5IJtmeO8kIc8ebNgYevX5CS4vR8Tros0L2iOhPbFUrF7pWEvzeg9ob5Nw3zJ4F+qlm/reju+0PhBwrU3jB5Jmf7MFPsH0XiPBCblsd/6adYrVYsFovfxMJfj//Rq13+TeNPvPJr/OPLL7E5nbF4L9DPNfuHGl9rTCubMWlFspFF2XJS7HEq4JRAjJUemJmWfSj5Ly/+ALP3oVoFmjua5p4YSZvJMckALnJc7jlxO6liUQGjIhPdU+qBd5t7/JNv/hBH3xDHZX9f0x2LDobp871o8S5Pih1OBUotuVanAhPTUSnPPzv9LO/+0pLjrwWGiTzTMBOoV/mMWFiYFv1v+kwTLQjE/2n3o9gnE6YvAu2xprlviIUYsjGKSi6xKK7nptQeoyKl8kxMx9kw57/68EdZfitietjf07R3BBExLSSVI0gXOSn21Lr/TefmF1Zv8fNfPubka4FQKHYPdebMXJP8kpED/aTYY4iHudmGkpftPKMMQjDzUXO1rQlXBbrV2Ebh1ipHgIliI9wHtwsUV7LRujsTHtQbfmD2hG+v76Baje4Vk1da/rPXvszEdPxf+h9h/+5EYNvPNPznn/hV9rHg//byh7jzlUBScK4cm3klpLVcYaV1YlG3zFxP2zuKSzj6yprmlSmXv0/xifkZXbQS0RUVp4NEUfVFxO/kxPdXVvQ8TiPFNkpknfVNtM9k0pDojhVp4pkvG6lE6Bwpwp3ljj/y8Bs8Kq742v4hX756xH6QFN5b0wsiiv/H+vPMn0B5OWCbEpQgGboXJ0dFKDZQnUOoFNvX4Q/d/RZLu2cfSvax4LSf8d+1n4TnRX5/ueJmEFi7XEVMnygue+y2Z/OJOZd/IPAfH32VqzBh6VqeLRZ88+Vdyl8vOPqmJxSKfqaJBYfyXID2rmI4SbhZj+8rirXCbeT9Vhce2waiK/Ez2ffFlaRSzJCkjP1CH+YvZM76ME9UJy112XNvuuON2SVOB7og0P+6r/nVs6msywjGRT6+OMOqwFO35LyYUujAW/Nz3qwuGJLhRb/gqq/po+Gym7AfHKtdzXAmFRQqQuwMm6ZiVnW8vTzjteqKta/5YH/Muquk+ssOaJW4amtermb4wYLXB+OVDMQ6kUxCnWomp57iogWtSEaTrKI9qsS5nwcmd/d85v4LtEr8wpMZelC4fcTupUoDJe968YFH9/GQJkJLGjeUCtNpNnvDqq8odODOdM+ybmkGx0uWeIQoTtDsmpJYDnxsccHb0zOMkrNAk/gfeJuvx2PKKzFk05OG73/wjC+/fEh4t2TyPGH3ifrMY/eBWAjymSyYxpCcwU805IohFaF+kZh90GDWHWFe4o4KYqmED1GJwb53vOVH7ryPUZFvHN0nlFVGuxOV9dR24LjcHzQ5xvGimfP+t6Ys3gvy+7nazXQJ1RrOmilWRx4sN7DccL6b0H5jSf3iuqpyvE/l08E5jFYRrTjCwvtRtPdg9mrLm8tLfvlsitsrytOWpGv6hWVoFZ2G6n7PvG5Z7Woar0lKS5FDNWBt5Hi25835JbUZGJIEgHtf8GvmVfpdhR6yA3RhMxKfaO4LcuoWHZX1DMGQgsa0GUUtoD0R78Z0CvVSHM7Zs8jkSYu5W7L6lMEdScFGUXicCVyezzHvlkyfR/b3NLvXwE4Hohr4XsfvWefjX15+nNPLOXXML9RwKIONTuAo+e/Es82cIRimrmNZtFgV6XIqog2OsC6uF4a5DsPGyDNaIMG3Vnd55hYsipa57dAq0QRJ9bzczzGtQFk3I4ikMyxZZg+2c7yzekhpPAvXMrW95Pfzdd6/PEZ7uZdkEC8yicMxzMAnRSwiF/uad8xDajuwKBpKHfBJy3WCYbeqOUpJrnMjmgkFpMW4mRIfbo5Y9xUz17F07UeeadXV6L0hGoWy6fo6CkKNCH+VEL3ia6v78kx5bm4+0wfrY0ynDhvv4KkbSSH4WpCrbVPyztVDKXMuGmozsPElL/ZzmkHIjE3niLlSR3fiQHzkXTlFLGRzu8n1RifCb5w94rybcradQk7Jxag57edYLaiEzmS1rrW8t7+DT8Jx6KfyOSpC2DiCk3Iz6zwxwtWuZq0rml2JrmH/+kzg7z7yy+evSlCgJMdubJAqh6UmWUDnHDrgKwVK40tJD4QylzEOQJSqIqVFw0apRFHKZk5J8fXtfZ7YI1a9pG2cjjTe8c3NXYZoUF7RLjXRSrnveKCGWngNIqCncDGnHLaWf3355mGdLqygfjFqdOTA41BR9l6/UPjaoIdEVVe4jaOba5ptyT+7+BwxadZDJQdcylD5JEO7S+EOKC8ck7E0VbeawRQiUGTIjgok5dDeigCdyWu7guauRgUxcCPrP9pstPP67XaFcAWCoHM680u6HPUy6CxOJ4jIRT8hJsXjzREX6wnGJBrvuJzK91d9LahQLv/tO0foNcYkhrnsEwbNfi3w+deBF+UCn3RGPgwxwWmYkpJiGAx960j+usxZxeyXuYgqA35i6BcGFUt8rRkmmugknRHLCCYRgua8ncpDa+iO5P34yY3zoIL2xKC9OayHpGQdhlIRajHU267EZm6IQsrNtRMEE53QJhKjoveGx9sjtr488IYAnm3mhDJlsbWE6g2PN0e0TYE1cgYkDSpZzNwcgrWkINS5mqyUMnGzE4c3Wdi+XmP6Skq9Szm/hznEaUBPPN1g+aXL1yXNMBi6I0lPqZD48OUJxgaKwlM5j1KJlJGabVMKn6UUYTg/UTInNRDg5eUcbSLOCYrVtU4qm6TYT8pn8zk3VqAkk8/fXK6erKT5YpnY7ive5xi8lnt8fUK3lHU4OuVtU+C9pm8cqpHKlwQEE0lRs+8Kzt1UkDUVsdkmKJMIdSLZTKquE+kGOoIR8T+QqpzUjwG8kmcpOaSqkpb7bY8VKlb0U3EIh3UBJtEXTirh9hJ4R3ftuPi9JTbfu0vxezbt8vr/4a9T9BOmTyUV4WvZXLHIpZiLAPbGBANmPnCy3FFZz9lmSnNeo3pNeWaYPLsmlvaL0dhHwuyjMBYaymXL3cWOkKSsLlwJUbN+LkzzpKE/UgxTeWF+noi15NAP1yki8+M9R3XLrndcns9hZzFbzeSpolwlQgndsRigUCb8QiDom8+kJ56jox3TYuBiN2F3PkF1GnepmT4B20qJar+URexrgfgxN55JgVt03FmKLsLp1YzhqkJ1khapXwgZsV/kje0Sw0wii4/MjU1MjhruzPbXHIB1gW4Uk2ea6lyg0O5I5ZLTxLCI13Bqvo6qAsujPfOqY9sVwqpuraRJ9lJlNJYbqlw6G7JKaNLIPQFuranOpPS0n0O/TCQn/J1UCBO9Omp57eQKgG+++5DZN+QQ2b0RmL0hgkTb95fMPpB8ra/kwI4uMRwHzGIgRYg7dyCWml7ujbxhoxHuwOS1La8dXXG6m3L53jHlmbkBxeYpyAbS19CdRGIdP5qWcBFTe4yJlOXAUd1S5hK61WZCHDT1rOPhckNpPM/WC64uptBrzNZQXOnDwZ0MRJMYjiLqSBAz/ayifi4QbXtHymEpIncfrPnMnedsh5JfefcNSVNm5EoP4sh1J7K2lFcU54ZinRVqjxJhJmt3crJnMWk5v5phvjalfiEKse39hJ8HzNZQv5TqnVjKe4uFlCOO2hHJin4JWpwfnXVqxImS9KJd5XfvoTuG7l4QZ6IT7oxCrpHKRFIJszPYTEz0kyQHtI24ZcfJQlR9L58uKXP6bVhEUub4EBE9mFEZtMnlp8sopd+Dxmyk2icZ2cvJyZeaeKwLQpq8cgfNiFDJc+hG4TaCfHYnCf3anrruWT+bs/iqpdjkVNwjSc9i0wF61yahc0XLcFXhLswhR5+yw2Y60J26RkONBCV+mgh5f6syol1E60hReko3kJKi9xbvpcw1RZVTRcKpSz7DKCOvRgNlEMOUFCmIXgadxq3MtQ5TRnm0l1LR8f01r3qoAubcMX2iMU1iWCi6k0S0KROx5Rrtw8D8tTV1MXB+NcNfiVDeQeEzglsZiqwpNKYaZRJks+mxDH+ViE6xf0VKuolgtiZXnYhSqpp4IW2/tBRr0bwZltc8IJXXRywSae4x5UdRltBr1N5eV+kM13MWjZxno1OTlKz30Tnwk0SYB5FoKANFJWfDrOpYliLU9+H5Ef3LiThHdcRMsqMFwmVSidm0ZVm37PqC82+dMHtfkLHuSFSHDwGjyuhJL2kyksrp7Xye5PPOtorqVDRhhgk09+VeY9vy3k/9b//9TruULwyFUqiQsjTz9QkdbULNPK709LsCc2HRXjFExcYFOudpVhXFS3sou0XlA3lELLJHahc9SiWGVYldScqh0yUrF0QR8LKkejnyDa6vMXq9aIh1wC07YjDEiwK704QisXOVSEfvS/S5o7jMqps+R2s3nikZSFNPMRkYGoe6lIPKD5ptEYhRs9+UuFOL3assnz7OzfX9xCKh5wPGBoZNib204rkCmyLIs15VlC/sIQebTI66biAosZKDOSWFvyqwa0OyicZUrEyk6y3poqQ6y+mVfnwmDk5YMpAmgWLe43tDuhBJfD8xbDN7fd8WYtgbfWB7K399SMkzybtKRYSMSKASvS3Qg0V3GaY9lQRpdyKS38pFUoJVW0mJXqczwgCm0ey2uZQ4H1Dj57qdIFNhoolBDlKz07iVEDf9NNIfB3SvKS405VaIWP19Q2EClfOkSWCYS1XFiLZEy6FKJUwSceExE0k/aROlAiEhKpRRDOgsl8ye7yaEqwLTaBqA5YZCB3pv0CuHbsUZ6hcyaaPjgIJURo6WkmO8Whcka8ALCqKCJZRJWOtHTqpjYi6hHJGPAKkQca7Zgy19b+lVTXT6gKYUK8Mw07RVwaQcMvIhMvJ+In9rFz1eFcRL0VMgivOc+oxsumwYa+TAdRG1N7grnaPUhL7TC7I0TNBeYboEKFIdUC5CV+By5GycGAQSuK3CbWWN71+BcGdAW5nzbVvS9wa7MpTnMo96MAyd5qZqmPYKtxLO0TBV9CeJct7RNw59YSjWmXhuJKL0dWIgk0gbQ3GpsfucIkqaWIpS8AjhoxJF6ZlVHZt6gp9aWc/HCf2wZTrpGG7oc6QIfnDCC1LCnyGCGrLWUbquuElKDHOyCQwwG6inolXTd5bQGaLWBxFGrRKF9ZQu4YOh6y1+sKIqvLHYRt69GoTYO0wTatFz52jLpinZn0/Q++wM6XwP+hoNMJ3CqaxZUyUoI7YMRO0wbcLtxSkZ7g+4emDYOeJV5iHNB06me0rjeekXlKfSIqO7K9pHCVAX9YHrIkGVIin1kXNF0nWCFgxHgcW9LV1vCauZcCUcJG3wKs9pJtamkQw+DXKtkRtVRKZHDZNMzhdtElhtJqjT4qBsPCxlbROUiAfmd2aaHHQNo+EXexMHRUqaCHRJidOpI7WTNJ4xkVQFiApde4pyQOskZ0nWDrJZXC4mrm1ZPqvjjeBQxex05aBIdZrqTOM28tyxkDUuyKXYH5RQD1CK0H4Hweu3GL9nnQ+VK5lMJ3k4gezyyzdgXaAsBzFqxpICoBPOeQobMgs4e5o9B55IGPPOyEYoygGlYHCOZLKKp40U1uOzkuHI+jbdWOqo0BnaTAqwiaoa6PtE51ze6GBNxNmAsUJeHIVmxusAoihHzjcWkaocRMjF2Mxolvr20nmUTgcoXPdycGufSzujQHTJJIrCUxQen4W9UApMVjrUklSVPh0cHJCxIuDwTCZRVoMQMq0Tr1zL3JROdB/68T35/ExtIjjFEK+vo5w8U5NEejtpuReTn6ntpf5edwrbCtlQODTkzT9GCmPCWjaepCYkQjDNuGjkH7tVEC3JQXeiaXN5mdlpyouE9olhrmkaK2umFZEmJSXxckAVEoF4r2FQuLWmPpV33yLplAOJz4pDbIxodxRGDOHNiN60CZVTUmOajUGqmLAJYyPGREkX7Bx4IeE2U0dlBqmMcYkYE9qJXoMeRRZyZDIa9MP+ySx0FMzygXip07VDocVZTS6RomLdV3TBXivwcr3uk5FoTaDrMWL/6EGjB4VfFZwHDTtLsZX3Mwr3xVxxoILkyTESRcbixkWSAhVRVcAUAT/og6pjMmAzjD4o0IPoXaDA1LLm25WT/d5D6iE1IywsULx4myKipkwieCNKrb2h2ivcPl0fsoa8B/Pa91l4K58BKFHh9d7kNXBtmJIRh5kiYovA0F7zw6LLEWQVUUEimfF9zOuWB5MNZ/WM6Eq5biES3ouq48Ibws6BV4KCuIgyUar2bBID1BtxLKMY9lDlVLHhgA4YJ4JvPmrabYFeW0GOJj3HE9lQXTA5ZaTodoX0/cgKwiNpdAQTVATfWC7UFN9Z9E7QA5Urd1TK6y0pVEa0Dns2Ab0maIMZ1KGMVl66GHGCCEgSIUVFoWWfpSB71/SCasfREVAyzyqvE7cWh3B0/g9OyPg5LnIy3bPSFZsopcuhEgfazAepsMOI0R7PwhzcMOTKHxMp3cCyaum8ZdsVmWMhZ14UoW2UV8LnyCjdWD2ls3iaHsg6LuATJCfrCK9IO0sAGpVoyx6XdY/G/Rr3lmYv55qdeCYToQ/sO8dmXzJ0lmKrZU9nHhiI/TBb4dclLWKb0ci8urWUiIsTKXt2tB3aX8+prxPxIxK/v/X4Pet8mA6sF4KbbSIqGZEyRpyG+azh7mTPk6jZbcRKqTIyrzombuDciHiYbbP2wFWQ6NMZ+kW2AEXkeNrgTKBrHWEr02GLwFEtC2ithNyoO2myVF0GQqEZJgY1QxTxas+D+ZZtX/B8V2RFyEhZDRxXDd1g8XEkTEK5TritRK3DXEElB8Jk0vFwvuGlSlytC6JP4CLTqmdZtvJMXlAPt8/kvy6StKVfyrylInE0a5iXnUSoGyvIRBmYVx1GRy70tffr8jOhwFcGFtlA1oG7sx0halGu2xmSS5SlZ1mJkkyTrp2gYpMoV0Hy0/Ocd9ZQTgYezjdc2Aln24LYKZKLB5ntbVuiG9G4KDYwfR5xO7lOuxRCoai8SkSZilwyZiKDl6ZrxSbhy9xkTismq0S5iSQlJdu7SYXWiepUcfzOBt0HolsyLCzJJMqLXMc+lrApMYjDXOF7jW40sw8Tx1/dE2rLxfeVxOLaafSVpBAq55nYgT72lPVAOwhyYjpJs0Wb8L1EVCoo/EQTsIQqUNWRuhhodgXFCyF9tfc163lJaTxaiVxyLBR13VNaj80Hj86RbtJJdnSSyNI08g4wiTfml2gV+dDdyYdGojcKP42SokqK091UOBFeHUpSTSeS2yCOlNWS+C6uNLPHYmS7peTKbQP2w3xI9yJcJjobGt0KkjRCyraRA2uYSQpA7lcctWRhsmhZThpepCXxyqA1JBeZTVqmxcBOz3E7IVhutObByZpl2fLO2YRiJZGzyhL+kNGmQhGQQ9SVHqWgvaowK4PrBUauz2J2NKQsMtmR0yX3WGwS1eXo6cGyblEqsZ2U+E6c0sOcFpHJsmFSDpz3Bu0ddidoUJwIsjikEnUuaZdkEx9fnvP7Fx9w0U55Mp2ivCLMIm8cXXGv2vLzuzcE0d0r+uNIvBfEGbUB5wIhaPqrOZMX4mQ296QaLtkR9UiSPp103J9t2fYl292CyWMt/I8H8PmTJ/hkeG97wkUzIQSNfVkI2ZIbEbPJAYLN5dqnjmgcdmwy13FwesaATIxaEkci7x8dlJT2e0mtKC97UQdxOkRYTGP24qQNXlPbgYntoTPUL2WdDRMpJlAmEo1U8phezodiE0ha0dzRdJlgORJGk4Ji1vODJ094d3uXr8YTJmdRzp868vaDc16s54QPCspVkiBYJ6mWC5ohORiEmH9vuuP16RWn7YyrpqJtCqLXKAvk4E53CjqF3WnKC3HuhcuW56MXB3dMhZv5QFEO0qvruZznbVDsJh3lKLxmIylp7LlUuCQN+48pju9eCZ/p2Qn2eYHrFPULERQMpULnvjl4xeS5YvpM5q5fKCmnbWH6PFBdDJlvYwllnr8IpEQoNcM04U88sfHfs43/Pet8SHQEto3YJjBM9cFLSyZRO8+8aCndhJ0ImaJMpDCB0mSUIFyjDbaJ+TAy159hErNCmsxZFwiZlKNNpDT+I/eiPdl5EGhTewkpE2BsYO7EIGsb5VzS4EygtoPI/CayPG7CdDEzvhVkoSS0GK950bIuSulMqDUY6aBY2wGl4wEK17nviG0DeriRd9GJadEzdy3OBbrM/TA6yTWyqIA+PFPCNkEMvM/5lxwZzosOHzXGRrwREpO1ci97I0x/naNY2+XraHWIalJGouZFS+Nd7qciz1rYQGW8VJMEmVvbJIp1wK161MLhK4XP0KxI3sv7MSZS2IBK+W82InQWSslbFNvI5GkLCfYPpjS9AReknO7lCrqeYjPHtELONA24vdxHNBLlh3T9ubpXlOuIe3KBnU1wrxdSLaEAlQ7IhzVSUVRoj3OevrAkY1AhYbsoKRydpZqdIAVxUCQneVlrAilo7FbEpPxM8u4hCfnUOk9QJhPOhBwIHDrOikVI12t2GA1F4sg1WB0OPIoDalMkWWtJ0fbSTEsFNeYBUEF6h4TMuzBaSHumFcXFUCh8LS0EtAe7EzVGnRETM/Y28mJIxr2kvRzi0UlaKKascxJl3dTFIA63mxLGNGfeIxPX59SIdAIGWJYtD+oN7+iU15JU5Zg2glIMMy3E6hypm7HHSe58LCXcCbuXNewy8iEkakiZ2Gw6sPuInkpKpnYDnbdsbF4HmW80IjdVMTAtei6toJZmyId2Dk4GW3AQ9dLwoFzzZnHGSbXjQ5dITkEpQlT3c6deuxPOjJ8qoQ5oqUKYlj0+GIYkAZcehFNGnjuBkpOglzYwc52srUFaEAxRMQAPizVDMry0My5VTYziFJSXN6JfB9iM+mXkw+a0gfLisJpeOiBHx0FnJmnQfIcyauZ3pRsl3DcbtKdIRj6u0Umr8zkfFMUu5fetcw8UdY18RIUeEsXKi97FvDiccQeUE9GKerW8ZDXU8iz7iKk1uMijyVoqnNIS20paEJ1RLwVeS7m/Vkl6KRU7dr4gRi1dmqM4KyPSoLysQ5ODNtsmfAUDsuZML3to1H+xzlOXPU2a4Layr/sjUVU1GYkcS3JNq6jOJShoXtNUVlKgqdOiCN5KWtm2GQU8IB8SiE5e9JJOTTa/UyivPO6iITkjaExtbjiVci7EIqFrD+k/AOejP8ppk2hxjaHP7H3lRQb55eWcdVuyXdWiAdHD4ApeTmaUzhO9ltbWhRz44NBByDEgC4Cd5YOLY7ROtJcVbp1JOFXJk6xCiRYio66V5GmtNDgL5bVef7cu+WZxl65zpKsCt1WEwbBaT/iAzGsoE/2xeJMqGnyt8ZU6wPe6VVxcTaWd/bbCrCS6GbTldDKjGSxhMKRpAq1IVvB+0xuGWfZEPei94fH5ES+LGdvLCW4tede+KHhaL8RgJRE68pXAf0mLI+Hr65xjvy54t7oj/RCuSoqNtJzfTWoeG+kUmmyiOwJTK1TS+FL6oEhkLwfK9mrC17lH2xTolcNuRNvj/GrGEDRtU0gfkCNhTidtsY29jqpymW7KTguDYrep2BtxLrulJrjrih+V5HvDdCLe/4OErTzaRNq7it3nHqACbF819EdijPtGhNsOUDASoYVKSIlhAttHBvP5R1KNscjwaBRETAcgKVabCe/VJ2w6WZdsHXYvNxYKTXDCLQmFOqS4VFDQGbaXE3a2IvWa7k5kWCiGZcAlxaYrpdfJqgKvWEXF4+xo950TroiV9zrm+g8HLKD2ll85f1XEvRrpQRPJugtXhuQ0wST0RJzL3qbM5s8CYDrfb1KsNjW+E2Rr99Bklrw6ODrdSYZlByg2osUzzKUkHjj0v9FeeB6iimgOeW45+DUXl1N2bUG3LQXMMYK8XGymbFwJMRObK7mHd0/v8KRYogZNe0cxTE1OUabrksjRcO0V+/OJkC1DJsoV0AyKmFOM/XxE0nJqKvOZmrsKX1mGmUTjH54f0bcOuzK4jVRf6UFJ88DKskqKtpLqmH4uL6WfS0DQNoWI05VIqlLB+/sTavMmL/dzMbw6QWf46sUDnlVLQTYeBnSvCNOIye+92Zfs9yUpKJQSKQAVpYIu6THPnJ07r9k2JY/1kexjl2jvanwtAnCPu2Oa4PhgfczFakroDGaa2L2WOS1O5oMoxETT31D3teOcyjs+lKVGDkTiZOSMMSO3S3EQIgylKEVHJ2ks1UraRwHDQuZNFZHtUOKjIU08q4+VIrw4Ab01oITgKnIMUiHVHZVSKLBQUo2TRIxtRGe2q5qfffl9nO6mqKDolkaqs3aGX3v5iN22ogow1NIoUA0iOpaCEvJtVPheKv/2vmDbS+23dYEhiDbI2Ato5PjEAnaPpBdSyucdKmH34hkJT0yqj8bUSrhRZTP0ViqQ9iKYqYKk+vaPcqqwiJzvpRpKlZH2XszVgwoVtPRx0tkWIms7mvKw30Mp+zgUBe6B2D1fy35XIR2I9NFCsdYMsUS133va5fdutcv/8a+imGKvbIaJZaGoKA/r65RlhRXFWgxvvxTSUSxTLlnLycatw651zqXliPYGGQsEJnQbQEF7RyoRsEJyVEUgRSXGcyt563HiJccrm0Z7cGvJQcYSmnsJP5cGXZRRcoSdwVzZrOsgQjXjC5TNK97rKDo1zLNYTR0l91cGUSncW9yVEcLXoA6ecnByHVQuq9zInHXH0N2Ra6RCyvlICjYWtxbDqzuFyRH9ODcqiBGxWzk82ruJ/iiKsStE9CYNGr2SVvGHZwpyWI+VI6aXPjm2EQGe5p6ItI0Ny7SLpAgpiAiTWjvq51nlcib3HquI6qXLpEo5XZsjmGItHr8KsHtN0b3dUlTDISJMSXF2NSOei8gYRwPzRUMCNqcz3Lk9OEx6kPfR3QuoY+FKxE5KNJXPudFWjGV5IbDuMFMiGHRfoODi3GC3ci23lWjcV6JI6WtBgEY4WmdVShVk/c4/ccWD+YZNX3K5neAHw3BVUj0T/ZBhkatUXIRONB1UkOh9lGa/KUw1zLIiqkq4rcZuyd2JZd/EAjafCBy/eUlKiqvLKayckPtu5sW5zvGnzNLXnaI61RRrEdnbfbrjwYMVm6akeSb9HqIVdVlsQvVa1Fw72SfVacLlhna+zkTfSu55LP07dNrV6VDFoQJSPQCoQYwgiM7HWO2lXBQ4Oijc45LpY3lmX+eSRIsIsd3JBMFeS3dmQNUeWwTpirq30F8jlPL5sg7GapLyStCGpDjwbIaponkgaaXkItR5nXtNak02RIKsERVhHqjv7qmKgdVqgnpRSgm7yQ6QAX234xOPXrIoWp7vFpyuZ/jB4K8Kqa6KimEepb+RTsINCQqVFEmlQ4T8kRfqBA3RJjGZtiyqjl1XcPVEyJyxTPhXOo6Pt5L+ywq1l5sJ8d0Z1ak4G82rHnfUopRwc5RCGuKdl5i9PhBOxwjdrWR/+Bl0J4FUJHSrcWt1ENiSuUwMi0Q67jEu4gpR7x2b5aWkGIJh92TO5ENJ+R3I6lYq2yavbdE60uxL/FhZt7IH3tLoUKmYnZL+RqooB4jSLJRcpSjnF9yYz+xEAVAGJouW0nlWqwnmw0p6u4z7EjlLzVtbjmYN+95JIBY06bKgem4wAzT3I/aNHWXhWZ9NKZ6LXMAwS4SlCH+ZK0t5KanS9lGgerjDmCilu630xalmHYtJS9M7Nu8vmT7W+WwQJCe5RDoaqGbdwaFJnfCtxn0kmyTP695SvpD5G0Xa9AChb/mV/+rf82qXxaKhN4bOlFLKtjWHVs7GczBAOvMfBEaWiENQBpnw0nm2rmKw7tCRsbwUNrwdGf9RjKJtOERyyYiexHAvMFs2pKTY20hfOVSvKC6ltG6s9HCbDDvvM4xW5k6ZQUsN9mJgMRf+R2MqQqcPipcqgAmSp4ecgtgJZC1t0xW61wzLSHHSU5cDu6JgMCUMCrsxmF6hhvxMzQjrJSFSJuFNJCtVOMOdyGQu/I+dq+hdbrp0JUZBR7LRzHoa+yTEQSv3kpRwMcKDwHzRSMtqU9HXRnrHXGhJUWWCHlwvUNOnTFISMqefJcxRy3za4oy0lDc68uHpMWE1yfLs1we69vm+vBia4UQMjQ4WzskSwJHve/05j+o1q6Fi01f4pDEna9q5LPlpMTBxPSFp+t7ShVqIr606HPiplDp/YyL1ckft/OFQts01LFlsIypp3EYTKmn/7tbZ8cu+fSjEIfV1IkyEGDhGhKZVlJfyvoal4s2jS/7gnW/yq+vXxfnoDWYvDbHsPqcrrCEW+oBwyKGncmrver5g7N8iVkf0BxCoe58o17JWVa8wOklPDRclQk3CD8BG8BqzMtidJhZSlugWHcOuIF5ep6Hmx3t+9MF7PN4f8Wu9lTWa01Mg9xkqcbJ1J+ms6mJgmFqaOwbKdEDfkhaj1h8JX0H3CrMXRDTUCX8kIWTx0lK/lDNgU0Fx3DKpeialcKUa73h/+5D0zIAXsSu7E6erO4Fy0h/SMCrrXEzKnsp6aeGuZwxb0TkoJgNVOUgF22Ut5b6ZV2DbdK12GRN9qwlVRiDmmur+npPZnstdzb6dYhp9IKamTARvtyWtLqSfSxKkwfQSWQK0J/DDJx/wsfKUf2k/yeW+ZhgMppFzjQj9AmZ3dzgTWG9r0TkKCFdhvL9chZVsIt3vODneSSWcN1zta9rWSd+dC+E+uWnHDz/4EJPfY0iKr9v7fGhmQvqtxWE7WeyxWoQfKzPwYj/naXtCyKkHKSdNqEGg+wM/0QA2ilzA9LqCzu7FcRrmicm8Y1L2DN7QDbKPHy43fGb5giFp/pvLz+E2RojvxTVpWJ30/OHXv4VV0l7h2dUiy85rYqfRXlHkoHHUJhpmKfeokfMvGtECGZsTag/ccKiSznu5yyX7M0WaK+piYK0/GiAeDLhLfPr+GZ9ZPOdZu+SDzTHN4Dj3mrDS2Z7J7yYATa4ukUBCDbL/RVo/ozwu8ol7ZxTa85UXDwkXJUknymPPZ05esPMFv7CqRWohjpwb8AUcnWz5oQeP2fmCd1d3uNrWWBt5sNhwp9oJOTk4hmh4uZmx6RaoaLDbzPm7CvjhP4C0S0gCH6pCCGCxz42h8hgX7SjsMubR5Zuy0WKU3L3SgoIkk0QpUN1wVg8espTyJZVfcBL+AFERMy9DGUEektK5MkZ99F5yntGjDimD8Qcp3wuALgIRpHb+moLy0etkouVIbBxLusZn0joJImM0sdWSe/uuucmlhuRnGn+W50YphdaRWAXSoElWfyQqGiHR4GQuxrLegyJjEvZ6SkK2CklSiGPV0M17OUCGWpyyA8s9QgyGIX/te3mJw95RjyjVzbL5qA7KqRLZi3G8FiESAzdEwy4UbPpKSHNjVVF+B623EtXmuThE1SmjQABeEbwhJfDWEKxEwmQDChKt+05Ew+AaYj7wk7SkIdDXGiKhjuhOeqmYTp5lLE1WHp7v5nylfIUnuyV9b0k5GhdJdnnGa57H9UgmpxkPueXxB9fOSMoHmIqgSyVkWSf/v2sLUlKEdYG7lHSGPwroOkqLlGjzASpl7eNGSlkcLGnw3nDWzdgOWXJUZ0erM9clpfn7ySqGqUYHiy/1oVrkIEA1cj3GtEni0K9F5fJE8pkQirFiRPoG9d5gjaWzlhCFAN4vJICxrSjlyvtS+EFE0UTNVtZUn7lhvc/wlEkoI2WNNleNHcr2zTVqo5JwUVTMKZgcKMXcG6rzUio7ynSTsuFC0A8Gfdg3UomE8AnyGom94Zu7e2xDyYtmLhL72UkJBYcqp926QplE3FnRp4my70c+hc7qtclAvyq4UKBuOImhtZjMC1IR9uuK37h4hNORyg5URmT+pTFfPjujYtcVQkoGOmvZtiX0OjvE4uwofX0fByG7QZG0Rg1ZwjxykPcfq2n63qCUo+8tQycH2oUNPC0WxCRlwv1SRMsOe0JLmul5M0erxKYr8YMhjvok4/EUhIcU0/Vnj9oowUl6ghtr0XSZHD1yHzKXynRj6bSmuazFydlZjJXqmXHux+d+ul4Qk2Lbl6yaStbqoK/f0wB9K1wshpvzIcHm4VjMe0d5zfPtHDMKowV5jqZzPNsv6IIlDcJXuin0JmvectrOaLxj05T0+wLvIhdmQojXZzqAVolUR+murXQm92qpTvsex+9Z58N7jSkS9bRDKdjFmmSkJu+m95gsDIU6GP5xsxCQMjqdGwwVwgTvGskJfud1JM0w5jS5hseCROhaJ8pyQFUDXeuIK3tQXJUbkc/2tSLlxmDJ5EUSpJmTzwdaVfeoCex1JQYf9W98plFXRPgviRgM3ovk92TekRLs+yko/V3PNBqrw9zAAer12aC5wlOUnmEw+O0o0vEdc1OJ148aDZeSiN4L6UmpRFn1qBoaVxAvbxBg89yIPoa63qx5brQH32ta4wjeEPdSzmdXBrcVRCpU+VpKomLbCuLlp0rKVAvp/dEvsq6AS2x7WSsvNzM261pK8spAWQnptm8Nm9xnIwYjTq5XqCT54qTBVJpQ5GZpOhNCAVVG/CKzxXstTl52NkdxHjGWUpI5zCSFFUsIJwO29virgmKlqS7Sgd8SrURHL56K0mYYrudDGkeNZZr5sEzqI+JE0vdCIne7VbisaTIaclmfSXLZCbE2+ppLtb+swWvqx9IPJJSKVa2p7/d0rUN5Du3IVa9yHlocMT8VA+s7x3vrEzovR4sqRQ2xuNLSjr6QtFEoE36S2D9Q9IvrY+gm1D0e+OM+HKNhadIx8pXyeZE70yYNoTN0ef2NqpZmNrB/Xfpz1C80dcfBEPStJVgpiS0KT8rk26YrDsJaIsKVMoF0oBsc3egg5ah4dB5tIyTHpDmgoyhFs3OsTcXQOEyrszrrdXrBdAq7kdLLfpkY7g+idrp2aC+8GLUz/MqTVymKBwyDzY6TRN+hzgawVejHJUmBG67F2w7N4rJRk3tU2L3Bn9dyjSoRq3RdQZWj/OJJwYuL+1I+ftxTT3r6zhLLKDwfl2DQ7FY1ykT2RYExka4RcT7T5vTR6GTfSPuNnYLVYIQI310LWx14S14x7Arpe9LY3MRNcdUZvh6MaJO4yP4Nj/JSSWJ32bi2hq+f3UepdEhFEK51O0YjbxvhWMRSAgaVOJBlx6ESkubbcU3azoGfOCWCwIUK7NYRKoe2WXzxJKKHrGWUHZWrD4+4LBbCP8opG9Vk5dsk85LOi+sKITXaA3nP46YJlewdvdfS10qLTLy0t1B065Jvpzui4dOaa7L8jVRYsy94V58wDJb2osJspIT8qjVsamk5Mal6qmLAmsj0zh6/1HRXFXbvSEoT+v8AnI8YFVYlSidllfuiPORbD2P0TAsOL0W+n0k8Oap1LlI5T4iK1tUfsYuHS5lr7/HwOdkAC0oALmtTpASdqTjsjNFQ6+vFOuZ+xzQrURGCPlRqOBvoCvcRYa9/4zOpa2coxTw3VmrKtYK9i7/pM41G7VDjn26gFlETY6IoAqUNGB3Z2MRN5GN8poOGgbqxEUfUIiq0htJ5nA14rwk3yJ8Hxvo4N9lQHhy3hJDugmgt6L05iI2NdeRj1JvyNaXXSMrywKL7EWzKvBvRRvHB0HkrYmh7EVoLCoKTqHUYDDHIwS3PmSSKHp3OJAceXpOIxENTMClri4WUW4Y64YcbUvlBnLvxGkJYlJRLqEW9tKp7tusC00GxESemNxmx8KC3lsHr63sYncki620ogZjU+H5GIMlcd8U09vpZDkjY+C5LqW7RPYfuriqBaiUidxuoLiPDRCLWwnq81dILpUu5oumj0aWgYonoJfr141yZSMr6CG6TYCrOGEocM0EMuCExf70HD6mjvNYO0WCAlCsfxoqAEdlLOq8nL87+kB1+5wJpPhB7Q1i5w/pUAdFbAVJW5wREaydcb06VJcatiZQ5NXjY/pn3FYt0IO8Zow6EVzvkaHwQJI1BZ8MrVU4yl6JZ4nZijH2tULkipmkNyRhS5iR165LeFmJgRgXiTARVGSXRWQ305h4UzsJ1Y0AzQMraQWN7hGEu2hLjGk5K5t5tlBDpS2iNo1UIemBEKTVlhCt14owPSRFMInYGm1EeTZLKlWw8D1/ju4dD2vAmKnE4KwZNymW5dpc7yJaGphZHR6mEWQzEoPDJobMhVIOi2UvDwNBr4cGMQnqjcxMF+YDrdOhhz+jr31GRQyVXbrN1GFK1l1AhV4eR08sTJVzELLSmB6TixyvsWuc0dlaUVulA1BWHcSyZV9cct/xORm4XjOmYnHLdmuuzaORt9Zp+7yBmUvq4fW88X+yNOGeDQTfXKq/JGkJUxCLQZ9ulVGJeS4XnmTeE2olM/g3hzH/b+D3rfPT7gqBKWlOgdCK1hlAmmI+rRf6J44E7RkwjSa2I0BphmZtEY6Qk6Zrdfv0CxKheXyfmsrmUO/gNjcMr6I1lpyF6EcrxMw6Ix+E6Of+XlETg0SIlpkHR75200jbyb9hbrINhzkeeKelr5bgD214jpLXO0HlNrxOtzepMgyZMBMb+rrnJ1xEFyXS4R99agpYeE3uTD4Uk+c6bm/Lm3ByeLxsaeU9SbdG3VkSbOoPJbdK/85lGePLAmM+kRbwm7ESB1OyFPa+SEIiHee5/0o8PITntYSbvkUEzIB0gk4GoEmpQXK0nbGwQeFaJY5EGTbspBUG5ATEnnw+kJI7LML2ee9VpGBRDUFy12QPLJD5yqm/sE+JreVfai5OgJxkNmOWDx8g733Zi5PslRGsOTPekhSx8qE74yPxxWJPjOr8umx0PK0HHQKoKhrl8fywFHp2E0VONViK0pHM3VRdJWjEsNPt7+tBD5+pySho0zgojfkTjfCbhXlc6QOoMm10lnXZbI43TfNaayGnAWCQRu7KCwiSb06w3D3yTDu9gXHuStks3nkneYTQKlYnjsZD1lHLZ6DZImbLvDakzEGQ97R/kNuALIV8rnYS42d8Ic2+OpIhKc+FnXKopoTdoIyTbZFLu6ZErFByHKHVU/I0uv5e9kB1jcUNSW4/3LmtbrpFg42gag+rzHJd5P+eeH+RS/0OVU3Y0Y5EOjfZ0Lm8mR/GHaP8GsnDoR3JIycm6iRZUMZ5l1+eiipmEG5E0iVeozCcao63USxCigjqcyePPVCaj9wvQE677a+XP8TY/3cHAyj3rVouzlAOMEUGJjSVm0Thtcm+kXLEFspZUIgca18YxOllL0UC/VESbFYxr4eHcfPdyQ/m+gvSB0aPxz786cpWkJYScpTGvC0DODXLqNROIR3vBjVb0yQlJ+aak+c3zGDg4r+JgpmsnJMv6j/bw4EDq/McpBwnZViRzo6eXV4IsZVK/aVUuH5e1nyK0RkixY5ZfqUQYNFSJ7kgRut98+/xm4/dstctbf/1/hy6qg+ceXWbMm5Rr1ROHviP5jZgiUNW9dEvdVHBWXm/KfLCN3RCFKyAs70N0lV1sV3lRGo2a3UWNubIHGGzU5Pd1IpVR7mG8Tr5GSqBtpKiEld10ju68xm7MIRo9IBzTKE6FRuShbzxTSln1tO5xJrDZVcTT6rpkKz9TLDLzeqzjd9/xTIAtJeIG2FxOMBfuOkIfD6FaVBcPzzRqIRxWfKKoBsrCM3hDc15j1vYaIs2RfpjmHjUayIfCR+bGyTMVNrDdVcQXFXYnRE+3lcivX0LzahDZ7K2hPBMW+zBL9Hdzpceg0e2NEtlxJadrPYdY5/4bgN5YbGacD7NEnEvorPbm0AU01LkXTQK9MwKRjoeKJ6ePxFgfkCmdCZGzAVd64eX4rGyowNiI0pGhcdhTaS/uq4Q/9qg6iPPT6QOa8BHnIw9RBs1GoY6YRS8IzrbAXEl7gQTXKZgir084HPqCpGhUP35O/pmGVEZ0JSmH1BhBQYKkEEyTW5kfRdLMy3WyA3VzecAN1ChyUKSMDsLCoyqpGhsVIeX3rg9EXLw+hMeLDpIqIYo4HS7v+yxARQJKQZS0Sgw7h97awz4VZyWjARnl8UfSDkHpdOhe7L2mO69xVxI1hlL0OpLKolIAXuVqNpXJqnk+lCAjB4gp/7p1gfmsYVoMnG8nUv2z1USX9+u4hhsx4LFIIpOtQW8M1am+rgY5zufEOM/ZCRaUQGXdH/ngYXFd7aI6I9L7aVyreXpNOgQQh+eLHNoBfGQ7GYiT/PlRoffXDR8Pr35EkfI7HdEDPxFSuKoCqdforaSPYpmIMy8NLTstUuzjHNT5nM/7e7wv040aOWMp+I0NomVOzVxKGUNjpTlbIlf3ydylcd2MNz8eFONaGp9lJOdmrgw6G/UbToJ4euqwlm/+XbLpujKxM/LcfXa+c+UXKiNXKt9XRjtHLZabZ3hKXAdMSZrDqS7//jgPOTjk5t9+50hK9tTIzdDXjs0BbekV5bmm2Iyp3Ovq0ljGgzN1UBxX6aDhFJuWx3/pp/79rnYxe4Ud1IFY2C8S4Via5oxNt4xK+KilPCkpJlXH3ckepRLvto6UJbtHgiIKWgdq4jE2Yl2gcMLKC/k6WkfmdcdJvafxjt1VnZUX8wHmyXoNstC1ltKvIpMRfYbnrQ0cTxoWZcvL3Yyz04nUb8cMu4Xc8fXo+jplKaqVIUmKJkZNVUgfg9oOfNsbuqE69D8Zc7n9MYQqYMtw6OJ4c24AZvmZUhKdDN2pQ4XMoWS4EgOqdcIVkka5OTfGRJaThmXZsu4qnpzXh/zl+Ey+Ar9Ih2cqioAz4SPP5JznznTP1PV8kBTNUIvzkat89CD1+MwHjpZ7rsIc0wsHZJiCmQ/Uk47dqkavzaE0NhaykUwrVUwk6JUiTMQ4qEFRbLJBtBAzj0VIiKIQGmZgZoMYyf11hZVUjIgSIUodcqWxilJy7CL1tGdWScffkNN+N8fKS/qhWEm05ZYdD4837HonTeP67LAM4ogcSiO5RgIAVBWYTjoKG7gYDKL2JIdTivnfIh7e5Rgdjw3yFPmwtLkEVEuzMjNqcVgxqqEzqK2jvJRorbsXmZ3sGQZDd15jWg2aQxm4Cgq91Qdp6LFB4DBL6KlnudjT9o52W0pZK/mwVPL5RW4dPvakSAmGzhKT8E0oInYimi1+MIKsRIWpPcv5Hq3gfDDCa/BqZC8x5vT1ILl8XwZevXtFoQO7oaAZLODohxuS8TOQlL46zLuU1CqKK0GVunuJanEd6qWE7J2cxpyVPR9fnnG/3PAr9jW+8XSG2WdOWBGlZ0lrSZ0WW+Eidj5gXaBrJhQbKdPeGwX3EpTirKjcbmCUDhgdvRHJiE7WsFZJ/DzMtUHMhkkXIc+1yv2LJKWRgoUsWX+IzK04BKYa14SUmoM4dyMH4WagZ3rEWdeKwUaKSU+vHOxEqCrZRDHvmVS9BFW9znytiM5nvO8NMaOaHJqtyTWTiTmFkfugKEXMpG+tkqC+Lof9GfWWG87/Kg4lpEpxaNmQEvg+kzIT186FSejKY5yUEI9Oa0pCsh5TdCo7oGP7easj621N2poDR0RVAVuIwu74+36whKAkcHKRKldghaAPhOjxdwE80oPp4HyMZ8UYNH706JEAZ3SwMop+KL8mO4w+p8eGLKjZiXOlezAHUq2+LnfPgUaspAzaVZ5ov3fo4/es83EgKeZUQcjaCCQRcxkyBK6LQFUNGB0YghH2cFQM24LiBtwYyuyZlRLVxqjoGke3K0AlbOkpS+kGuOsKtm2J9xrVmAPrOuRSyWQFGktJcsN+V9JkbX9XSo8JgMt9zcVuQtu6Q/RBhta9Eh7A+EzBG3ZdfiYXKauewnlCUrzczKTUd13h/OhZg8/pmFCm3JRMMXRWRGf4KBLUDpbH3ZE0y9s57Dg3o5iWQZQZ89y0+4I2cypc6Slza/d1U7Ha18I8b811Rcz4TA7Z7FERomGfn0lZyV8XzpOAs+2U0zSj2UkuNpZcE2u9GDulM/u8CPRLS3RKylSReReyYyRaJVFqMSJHVkqxQzZCjZEINpKbesm8q+HakfBVRgBMjoRyNC7pDSU9FnIvEiFtZm+/iOgiiGPbOrrWXRv70RgVXnQPcjdRkpSKpsFwsZsI/yTns+k1ZieR8CFyV5lTMerWJNjtS/ZA3Ftsbk4Wx3WZuRIpSmOr6PWhigKTiPMcrWdtBxLEwTA05vDsIyoWnejejNDvKKyEEmg6mUSqJHWROgNI6WLS+eda7ik2llWayL105gCdM6J+mRg6Oh4x5mjPpGvEJEO8Ycjwzog6BcV2PzYmEuRNBekXNHZTHZ3TaAR5S0nRR8OuK9jtS0Jub3+oCss8iAOalBFJX0NS6pCu8oMQrsfGgDo3ZrNGgoinuyWn7YyX29lBu0JFoNUM0aE6c5CVV8ngKfBaSjala3YWeIscdGYOXZ+9BBAHblE+4wBCY6VFz4jqZYMfrQadiIMmjtoN4/D6EKglDbhr9IdBEYLLaIs4GQe59FHgrkgSXGWCrRoDgpEzYZKcv0qLQxMVvTf53XIwaslrArJ+Ie/DSpr0jZ97kyt3XcmV0SeVMEWQ50tynRSyMzEifwqSV1KZpyCo0b6MXyPyIYhjAlLQRC0Oft8XhzTKRyCYEUnQid5Kej0OBlUkATaKmM9Y6euUOnP4jLF7cxo0jdfCl7qREhZ0IV+/z07o6FTqDHV0GqKcd7iMggN4dSjNFZJsOpwtMocpozzZjsxzBdtNpHccSr5iRjuSu7Z7wX9HCd5vMX7POh8q5rz1cZCmOplcFXNzneJctC3aewHzRseybnl+OSc8m0gPhhzpqCST55deoC4t1QBx0OiVo7iSVdy+OnCyENTkxYsjzMtCBLZGZMAInBnnXg7LfOilQWMvHG6jpJ39my33l1u2XcHl0yXuyqCjVEGoII7CcJxTAYrrZ2os7kJg/u4kwpvS4Onlekb7dIrdawp/Hen4WWI4yukHnVAqHTpOFrm1dvvIUy32lNbz7GyJei5pqPImBD2NhGWGOTOMmILGXFrcSiDi4XXFveWWzlvOni+wZw4VocipiAMkP71+phQUqTO4C4vdSp1+eCtwf7HlfDdh+2yGWxvheNpEv5R8uZ/JPA3zdOjEWE4G+tcSg5dyOpUQZU+dSAtPTOAqz3TSoXXkwswJTYHJiIbN7O5YiEAaiHG123zwVFkzQosxTDEfWE40OUJKqMm1QxJm8QCpllnIrG0d/qzGriWKHTdoKBPtSU85ESQoPOjo7+bDcOekL9H4+4DdGMoLdeg6OZYl90sRrDNlIDSG9ELUTp3P+jBJHISxTfqYd09JoRop601AeNjz6OElTkeGqBmCaCasn86pn9mDvPXYMKp5GAmvi1Q9jSVeZN0Ok4gzaaBXzzrqUiLYdCnluKGEfh5JkwCDxl5YdG8P85LyvEcX0S6gNAdnPkZFinK/1gbKiWjSbLY14bJEDUoE5yYebRKhNQxrkc1OU091VxqjtWc1diviccMyEpbS6biue3zU+KhFzOuiODiqoZL1pXuF3nMoe48O0DnVkvk2ZO6UMhFbSlWd1tJ4sTSBXV/wrYsFobXSWr67RtqKC6m604O6oZILvJQjOdQiQnWAuL3KLdnVgYStx47dSSqIhoU4xMor9KV0gLV7kWIXI6VyC/ecunB5X5Q5pZCbxtl9drJniTTxUhmytdddV3OZaTDCZ0pTD1HQPiIoPzrQEpSM6IKxARYcVFhD0MS2kHPrJuehk3JT2RCyX2MVSCf5nGvtoSIk6QQmo1Oa3OU1UdUt07InJMXlZkK3LeX5chUMKWuc3CTQZycuTHJvHkD1uSTaCEoQEtAaqueWYs1HifSH/06HdQ654drxgC2lD0v0ouqrNpb6pclaSNe/HxyESlBFNabW0g0uj7q+X5mbjMBGhV2L0i5KzuRwJE6zasS2jOddKkekJKc6kyKhD2eWPwmH9L062F4Rx1ODJllB7ItCUKpp2VOYgE//oSAfGlQdDg18/CCwtO60iMI0MEw1RkdqOxCDoVhp7O7aOx7JjWbmsc4LRJZzzqZVFFdI1HpfURjpl5E6TXGpDiqdBzJrGXGzHqWQe/EavMbuRSRKeUUTFLUd2PVSYlZeyIqKo7euIdWBct4Rg2j/p6BzlYEom46NeyorHW7dWlOs1EfId9GAngrHIHhDGASmNq2mWInx6I9lbkrriYOmvpLyvsPcWDl43KwXAuw4N/kQKq/E+PUPNaUVFEa1RkTa0o1nUsIvKGa9GJDBiHH1UjpYXgFK4aOisoKg2LW0Lw+VqAXGMjK2cyZJlK9yysA56ZUCMAxWSvy8Et2FIqB0pK4kPWVVZF1ODqRfgdvlHfYuQ4QqYXbivKKk5FNV2flAPP+xhGQkCh4Murnu26FNpCw8pfMMgyU2mvJKHSqdANQE+pkhlB6dm1GNSothl5UfTcrGLTfo2omYWHQciLR6KkiFdZ6ws1IN1N3gIY2HXW4cRiTDrLJfzF6Qgmgij6ZrJrZnO5TshpK1Ltl4UaAV/QcRghumir2L3D/Z0HvDZTc/3G+YCdphbKQuexZVR+8tLeQUiSBpduLxWyeKlhuuybW53DqqjG4Aoj9DRo2ukaN51eFMYNeUxF6eOzklFSg6EsK1loWvFbNanJX2qjpwD6IFO/GSlrSSBhyCRJ5ue40mjgJsY+fow7xmVC/WETUV3guDkJFT0lCosWEuRkkH6RAVYeMwG+mXo7IuxKikO1ZOjFo20stKjEV7T5rPpTp8RMV2/D11SLvcODLLmJ0PI/wIL8JZdseh7HtUi42FOuj2hLxUROtC7lNlJMEUkZCjbLvPqFiOkFGS2nAjV2hM7Q2GkJ2UVGQSqEoYA1r7nOqRpouit6GukQvIqY6856z8a8pAPfL5VEXqijEvdoPMKl9aS8fek3ovGhptSZevq4ZrNCyZa52lm+skWUXIZNQD1wpBagjCQSrWUJ/Gg+T46NjJ2r6BhJDtWBGZTVva3tF50d8Yz2q7T3lvQtIK7cCMVWg3KoFiOWrZ5LnPDle6QXzVfW4EqbIoWkaPpJv6KLswOkfirGobJdjSCmndESnmPbOJVLPEKB22B29oYynz4KST+7xuMSpJo0sV8Xbgex3/zs7HP//n/5y/+Tf/Jr/4i7/Is2fP+K//6/+aH//xH7+e6JT4qZ/6Kf7e3/t7XF1d8Qf/4B/k7/ydv8MnP/nJf6fPORxQWR8jjbk3ILkkkXQpBJ5dUwovoTMYlw56HekmbB0UXonzMsJ5oUi5wy2g4GKXG79E6beQwrUDM0YgMchqTRkWRid8nZm+VRJBm82cppWINpR8VIvByPXHZzpcx2QZZi2f3XWOF5s5Q2exY1XCCE2qDHcH0dlI2ciQZD6GRV6kJrHeVyLcNejMibgxNznaCF4LJBryvSjxsKUaA0hwup0yDMItCCUHAZ6UD2Uyp0O4BePcSPQEUpniB8OLzZymKcBk1vcYddlEIpFK+fyxXfUwWLSWdvMKybW6wh+i4xgVBEOTFM8zCzv0BjWm2Qo56FEpl6qmwxqKuZz5o6XVeY3ld5I+0u79o/8Zgma3L9lRytpTIh2fdDpEQyOj3ndSDaSUP8D0fhLw7sZFkSipX6pD6+ox4o4OUmPoBhFiimM1Vj5zU45YcELwTTeqGmIZ8UGimhQ0jzdHWB3Z945usAy9RMnXWhniqIQyQRnpBivCdlXAL0cLKyhZ8JrNtqbpChE1sgk/k72AllQKNgnykJ3qQzWWS9JKPcjfmVJK+BII+pTXVB/MAQXp555YaygD1oYsthcPkZ8yIhCmlb52ypCD128c3lpSUgdUzUw8/R0pzT9EuWTHPJepS4VO3rtJEKXDujHiJIegJb2qEn1es0Mvlj46ckmsNB8br4sipzmuid99Frca5kn64WRifKglR6+G/BXH9Fo+yyoO7z5WeS9Gclde+bCxWmWswhn1HWJxHf3Ke8mOSRVFTC2T/XulD2lR4WcIyjHspGmkLYV35k0iDLlCIj/D2Op+5DmkFOUmlDjVIzH44DTDtUR+djLHfWddYJgPwrPIXaflh1KtEbwhRi19a5JivyuF0O2viehkjttYFXSQINA5VZQ4EGd1kLUYx61qRcwsGn0j9SQXGfVpDgGISoIstYZVmBz2ubJCkG3v6YOuyYh+SYqQg1TDAeEoclXaGMSOAZHNAUcCP0802ar7sQgBCbqGlA7n4LgP1bgOdYJChDiVFU7ltBgYombTOPreSFDZGOlAHBSNK4SaoDJnRkHY/w4iH7vdjh/8wR/kz//5P8+f/JN/8rt+/jf+xt/gb/2tv8Xf//t/n4997GP8lb/yV/hjf+yP8ZWvfIWqqr7nz/HzzFD2uazrhjOZqkD3aCz1gP6iok+VlPSN+fjxd/PLSZ2U3d68Tlx42lyOSFTsnk9lg3vpj3DzGgcYvRld5fxDk/B3BvxJvk6vWT+dy8LVHGD+w70YpNzvO56JItI/GFcZsCq4uipQQdQDo/uOZ3JJytlyHvnws6mnnYz4naJ5OZFnClkyOH30OmiIbS5HHa+jIBwPNEfXc7N5Os/XUQzL+F3XAL77mWxkuJsY7iLX2VmutguZG5voj+S50kQgPuuESFk6z7537PclvtdYF9CVdAe2JjCr5PPX+4pmVUm5p1eEHE1SJeLCi686lsXmd8XoRAJJXZMex8g7HSKxhCqDdClOSvKzWRkQJVFQHDT6yklPGyOHWXcvkExCTwdsEUjewMahLgtiGRny4etcoLqzw+hI760I1wVFLDXNVJC5seoIJbCpu7SHXixhGg+O1GGUEoWOxjBmboSoUIZDtP7iw2NIubQ5EweVTbT3hcmujnpmsxYHGG/YNQVaJxbzhurOQO8Nq82EsJMILrQFcVDirJWJ9tHAWL0Vg8JUnnLZUNhAN1jafSFz2WlpCjkIPB+OQJfC70iZ+e+1Yd8VmBzNLl5thUgZRMMj5Ih7yDoT2kW63HCLoA5kSLtV2K2TZogPFG3hcSZw72TN5MFA6y3PXhyhzqSMIozl7ZmjNZZeKq9QvTRjYz5QVIOIGTYWenGGQ06xJgtUknpKQfgFMQgilCYB7fKzjtU/o7EdSYDZGVDOY2ZixIM3hEy0xSuGnJ5Ik4CbDPLuXSSU+fsuYrKT5myksIIgKpXQCmKCIRgJYpIiHClClNRhlVsLAIRcxRWDZmjsgX+i9xq90vhpwr7Sc2+xpRkcK13heyvOIWQ9oHQwUiA6Q3AdUGid6DqLb50g3EXAZcRwnJOUFItpy+xEjNzzqwXteZ3fi4KuIAGdKuiUGHvdS/GCkKA5lJ4PRxG17EWfUSWUjpLu21tULsvWPiNtuWFeQuxP+4ZwuNCCHIzO0ViC6qx0NC5s4GI9xT+dYHcShKWTAVt6qAbUfTlPmm2JunTS3demA1cmWanwUlqIpNokSS3ZiM0FAX0vYnMA7qilLgdiUrSdO3AjWQyknIJJg5FzUY3PLdfUea6dDdyfbzku96y6mrPLOX5V5O7H+lCC63cVfZmu9XKiIrYt3+v4d3Y+fuzHfowf+7Ef+01/llLiZ37mZ/jLf/kv8yf+xJ8A4B/8g3/AgwcP+Mf/+B/zp//0n/6uv+m6jq679pbW67VcyyURIk0qT5S8jDEqthn27rYl5jKXb9l0ILnJRfI/Y2ke+UDPHqMugxiIBMOqxOYSvVjkw0ZdX+MwsjLo4ToaTBUkpTNY4mWByVyC+P9t799jbEuu+nD8s+qx9z6P7tP3MXNn7jxsY0xMgICDjeWAfijCCkQoEIjysAyxkkgIYgSGCEi+kYOiJBjILy8IghBFIVJISJCABCJCHGMMKMaAjXEc+2uMH+PxzNx3d58+5+xXVa3vH2tVndNjY8bxMI+rs6Q7c2/36d27ateuWo/P+nxqAUrt3ku5ZjDnx+QYtpK08NB60J1qKypVp20EvjumtD0oy3WqVJDUw1kFe+wL62dS+vhzETz9AXPTRDgfpdx1WsEt7TYKfIpjgmXYWsCWY+/Ax5VgD8xOK6OTThHrEqo64Gja4qDqcZNm2Kwb8GgQd1pPKxcx9YLkX/eiCkqBYDciRU9J6vJ0JJ0/KVqkDNjKaHFWnoBKnagno+ETAEMwlgvj5cCuAC3L57TkVp1I62WcSFeAqSLm8w4HTY/TtsFqqYBjGM0uEYyJWEw6TP2A1VDjmCEaHS4BjWyyZBKc1rzbMIFtpVtmPGQEL102u2YrceAkspQMBjNg9UBjAHFZaRkAIo6nqp79BXHGqYq45+IZPvvoFoZk8aHjSzjtZwAiZvWAq/NTLIcGq02DmKBskgS7kRLaoF1gubuGE8HahHsPV7jUrHE6TPCEOUTfeYTgi34HCIhByikl7a7OYAgSYU6qEVemKzRuxEk/wZ12Kuh7BXiXjKYepBkoDijB1gCwIwwLixgNnEm40LR44fwOlmODW6dzRFT6fmm2Sdd87pwwnbSZRo0WqyoIm2qQ71GQcrAZJPsz1OKEMZESbBG4SqhmQ2nnD0GclqqKmNbSVr/qaqxVpda6iEkzSilp8BgI2qEiuCQAMJMAr++9HPLyLs6nPS5MWziS0nSzkxZPTAjJ4LifYj3spvjEQjSIycAQl/saghPHonfgzsKcKZOolej3sO7kPsedo0WzsvkdI2J1fhjJSCt6U43w2dEZLZglG+t2DvaUhLNl4kc8MDuFoYRVX6NzNZgNTDA7pcgtb0zODpasZi5f1wnT2aAA4QhvJct3Ok4BBdNLKUqT7noN8hGTeY9pLc/E6Z88p4kJEz/iUrPGzA54T7yKk36GainrfARglC30ntkaEzfiY9URjsdDwbvkriQD2DqiboZt5ldF/fI+mJhkj0kS2B/NWzx8eIzEhI+cXMTJMAMzCiCUWQjXUtwGnARZy95HND6gcgEHvsPCd+iiBEWmlXVvW5EnyHxBuWSYO51ivxt9fmp7WjEfH/nIR3Dt2jW8+tWvLl9bLBZ45Stfibe//e2f1Pl405vehL//9//+J70em+1DwGBgT6wAnRrGuAgwPkraTTVAAK1p5lMxz4OBADMhEaRdiWcf5hbjXPiGaTBb6mZDiLtsnznzYVh4BiLBrJUBzgLh0CBNJVqzvSoiWigZ186ASA97JwczBgO7NKX/OyykXYw7W2i64WXDzC1R58aU56YzcCciIR5mCeOBpJ+pt9v2YKJSPz0/Jp0bBmhjCzAxHBqMcyoYm4ybkDa383NT+rwdyyZ8ZpUxEYiLAJ4QUi+y9WaQhUuZTZblkHde2hOZCUO0WHU10p0Kfm0QDixCLZHquq9wspoWLg04BlMC97RtN4SkZut6RAgJwUoGIGlJKO+CWSuIMopc22vdShykAAC10LEbw0AVP6HlLadlk6Zzycpcrjc12rbC2DnYlYXrCMEAiUS2PkaDa8cHRTdou+j1kAJgYABISx98EnI8h9JpI621VFroeKd7YWw9zKkAg+Msws6zfjl006EC0s8dKTnTc9bWeF+4AgDoRwerjIanrZTworbBmmmQrBmMsGV6AjRlm5JgtBIBKRpcPz3A7fUUfe8xrKqSLs8lB9MT3IlD2ljtguFSJgrBIiXCxnrcMjN4GwW0fDqRDInZUlMXXoQkrbaxYaSM4QhSEiMG2mWD3gtb49z3uslmunaNOrOTWieYSZBsF5xgBZzsA13nEUdbyLZM7rDSDdl0ZpesU8amGjHWJIzBYmi9ONmNAFZjkvp6Gqx0ZDChhTgVsrYD4HEOmMuJ0K5rZJZR0lbm41mF9awuWYecychbQEwG7boSGn/LqA97HM1b1WySLMgQpbT2CdTZuTRHAtIkAvooWjreRqAG+t5hPKuEKM0nhFmA81HWhkoHxEbW1+gi2rZCWnnQSIiDQavOq/MRk3qA1W6irB1UtHewzVAzi6hldkQytmUXJwEDUGewPp6Ik9OMqFVmgtcO/kzGmiyQDtTB6yVblyqLFvgEsi1jBOtjTEJQnMSJieiDRZwmDNFItyRLe+6mq3AtGTgbsdrU5T0WZmU5OCKLrhQg67FPTjCHfivg1g1enEEG7mBW9LH63pd740QFzJ1aB3OmwWSTELShg5Mwgg/BYupHVDaKTIJm2hMECJ2xMqkWMjcpVXLBpz1Ve1qdj2vXrgEArly5cu7rV65cKd97sv2dv/N38J3f+Z3l38vlEg899JD8wzDsRLIKw/UpDj5KaI4T2ksG6wc94kxUNv2ZdpIoRqPU3fIh6RP8VD3+Gx6LDwoAZ3O/xeZ+2WD8mRHgGYARwsZYqHWNtCVRve3Nrz/qcfhIQqwIqwcd+nvk8PNnBrbFFtSZX4h8L2YbpfR3Jpg9ajC9kdAvCKuHPMKhKFT6M3FioragJn7SmCwXzoN4PMXhh0Q1tr3XYv2AkPiUucktVJbVeUDJcKCO8BMB67rHKiw+JC/o+qpDe584aU6plQvQSdHl5V4IoEZSpMOqwvSaweyxhDAlrB5yGC6KU+bPxGuOimOIkEXtfMC06WGNcJN0wWN1MsHh71tMbyacPWSxOfCofMDqdAL7RC0O3iHD3tPDuoixnYhImwLwFvMWF5oWbfAYokVMBt3o0OfW3yqWzTwp9iYMQmZ2+FFG9MCpceAj2fyqeiygujDKYZg3CtMDRjc34xPSYIGbHrQhNKOA/sSxJQwEzJset44PYD48wfRY6Ma7KwE01ZbS3E7dRPhKIspqOmK4R7/nWBxvgqDPOylRJGuBidynveNx8CEDO7I8gybCaF06lyKKE2JkE5ofdHLI35xhPLZSe77S49LFFfpgcXZzDntqkSqGvSxfP11NgOtOVGKdZBPvPVxhiBanqrg6dg7p2hyxlfd00m/ZITNFuu2B5pbyghwatPcIgp/ZILJDNIzQO2zWEuGlWzUm10Q9eVgwhouppMYRNRnnGOEobB1tAEiAWVvUH/dIzuNmkMg+sfJdOC54JTaChfCHPRbzDiEabBqhn0YSoqexq0t3h+0BilTEAk0EACMYCg+Egwh4hqlFpmFSjVhtatDtCn5DCHOHNYCqDuhbD96IU4OeMVpxDtxsxKWjFZqd8klMBo/dPIK9VheF7WopKfbx0GI48NIiGlGwF5kZ2gRgfodQnzDGKeH08yzoYANLjE2sMPQOY+tRf9xjflOyW+190jkEw0hHAYkEmGpMwmqoYIhx2PQgYjzWL9A85tHcAoZDi/Z+g2EaQRuLWpXBx0OLNpKU3E4rTK7r12cW48JirBL4aMD9R0vM/CBdd+0MUUsLxbtTzAVFUqVonYMDwTNJuRpFmLG6Y2Eft6K7ctkhLEbwYFHfdGhuCY5m/WCCudwjbhyaRz2a20BsCG1Xoz90KvCWWU0ZOAgCgifGHcwAaBbz4oBwIQcLBnHjEKNHH7cZuhwbmNbAtQAlwrAgjF7kHWJuzWVgmArRI5EoIWOpRINDhX6cAka6M3E4FsqCMFrEYOBuO0xuarfjXB0iyzLfjRMdI5K9uB21XbhOYE8YGrmvsv8bCTixsqIV9Glwlj7r3S51XaOu60/+TYNCmjUkQn2SML02go1Hf0k0BESfQv6wBTLJTY7qcsbCa8opDYTJ7QDXJoSpR3+B5Do9lYPL1IQUAdkdtbpAADkhjgmjhWuB6Y2AWBv0Rw7jgSkIedtDOxUAytoquQ+bJOqpqoAeQHXKmF4bYYJHd1EorW0e06AvSh6Tzkkek9OabAqEyZ2E+jggVhW6S5LmNJqFyXwNGbUNs1MxsaLvMgxCzjW5qV0lBx7DkUxizuYku43qxCHTMIMgjK5VwEAV/Bljdm3EsHDoLlqEKalQlaa+Cef0E6wV7R2dcYzJAJ3F5LY87/6wwjpohNdZVKcEv85gTIm0RzNR8J6MbOpHHFQdvI1og0TrSUsbzKL14a3UTKXmbQDaea4NYdWJG5+jGoKkVWMkRR+iaEIYLckYkxDZwm9IuoJ0TZgg4mtEQG0jUiRM7hDmjye0lw2GhREOBGVgpETgKGOxihHhiaRZi2k6O/M+ZGQ7IGyX01sJZmR0lyz6aMA6XlD50e074hIm1Yh+dDCtweSG0JCvL2inU5KW3fq21PfTZWDRdOLQcda0kCzWohIZ+9Z5IQCMBvXSoDpB0RWhpHTrWZCvZ9SnrM/PoD/STApBMBHa+RRVEK4+JUxusrYpkgjbqTNIWqaNXjqTyMrzM0rahDNpR2QLhIWT8h0ky5IdFc4Myj6haUYcNh1GBZt3xgsVe2dBCmQ0I0pbpFFAprw7KJGhfEHuxdkEb2Sjcq069xYYBxHD5NHAaJcJR0g7qWHwVFL6B1UPRxHOJAzR4TEcwW1EB6Q+ZkxuC59E10tmtWiK6PuRPBUtodn1hMnNAcPCYfVCW5yxzLmCwaA+JsyfiBhmRgDRh3I/rpFMhjFSFhiCReUiahtQq4Pkz4DpTeFeGRYGwbMEWCsRc2NDCAeSJctfF9VhUop/g3QoXYSHvsOtOEMfHIZgC4nidq8HkGQt5jbk2GynP2MAEVEclOQJcWIwNkJl7zZAtWRRbnaMg3mLJU9gRo/6JCFMSIUETXE2c5v26K1whuzgx6iOmMyEFLDtPfqzuvCNuI0pHD0CGWDRiGnFQY8NYQwGSdeEBBqEZICgYF7uDZwyPfulsESzEUBsPJB3IWd+UzCoOnFOt4Dl3PlkJFOZCH3j0I4eQ7Ditzsukyjn4Q4762CQvICRn7XMx3333QcAuH79Ou6///7y9evXr+OLvuiLPq1rUZQoLwzSFZLb6IYjh3FKRRskThi9BzJ5CgElcgQ0czEYSUGxiNWNMyOCPw0pzz0jzCWlJL8c6sTkFL1cL/UWnakkHerEk4+VbNKshCuiR7K9TiYWMlDkPxmEwaKDgkkbYDhyGGYk8tmq4ZAubD3hfJ0M4IeRDXnoBdAFBsapAdiJqq6yEoYphMhMh1BSetCXwwDcW/TOi0dsgfFApdSbnCkBxkNVDc33ouAig20WJPYWPXkhI6oIw8JhmJnStZRIEOLj4ZPG1Bu067qkMDMgjRKhPzQwwYt6bSB0bQVSzE0WUIvBiOy8V+T4KK1ij99e4IafF5Dcbisgs6yrNh++rCn2XqL97oIV7QMmdGc1yAkmxbqIlGjLgJiEv0TIx6RsM55KJMxGCKnAAE1kPGHK4AScto1kRwiIubPAiiPIo4E7UxBmR2jDBK1PhWbfmISu8xjX1VaPxmcWU6BTgjkPYJjTljgrKojTKb1zIqSJHNpSgzS4desAHA3cIGs6KyH3waEfXSkrmIEwtA6311MBu80Zm/skggqtwwdu3CtlMWXNRCfZQNeybv4iYhYbYS5OXmjcRSVY3qHYJHHGFIVPuslRpqFnFaXzss7jJClj67ZjRTZGKxv6RCQTEhNW8wrjWg+tQFifyovPmTQPEPAiG2A0WNkJxtFtgaC0BUBKBCg04qRdYJkrJXdMABDwKWRfCb3F8ekMJzRFWHt4g8LfQK1FGGV8qU5ABW3TlYMsbpyUsNxUztqctRlsKcuZkeQwSqKdkx080nWe359k5aweJwS7cBincoDdOp0XBs/JtMc6EpJ3JYtLkYq8u/MR80kvpaJopZV09Fj3lSyrziNMgM1lo3sIl5JQbFA6umS+rUofAKEhvXclQEyE426CPsq6W55NhR8pE87lbBUYTIRhwaWsmrWoctBTVHN5W0LI+wBIzoH+grbQNlKacz4izBj9wkgnikUh4it08hHiLBolDuvVsWDAHSYcaDYoBCtZyiBkiKaXfXo0AHJHVW7WGgFaibBgdnLB0kk0pqpk9MJC+VgGh+pMzy/W4ysKOD7rLMWK0V6W9z5MuHTUUZSsCwfC0HhstDws+LMdXBwgIFUv2a7kRMcnRUJqt+WgP8yeVufjRS96Ee677z685S1vKc7GcrnEO97xDnzLt3zLp3Ut0xNoY5BShdEybCD0FwlhYlWiXMh+0iKiOWrhbcTp8QzuWgXXaVtZ1L7mZEtUaC2wuSJPdjjKrZ4JOBgl7cyE1fU5qptWo08gBQgOBEBQeuPQAKurdkvG46Vzwy96zGcdNl2F4YmZkJhpqxkbgAOQ2GN0DqYn9EeE5CzCVDYw9qI5Mjnq0FQjTpdTmMeFUj1ZUXJlApAMUpJ0qgPQ3kPojyyGwx0w58UBk0PpDljemqG67qUul/lLDJDYIgSJtFPFWN0v0d94qK2pnkGLAfNZhyFYtNfmqG5rPTRm7hFCYoexl0hwnANnD1jEZmduqoT6qMO0GUTP5fEJ/Jmoe8ahxmgrZVlNxTHZPMDo7jXC4NoZjEF5MYwQYBEDae3RBwM7D7CXWqlv3pzBfmAGGgBtXVfyIEaY6vWzhgXrBucBk8SZPXtYxkcRqB73guyeJ4SJHNo0ZCeHkR7o4GY9uraCeaJB9XFfDqPuHt0BLAQXYwCMFqcnU9DGFgclTACuk7AynjlMrhGqM0asDMa5gC3bqxFHl05x7/QMH7h5L9IdD9sJgV5aBNGCaB3odlU0Njb3yZoPM9nwORLswYjZrCvANUNANzqsHz3A5JGmsMCOcy6gslVbY+i3G6VjwN7xOE6HgEtwVzrgoYDYergnGtCHKxgPxJnyvywNmjssSrkTg+6yOLfDBYZ94Qr3Hq5xsp5geWsK6o0w7TYCKBfQoVBad0MDf2oKX0F/EQAR+gsJ7mhQgLGqDyeANw5mJfNMswEPLE4BAI8kwoam23LJI+I1xEb2FUoCrLOdOtanBsHW8j5cHDCZ96XTASTPDhNJt0tmU5yTofdIx5Vs6FY0YjgYmJWBXQmjpfGMVAPDIommxk3xCsZFAt/bw1URw6qCueMlq9I7DCcHwoDOQG4npmlCuCyl5eQ9QOKwxAlKOykbwKrPlRW8kwdwkTDOHdhK9nN8dIpxwpg/sMRnX7yFR/0FrCZN4a+wPeBWFuFAHI8XX7iFk36Cj925gG4tnUzUivYPAegvJ/T3oOBgstR9f0Ewa6Rfo6RlnauhtHKXFO1ocP3OoXQ6ndaobls4zTbEadpq1ShWL14MMNqhM5408CcCsrYDFecwiwCW1uckmKD+YsRwKER206MWi0Y6OG7eU4OdShkkKNhSJSoigJ6Q1gZpFOZZfyoZ4819hPnDPV6yuInjYYLH3QLt4LHsDlCdSPZ7ONTyZ7XTKZUkO+PXSo9vd+71zIKSiFJ2V0fc8+AJAOD2cAnTawSjGUZoSdmeOFSnsnf2FxPCA9LkwdFItjUQ3KlklZNnDFRhlRl5SYnisvPKgHGM6bTHtBLQ7dSPsJQQ1j0+/hTP+E/b+VitVvj93//98u+PfOQjePe7342LFy/i4Ycfxhve8Ab8w3/4D/GSl7yktNpevXr1HBfIU7HsRRIBZDTz0cihmT18tgw/GfHg0QmO6hbvGa8ioJL0OwhJ0bwilKQRMwGjtlsXimzLmM57vPjiLQS2eO+yASVXUM6UqxW9AaesXMkCyLRyELJSbV9crPHCxR1cWx/ikVsTmGDApCBFC2mf6wEOGpVWUGcqe/kM00Tcf7TElckZ3s9XcGZq8XpZx2RkfPoXiTAmANXaceHkOs10xIsu3kFlAn53UwMsG1iCZi1Y5tiwKYs7zPSgriFeuGMczlt89sVbOO0n+L07U5CCoQy0xgoAvaQZcyvoOIcyQ8q9UB1x72KFB+cn+Ii/iOs3pExilbGRSQ7zWNnCPzDO5S3PugNmVLY/dSYAcVKYDNxswMMXj1HZiP99PEFzS3RiCpmVlfopG1HGzEyOsg6o0AcnLxwLYNmo/IqU/McgKBU59XIv0TDm8w4vuXQTj60WuPnYBH4pz3KcS+dL0U3JPCq9BQ9OCc40/a0YHGMSOBL8Sg7qWFEB7vYXDGZ+wD3NCh8094hE/VrWD2u3UGhRqLrZ5PmTZwDVOjE24uJsg9oGNDagsgGn/QS/Hw8xuSnja++VGnlu7w5K/+6znhDJIcVrizQBDi6t8ODiFI8cX0D/4Qmm14WDB0m6KWxLcG2C2ygVvqHSLvzwxVP8scUNfHxyhA8TJLulbY9ZQ8O5CALQkWzGmUE1zIUunadRmGZdEOZSTccPrSslByLgqGrhTMTxdIJ+Xgl51lklTJUkoG65b6hQm6wx25EyshL6ud1qcuTMmWFUkxEH0x7OSheCNxF32iludgsh0iJdO0r7Xp0IFmg8JHSTJIyTo5RN7ADEqeCS5tMOx707f9jlw1MxM2yA1hPcdIC1jH5jESZ253DVjE1SEjegdHyAZV8l5byhAPilQYhSZrxvcoazscFSZS7K3hzkXmoXcG99JgDLJOubBiFGtJ1QH4yXREAxbRzMiYDpY2bl9AyztkUTKNYMmgVUzYhxcKLfo+WL2DpEFoLC6kTWeebEIc165P18dtDh4aMThGTw+/Fe8NIik8fZ3Fige9657kgDcCPOjKkiZs2A2gY5XOcBY8zkbdpZo+Xj7MyYAACkToNk+/qLQGUjrtRL6dIba1iTsKQ5bMeo1pJ9GEcq3D2ZMt4qaRhF4a8KE3UiR8AoYWQH4Op8CUMJN+sLkkEqmXs59ARzJ+uhuy/h4sUVAGDTSWCRenFmbCd7qukI0duSeTRWsQyJC+i+dhGzasDEjbh/ssSha9HbEW99imf8p+18/PZv/zb+9J/+0+XfGSz6ute9Dj/xEz+B7/7u78Z6vcY3fdM34eTkBF/2ZV+G//7f//unxfEB6ORnIhwLIfyymja3KDz3MRrcWM1x0k1ksdal12V7LculJY1H2rJo2m25pO8dPn52JIJgSbQ34i5MneResnaGcVQOtnwNADhrazxCF7DqagH9zJ50NxkQq6QwGSBVPHdFHd9azbAZPTZdJcRh8/PXKWMykplhR0DcvR/GOFo8tjyENXrwqez5J70OA2mgrbR1vh9ibLoKH1teQK/tc6JPcn5MRe9GnQhJZ3I5WDkRjjcTjMlguWmEeGrOBURbwL1Wwb3axVEyPZU+1526YiGRM4Iev7meicQBiR6JOdDugyjvTZgKWVPOrOTrpFpVRj9JRiSPLzY73CYWSIoHWm9qfNhcwqarlCZeS4IOyMyNghlJALRtOG6d1kwEhUgInVeCKSnPxUoiVyGESnh8eShCaJsaVAGB1dEcDELMjpQ8692oeHdeQy9p+9L9QCwllQiMc430GwHPce7KghzeyWuWxkFKhEoMtVo3eJQJ600N60R0Ldbb+aZk0B+JEz4cSEo8zKTN+sbZHH1wOOtqbLLgnJG0LgAEmzBYXbT67qbcDp/psRPQdx6jtYU5M5MS5vZykwg3uzkMGKuuls6NIPIBQjQoGYj8roselP5dNWHye9K1VWHmzFwrYXQ428g8LU0qnBVQ3EA+7ESbZDtHcbIlv0uZIFEbOMaNx2k04KzOmoHCaslCNAW1pDJuKgSbgKSHuGYz8zvPlmE8PrlpK3rRSbGMtq3wvuP7cLyZIDmgvSxl1HEuXErsGGddjd8/uwd32in6dQVqbVHGzeKXNJpywEsGkcQpZwKPsq/2F1XzpJG5S1mLJceNjKJPxEbI/ChuA8iiTaLrZ7Nu8BgtRNBy7eB1Hyjzhh3HzMj/KZE4MBpspmBwcjZBO3hxaHtb9oOkzhgxkEY96HPrapJ7HGdSSkyOcWM5xzvoheiCw7JtELRLp78gnwlTOStSxduSHeu7b6UMFyeZiBIFz5dLYY8uF+VR9hckWGfLoLUrTmry2/Nm3dbSWajPLGP5cgnYjATeSMnyHN2BOqCRCe3gRQttqHBrMxPw8/qpk4wRfzrw1GfAlsslFosFXvB9/xA4qEXe3LEQEp1qLbwB4mEQnoNIWyni3ApLDPTCxEZJgTyN6o6srbRRsUZOc9FqOUdGlfusmYBOZZ1JXgwoKNCcWUkfOiFE46mSOGltNoP4yLFkOfSlFOZAQb1j0DENkiUIiwjUcTumBNn8lWSGewPT2oKs5kbQ+LSxcGeqpTBlkdN2Sa6R69+WS7sxOltYAcuYGDAr0WEBAeNBAs/1bc1zszumqGPqte1K1V0xEuzSSWTsgXERgUbKFSqxidzeS1aIc6wTz1rwGQIITZ2FWbmi48GzKEyIayd6OaMebodRxpXJwRhAJRgJECMuK2lDZiAcCqkQAPBxpfoajP5yhL/QA8QY9WVkoxGYdo+MrQd3O2gqxjlWTLaMNE1yL4lEtlp5GOzhIKDY0WJsvSqTSso/A6VTFoTTlG7GcqRGQ9xIMEPOUHHJDlHujgGkZJXF53T9gyEluNxqPmRGRSp14WKyx0kaW6m6TSUU6jEa8J0K/kzLXg0X/QtpW9L6d97EKikfmkbacd0dB9cq0+09A6qpdI1h6Yug1ja03uHq2clyZWVa0X2C0I/nrq388bgzH14iaxgdhxcvdGw9aGPPf0YPtyzWVYT1HMCHI6qpMGqGlRepdqNOe94nIhWcGA3bZy/RfZJr91JmTF7KUZnwrjjywRScQOaqALaRNVjGbxV0Gxt5B2DOBwMlq0F6j/m9Z7lHsHRomIG2JIyZTjxzrFCee3ESsugYjK6zvJ507rk3cMfyjHN2gaI8p3EhzJxpGtFc7DBtepytJgi3GpjOIB4FXL7/FIdNh5O2wfJsiqh7urTGk7Rmd9v9o7B7aqajkOa1kuFLTuUJWLNlmx12U5LvjxdkP2AmKdF1RuYjM76mLa8LG+VJ2qVgyPOu65YGglsrdYLqQrHbZrzOySBAg7Ushmm2AM7SLs7YngUA7MGIC4u1tOZ2tTjB2jqbO97Yc7l3d2rhl+qIuLwuJOhLUwEA+xPhRwKg5GvbjFoJXuw2QEweWxK0gwBXB6ETuFXBbQix6/Dh7/t/cHp6isPDDPD75Pasd7v8QcYGQjLmE4yTjg4BHm0XHFkG9xZuKQdyOEgwB73QMFMFHmVTYMdFJIedKa1W5ToEYFB+BwDhQkA1HYV8LAknARNkM/ZRUvfObNtx9RDlIM6BbXXxXYqoZwNGbXHiQIUPw/iIlOR+WDMfma+ARwO7kkUcZgya9dJ+Z3wBWHFmQ7QC+CmZIs0KkRGnxy0VxLWI8AfCfjkwgUc9gPQ6whOxBZDCooCMqJOWZrZAuJiK1s4YCRxs4WMxPiLBbjMfGkVlum+zkVRsbBh8KaCejrBWuiycjRiCANZiNBj0hcsy4XIIRoyDARu7TZdmvgut34OBeCnhnotL1DbicVogjI0cBo0oIANA6/1OKzZjNhWP/SxaYY01QDMbcO/hCmMyuBEPEbLzkTe+EfBKbhYbQn8QMVl0GAeHsKxAylZIgGYa9F4haybWOXLXwwByMMV5Kk6er/WZndTwS0nnDoeMcHkU8qpWBb8iIVSAbYJQezOBB80cGT63mVanW9ronLYfjlhYfRV3Q1mwULNfpBmATO/MTjNUOylotqKTk6aS1bBTaSkfLSNEQmwMeBIxPexwMOlxK85hzkSnKZf65FChc85HMdoerOy3mcKs2JnBniaQdMY4AiqZP06EcSPic+i1i8QAmCVMDnqwgosxChCYfQbHJjTzAZcO1tgMHsdnXvl9CNFHmVdl1zTqOLhOgLNhCiEZU+0MyodQw7AHI5pGHdLeKRg4gUnS2qY18Otthq6owxKXSWGnKrEWMK3gVIi1LJ0FBn2C8ak4CYWdt3VIWrPlKoGUsI5V2wlJcB2m1yDiKMLMRnkXc+dXFIVs6o2UKNfqGCXFQCTAWAgmAoQ0BRazFvfNzvBIMjhFI5gvl/CCxR28YHoHH3BXcLaaFPE5acaQrCdlx3OSwJN0/vBn3jo9iWCx5bHZ7T4SUL9gvHgasThsEZLBapwCG+Xt0HdGxCcVo+IIwyIJ/xMgIOgnqQKzsWDVGIIB0jTCTALS2qO6I510yUIBq4xxwWiOxBkLytibNY0KMDhR+fuFxRqfdXQblQm4089wu5miHx2OuwP4E1n//eWI+qgTjpbVFH4jzzLMNGAw8n5gI+rTbkWoTuWdGg+ANJF5dL3QInB2Pgxt2X41yIuVQSALWjs0t6RzKA5PPZfxnHU+KEIiqtw+qBtCktYRpdTWw2aih2cjeg/OJQzERYgpe/uZfXM3tYXeagurghENQHqdlAzGfC90fiEgbwikZRMl1Bcqa4kkbCWkPjESIueNnrZRCmnaL5cSgnjgYMnW5OyGc9JSK5sotM6onjFLCjNVXMoLGAxY+2njVF+QWjMMJglYLVKJsEtnkOWia4CEbaRvVSfAQlhhnRxumachkzqVF8axYhmUknijc1MxgpOI2flUiJYAedlSMuqoiV4NAaW0Yo2wHY5aDuJE23QsAFhlXtU5OV1PYAyL0+e4fHZQ4p0szZ1tjNIzX4SuIC9ZUOXXqFEpiIVtVkttsZbfmfRrzFQ6T6TGLMQ9Secnb1ilfZSo6H4UBsiRhDwqMaI1SoKWuwNYlEJ9gnFc2vpydJWCkbZM7QjJ0WzWemEvnV25JT0rg8ZGo98clWXCIwc4lxAARHoSfT5Q5iBppA1IBAiYQpa2/ays9a6tJI3dOVDGF9H257PoIWtkW6LNpJgfXbbQ7AAFqWnnQy8rNqdK6OpZAxVTSXYy7UoSBCOaNCzvTdF2MXq//KQBm/yHy+8HMXiSEDUryk429lgz0AiLcmDBG8lLL3tJCCqW2dpt1jUbyZoiuy35cJ4DypkRfX4lU7OlEKeBAEPgQIKbePLlB5VwJ4gGS/7+bllHO7iyrpW0IvOW6VeDF65FYG1MpgDBM94gO4sE+fwQLNrgETK5HgGIhON+ispEnHQT4VHR1vpMilg6S/J65u3zz4y4eQ4KS3UuNzlsn6uWgpkAjFIyZCbJyuZsjwaIjIQ4oW3077B15hN29JP0/5HKz+f1QwaASwizJKXxfN/6zMbBYQMgxm3Wl3aeFfP295xtGjxiLsASox2dkIsFK+tWO0JpNOLMsgQzGWycZUfOZRRzFkafUar0TNMzJTb57OXtZ2l779TZ0jIcG6C/SM8ew+nTaWYgadtUDAYsI00i0EiU6M62jJ50YYDz4jDUXoS7WiNc9CZAMgNJNRN8QlLAqekM7IksurCIsJd7GOXgaHyQSJwb2cwApAZloXGVEK1ueJ2BWxk5GC4E+JkAvyofUOX2zEQlvRwbHZMR5yJWEkHatdXebgZfGODqAKfUw9Ywus4Lg+igWaAo14CTlCZYIjB3KjXieJBgLkoXgPcRtZcSwoZYVDUZSCOBa4ky4BOiiouZzki2wwDhKMBfHMrc1Mp4OXBT7iV7wyAdk1feh5ZggkGsRFbaT0aRvK5GOLvVsQDEARhbD/S5xs3SM+qFp6X2AUPtkCp1ZrTezgyJ1GsNb0aD9uZU7scyUCfZyKKojCIBZjDq0bM6JXpNZapkC8RgMajkPG+c0CMb0f3hqaTN44IRD6FU8vKsOW4BsomANBohiSLhZqEqCD4p+K1ehN4HJcBuzNYBJRTZ63BRsjZUJVTNKEJOzpa0PI3CJBsNAxmcy9DdTIC2aRqRdrR5dksdJAGkpHlV5pwmIyb1gME6jK7aOmzZSbEMXmhJbDCwp5KJiRGIU7NtzzOy6VMg8O0aQZMWqWKMnrdcGVquiBMhDYMS+xmbMHQe6cxLUAIZLyDz5TZUAH/bWjhhUAAzzUdMZ5LdWkcD7iWDSK0RhVQWgHF+1zOeS5hOIXoamuFLFW+dn9EAVcJ0scHBpEc/OqzWDcJgYXzCfNqj8QFntsaw1u02SWvsCCCtHdyJE/4bD8Ss6UEonVmli0NGC9dmR0syLBLNojxv2xMoyb6W+UdIHYEnOyFsGDEos7Lip7K6LFfClZLxbKxlv21rK4MmKsPAhDi3COlJv2AwsNo6ToHQ9hWObRI8DPSegsG10wOctA3O1o1oq4zbgxwQZ2kX2JlLrBS0VJY066HOafJaxoaOf9wJ+vKS3FikNoPnsTPXCaYWhtZUC+NsxpPIXArIHVEOammDRiHfinqIk2MYG4EpI3m9TmcLfMAMhLD0iE5kPUrZWB2W7Jhl5tNu43Dt9uT8IJIAcM0gjpnbEIKpiqMwLMRxDwcJmCmXUmfLnCVHcr9eMCfxUEDyUXFXzDv3FSQjb3vp8HGtZPpiLZgdrtOz12r7dBpFKGgM8oCNpMoABsLOw5sQqnrLkJkpujPwJ6ORd7MEqJJeVyYSxAgkPe21i6UNMasY5sxH9ripHAgkzkCQlCcaILmEg1kHQ8LDb01Cazwy0pqM3gfLgZ81I0SbQOqTyYsmysGsK2MCZANMO2MqTFGkhzQzMMhCNJEQD4BmMqD2Y7lO1IhjW9fbuYZlSL+pvOhWW5ZhpSzhNFMhYmj23NyU50QQmm9LwssQpA7LJIdmnhtn4w6ZkRLgJCq96CUbo/VQaxO8EzKjtHMwlPVik9T0AYxDBbsWPog4T8BEKNJTcFJT16xX7v0HQ9ozGQU7kssjManQ1iAlD7YATTW7YQByEUZLE4Z4mzJN280SUbI6xiQ4H4QYLhES+fNEX4CSlum8GpIoHZKStxNZl9mZlEXB2+eZ8v1DuTB0jSSJ1AgE9hHVdPwEsa4YjCqhElg7GbLf4m0Cc9RMzfn7hWHYRnQjeuOBU+kwyerNJVOYo6a07chJbtudRb2kg0siR/EUtgmYzzpULuIEQL9xBYOQo+ssS28ChORvkIySGagcYkQoRHYbl8pzzwRt4EyNLp9NOQpOMj9GuT3IcMEbEJMwOhJj1gy4b3aGNggIrxs8nBM9nNpGIWOj7bNi5V2hIMyothNiw1zGFTwAl/eSFGPB3c6iz8+8vMu6fkgmnBgwvRKd5SxEdiRs/rcCw43yCDkZPxOXjEexnA3LYNtKSuJVLfMafSz7Y+braTeVlCIG+ZkYRG02ywqwrom+qxCjEfVnVe4tmc28lydsD+kk7wd2Om/KXk9QxzUqVs7qxpv3KfnFtheHl0mxDDnzZ2W/ER2xWLg5YvSKW9OMrkHpxMvt7VKex7aMTqLGTPq+dqikTVafnekNOOTAQ+aXHUvmmriUZAuXyLiTEdbuOzOiZIXMKIFjUbOtNNPTRPhGBjtGEvp2zeKVtZBJ+YwEe97Hoiwdo/IbdRWQmXw7KGkkgesIdzgguQFP1Z6zzkehAM/pK2LYSv6fEfAU5AUYOlH1y2yoBH25dyZW0ktcau+ABHhDZUuEvFk36IzoCNQ+CKMh6zUgB2EGBVkr3QIpGcFjTg2y2NvybAoyCVUlLJpjriPnQ5O4jCmrFEZvMBIQRgWqDQ7LNIWxwuBpSTp7dhdLBipt8QSMYBmDU46SKqHdVOiNh/MRlQ/bjhF9STI+RA54HRMTIjFSbcuhcbZuYEgWZeUixrAzNzkVrZtzGVNlEIgRZ1L6oCBzkzMoziSM0WLo3VaFNVOLK9AWVnrM+95hHEUqmycRXMu9G40QOEm3SI7cd7Ma3Fvh2dDOA05y6CBS6aoAslOpYEBipEHUW5M6RFkNM3eB5Ppwyql3nUsiyTCMlfw+Ow1bZwFAjEae2XwET8T541xH7Q0oSTtnjkCRAIxGQHgAordItWq1KKYpQTobUGl5zjJipY6lRnNEgNVDTEjApLyVnaVS9qkE+Gx0zd1ZTuVwdgnpcCtMlucsBYM+edHvyc8uH3KaNcA0iGMWDIK3hXyvRNsNy3yxboKTAKN4mXVbY0PSAWFmo5T4Bkk3Iwm2InmZJ7eR9mhiFPl4MBA7ixOaFp0Lngiwmza2ZAGBnb2C88ECDOsK1+hAlF/XDq6TUk4mNiMC1l2Fx3ghZYXOIwaL0Uj6e3ABfe8K6JAipMSqDfOxzutKu6ry4aXPkpTgjggYWodYsWAaMmYJGXyqGS0F/wIApthxGLefZ/VpswND2iFErO+Hth4XJ5N350RB1skgGo/NsFO/3EUwkzxvTBJGL/sRM2EYnQQeBwFxKusgjQZD8FLaqZKy23Lptkpky/yd05bSzAPpXhSbHQc5l9QTttmykqGVuY5TbDFR+bpMGDunCUMuawaewSaDR/J60dJpaWsVD4SddM/EaIpKc96b4iwJ6yrt/MnOY3ZgFHOFPnei7KxR/Q+VUqo0TwDYlj9392ZiYDAYSzsX5Fk4YWoFhEOKSfdKJy3x2XJgwkHWa95bR23VTjUEr8Q7wcZTsOes8yEbKZfD0VcBh7OuaBoYfRLXTg4wXJ+CO4NhmjAcjDAugUc58JJmF7IccTMZsJi2sBqpAkLnfe3WAny9RmKgnUcM81BSTrmtKt+LsUKwsph05+7lrK9w5/oh+PEGyQHrgwA7CXKo6piSh2xYRiLYxbzDxI/nrnNrNcP62gy8thibhPHQFc0QUqyJqP7KdepmxGLWwptUrpGYcO3OIcKNCXgEunnCMJdUPYKMidTLJiOH+HTa47DpRV75slynCw43biyAJxpEAsaDiH42FkxAaSvVurq1CfNZh3ktHrC5V65zvJlgeX0OvlFjrBjD4QhbR8SNg7vlUbUqrqeRMKqE6YUW03rE2aZGf9wIu+ks4ODiGo0PCFHwGCkR2lUNnHpYjahTLU4JjQS7lM0xNYouJwa0+6hkjwCAhC6aJoyUDOKpB12vyp4UG40i6gSr0u+ps6W9jxUkSi7h4J4VptX5g3qMBm1fIQSDqoq4fHiKmR8wJIt2FAr45brBgAa2FQdK2v8kQrLdtr1wnNnS0SRYFxa+i3kvWBorSptEDK9/ZwBnBSVvENcOZmML+Jr00Gsub3BlcYYuOFy7dgTcmiBVDHdlg4euiGLmevDiOA4O/bIGNhYmZbI6xQsA4GTgfMSl+QrzSnQ5Vn2FkISZNouq2UnEwbxF7cNONkyc3uG4kUh4MeLypTNM/SjvyPFEwJ5HAc1c2CPPbsyRrovORTmIEmBOHXDbyyZ7FDC90CJGg7FVtVFIG3FWsyYGEIWHxvYe8YYX/GYvDkmsgTgD7DSAE7C5M8UmnM8MBJ+w6i1slRBbEVs0EWAQWJ8vLEt5YAdwDiOS6V5pyysnarcE4Fo0iKtGgxhdWCQg+fnlNZxJUvZZeYCAyYUWD1w4hTdRJAZARXmVmbAZPW5eX8Dd9AXcDaZzwc0udog0y2sHObR4qTgQgwKk3I3i4zTBXuoxmfYIwaLvPPqNRzUZ8eD9dzCvejx2usDy2gHMxoCnCfZwKMRyWdG221QIJGXKIjEBKHGZ+uE1EA/l8zRuy8+7pSSwlpsdAxdHLBYbGJMER0OMbnQ4uz2DORVsWKEBcEIgOZkMIlffViUYKMbYduewBMBx44DRwK5EFDUcJPh7WkybQYgozyrphIqSQUeCAJInkiEdRlMyNMmhYKEyoypIoAc8j2Vfk7ItgW2S7FkC3FkWQmUMlyP8kaBJx9ohaJmbggimsjdIVYKhESGJJgx3tgStuZOI50HKUyxZwKT4tqdqz1nngzVTRiV1lXBQ9zjwPRo34sD1MJSw7GqEbg5/RghsECoV/Yq0k/GAZiwYlQtY1B0qEzF1Aw58hzZ63LhzCLPRFjkLqXXuepA5UiCATMK0HnDUtHAkqpgTO+KJdoE7Tyzgz4Q/YPRWNjtFbhd+EkIZ06wacFS3qGzAgetR24DfTVfRDgcypqhjYpKsAG05NHIa2LmIw6ovktkHrkdiwu3VFNjsMDVm0hiWF5iBkq0gALWLOGpaVCZg6kbMXI/jYYobNw/hVrLJDM4gujwhWy84pxiNTZhWIy42GzgTcaBz80F7D5aPy5hiA4y1aDlQZ1GpHkGYqhKuZhYOJj0WdYd28BgGA7sxCA3hsOlxpKJxZ32NMYjKpO2UfnjCArQy4vEX3o5qmwHYtrTJH4nQUbBD42iRRukwkSiJC2kanDhZEdIZQDvgUSbAeOCw6XHfbCkH9VgjsMFm9Gh7OZCNGXHv9Az3NCu00eNkmGKIFiEaDK5WvpXtRl5YILWun7xEnqVOTQKorCpR/218wNwPRfK7sWMBz7abWrhABimJSapXneyaUfuAB2anOBkmuBYuoloKuZFzCQ/OTxDY4HY3w0pl2Pswge3ygsIWnAaIyJ0V6forkzO00WNZNRiTxWnX4E4Q9mFfBVw5OMPFeoMuOpyNDcZosdo0MK1swOOccKFpcaHZoI9WeEFg0EwHPHR0AmcS/t/OI5468MiFzwEsh6VIv4suyawZEKLBCc1KvVzWTP6ZbZrf9lugawGqKyrQOlFopU67rXb3sCC00zFROWCgpXyjmi2pUTbXSojUhLxMwNW1l86liQ+YVxIU3Kmm6PzOfWgUb5qABxanaGzAo2aBkzgDCLj/aIlXXvoopmZAzw5jsogw6JNDSBZ3hinunM4A9qW9Nyv/ggnKrrNtt03b8lYueWUK/0zlDkZRmGZHaCYDrhyscNJORDBvsKDpiPtmS1ydnGLZNzgbD6WsWRO8KthmBl5AeHwG77aASWyfh4k5W6ot4gRQsNqSLOsaNi/I7c/6OuD+wyWcZnsTk9wLz2TPBLRrj5EmsjdcnG3QBSf6J/DnnhkUNJ9BojwIkNj0gkkyAxAnhPm0w/0HZ7huD3C79eAMkyiX2ep/DaYqzLBsuOzZABVnkStGPe9hDKONDbDZAfMa+awZoSRjhOEiUNd5QTOiSwJUX2nJFDhHpc7avk67e36V4GcD5tN+u6eo5MRTtees85EayVRgMIiDQUeMzcTDUUJgkSs2WlvdFWKjTltaIRFqnsPUOsAwWl9h01SINkgUAMImVIijaFqYAMSOwN4WbzllgqkEpI1D8gbrpsK8GmBJdrghOZwNNWgUpj5KhNgSolE+Acvgid7NSIjBoU/AZuJR24AhiYPhYsKmr5SoR9kOO9G3AWSh5Q2Be4s4WHQmYd1UeovbyGbovYDoBsD0hNTaAuBKO6RZaeOQLGNTe7SNRzAGiQ0CGyyHBqw4EhDBdkYknvWASRO9ThAyn1QTNo1H6z2skTG11ovaZS+8FiBCbEXoLUfzWXBMNgxxuEYVjYpRWjltL3Ox7GowgE1fCQlbNODRbOubBtpxoXVdLUPSSJIRo/L+lq+ntcwBzQQobMy2dS93HhSQ4WAwkN9mTTTKp9EAg+DQhihjH5LDaqzQDh796IR+urfYALgznUmkOtY47RsMQRDswiGRhAtkRQW7xAR5YxmwmvpPDQOzAFKp9M26AYgRpj0aF0DM4qQNNcZosVw3CGsvm2Kgwi0itWMCyAjQOjr0USTPM5Cz7zyutwcIyeDOeoqul/KCUJOn4iQVnYtO2pbbBNxpBOUdk8GQRGWYmeCcpLGdixiTxSZUIko3SkfE2Dv4lbDRhqnDzfUMfXTYqBhcJhpc9lIW5GSkbEkoB1VJV+ckVxSCpBhNqZdDI7pMJmdGEmblCFAr67JgA3SNmc5gWNZCTb02IutguXAhsGbeEK3sHapTkss5ZgRSRTBVxGQybNtuo0FSZVRjhC6+D7JVD70v4zEqGw8Cus6hCxKtW8Nw+vN9cPjo5pJkPpiQdFICG20xrQWK0/A5+nMh0iJxcg2kHKndfUw5E4KCoTABoA1Q9FTy3I+EvnfYjB7d6ETTaCSMo8VyaNDYEZvBF2IyRDnMrWHERBii7PVhEAev6PboHFCkLRmgPtv8XqcKkhHcWQu59JTVizdjVTB1iQlDtIC2wZcSCMQhyOvXEKtjKAFgzjAyi74NM6HrPNLKC+Bewd95j9t0NY59QDtomZhyyU27MCvJejkjwNcwdyWrlAHfu2Rz54C02ilWAIuRthwj2TTLQ4AQuuXgHPI8KQBx7bDiRs4d7QRiaKlZn38YHFYQvFwKArQvHUBPwZ6zzoc/7BGNhzn2sD0hjAanVUBMBtYknJCgfrtVjclKImcTCRQF3T4eSBeMsYyw8nAngijumHDspXPCmgRvJuiCA1Ze++oBsPw+dsB4QYA0zIR0UsGdSVfL2jU4UXDqmalhiXG8mcCeSX++UBcbxE7S0OHiCD8b5SU6rmBbQphanFay+RpiLI1soGfrBj6PScmqkhfOD744wFUR49rDnkh6eYyE0zpgiFYAoSTuSVh5NGuhiSaWrpPkgLBIMEcS7mUSLhCwMYxjH0Rx00ZYYqz6CmZl4dfyXCgRTC8y1OFCgDsYhVHypIJbG8TaYukTnE3aISD3c3w2hVvLmCQ6UgXfnpTSl+E6RZJboLVWSiqQjcqvDPwZwMbgrJlh0zSInQWttSZaqWAaAdRK91HeTI1WP9gCo5XsTyYGo6TKkkt53sEx6sONOLcDoTpl5aAg8FzeYLsyoKUtdX+uIxCEMM61EqFvLlYIc4v1WOH2coZhUwkR06kQsI0HFk/YQ3TBYTN4rFdNKc+RY8BF0B1Rl/VrYXQcDqUbwgSCPQUAQnclYrZoMalG3D6eg6/XMIFwdsVgMRFdn9vrKVbrRuq2JxWqE7Ml6lJaeaEtJ8QgDJ7H/RTrodKWTHknhtMKH/MXBIC2FFAvWwDTCBxKedGcWVmzCtAFG8SJxQ0mnM1qUXTVzZqIMZtIB4o1jC44USuNtjgHOPGYPQ74FYOSxXF9iNNZkMOPpKMgBItbS1E+TJGk8ytpnXy3yyEfiANhfdaAI6FSimy2WrteyGKJncjZm16cNH8mrZvDkRClAYA/NaBjmUvbizMRGmFwTXXuYDPSwVYJMSLVCVg51DeE9yHWwMGsw/2HSzyxPJTyYmcRa4tuRoUjJ422OL4qhgvbEprbkh0b5w6n9zZIDcHbiIuHaymrDB6/e/1q2WPOtbbrHwDgoxGpN3DXhbOBKbd2C0tsfznBzEcpM56a0lljFGhpRsCvGXZgJEcY5qQMooRuXeGOnWHoHGhtYXqDaD2uzw7QR4flagK7Ebr5MJdMWe0C1n2FthUgajrzqE4kiykZGpSMZJzwllNIRetEN4m3EBQNNrLoprAuG5y2zSd03NkqCYll0ohfeX+YCZEJlhj3zNbwNsJRQuPGEhR3wSOwEamBRyaob1MJ1PJ71p3WuD7aonpbulumEUyMqgmY1gO8jUgHhNYJtjCNRjqO1LM24yce9GRFkFEYosVBluBhixkBoSh6R2fAHMFsc7OidIneccCxU26PtAPGFUeMIgFLjwC/zb4ChYX2qdhz1vmoJyPaIC2hbiOH7zg49E6AcEa7WlijaTMKYttaSZWFKcFV0hUQVh5G0fSxNwKWhHSjDMQYghO9DpU+FwEl1V0BUNWjEF8lcRrIAUNv0QcLgi3dMX3vNAMj17DaFx4UOFU3o6C8RxkTExAGaeU0xMJNQozYW9SjoPYBKi2KsQaMT6ibEWMrTpnphbxpGOQaeW5SMiULYwaGNSQdAA4Ih4CvtCWZq5JiDL3FEBxiSgjRFNS+2ckeWAsAhMiMYKSbpu88YhAWQaTzY8qHzDg41D2J9DoTuANS2JEgTwACw7K8rHaQjEdi8aZNL06UbaW/PDJArS1ORjAA5oLt4b4SASkVfCLVIxFHRJH9eTPS32VbAZSOgWAVO2OiRrwWZbPLGQIzKABVlZGhkaxtZcMNQe59jBbj4MCd1fZlcbbYAmPnsK4q9J1HWjuhoXYMTINk/VgO3Xqpm+tC+WDGbQcDJcKsHrCoO9zGHG4tkVZYWI10CUNw0sI8iFPm1tu6d9k0WObLgjCOpkiWZyVbGMB0hGEjiH97ZuHXpMyVgKsDAlmAbOmk2lUP7TcOnQKjq3osmJRJpWBqlq6imCTzMo5ClZ4l1utlxHDgYNZagvRJeDsIQiCm3AZggKqkoFRzzvmQcpBsnKmXlHjudmEr8+E0HR0UE8Fah8+sotKJo1m6Tp+DliKQIMJtuhlLHV/KNkkBpH4yYuisdrbJzzbViMvNSiiqgxLxESF5qy3MItgIBR3uZj78GqDEsJ2stSFaVKovk5iwGWZYnzWybp3S/GtIn8GBRDLuAAHFurUcNCZKG2bUzzkfMQaJgs+VfVj2Tb9O8OuEMDFIziCQOv6j8PekwWo7swBMu8FjZQXL5nOQkKhkE5J2WqTBFsyTHeX3ZbxD8tuOPMRteSxLWKR8UGZQeGav1jOyP6dWLEBsIoapIzgacJb+3cl8eBcw8z0WVQdHCTPXw1PEyBZt9AjJ4nF7iNCLThNbxUFZdQJ6m/GvYqSgYp9Kg0FlJfMxrQc4K5xTm67CCA8OmTPmEy13YzFB2pDDNrO8+/syxkW6koz8HLZzm7M1QslOW3kSYpB2GYm2jex/qUZhc32q9px1PtanE5CxYM8Ys9jZssKydeVBkYYAYS6LEEDxMM1AGJY1BpekJNAASVsO2+MJWrOljk4abQ+HspkDKOlo0xpsTifyUKB0xgRQb3F2ayabsrJvht7BVsKtn++lgIM2DmuagEcD43RMnpHWHsvBFhIkYwREGKaMDk8aUwDGM4+1Iv0LuROA4bTGYCuQl26dbOMBREshjwlyiHTLWsYRRTMA6vGu70xkTF7oqGOwIC+aJdmYNHXcGqxOJto1oqq8FuCNxTLOBDhXJRgbRfJ7wugunp+bnBLN6rixRsHYtOsa1yDdFMMRI070d9RR2D2ZEPQATk3a0hMTkCzDJEIykK4eve/Mflm6qYh17cgBT63F9etH4ECoIzDOaIdgSCOqg7RtQzRcCKKS39a9KRqcdBMsuxpp5WGVlybWEkHHCuBBcQtMoCYW6n5eO6RIcCNhOBTth2EB9BcjuGKktbQX5fbK2ydzLCuJ5MeFRj1MuHZrIRtqToW6hDgnDLpxxWmSro9ESL3Zdj+cOTxuj8DBwKmCM7vshIlzmCYJg1VUf7Uz90A5pFOtdXAHlequEAwLDwEAmgSERYtpNaIfHdZthRQtjI2oKmlPXC0iNvc5DAcO/QUpO0oXgAHOlJBvIlG5sUmiQ5U4kK4MefCx2ioac5NAdZQOBMsljWwHwrjSe+ttyXrEiYjtJacqwp4BL1E3WDZptxatjdAosd8kIhkgdbbQpdOZw9DbwsSbvJSKr18/wul6gnbZwJ2paq8T4ULjGAmxdNLxqEyqLCRQ3SV51nGaUBEjJoPbbY2+95Ix6ZWEignRKUMnyfttrGZIO1e6KpJndJel1BKmovSbu5eGVQXqLOxGBPBSJcrgYcowAzDOLWwrh3VWzQWEhyIONUxeO0rL368rjJlkDbLGbA+cXTvAWT2FcUKMaKcRI4BOZeVtzqolAMQayKke10HUjTo7lsIUbQfZdES7RPmLGoPgpcxpauUryRT6nb4PqlhMBPStx43WgwzjcbsQoL7SABizdaYrG7FuaynfqBhczoZxxeCJ8uJ0VvaFcZsdiQSs6oQzlTc4JxvxJIsKjs5lX2YSKYNTeS/iJCEuov5dAKfCPEa4dfNA7l/JHg0x4ixidOKs2Y0pHDLE0DI2tvT7yPu2OHRcJ+nQ4fiJN/oH2HNW2+XFf+f7wEc1wlGUlrOVRXNTVPfCBBgXSYFE25SP2RhUS1Mi3XyIhXkq5Cn22KG+LanScc4IB8qYmdsDWV4Wv5IHnttIk2WRuZ5FIBD8bYf6RPgMxkMWBlBN6wngieCWAjRCrjmSLBjRO0mg1qK+aeHWkn6VBZq0bqdj6gz8cstGmA/qOGGERRBVyFOH5qakQsMUGA5TEZ3Lc2PPZEyZTjsjwMcDaXkDE9wdh/pYFtl4kIXftnNDkeDOdrQAFHGfvM7NNAKDQXXTojqTF31YaEtivheShZxVL02QbIEJUDVY7ebRDQxGRN+qCx2qKpyjH5YedD3xcqQKcVL9iQUFbNvNoJkJZeALE90MTJ4Peen8qUG1lM/HGoXyOx++sUmYPXSGF1+8jXWo8NHrlxBOK5QuB4aSWgW4KmDcVKg/7lGdyibU3ZPAswAEA9NK6jQcRsyvrLCYdLh2ewH3+xNUS3mW/QVFrB+MuHRphYkfceN0juHmFKSRR+7+Gy8GHN67grMRdx47wvQRBxOB7hIj3DvAqGPqlbvAGWW8DQ6r63PUN/LmjrLxhLnMFVtGmnDRojB1LO2fufbddx64UYv+i2MF6bKouJ4KnwVFxWYlEf/rP6vHbNFis6pBN2qhj78UcfnBE1ycbHBzPcPJyUzSzQQpQzDgrleYPyqZtLOHgfjiFnU9ol3X4JVE8KaT38kGGO8dceHeMzgrZE8hWvSDQ/zoHLNHdc3PVTQRKJgrdvIM0sH5FkuqEg6ONrg422DZ1bhz/RBm6cA1w13sMJv2WG9qhJuN6H2Mym8y5v1Er5N2Mn87O3F3D2N8qEc9GaUbQ2vy67MGOPECQCx8EgAORhwctgCAs0cPMXtEuJBSrY6ukfc0Y1biIsAfDJKJvVajvi0ltOEoIR5EUJUwP9rg0myDVV/j1mML+DsOtiNMrzHqE0Z7j8HpKzp8zkPXsRkr3FzOMXQOqXVF58UMgNvIMx8PgfbeJLoiI8EqSVWOtHP5yq0km7N6GKg/9xSXZptz2ZBrpwfY3J6Keu6JQXNbnt/ZCxMufNYdeJtw8/YBcLOW0ulSFF0LQJPyfCiGxwHd5QQcDeDBorrm0NwWsbf2j3V4+P47ON5MsPrIAs0NKaPJmLhcDyTCjJurSfbTwcCfSodTfyni3hffxoMHJzgbGsEtjQ7ttTkOP2BRLaVc5VoGJQmGQk0FPyMLBeguELrL8gzjRJwYWIZtInwVpH3+YzMcPCLO4/JzIq68+BZqG9FHixAtNr1H/9EDTB+XEvzmgQh3TwfrEqZNj4kP6IPDneMZ0sprd5OcqbST6WKvXTZeMnr1vEddBcRNj/e/5gef39ou1VIi9uATqtmAcTOBPwOqU1GEZGuQajn0zeEI6xJG1EhrglW2RLORa8WaYBpNZd/yqI+5sCmKl07CcHoo1IhxUMbEsK3lJk8YDwl+KrgN23vUtzMAiABIh0ucxILt4I30VVOUFKsJskDHi4xqNmAYa7i1RXNLavpslNClkcPG1QHjWQ1WZkQKgFOUee8AqhNcMyKeOlRLwG1EoTNZKVPFgwR7IARbMdbAWurGeUxsBUci7YIEM7pSQ85qsuwI4SjAzQXbEfsajqiAMUud+wLDTweMXMFtHJqb0nHCRCAWhlO+EOAnI0YlHgJQuogyJ0vWDzFBtCIoErqGcXmxwpWpyHuftJNSFsop0yE4DIMTNUxt/YPVtluNtEyOhPWZ5E0ji4vxSHCtwfRaAlvC+n6t7xNvPX4DXJpt8CUXPorH+yM8dryQuQXU4dMNKZIQJrVWuSe0S6lO8PMB46aCOZXvxQlhUgn6/8bJHG4D0UmoCGke4eYjDuYtXrC4g6kbEJnw+LoCW9E18qfigIwLwv2HS0zdgDuPHWFyk2F7eT6RIG3Q0w6XpxvYnNZmg3b0WPkp2FhpJ10CzXFCrAirmhAvSFqbrWQOYYG6GTGfiCbKEARAmonZSIL0Ig/AQYKG6lTeO9+ylr8sus4izg1S59CcGan7T412pbUi3e0DguJAus4jjQZ2ACa3E1yX0F1ycluZMVexHkZr3cmKs/Tg4hSNHXHaT7AcFLRspf5GCSU6JoYyckJUhScJs0sbMAN976VMMBnxggvH+GMH1/FEt8A7uxpdJFCdMJkMOGh6Acz6upBRVWfyjoaGMB7KwedWwORGgm8ZoSaMU8FKCOBVOtm8jZho23bfOwQlp0tNgpmNMFaYcw0xxiilyNkTCXZgDAcGw6F28FUZh8GIcy1DsDjk1ak42t09jMnFFk014rMu3MaL57fwyOYibj2xKCVDtwH8JqFNBvNFi//f5d/HaZzgQ9PLOO6nuLWaYRkOhK9mJFRLRrVibMigvRcqQCnCnNk5zE6R7YD5tQjbJQxHXvArzRqLqsPlagVDjN81D+BDvZeMzamBW2+xHffM1mhswJ3lFCmhlE79iouTXng+1PGINWGcEcLcSGC5Fp0SsGBurs5OMSaDtiNMbsk71RxHuPX5KL+75JC8RZ9caUuVvTzg8y5ew588fAQfbu/Bu9JDOEWDNsk7Mb0Z4DYR/qQDjRHsLVLjxPkgUiI4AsUKYWokwzMBqI4wPmnpRDAs+T3LgeED81MsfIeRpYngenuAj8ZDTK/L+91fEOC3MQkXpy3un55iNdZoB491UIzJRsk4d5zjlDm4Kil/TuoR03pAiE9d1fY563yMc4BVNyMqRiM2wBippAIZ4kCkziG5JOC4zD9ht6k/9kISkyCRU5iaUs8qqOxAiK2kq2xGwGPrHScPSaNFI2h0zwgz2r442UkNRtQ6B3OO9S5H0bHR2qFKKscKCLOc2t7W3bi3GJO0QxbmPiNZH8k2AJxIuw1U6pxkbkoffASipkHNsE2XJbd92ZNDUQVmJ2UGsLyYpe0wkLzoWgqAAt5ipX80/Zei9IKnSpwsYQ3cHkjohVIa/XZMIElVA9BWVrmPxPKsDKS+eLqZIDGhH13pcMmU4Hk+YwZjRaWKRiZiYh13LjFRGX9mApR6Oqlk+Pa5FkeGJMsGAk7bBu89u4qTYSJaMTqvkj7Nv9sI0yuxPOOJPGsA0iIL3XS1TrruKjxhDxFHK1mwA5nHzAq56So8tlrAm4Tj1VTS5KpKGqa6+VrGad9gM1b6DmkZyzF4MAhwOKMGIdotuyykjTEj2pOTUh07kU+PU3U8TK7nEhCk6+JMs1BhlDIRD0ZIJ+vt5leAgbWsc1G8zeU+ee+6dQWM4iRELZ+erCeKV7Foe1HvDEFwAxwkq9YvCOPEyhoMRhyTwW7bPPO9EMDR4OZmBkuMtXZJhVHI+GKNLU+E/j2TlqVaxp+1eVjJ2HKHzRN+gVvdDOPgQKpHst5I+3ffeXl/k2YZZyQOQCVU1uxkPs0oZVZpV5VsaqwEaDoMDiMJhgqQDoOc1QVQMoFhtNgkvT8D9AsDO8rvDFPdB51kcNnK/IdO8AOOt/sBBULfeoRg8JhfICSLm+1sywxsNDvpLMIM6NsK714+iE2ocH11IJF1V0nwYuX9jzUQgrxb+V2T9103x/weQMbfHxrYRp7xpqvwxPoQx/0U190BDDFurOaIgxWiNguMB9nrTbi9mcFZKYEbptKhFBvpQmOn7Ls5M55LRFb2udw2PM4Up9FZfPj0Ek7XUnoPE8WYwMJOz+Muhrn8LNJ5QjAeDD60vIyRDW60B7i9nopURiKMB4SWHexg4Q8cKErmI1ayl+hDBojQHxmEuewn7JNA0BIhscWYjJRqDcrzRgSurQ9x7KbYjL7snZR0f1H9LU7SGfn4ySFur6fSOrsW/pH8rAo2DJo5yji4kZBgsVo36EeHuDk/J5/KnrNll4f+//8ANKulnmUY1KtsfE5b7tQU8wFieuVCSLIhhwPeopuzRsBGSyoJJZWegWgZUOg2SpdOUn4I852ygZO6vF1J7VNKLfpy71xH1D7Fs08eGA4ZaZLOs+mNpvDyl1Rsvk4e0yjKgyZouUlLKkXvgVii6zNTUPvnmO10TLbTFjoIG954sFPeyTS9a4lGsiPyCXOTdEydprIPWerbBkqpzsL/fyaRbj7MnjwmGiW6kIySbMSlTdbL9WiUuiNFOQDiPArjaaBtz/nOys36DcTynApPhmY3iuWf2SlJCbOgODluI4BMJjl4s2OV09tsGagjbKVKy2uR4s4skRm8GGdJShSByjNOlXQImUlA6kUN0gxCrsaTKDXTXurAWXo9zlLJphQIUC8aC6SHY/4MVQlWu6fCsoI/FrxBjnYL2ZJ90nwwSqsjA0gNF5I2+YV6SOgYpfzHpRRHfW7b3ZLoASjtiRSkRTs742VjNnmtbjNLhJ1x50xLftaakQPLu25bITULU631Gxa+jdaoA8FFDZa9KLcyA+gsTCvzJ3gAuffYoLTaFrMAZpKx4yTZLB4NyCc08x6TekDbV2hvTWHP7I6zqhnPXtlAnSoCOw2cNEtGo4HZGCUf274rqU7gZqfuH8+vd+k8YEAVazl/Jokibla4lUBj+4Pn5t7IPbo1lfLweCDKxFkwjuoI7i38TdE2knvTuXWqn6LdXpktNuv45I6c+pjgWmCcAf2lhKhy7vl9LeNiKfk5bS8fDxnDJX0vdm3cSjDQSKXrI061LA7Z5+06dyKpBg5JWS1OuKxt3l3jkPVs262UQpglaWePpJkfOjeP2Pm/ZFF4p61X/pcq1d7y+iwzY6liV4ziknLAy9quLecICgPveMAIR2G77+cxaMCFKMRq1Yk8y/5SQrqkrX5LJ+D8lEt84niMh0pQFoWM0W7EGRQHR96/XBLblv3znviJ85faDo9+9xuf32UXngVQ7fWwUYBczSAlscm2u4jzJJEuhDQRvIg88Fz4Z4QJPmHRZ9Q75cnWQC95YY4sPeQhg8UYmOaf317HZJ5/7Zfegu+01p8XSr6ObkjnxpRoK6S0qxtgxYFBHXc2JIlYY8OfOCblaCDeLmBWh4AnT9rYAG0d/eRjyrTQmRchl0jyy16eE2Mr/71znXNjyux8rJFHw8I7QlyQ5ZxUjZTzhmrB2h2QlXR3x5u5KMCa/anS9uehB6FiO7JDtr0/cTwEHClgYAAFv8PZ+bA6ga1FWkvrtol53Wgvv4L2Ml0yoM/YUGlX47hdi+x0LXZGQJSQtZJU6bXoCalQXSZwMr2MPzZKRe6Tlnok+wSo6GLmlBhI98InHWLbx1zGmeYB9aGUVMbeiTZGYhCbEtUVBdWoXWKDRoqVOl1J3pcittWk7U6lz0Dq/lImZatOUsYoPYmwq7RK5g3XAuFAFgAbVpE50tZ0/YyBMtpC5mTtxCFolS2WJeLO2ZHYbEmqdh0+45JGmFTUVDlItBijkfb5YecQiSjA9YzlSJU4pKiTsiQrRiwYRG+EiGz3vcv3rNwp0jkkjqrgwvI61nsas8CaHCrhgM85ifKOCLFZBsnmPUEcdhSHybUC4EwDgTcWVjt2KG2DhTiLsuZbA1qJM+A66ZhKlYgvomawl39H3ZPzfQBQziJ5T8SpZEQQ+ED4LpJVoHLOlGZ8F20PeCknpfJOk5aW87uSMWk5sAvzHTbQvPATQL0VDFV2IqZyAAgVAJX1lB2X5Lb3sMVC6LPfeYyAOvaDK/dTHB+rga1+LR/qUvvUB9PbknVK0wg7E+K5THfO2g6MIOuj3CO2ax4RqO9YVCfye4ZDiDhmDj6VcLA6MajvaLB8JBmU3f0hZ6jYorQ7G5bfY5RLJHVPem8/hT1nnQ/aOBDbEj0xCfsioA7HrgaIbkpmZJiKystEgxGdD9ouhQIuBYpGAcAle0G6UWTBIRBArdXfsXMdx4hOD7fsIICljkgoL6oJKFLMyNLyO9dJlZxQmbq4aBcoqZUJjFRRiWBpICCevw4bBjdPnhvealsAoApIw3YORB7+U4wposzNuTFVOiYF51JGqu9exydE/6Qxme2YSuo9t3JVSTJKJcLVl90BiXhLDvVk450XX711YYDdaa/LETqTiIDlTT5veJA5EoAvIxkSkT51VjLRHOWX/Mm34BlcAYgMJiMdBHoo5FIO57KFlXvN/f27qcxs2WFEEmclZXVLC7CWqnY3vlJSVOc66/QwAwwDZgaRgU3YypDnYexEMaUdNYOIP8lhyDna4vNAV3ZAVBpqSiROlH6+jJF2LlYiJ+lGEBZJHYsCf/PhwY5L1ga60eVrZFB25jTIJGdW1aNlczXb8eZx6KbLeS4YApwdCQl67xnISYxEWpZMJIfBKM8uGmzBz9OIUamsTZfJ9HadJcnu8GDAPsFWIq8QjBXQ9JMOpoxbEb4SmXMmeWdsFKK8NE0wTQAZICZAxDawvX/CNssKCDmY0eycHpS5fJpxUduFrWtR3xlx0mibTVKNpExCl3VVUMl64IpLC+Y4l4AvO5iS3dlZF3b7b3EiNUtmdI+GBhcasCRHqrOizl3uUPSaUSLBSxVxRW3BZQNwI9IIEuBomSruOIrQMrKTZ5nBliXSz+/3zprK8UvpatJ7l7GKE3Nur8lrIu8TOUObz23HMF68mBRM2eNoNIitRSQpOeX9JYvtEcvvi83WScugdOiZuAs8BintQYCUsGhbgsp7bvndDNH8Sduxly1ficoAIH0ahZTnrPPhb1vQgYBKkwO43oKr4mCRNoLM5zrBzgOsjUjRCjlYItDawi/FI0+1RjdWAHB2JtDd2DqgFU+ZpxFuEhScaRC03mWWDtUdU9KNUWvAPI1wjSCM08YBnYqnTSNcHYpSaIgk/AqnDvZUBakaRZ37BJoFWJ8Qg1GuBwJXDDMbpfUrmTImtBb+1JZUvaRxWedGGPdCb8XJSfqizcYiEDYGI1TvKwd/LIs6VpJ5EAbWCDuVzpeoYwLJ3PiJki8Fg6CS63Zp4W/ZkrLOmxJmAbaKQvi09oJN8AyaSQfI7piIoPTEeij3wgYJwjb1rxmg8tbmg4y3BFhxwgjzKBvWQDup920mhnILJssmnsXNpDVSyj2wSfQ19FeASQSVlk66fGhbxmCnc9bIWGNrhSiM5dpG9TtKBi47MJmIx+oBmp20qCDnVrJNYQqkCYNqkatHlHw+VwyuwzZzNQjWAJ5ha+lkKWrJCUhrjxSzmu9250g1l/79UlLRkgEnveau15c3XRYQn20J7KW7Kmkq3WxUxdhCnoeW9YyPokUEgFTxNAYrcuI5os34nNbCbMQBGeeSXSMvek0YDLJoYjl41w6mF6yH60i7JfQZRH0G+dCEHFKxOFEo2TQ7EtwOToA1ykuRkJxkfbKkOFsgREIaBWR6eHmNC9MW66HCnZMZwsbJuCsZd+otzKmHXRmEQ6C+MGIxbXHW1VgFA2ZzTigxrbx0yQw4p+lhtbQMBrorQHUpwPuAVZwAG6tBj0bOOy2k8u4KLkrYki1Sfs+aJKWNJNoeOStEWo5ko3vfNMm9zETTIwVTom52jHGeikbNrqRFOuLS8i3rmLZriYQozlYRZBJC7xCdiIYaLUtIh5S2yzIQZsCo63aXRHBciFijtcKX4Zx4E8NgEVXcs6kDGgXvjtEiBIMYLEJrlYSRwYcjZosO42gx3G7gllZLqVo6SeIIlHWLnAngwgGUKtnnuZJ31IxcQPwFZ5Z/nNX50sDBVBFVIxmONkht0ug8QzOCuUMIUIdI10ecJPCh1PDsmYU/M4VZNVZbJ5En8hkajJRENbCKjTppO4GR0Uw1GyDtZk5z8Ou2ayi1AU/VnrPOh+sAeCXYUgIU6yPqOqBDhdDZgrbNsvFBtTFiNOiHidSFByBAQUIkEUtVi6T4JkhKDwBMHTGd9rCqtCoOiEU8c4L/ABAMF6wJOSH7itGgG/ReDOCaEfNpX6h2UyJ0mwp07OBa8dqTg7QMEmC93H/fO4ydEB/BJdSTEZN6KGNKyaALjZCutUBMCm7SM9lXAU6VBWPPIBCokjE5kxCSUVlog3FjZcEljU69REXkGHUtL2arGz0bLrLmAMrcDL3Ipwu2gxRbo0kIHdM4WvS9BYIFLKNqRswmPVLaCsIlBc3Ku2sUN0bbModhKefk6Dx75NA/ihVgkrVAjoHgthTfRn9Qo+bCzBgkRQwSIFoWxnN+Z7NWRcqoxXPbaweQURE2AOQT6maQOWG9j1wKHEk2FcdbjMjoCrtqVhVGAPJORFEidwoAKXiYbFLkO0pUa6eyOYXegYM4m6Kwqil9iFOXEiE5CxiDgvwtWQEWp4gYGE2J4ACcV6fM9bqd75sghE+R5DrURCH1SnI4x0qjKivEb7a0+ELQ+QAGw3IgBUk5kh5G2QHNHB3kE7ySmCWN0OBSoRCPditRTipJkEuDooOkt5/LXoYBRwBzKR/lVL0JOeITpWCOABsDplRKX7ZT7hJPSMaAq4QL0xYvPryF2/0M3eiwYcAosWDlAs4wQUpe2oyjsJAeVKKLsdEsShatJJOQyBVZBDCUn4OVhAzlQHFOdHw2lrcM2pTXcyoaIUSMHtjqjlgjyrW6h7qJBFI8GEDxIiU7aDXQ0QCOvEhfMPN2vRgGVHAR+nsA6UBqJsLW2Q0eLYsez67zYXwqxHMdgHE0YDLgUZxyowR+Ron1YrXdC6C4nXwfuZV8Uo1FsHPtvcgWQAjdGi8HZDt4ENntWlfn3NURl+drrIcKt5b1Dt6PYZqApOWOXeIu2ZN2St2adWV1uHNmAZrJ/aSWnTbL8D7AEqOzGQiydTiIUQgUBQJAGhQDsICZCAMwr2whx9tmbsRZyM4mesk2ncN07GIGNRstmRsu60J8EEmNSFZbnj2lp87z8ZxzPjL+NfYdUEkNOCVGQkKqOsQYkdqE1MpmwCYg+h7Rj4h6MMZISC0h9k60NghINqkkekD0nXhxLYNbnQI3IpoeMEmvI5TGqRNWVEDS3YkYHBioRkQz6O8S0Cc7lnvEoBwUEl2kNiF1jNgTUtTrMCNxQvIDIo9IfZDrDEJ3G6sOMW7HlBIhtUDsIqiXAzPLuycjnyfHOjdRolg7IvoeZJKwRwaDFI3OjUZJhuWPhYzJSqtUagG0Tg5aP8jcANu56SPQAbHP2QBGAoMjA9WAiAFxNDKmzoJjkjGxcAuUuUmElJ2PYMDt7uG8dT5KChpAlp7GSEBHyBic1I7ifLQOSQGOwiunGZRIiu2AlMrU+Ug+gV2QCHWMiOp8JHU+UjBAx4i9ZsBI12TUdUC6DjoB5yGSZI0Gks9VAZQkO3JufBnsG6TmCgVvRlVOTR1LJJGCKBq30p2ROIHcAJiENDhZwwlASkgcgLxhaWo5tQnoXMFCFKwNEpC2zgc0E4SUQFHnIGxJu7JOBAVC7Mx2HbYR8AE8SMts7PK4ExhRKJ9jQMzgSHU+4hhkzp7sfLRRascD6Rz0SFHmILUa4qWIBJEzlTXmRDOpJ8R8SGmySMbK23XA2AKWBxLnjwEeJQXNJOljTjt/j7LfpM7IexyA5JJ8jwLCusdgBoyDR9z0SBt5tjEFRBeQNoTUAamT5xE3PYLpETsr2kqDBdkEGoU8MbWM2DnwQPKe6CYfOyPjS0Dq5DoxjHKNNpX1gSROXwoRMYnzkfqINIpOFLearSWAbUBidT7aJO9OPmTU+UiGwSkfpgE0Juk4ayPQE1JgsI1l3WTng2xC5BHGRsRBxsXjeeeDQkJMI2ATUif7O4IBOoPYGXEAB8hBmbO1nezn6AhRhTNTG5E2HaJPiGFEcJqtHRPiIO+EfD1svx4t0hCQWiB1FikCtOkQ1j3iyEhtp92UjGQjwEHG3Sk52K6N8l7wqPtOl5CSZAQx6Du0g1cpJRjSDGiU7CulgAiRv0gbAjoGBi1vjdvMLWfnI+katVLCJj/I2tY9qzgf+V3oElI1yn7aqmZOAtATeBTnIxnZ4ygRMEBZVVmd8fP3nuL22ae2P3eOfyp7znW7fPzjH8dDDz30bN/G3va2t73tbW97+7+wRx99FA8++OCn/MxzzvlIKeHxxx8HM+Phhx/Go48++oe27Dzfbblc4qGHHtqP9S6z/VjvTtuP9e60/Vg/c2NmnJ2d4erVqzB/gP5Mtudc2cUYgwcffBDL5RIAcHh4eNcvhGz7sd6dth/r3Wn7sd6dth/rZ2aLxeIpfe6pN+XubW9729ve9ra3vT0Ntnc+9ra3ve1tb3vb2zNqz1nno65rfO/3fi/qun62b+WP3PZjvTttP9a70/ZjvTttP9Zn1p5zgNO97W1ve9vb3vZ2d9tzNvOxt73tbW9729ve7k7bOx9729ve9ra3ve3tGbW987G3ve1tb3vb296eUds7H3vb2972tre97e0Ztb3zsbe97W1ve9vb3p5Re046Hz/yIz+CF77whWiaBq985Svxm7/5m8/2LX3G9qY3vQmveMUrcHBwgHvvvRd//s//eXzgAx8495mu6/D6178ely5dwnw+x1/4C38B169ff5bu+Omz7//+7wcR4Q1veEP52t001sceewzf8A3fgEuXLmEymeALvuAL8Nu//dvl+8yMv/f3/h7uv/9+TCYTvPrVr8YHP/jBZ/GO/+8sxog3vvGNeNGLXoTJZIIXv/jF+Af/4B+cE5F6vo71V3/1V/Hn/tyfw9WrV0FE+Lmf+7lz338q47pz5w5e+9rX4vDwEEdHR/gbf+NvYLVaPYOjeGr2qcY6jiO+53u+B1/wBV+A2WyGq1ev4q/+1b+Kxx9//Nw1ni9jBf7wZ7tr3/zN3wwiwj//5//83NefL+N9KmN9//vfj6/5mq/BYrHAbDbDK17xCnzsYx8r33+m9ubnnPPxn/7Tf8J3fud34nu/93vxrne9C1/4hV+Ir/zKr8SNGzee7Vv7jOxtb3sbXv/61+M3fuM38OY3vxnjOOLP/Jk/g/V6XT7zHd/xHfj5n/95/PRP/zTe9ra34fHHH8fXf/3XP4t3/Znbb/3Wb+Ff/at/hT/xJ/7Eua/fLWM9Pj7Gl37pl8J7j1/8xV/E+973PvyTf/JPcOHChfKZH/zBH8QP/dAP4cd+7Mfwjne8A7PZDF/5lV+JruuexTv/9O0HfuAH8KM/+qP4l//yX+L9738/fuAHfgA/+IM/iB/+4R8un3m+jnW9XuMLv/AL8SM/8iOf9PtPZVyvfe1r8X/+z//Bm9/8ZvzCL/wCfvVXfxXf9E3f9EwN4SnbpxrrZrPBu971LrzxjW/Eu971LvzMz/wMPvCBD+BrvuZrzn3u+TJW4A9/ttl+9md/Fr/xG7+Bq1evfsL3ni/j/cPG+qEPfQhf9mVfhpe+9KX4lV/5FbznPe/BG9/4RjRNUz7zjO3N/ByzL/mSL+HXv/715d8xRr569Sq/6U1vehbv6um3GzduMAB+29vexszMJycn7L3nn/7pny6fef/7388A+O1vf/uzdZufkZ2dnfFLXvISfvOb38xf/uVfzt/+7d/OzHfXWL/ne76Hv+zLvuwP/H5Kie+77z7+x//4H5evnZyccF3X/B//4398Jm7xabOv/uqv5r/+1//6ua99/dd/Pb/2ta9l5rtnrAD4Z3/2Z8u/n8q43ve+9zEA/q3f+q3ymV/8xV9kIuLHHnvsGbv3T9eePNZPZr/5m7/JAPiRRx5h5ufvWJn/4PF+/OMf5wceeIDf+9738gte8AL+Z//sn5XvPV/H+8nG+pf/8l/mb/iGb/gDf+aZ3JufU5mPYRjwzne+E69+9avL14wxePWrX423v/3tz+KdPf12enoKALh48SIA4J3vfCfGcTw39pe+9KV4+OGHn7djf/3rX4+v/uqvPjcm4O4a63/9r/8VL3/5y/EX/+JfxL333ouXvexl+Nf/+l+X73/kIx/BtWvXzo11sVjgla985fNurH/qT/0pvOUtb8Hv/d7vAQB+93d/F7/+67+OP/tn/yyAu2usu/ZUxvX2t78dR0dHePnLX14+8+pXvxrGGLzjHe94xu/56bTT01MQEY6OjgDcfWNNKeEbv/Eb8V3f9V34vM/7vE/4/t0y3pQS/tt/+2/4nM/5HHzlV34l7r33Xrzyla88V5p5Jvfm55TzcevWLcQYceXKlXNfv3LlCq5du/Ys3dXTbyklvOENb8CXfumX4vM///MBANeuXUNVVeUFz/Z8HftP/dRP4V3vehfe9KY3fcL37qaxfvjDH8aP/uiP4iUveQl+6Zd+Cd/yLd+Cb/u2b8O/+3f/DgDKeO6GNf23//bfxl/5K38FL33pS+G9x8te9jK84Q1vwGtf+1oAd9dYd+2pjOvatWu49957z33fOYeLFy8+r8fedR2+53u+B695zWuK+undNtYf+IEfgHMO3/Zt3/ZJv3+3jPfGjRtYrVb4/u//fnzVV30V/sf/+B/4uq/7Onz913893va2twF4Zvdm97RebW9PyV7/+tfjve99L37913/92b6VPxJ79NFH8e3f/u1485vffK6WeDdaSgkvf/nL8X3f930AgJe97GV473vfix/7sR/D6173umf57p5e+8//+T/jJ3/yJ/Ef/sN/wOd93ufh3e9+N97whjfg6tWrd91Y9ybg07/0l/4SmBk/+qM/+mzfzh+JvfOd78S/+Bf/Au9617tARM/27fyRWkoJAPC1X/u1+I7v+A4AwBd90Rfhf/2v/4Uf+7Efw5d/+Zc/o/fznMp8XL58GdbaT0DWXr9+Hffdd9+zdFdPr33rt34rfuEXfgFvfetb8eCDD5av33fffRiGAScnJ+c+/3wc+zvf+U7cuHEDf/JP/kk45+Ccw9ve9jb80A/9EJxzuHLlyl0z1vvvvx9//I//8XNf+9zP/dyCHs/juRvW9Hd913eV7McXfMEX4Bu/8RvxHd/xHSW7dTeNddeeyrjuu+++TwDFhxBw586d5+XYs+PxyCOP4M1vfnPJegB311h/7dd+DTdu3MDDDz9c9qpHHnkEf+tv/S288IUvBHD3jPfy5ctwzv2h+9UztTc/p5yPqqrwxV/8xXjLW95SvpZSwlve8ha86lWvehbv7DM3Zsa3fuu34md/9mfxy7/8y3jRi1507vtf/MVfDO/9ubF/4AMfwMc+9rHn3di/4iu+Av/7f/9vvPvd7y5/Xv7yl+O1r31t+fvdMtYv/dIv/YSW6d/7vd/DC17wAgDAi170Itx3333nxrpcLvGOd7zjeTfWzWYDY85vGdbaElHdTWPdtacyrle96lU4OTnBO9/5zvKZX/7lX0ZKCa985Suf8Xv+TCw7Hh/84AfxP//n/8SlS5fOff9uGus3fuM34j3vec+5verq1av4ru/6LvzSL/0SgLtnvFVV4RWveMWn3K+e0XPoaYWvPg32Uz/1U1zXNf/ET/wEv+997+Nv+qZv4qOjI7527dqzfWufkX3Lt3wLLxYL/pVf+RV+4oknyp/NZlM+883f/M388MMP8y//8i/zb//2b/OrXvUqftWrXvUs3vXTZ7vdLsx3z1h/8zd/k51z/I/+0T/iD37wg/yTP/mTPJ1O+d//+39fPvP93//9fHR0xP/lv/wXfs973sNf+7Vfyy960Yu4bdtn8c4/fXvd617HDzzwAP/CL/wCf+QjH+Gf+Zmf4cuXL/N3f/d3l888X8d6dnbGv/M7v8O/8zu/wwD4n/7Tf8q/8zu/Uzo8nsq4vuqrvopf9rKX8Tve8Q7+9V//dX7JS17Cr3nNa56tIf2B9qnGOgwDf83XfA0/+OCD/O53v/vcXtX3fbnG82WszH/4s32yPbnbhfn5M94/bKw/8zM/w957/vEf/3H+4Ac/yD/8wz/M1lr+tV/7tXKNZ2pvfs45H8zMP/zDP8wPP/wwV1XFX/IlX8K/8Ru/8Wzf0mdsAD7pn3/7b/9t+Uzbtvw3/+bf5AsXLvB0OuWv+7qv4yeeeOLZu+mn0Z7sfNxNY/35n/95/vzP/3yu65pf+tKX8o//+I+f+35Kid/4xjfylStXuK5r/oqv+Ar+wAc+8Czd7f+9LZdL/vZv/3Z++OGHuWka/qzP+iz+u3/37547lJ6vY33rW9/6Sd/P173udcz81MZ1+/Ztfs1rXsPz+ZwPDw/5r/21v8ZnZ2fPwmg+tX2qsX7kIx/5A/eqt771reUaz5exMv/hz/bJ9smcj+fLeJ/KWP/Nv/k3/Nmf/dncNA1/4Rd+If/cz/3cuWs8U3szMe/QE+5tb3vb2972tre9/RHbcwrzsbe97W1ve9vb3u5+2zsfe9vb3va2t73t7Rm1vfOxt73tbW9729venlHbOx9729ve9ra3ve3tGbW987G3ve1tb3vb296eUds7H3vb2972tre97e0Ztb3zsbe97W1ve9vb3p5R2zsfe9vb3va2t73t7Rm1vfOxt73tbW9729venlHbOx9729ve9ra3ve3tGbW987G3ve1tb3vb296eUfv/AJyhKP4W6dy/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allI,allO,H=getAllIOH(model,source,target,songs,width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c4158a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number=5\n",
    "I=(1*(songs==number)).astype(int)\n",
    "O=(target.transpose()[-1]==allO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0efa0cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cda2ede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69ade25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667d77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pos_encoder.pe', 'transformer_encoder.layers.0.self_attn.in_proj_weight', 'transformer_encoder.layers.0.self_attn.in_proj_bias', 'transformer_encoder.layers.0.self_attn.out_proj.weight', 'transformer_encoder.layers.0.self_attn.out_proj.bias', 'transformer_encoder.layers.0.linear1.weight', 'transformer_encoder.layers.0.linear1.bias', 'transformer_encoder.layers.0.linear2.weight', 'transformer_encoder.layers.0.linear2.bias', 'transformer_encoder.layers.0.norm1.weight', 'transformer_encoder.layers.0.norm1.bias', 'transformer_encoder.layers.0.norm2.weight', 'transformer_encoder.layers.0.norm2.bias', 'transformer_encoder.layers.1.self_attn.in_proj_weight', 'transformer_encoder.layers.1.self_attn.in_proj_bias', 'transformer_encoder.layers.1.self_attn.out_proj.weight', 'transformer_encoder.layers.1.self_attn.out_proj.bias', 'transformer_encoder.layers.1.linear1.weight', 'transformer_encoder.layers.1.linear1.bias', 'transformer_encoder.layers.1.linear2.weight', 'transformer_encoder.layers.1.linear2.bias', 'transformer_encoder.layers.1.norm1.weight', 'transformer_encoder.layers.1.norm1.bias', 'transformer_encoder.layers.1.norm2.weight', 'transformer_encoder.layers.1.norm2.bias', 'encoder.weight', 'decoder.weight', 'decoder.bias'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()\n",
    "#model.state_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bc9e5774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "436b2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d25e21",
   "metadata": {},
   "source": [
    "# RNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cc8fc",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5d128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        self.expansion_layer = nn.Linear(in_features=8, out_features=20)\n",
    "        self.rnn_layer = nn.RNN(input_size=20, hidden_size=20, batch_first=True)\n",
    "        self.output_layer = nn.Linear(in_features=20, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.expansion_layer(x))\n",
    "        x, _ = self.rnn_layer(x)\n",
    "        x = self.output_layer(x)  # Removed softmax here\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c324dc4",
   "metadata": {},
   "source": [
    "## generateIOData each song without combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b95b936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 8) (41,)\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.] [1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1\n",
      " 2 3 4 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8c1213b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songStrings = numpy.array([\n",
    "    \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "\n",
    "notes=list(\"ABCDEFGH\")\n",
    "\n",
    "def generateIOData(songNr, songStrings=songStrings):\n",
    "    notes=list(\"ABCDEFGH\")\n",
    "    I = np.zeros((41, 8))\n",
    "    O = np.zeros(41, dtype=int)  # Now preparing O as indices directly\n",
    "    raw =numpy.zeros((41,8)) # Now preparing O as indices directly\n",
    "    for i in range(41):\n",
    "        note_index = notes.index(songStrings[songNr][i])\n",
    "        I[i][note_index] = 1.0\n",
    "        raw[i][notes.index(songStrings[songNr][i+1])]=1.0\n",
    "        if i < 40:  # Adjusting for O to capture the next note as index\n",
    "            O[i] = notes.index(songStrings[songNr][i + 1])\n",
    "    return I, O, raw\n",
    "\n",
    "I,O, raw=generateIOData(1)\n",
    "print(I.shape,O.shape)\n",
    "print(I[0],O)\n",
    "subplot(1,2,1)\n",
    "imshow(I)\n",
    "subplot(1,2,2)\n",
    "imshow(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba02b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1423222422599792, Accuracy: 0.012195121496915817\n",
      "Epoch 1, Loss: 2.1423222422599792, Losses: [2.16 2.14 2.09 2.18]\n",
      "Epoch 1, Accuracy: 0.012195121496915817, Accuracies: [0.   0.02 0.02 0.  ]\n",
      "Epoch 11, Loss: 2.0848180055618286, Accuracy: 0.1768292635679245\n",
      "Epoch 11, Loss: 2.0848180055618286, Losses: [2.12 2.07 2.04 2.11]\n",
      "Epoch 11, Accuracy: 0.1768292635679245, Accuracies: [0.12 0.2  0.29 0.1 ]\n",
      "Epoch 21, Loss: 2.008313924074173, Accuracy: 0.1768292672932148\n",
      "Epoch 21, Loss: 2.008313924074173, Losses: [2.07 1.99 1.96 2.02]\n",
      "Epoch 21, Accuracy: 0.1768292672932148, Accuracies: [0.12 0.17 0.32 0.1 ]\n",
      "Epoch 31, Loss: 1.9235883057117462, Accuracy: 0.20121951401233673\n",
      "Epoch 31, Loss: 1.9235883057117462, Losses: [2.04 1.88 1.87 1.91]\n",
      "Epoch 31, Accuracy: 0.20121951401233673, Accuracies: [0.27 0.17 0.22 0.15]\n",
      "Epoch 41, Loss: 1.895916759967804, Accuracy: 0.32926829159259796\n",
      "Epoch 41, Loss: 1.895916759967804, Losses: [2.03 1.83 1.85 1.87]\n",
      "Epoch 41, Accuracy: 0.32926829159259796, Accuracies: [0.29 0.44 0.34 0.24]\n",
      "Epoch 51, Loss: 1.864927738904953, Accuracy: 0.32926829904317856\n",
      "Epoch 51, Loss: 1.864927738904953, Losses: [2.   1.78 1.83 1.85]\n",
      "Epoch 51, Accuracy: 0.32926829904317856, Accuracies: [0.27 0.46 0.27 0.32]\n",
      "Epoch 61, Loss: 1.8237559795379639, Accuracy: 0.31707317754626274\n",
      "Epoch 61, Loss: 1.8237559795379639, Losses: [1.97 1.69 1.8  1.83]\n",
      "Epoch 61, Accuracy: 0.31707317754626274, Accuracies: [0.17 0.49 0.27 0.34]\n",
      "Epoch 71, Loss: 1.7741607427597046, Accuracy: 0.31707317382097244\n",
      "Epoch 71, Loss: 1.7741607427597046, Losses: [1.93 1.6  1.76 1.81]\n",
      "Epoch 71, Accuracy: 0.31707317382097244, Accuracies: [0.12 0.49 0.27 0.39]\n",
      "Epoch 81, Loss: 1.7324854135513306, Accuracy: 0.335365854203701\n",
      "Epoch 81, Loss: 1.7324854135513306, Losses: [1.88 1.52 1.73 1.8 ]\n",
      "Epoch 81, Accuracy: 0.335365854203701, Accuracies: [0.12 0.61 0.29 0.32]\n",
      "Epoch 91, Loss: 1.696936935186386, Accuracy: 0.4085365831851959\n",
      "Epoch 91, Loss: 1.696936935186386, Losses: [1.84 1.45 1.71 1.79]\n",
      "Epoch 91, Accuracy: 0.4085365831851959, Accuracies: [0.22 0.76 0.32 0.34]\n",
      "Epoch 101, Loss: 1.6638051569461823, Accuracy: 0.43292682617902756\n",
      "Epoch 101, Loss: 1.6638051569461823, Losses: [1.79 1.39 1.69 1.78]\n",
      "Epoch 101, Accuracy: 0.43292682617902756, Accuracies: [0.29 0.76 0.32 0.37]\n",
      "Epoch 111, Loss: 1.6321057379245758, Accuracy: 0.4451219439506531\n",
      "Epoch 111, Loss: 1.6321057379245758, Losses: [1.76 1.33 1.67 1.77]\n",
      "Epoch 111, Accuracy: 0.4451219439506531, Accuracies: [0.37 0.78 0.32 0.32]\n",
      "Epoch 121, Loss: 1.6002275943756104, Accuracy: 0.45121949911117554\n",
      "Epoch 121, Loss: 1.6002275943756104, Losses: [1.72 1.27 1.65 1.76]\n",
      "Epoch 121, Accuracy: 0.45121949911117554, Accuracies: [0.41 0.78 0.32 0.29]\n",
      "Epoch 131, Loss: 1.5697491466999054, Accuracy: 0.4695121869444847\n",
      "Epoch 131, Loss: 1.5697491466999054, Losses: [1.69 1.21 1.63 1.75]\n",
      "Epoch 131, Accuracy: 0.4695121869444847, Accuracies: [0.46 0.78 0.32 0.32]\n",
      "Epoch 141, Loss: 1.538614571094513, Accuracy: 0.4817073121666908\n",
      "Epoch 141, Loss: 1.538614571094513, Losses: [1.64 1.17 1.61 1.73]\n",
      "Epoch 141, Accuracy: 0.4817073121666908, Accuracies: [0.49 0.78 0.32 0.34]\n",
      "Epoch 151, Loss: 1.5079728662967682, Accuracy: 0.49390244483947754\n",
      "Epoch 151, Loss: 1.5079728662967682, Losses: [1.6  1.12 1.58 1.72]\n",
      "Epoch 151, Accuracy: 0.49390244483947754, Accuracies: [0.46 0.8  0.37 0.34]\n",
      "Epoch 161, Loss: 1.4768984019756317, Accuracy: 0.49390244483947754\n",
      "Epoch 161, Loss: 1.4768984019756317, Losses: [1.57 1.08 1.56 1.7 ]\n",
      "Epoch 161, Accuracy: 0.49390244483947754, Accuracies: [0.46 0.8  0.34 0.37]\n",
      "Epoch 171, Loss: 1.4441823959350586, Accuracy: 0.49390244483947754\n",
      "Epoch 171, Loss: 1.4441823959350586, Losses: [1.53 1.05 1.53 1.68]\n",
      "Epoch 171, Accuracy: 0.49390244483947754, Accuracies: [0.46 0.8  0.37 0.34]\n",
      "Epoch 181, Loss: 1.4107650518417358, Accuracy: 0.5243902429938316\n",
      "Epoch 181, Loss: 1.4107650518417358, Losses: [1.48 1.02 1.5  1.65]\n",
      "Epoch 181, Accuracy: 0.5243902429938316, Accuracies: [0.56 0.8  0.39 0.34]\n",
      "Epoch 191, Loss: 1.3776328265666962, Accuracy: 0.5243902429938316\n",
      "Epoch 191, Loss: 1.3776328265666962, Losses: [1.42 0.99 1.47 1.63]\n",
      "Epoch 191, Accuracy: 0.5243902429938316, Accuracies: [0.56 0.8  0.39 0.34]\n",
      "Epoch 201, Loss: 1.3460075408220291, Accuracy: 0.5365853607654572\n",
      "Epoch 201, Loss: 1.3460075408220291, Losses: [1.38 0.96 1.44 1.61]\n",
      "Epoch 201, Accuracy: 0.5365853607654572, Accuracies: [0.59 0.8  0.41 0.34]\n",
      "Epoch 211, Loss: 1.3153078258037567, Accuracy: 0.5365853682160378\n",
      "Epoch 211, Loss: 1.3153078258037567, Losses: [1.33 0.93 1.41 1.59]\n",
      "Epoch 211, Accuracy: 0.5365853682160378, Accuracies: [0.56 0.8  0.44 0.34]\n",
      "Epoch 221, Loss: 1.287861704826355, Accuracy: 0.5426829308271408\n",
      "Epoch 221, Loss: 1.287861704826355, Losses: [1.3  0.91 1.38 1.57]\n",
      "Epoch 221, Accuracy: 0.5426829308271408, Accuracies: [0.56 0.8  0.44 0.37]\n",
      "Epoch 231, Loss: 1.263797864317894, Accuracy: 0.5609756112098694\n",
      "Epoch 231, Loss: 1.263797864317894, Losses: [1.27 0.89 1.36 1.55]\n",
      "Epoch 231, Accuracy: 0.5609756112098694, Accuracies: [0.56 0.8  0.49 0.39]\n",
      "Epoch 241, Loss: 1.2382966578006744, Accuracy: 0.56097561866045\n",
      "Epoch 241, Loss: 1.2382966578006744, Losses: [1.24 0.86 1.32 1.53]\n",
      "Epoch 241, Accuracy: 0.56097561866045, Accuracies: [0.61 0.8  0.46 0.37]\n",
      "Epoch 251, Loss: 1.2151538580656052, Accuracy: 0.567073181271553\n",
      "Epoch 251, Loss: 1.2151538580656052, Losses: [1.21 0.84 1.3  1.51]\n",
      "Epoch 251, Accuracy: 0.567073181271553, Accuracies: [0.61 0.8  0.49 0.37]\n",
      "Epoch 261, Loss: 1.1907513439655304, Accuracy: 0.579268291592598\n",
      "Epoch 261, Loss: 1.1907513439655304, Losses: [1.18 0.82 1.27 1.5 ]\n",
      "Epoch 261, Accuracy: 0.579268291592598, Accuracies: [0.61 0.83 0.49 0.39]\n",
      "Epoch 271, Loss: 1.167506530880928, Accuracy: 0.5853658467531204\n",
      "Epoch 271, Loss: 1.167506530880928, Losses: [1.15 0.8  1.24 1.48]\n",
      "Epoch 271, Accuracy: 0.5853658467531204, Accuracies: [0.61 0.83 0.51 0.39]\n",
      "Epoch 281, Loss: 1.157320886850357, Accuracy: 0.5853658616542816\n",
      "Epoch 281, Loss: 1.157320886850357, Losses: [1.14 0.77 1.22 1.5 ]\n",
      "Epoch 281, Accuracy: 0.5853658616542816, Accuracies: [0.66 0.83 0.54 0.32]\n",
      "Epoch 291, Loss: 1.1317873746156693, Accuracy: 0.6158536672592163\n",
      "Epoch 291, Loss: 1.1317873746156693, Losses: [1.11 0.75 1.2  1.47]\n",
      "Epoch 291, Accuracy: 0.6158536672592163, Accuracies: [0.66 0.85 0.56 0.39]\n",
      "Epoch 301, Loss: 1.1113107204437256, Accuracy: 0.6219512224197388\n",
      "Epoch 301, Loss: 1.1113107204437256, Losses: [1.09 0.74 1.18 1.44]\n",
      "Epoch 301, Accuracy: 0.6219512224197388, Accuracies: [0.68 0.83 0.54 0.44]\n",
      "Epoch 311, Loss: 1.1021668463945389, Accuracy: 0.6036585420370102\n",
      "Epoch 311, Loss: 1.1021668463945389, Losses: [1.07 0.72 1.19 1.44]\n",
      "Epoch 311, Accuracy: 0.6036585420370102, Accuracies: [0.68 0.85 0.51 0.37]\n",
      "Epoch 321, Loss: 1.083410158753395, Accuracy: 0.6280487701296806\n",
      "Epoch 321, Loss: 1.083410158753395, Losses: [1.04 0.7  1.17 1.42]\n",
      "Epoch 321, Accuracy: 0.6280487701296806, Accuracies: [0.71 0.88 0.51 0.41]\n",
      "Epoch 331, Loss: 1.0689958035945892, Accuracy: 0.6158536523580551\n",
      "Epoch 331, Loss: 1.0689958035945892, Losses: [1.03 0.68 1.15 1.42]\n",
      "Epoch 331, Accuracy: 0.6158536523580551, Accuracies: [0.71 0.88 0.51 0.37]\n",
      "Epoch 341, Loss: 1.0526903420686722, Accuracy: 0.6341463476419449\n",
      "Epoch 341, Loss: 1.0526903420686722, Losses: [1.01 0.67 1.13 1.4 ]\n",
      "Epoch 341, Accuracy: 0.6341463476419449, Accuracies: [0.76 0.88 0.54 0.37]\n",
      "Epoch 351, Loss: 1.0527413338422775, Accuracy: 0.6402439028024673\n",
      "Epoch 351, Loss: 1.0527413338422775, Losses: [0.99 0.66 1.16 1.4 ]\n",
      "Epoch 351, Accuracy: 0.6402439028024673, Accuracies: [0.76 0.88 0.54 0.39]\n",
      "Epoch 361, Loss: 1.0245595574378967, Accuracy: 0.664634145796299\n",
      "Epoch 361, Loss: 1.0245595574378967, Losses: [0.97 0.65 1.1  1.37]\n",
      "Epoch 361, Accuracy: 0.664634145796299, Accuracies: [0.76 0.93 0.56 0.41]\n",
      "Epoch 371, Loss: 1.0258464515209198, Accuracy: 0.646341472864151\n",
      "Epoch 371, Loss: 1.0258464515209198, Losses: [0.96 0.63 1.11 1.4 ]\n",
      "Epoch 371, Accuracy: 0.646341472864151, Accuracies: [0.76 0.93 0.54 0.37]\n",
      "Epoch 381, Loss: 1.0120590329170227, Accuracy: 0.6402439028024673\n",
      "Epoch 381, Loss: 1.0120590329170227, Losses: [0.95 0.62 1.11 1.37]\n",
      "Epoch 381, Accuracy: 0.6402439028024673, Accuracies: [0.76 0.93 0.51 0.37]\n",
      "Epoch 391, Loss: 0.9909243732690811, Accuracy: 0.664634145796299\n",
      "Epoch 391, Loss: 0.9909243732690811, Losses: [0.93 0.61 1.08 1.35]\n",
      "Epoch 391, Accuracy: 0.664634145796299, Accuracies: [0.76 0.93 0.56 0.41]\n",
      "Epoch 401, Loss: 0.9825747013092041, Accuracy: 0.670731708407402\n",
      "Epoch 401, Loss: 0.9825747013092041, Losses: [0.91 0.6  1.07 1.35]\n",
      "Epoch 401, Accuracy: 0.670731708407402, Accuracies: [0.76 0.93 0.56 0.44]\n",
      "Epoch 411, Loss: 0.968808963894844, Accuracy: 0.670731708407402\n",
      "Epoch 411, Loss: 0.968808963894844, Losses: [0.9  0.59 1.07 1.32]\n",
      "Epoch 411, Accuracy: 0.670731708407402, Accuracies: [0.76 0.93 0.56 0.44]\n",
      "Epoch 421, Loss: 0.9628894180059433, Accuracy: 0.6768292710185051\n",
      "Epoch 421, Loss: 0.9628894180059433, Losses: [0.88 0.58 1.07 1.32]\n",
      "Epoch 421, Accuracy: 0.6768292710185051, Accuracies: [0.76 0.93 0.56 0.46]\n",
      "Epoch 431, Loss: 0.9495501518249512, Accuracy: 0.6951219439506531\n",
      "Epoch 431, Loss: 0.9495501518249512, Losses: [0.87 0.56 1.05 1.32]\n",
      "Epoch 431, Accuracy: 0.6951219439506531, Accuracies: [0.78 0.93 0.59 0.49]\n",
      "Epoch 441, Loss: 0.9333815574645996, Accuracy: 0.7073170691728592\n",
      "Epoch 441, Loss: 0.9333815574645996, Losses: [0.86 0.55 1.03 1.29]\n",
      "Epoch 441, Accuracy: 0.7073170691728592, Accuracies: [0.8  0.95 0.59 0.49]\n",
      "Epoch 451, Loss: 0.939408153295517, Accuracy: 0.7012195065617561\n",
      "Epoch 451, Loss: 0.939408153295517, Losses: [0.84 0.55 1.03 1.33]\n",
      "Epoch 451, Accuracy: 0.7012195065617561, Accuracies: [0.8  0.95 0.59 0.46]\n",
      "Epoch 461, Loss: 0.9160646796226501, Accuracy: 0.7012194991111755\n",
      "Epoch 461, Loss: 0.9160646796226501, Losses: [0.83 0.54 1.02 1.28]\n",
      "Epoch 461, Accuracy: 0.7012194991111755, Accuracies: [0.78 0.95 0.59 0.49]\n",
      "Epoch 471, Loss: 0.9107332527637482, Accuracy: 0.6951219588518143\n",
      "Epoch 471, Loss: 0.9107332527637482, Losses: [0.83 0.53 1.01 1.27]\n",
      "Epoch 471, Accuracy: 0.6951219588518143, Accuracies: [0.8  0.95 0.54 0.49]\n",
      "Epoch 481, Loss: 0.8961822539567947, Accuracy: 0.6951219439506531\n",
      "Epoch 481, Loss: 0.8961822539567947, Losses: [0.81 0.51 1.   1.26]\n",
      "Epoch 481, Accuracy: 0.6951219439506531, Accuracies: [0.8  0.95 0.59 0.44]\n",
      "Epoch 491, Loss: 0.8865367919206619, Accuracy: 0.6890243887901306\n",
      "Epoch 491, Loss: 0.8865367919206619, Losses: [0.8  0.5  0.99 1.25]\n",
      "Epoch 491, Accuracy: 0.6890243887901306, Accuracies: [0.8  0.95 0.56 0.44]\n",
      "Epoch 501, Loss: 0.879724308848381, Accuracy: 0.6890243887901306\n",
      "Epoch 501, Loss: 0.879724308848381, Losses: [0.79 0.49 0.99 1.24]\n",
      "Epoch 501, Accuracy: 0.6890243887901306, Accuracies: [0.8  0.95 0.56 0.44]\n",
      "Epoch 511, Loss: 0.882627584040165, Accuracy: 0.7195121943950653\n",
      "Epoch 511, Loss: 0.882627584040165, Losses: [0.78 0.49 1.03 1.22]\n",
      "Epoch 511, Accuracy: 0.7195121943950653, Accuracies: [0.8  0.95 0.61 0.51]\n",
      "Epoch 521, Loss: 0.8587570637464523, Accuracy: 0.7073170691728592\n",
      "Epoch 521, Loss: 0.8587570637464523, Losses: [0.77 0.48 0.97 1.22]\n",
      "Epoch 521, Accuracy: 0.7073170691728592, Accuracies: [0.8  0.95 0.56 0.51]\n",
      "Epoch 531, Loss: 0.8522711843252182, Accuracy: 0.7134146392345428\n",
      "Epoch 531, Loss: 0.8522711843252182, Losses: [0.76 0.47 0.96 1.21]\n",
      "Epoch 531, Accuracy: 0.7134146392345428, Accuracies: [0.8  0.95 0.56 0.54]\n",
      "Epoch 541, Loss: 0.8451945185661316, Accuracy: 0.7317073196172714\n",
      "Epoch 541, Loss: 0.8451945185661316, Losses: [0.76 0.46 0.97 1.19]\n",
      "Epoch 541, Accuracy: 0.7317073196172714, Accuracies: [0.8  0.95 0.61 0.56]\n",
      "Epoch 551, Loss: 0.8443408012390137, Accuracy: 0.725609764456749\n",
      "Epoch 551, Loss: 0.8443408012390137, Losses: [0.75 0.45 0.97 1.2 ]\n",
      "Epoch 551, Accuracy: 0.725609764456749, Accuracies: [0.8  0.95 0.61 0.54]\n",
      "Epoch 561, Loss: 0.8324998170137405, Accuracy: 0.7073170840740204\n",
      "Epoch 561, Loss: 0.8324998170137405, Losses: [0.74 0.45 0.96 1.19]\n",
      "Epoch 561, Accuracy: 0.7073170840740204, Accuracies: [0.8  0.95 0.54 0.54]\n",
      "Epoch 571, Loss: 0.8269990012049675, Accuracy: 0.7134146243333817\n",
      "Epoch 571, Loss: 0.8269990012049675, Losses: [0.74 0.44 0.93 1.2 ]\n",
      "Epoch 571, Accuracy: 0.7134146243333817, Accuracies: [0.78 0.95 0.61 0.51]\n",
      "Epoch 581, Loss: 0.8078818768262863, Accuracy: 0.7195121943950653\n",
      "Epoch 581, Loss: 0.8078818768262863, Losses: [0.72 0.43 0.92 1.16]\n",
      "Epoch 581, Accuracy: 0.7195121943950653, Accuracies: [0.8  0.95 0.59 0.54]\n",
      "Epoch 591, Loss: 0.8033779934048653, Accuracy: 0.725609764456749\n",
      "Epoch 591, Loss: 0.8033779934048653, Losses: [0.71 0.43 0.93 1.15]\n",
      "Epoch 591, Accuracy: 0.725609764456749, Accuracies: [0.8  0.95 0.61 0.54]\n",
      "Epoch 601, Loss: 0.8121688291430473, Accuracy: 0.7073170691728592\n",
      "Epoch 601, Loss: 0.8121688291430473, Losses: [0.71 0.42 0.93 1.18]\n",
      "Epoch 601, Accuracy: 0.7073170691728592, Accuracies: [0.8  0.95 0.56 0.51]\n",
      "Epoch 611, Loss: 0.7909568101167679, Accuracy: 0.7195121943950653\n",
      "Epoch 611, Loss: 0.7909568101167679, Losses: [0.7  0.41 0.91 1.13]\n",
      "Epoch 611, Accuracy: 0.7195121943950653, Accuracies: [0.8  0.95 0.61 0.51]\n",
      "Epoch 621, Loss: 0.7843495160341263, Accuracy: 0.7195121943950653\n",
      "Epoch 621, Loss: 0.7843495160341263, Losses: [0.69 0.41 0.9  1.13]\n",
      "Epoch 621, Accuracy: 0.7195121943950653, Accuracies: [0.8  0.95 0.59 0.54]\n",
      "Epoch 631, Loss: 0.7694114744663239, Accuracy: 0.7378048747777939\n",
      "Epoch 631, Loss: 0.7694114744663239, Losses: [0.69 0.4  0.88 1.11]\n",
      "Epoch 631, Accuracy: 0.7378048747777939, Accuracies: [0.8  0.95 0.63 0.56]\n",
      "Epoch 641, Loss: 0.7666659280657768, Accuracy: 0.725609764456749\n",
      "Epoch 641, Loss: 0.7666659280657768, Losses: [0.68 0.4  0.9  1.09]\n",
      "Epoch 641, Accuracy: 0.725609764456749, Accuracies: [0.8  0.95 0.61 0.54]\n",
      "Epoch 651, Loss: 0.7595465183258057, Accuracy: 0.7378048747777939\n",
      "Epoch 651, Loss: 0.7595465183258057, Losses: [0.67 0.4  0.89 1.08]\n",
      "Epoch 651, Accuracy: 0.7378048747777939, Accuracies: [0.8  0.95 0.63 0.56]\n",
      "Epoch 661, Loss: 0.7573477402329445, Accuracy: 0.7256097495555878\n",
      "Epoch 661, Loss: 0.7573477402329445, Losses: [0.67 0.39 0.9  1.08]\n",
      "Epoch 661, Accuracy: 0.7256097495555878, Accuracies: [0.8  0.95 0.59 0.56]\n",
      "Epoch 671, Loss: 0.7470995560288429, Accuracy: 0.7439024448394775\n",
      "Epoch 671, Loss: 0.7470995560288429, Losses: [0.66 0.38 0.89 1.06]\n",
      "Epoch 671, Accuracy: 0.7439024448394775, Accuracies: [0.8  0.95 0.66 0.56]\n",
      "Epoch 681, Loss: 0.739319384098053, Accuracy: 0.75\n",
      "Epoch 681, Loss: 0.739319384098053, Losses: [0.65 0.37 0.88 1.05]\n",
      "Epoch 681, Accuracy: 0.75, Accuracies: [0.8  0.98 0.63 0.59]\n",
      "Epoch 691, Loss: 0.7282808721065521, Accuracy: 0.7439024448394775\n",
      "Epoch 691, Loss: 0.7282808721065521, Losses: [0.64 0.37 0.85 1.04]\n",
      "Epoch 691, Accuracy: 0.7439024448394775, Accuracies: [0.8  0.98 0.61 0.59]\n",
      "Epoch 701, Loss: 0.7395931705832481, Accuracy: 0.7439024448394775\n",
      "Epoch 701, Loss: 0.7395931705832481, Losses: [0.64 0.37 0.89 1.07]\n",
      "Epoch 701, Accuracy: 0.7439024448394775, Accuracies: [0.8  0.98 0.61 0.59]\n",
      "Epoch 711, Loss: 0.7144956439733505, Accuracy: 0.7500000149011612\n",
      "Epoch 711, Loss: 0.7144956439733505, Losses: [0.63 0.36 0.83 1.03]\n",
      "Epoch 711, Accuracy: 0.7500000149011612, Accuracies: [0.8  0.98 0.61 0.61]\n",
      "Epoch 721, Loss: 0.7031296938657761, Accuracy: 0.7560975700616837\n",
      "Epoch 721, Loss: 0.7031296938657761, Losses: [0.63 0.36 0.82 1.  ]\n",
      "Epoch 721, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.61 0.63]\n",
      "Epoch 731, Loss: 0.694539450109005, Accuracy: 0.7500000149011612\n",
      "Epoch 731, Loss: 0.694539450109005, Losses: [0.62 0.35 0.82 0.99]\n",
      "Epoch 731, Accuracy: 0.7500000149011612, Accuracies: [0.8  0.98 0.61 0.61]\n",
      "Epoch 741, Loss: 0.69076157361269, Accuracy: 0.7500000149011612\n",
      "Epoch 741, Loss: 0.69076157361269, Losses: [0.61 0.35 0.81 0.99]\n",
      "Epoch 741, Accuracy: 0.7500000149011612, Accuracies: [0.8  0.98 0.61 0.61]\n",
      "Epoch 751, Loss: 0.7044761478900909, Accuracy: 0.7378048896789551\n",
      "Epoch 751, Loss: 0.7044761478900909, Losses: [0.61 0.34 0.82 1.05]\n",
      "Epoch 751, Accuracy: 0.7378048896789551, Accuracies: [0.83 0.98 0.61 0.54]\n",
      "Epoch 761, Loss: 0.7248881384730339, Accuracy: 0.7682926952838898\n",
      "Epoch 761, Loss: 0.7248881384730339, Losses: [0.61 0.33 0.97 0.99]\n",
      "Epoch 761, Accuracy: 0.7682926952838898, Accuracies: [0.83 0.98 0.66 0.61]\n",
      "Epoch 771, Loss: 0.6917953565716743, Accuracy: 0.7560975700616837\n",
      "Epoch 771, Loss: 0.6917953565716743, Losses: [0.61 0.34 0.86 0.96]\n",
      "Epoch 771, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.63 0.61]\n",
      "Epoch 781, Loss: 0.6799687743186951, Accuracy: 0.7439024448394775\n",
      "Epoch 781, Loss: 0.6799687743186951, Losses: [0.59 0.33 0.83 0.97]\n",
      "Epoch 781, Accuracy: 0.7439024448394775, Accuracies: [0.8  0.98 0.61 0.59]\n",
      "Epoch 791, Loss: 0.6584673374891281, Accuracy: 0.7560975700616837\n",
      "Epoch 791, Loss: 0.6584673374891281, Losses: [0.58 0.33 0.79 0.93]\n",
      "Epoch 791, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.61 0.63]\n",
      "Epoch 801, Loss: 0.6685883700847626, Accuracy: 0.7621951401233673\n",
      "Epoch 801, Loss: 0.6685883700847626, Losses: [0.58 0.33 0.84 0.92]\n",
      "Epoch 801, Accuracy: 0.7621951401233673, Accuracies: [0.8  0.98 0.61 0.66]\n",
      "Epoch 811, Loss: 0.7120286896824837, Accuracy: 0.7195122092962265\n",
      "Epoch 811, Loss: 0.7120286896824837, Losses: [0.58 0.34 0.87 1.07]\n",
      "Epoch 811, Accuracy: 0.7195122092962265, Accuracies: [0.8  0.98 0.56 0.54]\n",
      "Epoch 821, Loss: 0.6450793147087097, Accuracy: 0.7621951401233673\n",
      "Epoch 821, Loss: 0.6450793147087097, Losses: [0.57 0.32 0.78 0.91]\n",
      "Epoch 821, Accuracy: 0.7621951401233673, Accuracies: [0.8  0.98 0.61 0.66]\n",
      "Epoch 831, Loss: 0.6365307718515396, Accuracy: 0.7500000149011612\n",
      "Epoch 831, Loss: 0.6365307718515396, Losses: [0.56 0.32 0.77 0.9 ]\n",
      "Epoch 831, Accuracy: 0.7500000149011612, Accuracies: [0.8  0.98 0.61 0.61]\n",
      "Epoch 841, Loss: 0.6304558515548706, Accuracy: 0.7560975700616837\n",
      "Epoch 841, Loss: 0.6304558515548706, Losses: [0.56 0.31 0.77 0.88]\n",
      "Epoch 841, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.61 0.63]\n",
      "Epoch 851, Loss: 0.6254407837986946, Accuracy: 0.7682926952838898\n",
      "Epoch 851, Loss: 0.6254407837986946, Losses: [0.55 0.3  0.77 0.88]\n",
      "Epoch 851, Accuracy: 0.7682926952838898, Accuracies: [0.85 0.98 0.61 0.63]\n",
      "Epoch 861, Loss: 0.6182693541049957, Accuracy: 0.7560975700616837\n",
      "Epoch 861, Loss: 0.6182693541049957, Losses: [0.55 0.31 0.76 0.86]\n",
      "Epoch 861, Accuracy: 0.7560975700616837, Accuracies: [0.83 0.98 0.61 0.61]\n",
      "Epoch 871, Loss: 0.6452504992485046, Accuracy: 0.7621951252222061\n",
      "Epoch 871, Loss: 0.6452504992485046, Losses: [0.54 0.31 0.79 0.94]\n",
      "Epoch 871, Accuracy: 0.7621951252222061, Accuracies: [0.8  0.98 0.63 0.63]\n",
      "Epoch 881, Loss: 0.617629773914814, Accuracy: 0.7682926952838898\n",
      "Epoch 881, Loss: 0.617629773914814, Losses: [0.54 0.3  0.76 0.88]\n",
      "Epoch 881, Accuracy: 0.7682926952838898, Accuracies: [0.85 0.98 0.61 0.63]\n",
      "Epoch 891, Loss: 0.6064867451786995, Accuracy: 0.7865853756666183\n",
      "Epoch 891, Loss: 0.6064867451786995, Losses: [0.53 0.29 0.75 0.85]\n",
      "Epoch 891, Accuracy: 0.7865853756666183, Accuracies: [0.85 0.98 0.63 0.68]\n",
      "Epoch 901, Loss: 0.6236387342214584, Accuracy: 0.7743902653455734\n",
      "Epoch 901, Loss: 0.6236387342214584, Losses: [0.53 0.29 0.83 0.85]\n",
      "Epoch 901, Accuracy: 0.7743902653455734, Accuracies: [0.85 0.98 0.61 0.66]\n",
      "Epoch 911, Loss: 0.5987674742937088, Accuracy: 0.7804878205060959\n",
      "Epoch 911, Loss: 0.5987674742937088, Losses: [0.52 0.29 0.75 0.84]\n",
      "Epoch 911, Accuracy: 0.7804878205060959, Accuracies: [0.85 0.98 0.63 0.66]\n",
      "Epoch 921, Loss: 0.6247794181108475, Accuracy: 0.75\n",
      "Epoch 921, Loss: 0.6247794181108475, Losses: [0.52 0.29 0.81 0.89]\n",
      "Epoch 921, Accuracy: 0.75, Accuracies: [0.85 0.98 0.59 0.59]\n",
      "Epoch 931, Loss: 0.5994521826505661, Accuracy: 0.7804878056049347\n",
      "Epoch 931, Loss: 0.5994521826505661, Losses: [0.51 0.28 0.76 0.84]\n",
      "Epoch 931, Accuracy: 0.7804878056049347, Accuracies: [0.83 0.98 0.63 0.68]\n",
      "Epoch 941, Loss: 0.5867453292012215, Accuracy: 0.7804878056049347\n",
      "Epoch 941, Loss: 0.5867453292012215, Losses: [0.51 0.28 0.74 0.83]\n",
      "Epoch 941, Accuracy: 0.7804878056049347, Accuracies: [0.83 0.98 0.61 0.71]\n",
      "Epoch 951, Loss: 0.5753206610679626, Accuracy: 0.7926829308271408\n",
      "Epoch 951, Loss: 0.5753206610679626, Losses: [0.5  0.28 0.73 0.79]\n",
      "Epoch 951, Accuracy: 0.7926829308271408, Accuracies: [0.85 0.98 0.63 0.71]\n",
      "Epoch 961, Loss: 0.5685209706425667, Accuracy: 0.7926829308271408\n",
      "Epoch 961, Loss: 0.5685209706425667, Losses: [0.5  0.27 0.72 0.78]\n",
      "Epoch 961, Accuracy: 0.7926829308271408, Accuracies: [0.85 0.98 0.63 0.71]\n",
      "Epoch 971, Loss: 0.5612086430191994, Accuracy: 0.7865853756666183\n",
      "Epoch 971, Loss: 0.5612086430191994, Losses: [0.49 0.27 0.71 0.77]\n",
      "Epoch 971, Accuracy: 0.7865853756666183, Accuracies: [0.85 0.98 0.63 0.68]\n",
      "Epoch 981, Loss: 0.5632450208067894, Accuracy: 0.8048780709505081\n",
      "Epoch 981, Loss: 0.5632450208067894, Losses: [0.49 0.27 0.74 0.76]\n",
      "Epoch 981, Accuracy: 0.8048780709505081, Accuracies: [0.85 0.98 0.66 0.73]\n",
      "Epoch 991, Loss: 0.582765482366085, Accuracy: 0.7865853756666183\n",
      "Epoch 991, Loss: 0.582765482366085, Losses: [0.48 0.27 0.71 0.87]\n",
      "Epoch 991, Accuracy: 0.7865853756666183, Accuracies: [0.88 0.98 0.66 0.63]\n",
      "Epoch 1001, Loss: 0.6483401656150818, Accuracy: 0.7621951252222061\n",
      "Epoch 1001, Loss: 0.6483401656150818, Losses: [0.51 0.28 0.85 0.95]\n",
      "Epoch 1001, Accuracy: 0.7621951252222061, Accuracies: [0.83 0.98 0.61 0.63]\n",
      "Epoch 1011, Loss: 0.5561074465513229, Accuracy: 0.8048780560493469\n",
      "Epoch 1011, Loss: 0.5561074465513229, Losses: [0.48 0.26 0.72 0.77]\n",
      "Epoch 1011, Accuracy: 0.8048780560493469, Accuracies: [0.85 0.98 0.63 0.76]\n",
      "Epoch 1021, Loss: 0.5440239831805229, Accuracy: 0.8109756261110306\n",
      "Epoch 1021, Loss: 0.5440239831805229, Losses: [0.47 0.26 0.7  0.75]\n",
      "Epoch 1021, Accuracy: 0.8109756261110306, Accuracies: [0.85 0.98 0.66 0.76]\n",
      "Epoch 1031, Loss: 0.5376805141568184, Accuracy: 0.8109756261110306\n",
      "Epoch 1031, Loss: 0.5376805141568184, Losses: [0.47 0.26 0.7  0.73]\n",
      "Epoch 1031, Accuracy: 0.8109756261110306, Accuracies: [0.85 0.98 0.66 0.76]\n",
      "Epoch 1041, Loss: 0.5323569923639297, Accuracy: 0.8109756261110306\n",
      "Epoch 1041, Loss: 0.5323569923639297, Losses: [0.46 0.25 0.69 0.72]\n",
      "Epoch 1041, Accuracy: 0.8109756261110306, Accuracies: [0.85 0.98 0.66 0.76]\n",
      "Epoch 1051, Loss: 0.5270585045218468, Accuracy: 0.8109756261110306\n",
      "Epoch 1051, Loss: 0.5270585045218468, Losses: [0.46 0.25 0.69 0.71]\n",
      "Epoch 1051, Accuracy: 0.8109756261110306, Accuracies: [0.85 0.98 0.66 0.76]\n",
      "Epoch 1061, Loss: 0.5253162756562233, Accuracy: 0.7926829308271408\n",
      "Epoch 1061, Loss: 0.5253162756562233, Losses: [0.45 0.25 0.69 0.71]\n",
      "Epoch 1061, Accuracy: 0.7926829308271408, Accuracies: [0.85 0.98 0.63 0.71]\n",
      "Epoch 1071, Loss: 0.5595611110329628, Accuracy: 0.7865853905677795\n",
      "Epoch 1071, Loss: 0.5595611110329628, Losses: [0.45 0.25 0.69 0.84]\n",
      "Epoch 1071, Accuracy: 0.7865853905677795, Accuracies: [0.85 0.98 0.66 0.66]\n",
      "Epoch 1081, Loss: 0.5409287288784981, Accuracy: 0.817073181271553\n",
      "Epoch 1081, Loss: 0.5409287288784981, Losses: [0.46 0.25 0.72 0.73]\n",
      "Epoch 1081, Accuracy: 0.817073181271553, Accuracies: [0.88 0.98 0.66 0.76]\n",
      "Epoch 1091, Loss: 0.5176573619246483, Accuracy: 0.8109756112098694\n",
      "Epoch 1091, Loss: 0.5176573619246483, Losses: [0.45 0.24 0.68 0.7 ]\n",
      "Epoch 1091, Accuracy: 0.8109756112098694, Accuracies: [0.88 0.98 0.63 0.76]\n",
      "Epoch 1101, Loss: 0.5098761394619942, Accuracy: 0.8231707364320755\n",
      "Epoch 1101, Loss: 0.5098761394619942, Losses: [0.44 0.24 0.67 0.69]\n",
      "Epoch 1101, Accuracy: 0.8231707364320755, Accuracies: [0.88 0.98 0.66 0.78]\n",
      "Epoch 1111, Loss: 0.5040514171123505, Accuracy: 0.8109756261110306\n",
      "Epoch 1111, Loss: 0.5040514171123505, Losses: [0.43 0.24 0.67 0.67]\n",
      "Epoch 1111, Accuracy: 0.8109756261110306, Accuracies: [0.85 0.98 0.66 0.76]\n",
      "Epoch 1121, Loss: 0.49854426831007004, Accuracy: 0.8231707364320755\n",
      "Epoch 1121, Loss: 0.49854426831007004, Losses: [0.43 0.24 0.66 0.66]\n",
      "Epoch 1121, Accuracy: 0.8231707364320755, Accuracies: [0.88 0.98 0.66 0.78]\n",
      "Epoch 1131, Loss: 0.5032360777258873, Accuracy: 0.8109756112098694\n",
      "Epoch 1131, Loss: 0.5032360777258873, Losses: [0.43 0.24 0.69 0.66]\n",
      "Epoch 1131, Accuracy: 0.8109756112098694, Accuracies: [0.83 0.98 0.66 0.78]\n",
      "Epoch 1141, Loss: 0.5064568296074867, Accuracy: 0.8231707364320755\n",
      "Epoch 1141, Loss: 0.5064568296074867, Losses: [0.42 0.23 0.71 0.66]\n",
      "Epoch 1141, Accuracy: 0.8231707364320755, Accuracies: [0.88 0.98 0.66 0.78]\n",
      "Epoch 1151, Loss: 0.5405666381120682, Accuracy: 0.8170731663703918\n",
      "Epoch 1151, Loss: 0.5405666381120682, Losses: [0.42 0.25 0.79 0.7 ]\n",
      "Epoch 1151, Accuracy: 0.8170731663703918, Accuracies: [0.88 0.98 0.71 0.71]\n",
      "Epoch 1161, Loss: 0.5064942315220833, Accuracy: 0.817073181271553\n",
      "Epoch 1161, Loss: 0.5064942315220833, Losses: [0.42 0.23 0.71 0.67]\n",
      "Epoch 1161, Accuracy: 0.817073181271553, Accuracies: [0.9  0.98 0.66 0.73]\n",
      "Epoch 1171, Loss: 0.48323915898799896, Accuracy: 0.8231707364320755\n",
      "Epoch 1171, Loss: 0.48323915898799896, Losses: [0.41 0.22 0.65 0.64]\n",
      "Epoch 1171, Accuracy: 0.8231707364320755, Accuracies: [0.9  0.98 0.66 0.76]\n",
      "Epoch 1181, Loss: 0.47629087418317795, Accuracy: 0.829268291592598\n",
      "Epoch 1181, Loss: 0.47629087418317795, Losses: [0.41 0.22 0.65 0.63]\n",
      "Epoch 1181, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1191, Loss: 0.4715442955493927, Accuracy: 0.829268291592598\n",
      "Epoch 1191, Loss: 0.4715442955493927, Losses: [0.4  0.22 0.64 0.62]\n",
      "Epoch 1191, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1201, Loss: 0.4675585739314556, Accuracy: 0.8353658467531204\n",
      "Epoch 1201, Loss: 0.4675585739314556, Losses: [0.4  0.22 0.64 0.62]\n",
      "Epoch 1201, Accuracy: 0.8353658467531204, Accuracies: [0.9  0.98 0.68 0.78]\n",
      "Epoch 1211, Loss: 0.47063349559903145, Accuracy: 0.8414634168148041\n",
      "Epoch 1211, Loss: 0.47063349559903145, Losses: [0.39 0.22 0.65 0.62]\n",
      "Epoch 1211, Accuracy: 0.8414634168148041, Accuracies: [0.9  0.98 0.66 0.83]\n",
      "Epoch 1221, Loss: 0.5358134880661964, Accuracy: 0.8109756112098694\n",
      "Epoch 1221, Loss: 0.5358134880661964, Losses: [0.4  0.31 0.76 0.68]\n",
      "Epoch 1221, Accuracy: 0.8109756112098694, Accuracies: [0.88 0.93 0.71 0.73]\n",
      "Epoch 1231, Loss: 0.4885357692837715, Accuracy: 0.8170731663703918\n",
      "Epoch 1231, Loss: 0.4885357692837715, Losses: [0.4  0.21 0.71 0.62]\n",
      "Epoch 1231, Accuracy: 0.8170731663703918, Accuracies: [0.88 0.98 0.59 0.83]\n",
      "Epoch 1241, Loss: 0.4596053324639797, Accuracy: 0.8353658467531204\n",
      "Epoch 1241, Loss: 0.4596053324639797, Losses: [0.39 0.21 0.63 0.61]\n",
      "Epoch 1241, Accuracy: 0.8353658467531204, Accuracies: [0.9  0.98 0.68 0.78]\n",
      "Epoch 1251, Loss: 0.4528217129409313, Accuracy: 0.829268291592598\n",
      "Epoch 1251, Loss: 0.4528217129409313, Losses: [0.38 0.21 0.63 0.59]\n",
      "Epoch 1251, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1261, Loss: 0.44784194603562355, Accuracy: 0.829268291592598\n",
      "Epoch 1261, Loss: 0.44784194603562355, Losses: [0.38 0.21 0.62 0.58]\n",
      "Epoch 1261, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1271, Loss: 0.445934496819973, Accuracy: 0.829268291592598\n",
      "Epoch 1271, Loss: 0.445934496819973, Losses: [0.37 0.21 0.62 0.58]\n",
      "Epoch 1271, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1281, Loss: 0.4459094703197479, Accuracy: 0.829268291592598\n",
      "Epoch 1281, Loss: 0.4459094703197479, Losses: [0.37 0.21 0.62 0.59]\n",
      "Epoch 1281, Accuracy: 0.829268291592598, Accuracies: [0.9  0.98 0.66 0.78]\n",
      "Epoch 1291, Loss: 0.4356645494699478, Accuracy: 0.8353658467531204\n",
      "Epoch 1291, Loss: 0.4356645494699478, Losses: [0.36 0.21 0.61 0.57]\n",
      "Epoch 1291, Accuracy: 0.8353658467531204, Accuracies: [0.9  0.98 0.68 0.78]\n",
      "Epoch 1301, Loss: 0.4462307319045067, Accuracy: 0.8475609868764877\n",
      "Epoch 1301, Loss: 0.4462307319045067, Losses: [0.36 0.21 0.64 0.58]\n",
      "Epoch 1301, Accuracy: 0.8475609868764877, Accuracies: [0.93 0.98 0.68 0.8 ]\n",
      "Epoch 1311, Loss: 0.43054694309830666, Accuracy: 0.8414634317159653\n",
      "Epoch 1311, Loss: 0.43054694309830666, Losses: [0.35 0.2  0.6  0.56]\n",
      "Epoch 1311, Accuracy: 0.8414634317159653, Accuracies: [0.93 0.98 0.66 0.8 ]\n",
      "Epoch 1321, Loss: 0.43286463990807533, Accuracy: 0.8353658616542816\n",
      "Epoch 1321, Loss: 0.43286463990807533, Losses: [0.35 0.2  0.6  0.58]\n",
      "Epoch 1321, Accuracy: 0.8353658616542816, Accuracies: [0.93 0.98 0.66 0.78]\n",
      "Epoch 1331, Loss: 0.42082545533776283, Accuracy: 0.8414634168148041\n",
      "Epoch 1331, Loss: 0.42082545533776283, Losses: [0.35 0.2  0.59 0.55]\n",
      "Epoch 1331, Accuracy: 0.8414634168148041, Accuracies: [0.93 0.98 0.68 0.78]\n",
      "Epoch 1341, Loss: 0.4299825243651867, Accuracy: 0.8536585420370102\n",
      "Epoch 1341, Loss: 0.4299825243651867, Losses: [0.34 0.2  0.64 0.54]\n",
      "Epoch 1341, Accuracy: 0.8536585420370102, Accuracies: [0.93 0.98 0.71 0.8 ]\n",
      "Epoch 1351, Loss: 0.42058485373854637, Accuracy: 0.8536585420370102\n",
      "Epoch 1351, Loss: 0.42058485373854637, Losses: [0.34 0.19 0.6  0.54]\n",
      "Epoch 1351, Accuracy: 0.8536585420370102, Accuracies: [0.9  0.98 0.73 0.8 ]\n",
      "Epoch 1361, Loss: 0.5086616612970829, Accuracy: 0.8231707364320755\n",
      "Epoch 1361, Loss: 0.5086616612970829, Losses: [0.34 0.21 0.89 0.6 ]\n",
      "Epoch 1361, Accuracy: 0.8231707364320755, Accuracies: [0.95 0.98 0.56 0.8 ]\n",
      "Epoch 1371, Loss: 0.4748521186411381, Accuracy: 0.829268291592598\n",
      "Epoch 1371, Loss: 0.4748521186411381, Losses: [0.35 0.2  0.75 0.61]\n",
      "Epoch 1371, Accuracy: 0.829268291592598, Accuracies: [0.88 0.98 0.76 0.71]\n",
      "Epoch 1381, Loss: 0.4255256876349449, Accuracy: 0.8475609719753265\n",
      "Epoch 1381, Loss: 0.4255256876349449, Losses: [0.33 0.19 0.62 0.56]\n",
      "Epoch 1381, Accuracy: 0.8475609719753265, Accuracies: [0.95 0.98 0.68 0.78]\n",
      "Epoch 1391, Loss: 0.4062717631459236, Accuracy: 0.8597560971975327\n",
      "Epoch 1391, Loss: 0.4062717631459236, Losses: [0.33 0.19 0.58 0.53]\n",
      "Epoch 1391, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.71 0.8 ]\n",
      "Epoch 1401, Loss: 0.40032191947102547, Accuracy: 0.8597560971975327\n",
      "Epoch 1401, Loss: 0.40032191947102547, Losses: [0.32 0.19 0.57 0.52]\n",
      "Epoch 1401, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.73 0.78]\n",
      "Epoch 1411, Loss: 0.39582422748208046, Accuracy: 0.8658536523580551\n",
      "Epoch 1411, Loss: 0.39582422748208046, Losses: [0.31 0.19 0.57 0.51]\n",
      "Epoch 1411, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.71 0.83]\n",
      "Epoch 1421, Loss: 0.39069534465670586, Accuracy: 0.8658536523580551\n",
      "Epoch 1421, Loss: 0.39069534465670586, Losses: [0.31 0.18 0.56 0.51]\n",
      "Epoch 1421, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1431, Loss: 0.40140755102038383, Accuracy: 0.8597560971975327\n",
      "Epoch 1431, Loss: 0.40140755102038383, Losses: [0.31 0.18 0.61 0.51]\n",
      "Epoch 1431, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.68 0.83]\n",
      "Epoch 1441, Loss: 0.5189583003520966, Accuracy: 0.8048780411481857\n",
      "Epoch 1441, Loss: 0.5189583003520966, Losses: [0.33 0.19 0.63 0.93]\n",
      "Epoch 1441, Accuracy: 0.8048780411481857, Accuracies: [0.9  0.98 0.71 0.63]\n",
      "Epoch 1451, Loss: 0.39034533128142357, Accuracy: 0.8780487775802612\n",
      "Epoch 1451, Loss: 0.39034533128142357, Losses: [0.3  0.18 0.57 0.51]\n",
      "Epoch 1451, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.76 0.83]\n",
      "Epoch 1461, Loss: 0.38168005272746086, Accuracy: 0.8719512224197388\n",
      "Epoch 1461, Loss: 0.38168005272746086, Losses: [0.3  0.18 0.56 0.49]\n",
      "Epoch 1461, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.76 0.8 ]\n",
      "Epoch 1471, Loss: 0.3766314126551151, Accuracy: 0.8719512224197388\n",
      "Epoch 1471, Loss: 0.3766314126551151, Losses: [0.29 0.18 0.55 0.48]\n",
      "Epoch 1471, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.76 0.8 ]\n",
      "Epoch 1481, Loss: 0.37201938033103943, Accuracy: 0.8719512224197388\n",
      "Epoch 1481, Loss: 0.37201938033103943, Losses: [0.29 0.18 0.55 0.48]\n",
      "Epoch 1481, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.76 0.8 ]\n",
      "Epoch 1491, Loss: 0.3693596161901951, Accuracy: 0.9024390280246735\n",
      "Epoch 1491, Loss: 0.3693596161901951, Losses: [0.29 0.18 0.54 0.47]\n",
      "Epoch 1491, Accuracy: 0.9024390280246735, Accuracies: [0.95 0.98 0.85 0.83]\n",
      "Epoch 1501, Loss: 0.3738204501569271, Accuracy: 0.8780487775802612\n",
      "Epoch 1501, Loss: 0.3738204501569271, Losses: [0.28 0.17 0.57 0.47]\n",
      "Epoch 1501, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.76 0.83]\n",
      "Epoch 1511, Loss: 0.36700715124607086, Accuracy: 0.8902439028024673\n",
      "Epoch 1511, Loss: 0.36700715124607086, Losses: [0.28 0.17 0.54 0.47]\n",
      "Epoch 1511, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.8  0.83]\n",
      "Epoch 1521, Loss: 0.36021913215518, Accuracy: 0.8841463327407837\n",
      "Epoch 1521, Loss: 0.36021913215518, Losses: [0.28 0.17 0.53 0.46]\n",
      "Epoch 1521, Accuracy: 0.8841463327407837, Accuracies: [0.95 0.98 0.78 0.83]\n",
      "Epoch 1531, Loss: 0.3969830088317394, Accuracy: 0.8414634168148041\n",
      "Epoch 1531, Loss: 0.3969830088317394, Losses: [0.28 0.17 0.66 0.48]\n",
      "Epoch 1531, Accuracy: 0.8414634168148041, Accuracies: [0.95 0.98 0.63 0.8 ]\n",
      "Epoch 1541, Loss: 0.36280233785510063, Accuracy: 0.8841463476419449\n",
      "Epoch 1541, Loss: 0.36280233785510063, Losses: [0.27 0.17 0.54 0.47]\n",
      "Epoch 1541, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 1551, Loss: 0.35196077451109886, Accuracy: 0.8841463476419449\n",
      "Epoch 1551, Loss: 0.35196077451109886, Losses: [0.27 0.17 0.52 0.45]\n",
      "Epoch 1551, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 1561, Loss: 0.34815240278840065, Accuracy: 0.8963414579629898\n",
      "Epoch 1561, Loss: 0.34815240278840065, Losses: [0.26 0.17 0.52 0.44]\n",
      "Epoch 1561, Accuracy: 0.8963414579629898, Accuracies: [0.95 0.98 0.83 0.83]\n",
      "Epoch 1571, Loss: 0.3502312935888767, Accuracy: 0.896341472864151\n",
      "Epoch 1571, Loss: 0.3502312935888767, Losses: [0.26 0.17 0.52 0.45]\n",
      "Epoch 1571, Accuracy: 0.896341472864151, Accuracies: [0.95 0.98 0.8  0.85]\n",
      "Epoch 1581, Loss: 0.779612772166729, Accuracy: 0.7317073345184326\n",
      "Epoch 1581, Loss: 0.779612772166729, Losses: [0.43 0.2  1.64 0.85]\n",
      "Epoch 1581, Accuracy: 0.7317073345184326, Accuracies: [0.85 0.98 0.44 0.66]\n",
      "Epoch 1591, Loss: 0.5438546948134899, Accuracy: 0.7804878205060959\n",
      "Epoch 1591, Loss: 0.5438546948134899, Losses: [0.34 0.18 0.9  0.75]\n",
      "Epoch 1591, Accuracy: 0.7804878205060959, Accuracies: [0.93 0.98 0.56 0.66]\n",
      "Epoch 1601, Loss: 0.39114029705524445, Accuracy: 0.8719512075185776\n",
      "Epoch 1601, Loss: 0.39114029705524445, Losses: [0.29 0.17 0.55 0.57]\n",
      "Epoch 1601, Accuracy: 0.8719512075185776, Accuracies: [0.95 0.98 0.78 0.78]\n",
      "Epoch 1611, Loss: 0.3739089258015156, Accuracy: 0.8719512075185776\n",
      "Epoch 1611, Loss: 0.3739089258015156, Losses: [0.28 0.16 0.53 0.53]\n",
      "Epoch 1611, Accuracy: 0.8719512075185776, Accuracies: [0.95 0.98 0.78 0.78]\n",
      "Epoch 1621, Loss: 0.36418598145246506, Accuracy: 0.8719512075185776\n",
      "Epoch 1621, Loss: 0.36418598145246506, Losses: [0.27 0.16 0.52 0.5 ]\n",
      "Epoch 1621, Accuracy: 0.8719512075185776, Accuracies: [0.95 0.98 0.78 0.78]\n",
      "Epoch 1631, Loss: 0.35594213753938675, Accuracy: 0.8719512075185776\n",
      "Epoch 1631, Loss: 0.35594213753938675, Losses: [0.27 0.16 0.51 0.48]\n",
      "Epoch 1631, Accuracy: 0.8719512075185776, Accuracies: [0.95 0.98 0.78 0.78]\n",
      "Epoch 1641, Loss: 0.34859756752848625, Accuracy: 0.8719512075185776\n",
      "Epoch 1641, Loss: 0.34859756752848625, Losses: [0.26 0.16 0.51 0.47]\n",
      "Epoch 1641, Accuracy: 0.8719512075185776, Accuracies: [0.95 0.98 0.78 0.78]\n",
      "Epoch 1651, Loss: 0.34231382980942726, Accuracy: 0.8780487775802612\n",
      "Epoch 1651, Loss: 0.34231382980942726, Losses: [0.26 0.16 0.5  0.45]\n",
      "Epoch 1651, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.8  0.78]\n",
      "Epoch 1661, Loss: 0.3354012221097946, Accuracy: 0.8780487775802612\n",
      "Epoch 1661, Loss: 0.3354012221097946, Losses: [0.25 0.16 0.5  0.44]\n",
      "Epoch 1661, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.8  0.78]\n",
      "Epoch 1671, Loss: 0.3300733342766762, Accuracy: 0.8841463476419449\n",
      "Epoch 1671, Loss: 0.3300733342766762, Losses: [0.25 0.16 0.49 0.42]\n",
      "Epoch 1671, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 1681, Loss: 0.32610196247696877, Accuracy: 0.8841463476419449\n",
      "Epoch 1681, Loss: 0.32610196247696877, Losses: [0.24 0.16 0.49 0.42]\n",
      "Epoch 1681, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 1691, Loss: 0.32540999725461006, Accuracy: 0.8841463327407837\n",
      "Epoch 1691, Loss: 0.32540999725461006, Losses: [0.24 0.15 0.5  0.41]\n",
      "Epoch 1691, Accuracy: 0.8841463327407837, Accuracies: [0.95 0.98 0.78 0.83]\n",
      "Epoch 1701, Loss: 0.4086213856935501, Accuracy: 0.8597560971975327\n",
      "Epoch 1701, Loss: 0.4086213856935501, Losses: [0.26 0.15 0.73 0.5 ]\n",
      "Epoch 1701, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.68 0.83]\n",
      "Epoch 1711, Loss: 0.3278863951563835, Accuracy: 0.8902439028024673\n",
      "Epoch 1711, Loss: 0.3278863951563835, Losses: [0.24 0.15 0.5  0.42]\n",
      "Epoch 1711, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.8  0.83]\n",
      "Epoch 1721, Loss: 0.31844012811779976, Accuracy: 0.9024390280246735\n",
      "Epoch 1721, Loss: 0.31844012811779976, Losses: [0.24 0.15 0.48 0.41]\n",
      "Epoch 1721, Accuracy: 0.9024390280246735, Accuracies: [0.95 0.98 0.83 0.85]\n",
      "Epoch 1731, Loss: 0.31473420560359955, Accuracy: 0.8902439028024673\n",
      "Epoch 1731, Loss: 0.31473420560359955, Losses: [0.23 0.15 0.48 0.4 ]\n",
      "Epoch 1731, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.8  0.83]\n",
      "Epoch 1741, Loss: 0.3106774874031544, Accuracy: 0.9085365980863571\n",
      "Epoch 1741, Loss: 0.3106774874031544, Losses: [0.23 0.15 0.47 0.39]\n",
      "Epoch 1741, Accuracy: 0.9085365980863571, Accuracies: [0.98 0.98 0.83 0.85]\n",
      "Epoch 1751, Loss: 0.30879758670926094, Accuracy: 0.9085365980863571\n",
      "Epoch 1751, Loss: 0.30879758670926094, Losses: [0.23 0.15 0.47 0.39]\n",
      "Epoch 1751, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1761, Loss: 0.3212854266166687, Accuracy: 0.9085365980863571\n",
      "Epoch 1761, Loss: 0.3212854266166687, Losses: [0.22 0.15 0.51 0.4 ]\n",
      "Epoch 1761, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1771, Loss: 0.40287189930677414, Accuracy: 0.8597560971975327\n",
      "Epoch 1771, Loss: 0.40287189930677414, Losses: [0.23 0.14 0.78 0.46]\n",
      "Epoch 1771, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.68 0.83]\n",
      "Epoch 1781, Loss: 0.3156750798225403, Accuracy: 0.9146341681480408\n",
      "Epoch 1781, Loss: 0.3156750798225403, Losses: [0.24 0.15 0.47 0.41]\n",
      "Epoch 1781, Accuracy: 0.9146341681480408, Accuracies: [0.98 0.98 0.85 0.85]\n",
      "Epoch 1791, Loss: 0.3026321530342102, Accuracy: 0.9146341532468796\n",
      "Epoch 1791, Loss: 0.3026321530342102, Losses: [0.22 0.15 0.45 0.38]\n",
      "Epoch 1791, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.83 0.88]\n",
      "Epoch 1801, Loss: 0.2981436178088188, Accuracy: 0.9146341532468796\n",
      "Epoch 1801, Loss: 0.2981436178088188, Losses: [0.22 0.15 0.45 0.38]\n",
      "Epoch 1801, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.83 0.85]\n",
      "Epoch 1811, Loss: 0.2946806289255619, Accuracy: 0.9207317233085632\n",
      "Epoch 1811, Loss: 0.2946806289255619, Losses: [0.21 0.15 0.45 0.37]\n",
      "Epoch 1811, Accuracy: 0.9207317233085632, Accuracies: [1.   0.98 0.85 0.85]\n",
      "Epoch 1821, Loss: 0.2912290580570698, Accuracy: 0.9207317233085632\n",
      "Epoch 1821, Loss: 0.2912290580570698, Losses: [0.21 0.14 0.44 0.37]\n",
      "Epoch 1821, Accuracy: 0.9207317233085632, Accuracies: [1.   0.98 0.85 0.85]\n",
      "Epoch 1831, Loss: 0.2943605110049248, Accuracy: 0.9024390429258347\n",
      "Epoch 1831, Loss: 0.2943605110049248, Losses: [0.21 0.14 0.45 0.37]\n",
      "Epoch 1831, Accuracy: 0.9024390429258347, Accuracies: [0.98 0.98 0.8  0.85]\n",
      "Epoch 1841, Loss: 0.3073979765176773, Accuracy: 0.9024390280246735\n",
      "Epoch 1841, Loss: 0.3073979765176773, Losses: [0.21 0.14 0.5  0.38]\n",
      "Epoch 1841, Accuracy: 0.9024390280246735, Accuracies: [0.95 0.98 0.8  0.88]\n",
      "Epoch 1851, Loss: 0.30278097093105316, Accuracy: 0.9207317233085632\n",
      "Epoch 1851, Loss: 0.30278097093105316, Losses: [0.21 0.14 0.48 0.38]\n",
      "Epoch 1851, Accuracy: 0.9207317233085632, Accuracies: [0.98 0.98 0.85 0.88]\n",
      "Epoch 1861, Loss: 0.2836725749075413, Accuracy: 0.9207317233085632\n",
      "Epoch 1861, Loss: 0.2836725749075413, Losses: [0.2  0.14 0.43 0.36]\n",
      "Epoch 1861, Accuracy: 0.9207317233085632, Accuracies: [1.   0.98 0.85 0.85]\n",
      "Epoch 1871, Loss: 0.2796291895210743, Accuracy: 0.9268292784690857\n",
      "Epoch 1871, Loss: 0.2796291895210743, Losses: [0.2  0.14 0.43 0.35]\n",
      "Epoch 1871, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 1881, Loss: 0.2764519304037094, Accuracy: 0.9268292784690857\n",
      "Epoch 1881, Loss: 0.2764519304037094, Losses: [0.2  0.14 0.42 0.35]\n",
      "Epoch 1881, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 1891, Loss: 0.2735665701329708, Accuracy: 0.9268292784690857\n",
      "Epoch 1891, Loss: 0.2735665701329708, Losses: [0.2  0.14 0.42 0.34]\n",
      "Epoch 1891, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 1901, Loss: 0.28418468683958054, Accuracy: 0.9268292635679245\n",
      "Epoch 1901, Loss: 0.28418468683958054, Losses: [0.19 0.14 0.46 0.34]\n",
      "Epoch 1901, Accuracy: 0.9268292635679245, Accuracies: [1.   0.98 0.83 0.9 ]\n",
      "Epoch 1911, Loss: 0.565460454672575, Accuracy: 0.829268291592598\n",
      "Epoch 1911, Loss: 0.565460454672575, Losses: [0.21 0.2  1.12 0.74]\n",
      "Epoch 1911, Accuracy: 0.829268291592598, Accuracies: [0.95 0.98 0.68 0.71]\n",
      "Epoch 1921, Loss: 0.3136018291115761, Accuracy: 0.896341472864151\n",
      "Epoch 1921, Loss: 0.3136018291115761, Losses: [0.22 0.15 0.44 0.45]\n",
      "Epoch 1921, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.8  0.8 ]\n",
      "Epoch 1931, Loss: 0.2757461778819561, Accuracy: 0.9329268485307693\n",
      "Epoch 1931, Loss: 0.2757461778819561, Losses: [0.21 0.14 0.41 0.35]\n",
      "Epoch 1931, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 1941, Loss: 0.2695976607501507, Accuracy: 0.9451219439506531\n",
      "Epoch 1941, Loss: 0.2695976607501507, Losses: [0.2  0.14 0.41 0.34]\n",
      "Epoch 1941, Accuracy: 0.9451219439506531, Accuracies: [1.   0.98 0.9  0.9 ]\n",
      "Epoch 1951, Loss: 0.26583414152264595, Accuracy: 0.9390243887901306\n",
      "Epoch 1951, Loss: 0.26583414152264595, Losses: [0.19 0.14 0.4  0.33]\n",
      "Epoch 1951, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.9  0.88]\n",
      "Epoch 1961, Loss: 0.26260605454444885, Accuracy: 0.9390243887901306\n",
      "Epoch 1961, Loss: 0.26260605454444885, Losses: [0.19 0.13 0.4  0.33]\n",
      "Epoch 1961, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.9  0.88]\n",
      "Epoch 1971, Loss: 0.26120175793766975, Accuracy: 0.9329268336296082\n",
      "Epoch 1971, Loss: 0.26120175793766975, Losses: [0.19 0.13 0.4  0.32]\n",
      "Epoch 1971, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.88 0.88]\n",
      "Epoch 1981, Loss: 0.25745638459920883, Accuracy: 0.9390243887901306\n",
      "Epoch 1981, Loss: 0.25745638459920883, Losses: [0.18 0.13 0.39 0.32]\n",
      "Epoch 1981, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.88 0.9 ]\n",
      "Epoch 1991, Loss: 0.2551518864929676, Accuracy: 0.9451219439506531\n",
      "Epoch 1991, Loss: 0.2551518864929676, Losses: [0.18 0.13 0.39 0.32]\n",
      "Epoch 1991, Accuracy: 0.9451219439506531, Accuracies: [1.   0.98 0.9  0.9 ]\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "num_epochs = 2000\n",
    "number_of_Songs = 4\n",
    "songs = list(range(number_of_Songs))\n",
    "L = []\n",
    "A = []\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(songs)\n",
    "    lo=numpy.zeros((number_of_Songs))\n",
    "    acc=numpy.zeros((number_of_Songs))\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for song in songs:\n",
    "        I, O, raw = generateIOData(song)\n",
    "        inputs = torch.tensor(I, dtype=torch.float).unsqueeze(0)  # Add batch dimension\n",
    "        targets = torch.tensor(O, dtype=torch.long)  # Targets are now indices\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, 8), targets)  # Reshape for CrossEntropyLoss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_indices = torch.max(outputs, 2)\n",
    "        accuracy = (predicted_indices.squeeze() == targets).float().mean().item()\n",
    "        acc[song] = accuracy\n",
    "        total_accuracy += accuracy\n",
    "        lo[song]=loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / number_of_Songs}, Accuracy: {total_accuracy / number_of_Songs}')\n",
    "        print(f'Epoch {epoch+1}, Loss: {mean(lo)}, Losses: {numpy.round(lo,2)}')\n",
    "        print(f'Epoch {epoch+1}, Accuracy: {mean(acc)}, Accuracies: {numpy.round(acc,2)}')\n",
    "        \n",
    "    L.append(total_loss / number_of_Songs)\n",
    "    A.append(total_accuracy / number_of_Songs)\n",
    "    \n",
    "    if len(A)>= 2000 or total_accuracy / number_of_Songs >0.97:\n",
    "      break\n",
    "  \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71e72d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Loss\n",
    "plt.figure(figsize=(8, 6))  # Set figure size\n",
    "plt.plot(L, label='Training Loss', color='blue')  # Plot loss with a label\n",
    "plt.title('Training Loss Over Epochs')  # Title of the plot\n",
    "plt.xlabel('Epoch')  # X-axis label\n",
    "plt.ylabel('Loss')  # Y-axis label\n",
    "plt.grid(False)  # Add grid lines for better readability\n",
    "plt.legend()  # Show legend to identify the line plot\n",
    "plt.tight_layout()  # Adjust the layout to make room for the elements\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Plot for Accuracy\n",
    "plt.figure(figsize=(8, 6))  # Set figure size for the accuracy plot\n",
    "plt.plot(A, label='Training Accuracy', color='red')  # Plot accuracy with a label\n",
    "plt.title('Training Accuracy Over Epochs')  # Title of the plot\n",
    "plt.xlabel('Epoch')  # X-axis label\n",
    "plt.ylabel('Accuracy')  # Y-axis label\n",
    "plt.grid(False)  # Add grid lines for better readability\n",
    "plt.legend()  # Show legend\n",
    "plt.tight_layout()  # Adjust the layout\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cac88450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "I, O, raw  = generateIOData(0) \n",
    "\n",
    "inputs = torch.Tensor(I).unsqueeze(0)  \n",
    "outputs = model(inputs)\n",
    "\n",
    "_, predicted_indices = torch.max(outputs, 2)\n",
    "\n",
    "num_classes = 8 \n",
    "\n",
    "predicted_one_hot = F.one_hot(predicted_indices.squeeze(), num_classes=num_classes).numpy()\n",
    "\n",
    "\n",
    "O_tensor = torch.tensor(O, dtype=torch.long)\n",
    "original_one_hot = F.one_hot(O_tensor, num_classes=num_classes).numpy()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plotting one-hot encoded predicted indices\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(predicted_one_hot, cmap='viridis', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('Predicted One-Hot')\n",
    "\n",
    "# Plotting one-hot encoded original targets\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(original_one_hot, cmap='viridis', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('Original Targets One-Hot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0f38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.rnnLayer = nn.RNN(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.outputLayer = nn.Linear(self.hidden_dim, self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x,verbose= False):\n",
    "        x = self.expand_layer(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.h0 = torch.Tensor(numpy.zeros((1, x.shape[0], self.hidden_dim)))\n",
    "        out, self.h0 = self.rnnLayer(x, self.h0)\n",
    "        self.hidden.append(copy.deepcopy(self.h0.detach().numpy()))\n",
    "        self.store = copy.deepcopy(self.h0.detach().numpy())\n",
    "        out = self.outputLayer(out)\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.Tensor(numpy.zeros((1, 1, self.hidden_dim)))\n",
    "            for i in range(x.shape[1]):\n",
    "                step_input = self.expand_layer(x[l][i].reshape((1, 1, self.inp)))\n",
    "                step_input = torch.relu(step_input)\n",
    "\n",
    "                out, h0 = self.rnnLayer(step_input, h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "            out = self.outputLayer(out)\n",
    "            for i in range(x.shape[1]):\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "        return numpy.array(O), numpy.array(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a147d7f",
   "metadata": {},
   "source": [
    "## Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8984571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim**0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bac7d",
   "metadata": {},
   "source": [
    "## RNNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5579631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNA(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(RNNA, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.attention = SelfAttention(inp)  \n",
    "\n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.rnnLayer = nn.RNN(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.outputLayer = nn.Linear(self.hidden_dim, self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x, verbose= False):\n",
    "        \n",
    "        attn_out = self.attention(x)\n",
    "        \n",
    "        expanded_attn_out = self.expand_layer(attn_out)\n",
    "        \n",
    "        expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "        h0 = torch.zeros(1, x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        rnn_out, self.hidden = self.rnnLayer(expanded_attn_out, h0)\n",
    "        self.store = self.hidden.detach().numpy().copy()\n",
    "        out = self.outputLayer(rnn_out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.zeros(1, 1, self.hidden_dim)\n",
    "            for i in range(x.shape[1]):\n",
    "                attn_out = self.attention(x[l][i].reshape((1, 1, self.inp)))\n",
    "\n",
    "                expanded_attn_out = self.expand_layer(attn_out)\n",
    "                expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "                out, h0 = self.rnnLayer(expanded_attn_out, h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "\n",
    "                out = self.outputLayer(out)\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "\n",
    "        return np.array(O), np.array(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162c30e",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c374aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.lstmLayer = nn.LSTM(self.hidden_dim, int(self.hidden_dim/2), 1, batch_first=True)\n",
    "\n",
    "        self.outputLayer = nn.Linear(int(self.hidden_dim/2), self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x, verbose= False):\n",
    "        x = self.expand_layer(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.h0 = (torch.zeros(1, x.shape[0], int(self.hidden_dim/2)), torch.zeros(1, x.shape[0], int(self.hidden_dim/2)))\n",
    "\n",
    "        out, self.h0 = self.lstmLayer(x, self.h0)\n",
    "\n",
    "        hh = numpy.concatenate((self.h0[0].detach().numpy(), self.h0[1].detach().numpy()), 2)\n",
    "        self.hidden.append(hh)\n",
    "        self.store = hh\n",
    "        out = self.outputLayer(out)\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = (torch.zeros(1, 1, int(self.hidden_dim/2)),\n",
    "                  torch.zeros(1, 1, int(self.hidden_dim/2)))\n",
    "            for i in range(x.shape[1]):\n",
    "                step_input = self.expand_layer(x[l][i].reshape((1, 1, self.inp)))\n",
    "                step_input = torch.relu(step_input)\n",
    "\n",
    "                out, h0 = self.lstmLayer(step_input, h0)\n",
    "                hh = numpy.concatenate((h0[0].detach().numpy().flatten(), h0[1].detach().numpy().flatten()))\n",
    "                H.append(hh.flatten())\n",
    "\n",
    "            out = self.outputLayer(out)\n",
    "            for i in range(x.shape[1]):\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "        return numpy.array(O), numpy.array(H)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb3a66",
   "metadata": {},
   "source": [
    "## LSTMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db764e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMA(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(LSTMA, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.attention = SelfAttention(inp)  \n",
    "\n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.lstmLayer = nn.LSTM(self.hidden_dim, int(self.hidden_dim/2), batch_first=True)\n",
    "\n",
    "        self.outputLayer = nn.Linear(int(self.hidden_dim/2), self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x, verbose= False):\n",
    "        \n",
    "        attn_out = self.attention(x)\n",
    "\n",
    "        expanded_attn_out = self.expand_layer(attn_out)\n",
    "        expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "        self.h0 = (torch.zeros(1, x.shape[0], int(self.hidden_dim/2)),\n",
    "              torch.zeros(1, x.shape[0], int(self.hidden_dim/2)))\n",
    "        out, self.h0 = self.lstmLayer(expanded_attn_out, self.h0)\n",
    "        hh = numpy.concatenate((self.h0[0].detach().numpy(), self.h0[1].detach().numpy()), 2)\n",
    "        self.hidden.append(hh)\n",
    "        self.store = hh\n",
    "        out = self.outputLayer(out)  # Corrected line\n",
    "\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = (torch.zeros(1, 1, int(self.hidden_dim/2)),\n",
    "                  torch.zeros(1, 1, int(self.hidden_dim/2)))\n",
    "            for i in range(x.shape[1]):\n",
    "                attn_out = self.attention(x[l][i].reshape((1, 1, self.inp)))\n",
    "\n",
    "                expanded_attn_out = self.expand_layer(attn_out)\n",
    "                expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "                out, h0 = self.lstmLayer(expanded_attn_out, h0)\n",
    "                H.append(torch.cat((h0[0].detach(), h0[1].detach()), 2).numpy().flatten())\n",
    "\n",
    "                out = self.outputLayer(out)\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "\n",
    "        return np.array(O), np.array(H)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f85d0",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778d297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.GRULayer = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.outputLayer = nn.Linear(self.hidden_dim, self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x, verbose= False):\n",
    "        x = self.expand_layer(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.h0 = torch.Tensor(numpy.zeros((1, x.shape[0], self.hidden_dim)))\n",
    "        out, self.h0 = self.GRULayer(x, self.h0)\n",
    "        self.hidden.append(copy.deepcopy(self.h0.detach().numpy()))\n",
    "        self.store = self.h0.detach().numpy().copy()\n",
    "        out = self.outputLayer(out)\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.Tensor(numpy.zeros((1, 1, self.hidden_dim)))\n",
    "            for i in range(x.shape[1]):\n",
    "                step_input = self.expand_layer(x[l][i].reshape((1, 1, self.inp)))\n",
    "                step_input = torch.relu(step_input)\n",
    "\n",
    "                out, h0 = self.GRULayer(step_input, h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "            out = self.outputLayer(out)\n",
    "            for i in range(x.shape[1]):\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "        return numpy.array(O), numpy.array(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aab03e",
   "metadata": {},
   "source": [
    "## GRUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c644dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUA(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, inp=8):\n",
    "        super(GRUA, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inp = inp\n",
    "\n",
    "        self.attention = SelfAttention(inp) \n",
    "        self.expand_layer = nn.Linear(in_features=self.inp, out_features=self.hidden_dim)\n",
    "\n",
    "        self.gruLayer = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
    "\n",
    "        self.outputLayer = nn.Linear(self.hidden_dim, self.inp)\n",
    "\n",
    "        self.resetHidden()\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x, verbose= False):\n",
    "        attn_out = self.attention(x)\n",
    "\n",
    "        expanded_attn_out = self.expand_layer(attn_out)\n",
    "        expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "        self.h0 = torch.zeros(1, x.shape[0], self.hidden_dim)\n",
    "        out, self.h0 = self.gruLayer(expanded_attn_out, self.h0)\n",
    "    \n",
    "        self.hidden.append(copy.deepcopy(self.h0.detach().numpy()))\n",
    "        self.store = self.h0.detach().numpy().copy()\n",
    "        out = self.outputLayer(out)\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.zeros(1, 1, self.hidden_dim)\n",
    "            for i in range(x.shape[1]):\n",
    "                \n",
    "                attn_out = self.attention(x[l][i].reshape((1, 1, self.inp)))\n",
    "\n",
    "                expanded_attn_out = self.expand_layer(attn_out)\n",
    "                expanded_attn_out = torch.relu(expanded_attn_out)\n",
    "\n",
    "                out, h0 = self.gruLayer(expanded_attn_out, h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "\n",
    "    \n",
    "                out = self.outputLayer(out)\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "\n",
    "        return np.array(O), np.array(H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33cc1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, songStrings, number_of_Songs = 4):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    songs = list(range(number_of_Songs))\n",
    "    L = []\n",
    "    A = []\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(songs)\n",
    "        lo=numpy.zeros((number_of_Songs))\n",
    "        acc=numpy.zeros((number_of_Songs))\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        for song in songs:\n",
    "            I, O, raw = generateIOData(song)\n",
    "            inputs = torch.tensor(I, dtype=torch.float).unsqueeze(0)  # Add batch dimension\n",
    "            targets = torch.tensor(O, dtype=torch.long)  # Targets are now indices\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, 8), targets)  # Reshape for CrossEntropyLoss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted_indices = torch.max(outputs, 2)\n",
    "            accuracy = (predicted_indices.squeeze() == targets).float().mean().item()\n",
    "            acc[song] = accuracy\n",
    "            total_accuracy += accuracy\n",
    "            lo[song]=loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {total_loss / number_of_Songs}, Accuracy: {total_accuracy / number_of_Songs}')\n",
    "            print(f'Epoch {epoch+1}, Loss: {mean(lo)}, Losses: {numpy.round(lo,2)}')\n",
    "            print(f'Epoch {epoch+1}, Accuracy: {mean(acc)}, Accuracies: {numpy.round(acc,2)}')\n",
    "            \n",
    "        L.append(total_loss / number_of_Songs)\n",
    "        \n",
    "        A.append(total_accuracy / number_of_Songs)\n",
    "        \n",
    "        if len(A)>= 5000 or total_accuracy / number_of_Songs >0.97:\n",
    "            print(\"Early stopping criteria met\")\n",
    "            break\n",
    "        \n",
    "    return L, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33de574",
   "metadata": {},
   "source": [
    "## Train each song without combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00ced8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN...\n",
      "Epoch 1, Loss: 2.0854634642601013, Accuracy: 0.17073170095682144\n",
      "Epoch 1, Loss: 2.0854634642601013, Losses: [2.09 2.08 2.08 2.08]\n",
      "Epoch 1, Accuracy: 0.17073170095682144, Accuracies: [0.1 0.2 0.2 0.2]\n",
      "Epoch 11, Loss: 1.9767688810825348, Accuracy: 0.17073170468211174\n",
      "Epoch 11, Loss: 1.9767688810825348, Losses: [2.03 1.95 1.95 1.98]\n",
      "Epoch 11, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 21, Loss: 1.8982400596141815, Accuracy: 0.27439023926854134\n",
      "Epoch 21, Loss: 1.8982400596141815, Losses: [2.   1.83 1.85 1.91]\n",
      "Epoch 21, Accuracy: 0.27439023926854134, Accuracies: [0.29 0.34 0.29 0.17]\n",
      "Epoch 31, Loss: 1.8097889721393585, Accuracy: 0.29878049343824387\n",
      "Epoch 31, Loss: 1.8097889721393585, Losses: [1.93 1.66 1.79 1.86]\n",
      "Epoch 31, Accuracy: 0.29878049343824387, Accuracies: [0.37 0.2  0.37 0.27]\n",
      "Epoch 41, Loss: 1.6763909459114075, Accuracy: 0.3780487850308418\n",
      "Epoch 41, Loss: 1.6763909459114075, Losses: [1.77 1.38 1.73 1.83]\n",
      "Epoch 41, Accuracy: 0.3780487850308418, Accuracies: [0.44 0.56 0.27 0.24]\n",
      "Epoch 51, Loss: 1.5653048753738403, Accuracy: 0.43292682617902756\n",
      "Epoch 51, Loss: 1.5653048753738403, Losses: [1.61 1.17 1.68 1.8 ]\n",
      "Epoch 51, Accuracy: 0.43292682617902756, Accuracies: [0.49 0.63 0.32 0.29]\n",
      "Epoch 61, Loss: 1.4723026156425476, Accuracy: 0.4573170840740204\n",
      "Epoch 61, Loss: 1.4723026156425476, Losses: [1.48 1.   1.63 1.78]\n",
      "Epoch 61, Accuracy: 0.4573170840740204, Accuracies: [0.54 0.68 0.34 0.27]\n",
      "Epoch 71, Loss: 1.3926761001348495, Accuracy: 0.49390242993831635\n",
      "Epoch 71, Loss: 1.3926761001348495, Losses: [1.37 0.87 1.58 1.74]\n",
      "Epoch 71, Accuracy: 0.49390242993831635, Accuracies: [0.51 0.78 0.37 0.32]\n",
      "Epoch 81, Loss: 1.316896915435791, Accuracy: 0.5609756037592888\n",
      "Epoch 81, Loss: 1.316896915435791, Losses: [1.27 0.77 1.53 1.7 ]\n",
      "Epoch 81, Accuracy: 0.5609756037592888, Accuracies: [0.59 0.93 0.41 0.32]\n",
      "Epoch 91, Loss: 1.2406113147735596, Accuracy: 0.585365854203701\n",
      "Epoch 91, Loss: 1.2406113147735596, Losses: [1.19 0.67 1.46 1.65]\n",
      "Epoch 91, Accuracy: 0.585365854203701, Accuracies: [0.61 0.95 0.44 0.34]\n",
      "Epoch 101, Loss: 1.1701214611530304, Accuracy: 0.6219512224197388\n",
      "Epoch 101, Loss: 1.1701214611530304, Losses: [1.11 0.59 1.39 1.59]\n",
      "Epoch 101, Accuracy: 0.6219512224197388, Accuracies: [0.68 0.95 0.49 0.37]\n",
      "Epoch 111, Loss: 1.1056396812200546, Accuracy: 0.6219512373209\n",
      "Epoch 111, Loss: 1.1056396812200546, Losses: [1.04 0.53 1.32 1.54]\n",
      "Epoch 111, Accuracy: 0.6219512373209, Accuracies: [0.66 0.98 0.54 0.32]\n",
      "Epoch 121, Loss: 1.0484228879213333, Accuracy: 0.6402439102530479\n",
      "Epoch 121, Loss: 1.0484228879213333, Losses: [0.97 0.47 1.28 1.47]\n",
      "Epoch 121, Accuracy: 0.6402439102530479, Accuracies: [0.68 0.98 0.56 0.34]\n",
      "Epoch 131, Loss: 0.9968386441469193, Accuracy: 0.6463414654135704\n",
      "Epoch 131, Loss: 0.9968386441469193, Losses: [0.92 0.43 1.22 1.41]\n",
      "Epoch 131, Accuracy: 0.6463414654135704, Accuracies: [0.71 0.98 0.56 0.34]\n",
      "Epoch 141, Loss: 0.9504163041710854, Accuracy: 0.6646341383457184\n",
      "Epoch 141, Loss: 0.9504163041710854, Losses: [0.88 0.39 1.18 1.35]\n",
      "Epoch 141, Accuracy: 0.6646341383457184, Accuracies: [0.71 0.98 0.59 0.39]\n",
      "Epoch 151, Loss: 0.9073110595345497, Accuracy: 0.6890244036912918\n",
      "Epoch 151, Loss: 0.9073110595345497, Losses: [0.84 0.37 1.13 1.29]\n",
      "Epoch 151, Accuracy: 0.6890244036912918, Accuracies: [0.73 0.98 0.56 0.49]\n",
      "Epoch 161, Loss: 0.8724217042326927, Accuracy: 0.7195122092962265\n",
      "Epoch 161, Loss: 0.8724217042326927, Losses: [0.81 0.34 1.09 1.25]\n",
      "Epoch 161, Accuracy: 0.7195122092962265, Accuracies: [0.76 0.98 0.66 0.49]\n",
      "Epoch 171, Loss: 0.8435485735535622, Accuracy: 0.7195121943950653\n",
      "Epoch 171, Loss: 0.8435485735535622, Losses: [0.77 0.32 1.06 1.22]\n",
      "Epoch 171, Accuracy: 0.7195121943950653, Accuracies: [0.76 0.98 0.63 0.51]\n",
      "Epoch 181, Loss: 0.8106521740555763, Accuracy: 0.7560975700616837\n",
      "Epoch 181, Loss: 0.8106521740555763, Losses: [0.75 0.3  1.01 1.19]\n",
      "Epoch 181, Accuracy: 0.7560975700616837, Accuracies: [0.73 0.98 0.71 0.61]\n",
      "Epoch 191, Loss: 0.7670073360204697, Accuracy: 0.7621951252222061\n",
      "Epoch 191, Loss: 0.7670073360204697, Losses: [0.71 0.28 0.98 1.1 ]\n",
      "Epoch 191, Accuracy: 0.7621951252222061, Accuracies: [0.76 0.98 0.71 0.61]\n",
      "Epoch 201, Loss: 0.7355511859059334, Accuracy: 0.7743902504444122\n",
      "Epoch 201, Loss: 0.7355511859059334, Losses: [0.69 0.27 0.94 1.05]\n",
      "Epoch 201, Accuracy: 0.7743902504444122, Accuracies: [0.76 0.98 0.73 0.63]\n",
      "Epoch 211, Loss: 0.7079520300030708, Accuracy: 0.7804878056049347\n",
      "Epoch 211, Loss: 0.7079520300030708, Losses: [0.66 0.25 0.91 1.01]\n",
      "Epoch 211, Accuracy: 0.7804878056049347, Accuracies: [0.78 0.98 0.73 0.63]\n",
      "Epoch 221, Loss: 0.6807852610945702, Accuracy: 0.8048780560493469\n",
      "Epoch 221, Loss: 0.6807852610945702, Losses: [0.63 0.24 0.87 0.98]\n",
      "Epoch 221, Accuracy: 0.8048780560493469, Accuracies: [0.8  0.98 0.76 0.68]\n",
      "Epoch 231, Loss: 0.6811508126556873, Accuracy: 0.7987804859876633\n",
      "Epoch 231, Loss: 0.6811508126556873, Losses: [0.63 0.24 0.86 1.  ]\n",
      "Epoch 231, Accuracy: 0.7987804859876633, Accuracies: [0.83 0.98 0.76 0.63]\n",
      "Epoch 241, Loss: 0.6457910537719727, Accuracy: 0.7926829308271408\n",
      "Epoch 241, Loss: 0.6457910537719727, Losses: [0.58 0.22 0.84 0.94]\n",
      "Epoch 241, Accuracy: 0.7926829308271408, Accuracies: [0.83 0.98 0.71 0.66]\n",
      "Epoch 251, Loss: 0.6249388717114925, Accuracy: 0.8353658616542816\n",
      "Epoch 251, Loss: 0.6249388717114925, Losses: [0.57 0.21 0.78 0.94]\n",
      "Epoch 251, Accuracy: 0.8353658616542816, Accuracies: [0.83 0.98 0.8  0.73]\n",
      "Epoch 261, Loss: 0.5967255420982838, Accuracy: 0.8048780560493469\n",
      "Epoch 261, Loss: 0.5967255420982838, Losses: [0.55 0.2  0.75 0.88]\n",
      "Epoch 261, Accuracy: 0.8048780560493469, Accuracies: [0.8  0.98 0.8  0.63]\n",
      "Epoch 271, Loss: 0.5788796134293079, Accuracy: 0.8353658616542816\n",
      "Epoch 271, Loss: 0.5788796134293079, Losses: [0.56 0.2  0.72 0.83]\n",
      "Epoch 271, Accuracy: 0.8353658616542816, Accuracies: [0.8  0.98 0.83 0.73]\n",
      "Epoch 281, Loss: 0.5661096647381783, Accuracy: 0.8292683064937592\n",
      "Epoch 281, Loss: 0.5661096647381783, Losses: [0.51 0.19 0.74 0.82]\n",
      "Epoch 281, Accuracy: 0.8292683064937592, Accuracies: [0.85 0.98 0.76 0.73]\n",
      "Epoch 291, Loss: 0.6438316181302071, Accuracy: 0.774390235543251\n",
      "Epoch 291, Loss: 0.6438316181302071, Losses: [0.55 0.22 0.81 1.  ]\n",
      "Epoch 291, Accuracy: 0.774390235543251, Accuracies: [0.83 0.95 0.73 0.59]\n",
      "Epoch 301, Loss: 0.5543409660458565, Accuracy: 0.817073181271553\n",
      "Epoch 301, Loss: 0.5543409660458565, Losses: [0.49 0.19 0.69 0.85]\n",
      "Epoch 301, Accuracy: 0.817073181271553, Accuracies: [0.85 0.98 0.76 0.68]\n",
      "Epoch 311, Loss: 0.5279846973717213, Accuracy: 0.8536585420370102\n",
      "Epoch 311, Loss: 0.5279846973717213, Losses: [0.47 0.18 0.66 0.8 ]\n",
      "Epoch 311, Accuracy: 0.8536585420370102, Accuracies: [0.88 0.98 0.8  0.76]\n",
      "Epoch 321, Loss: 0.5133333690464497, Accuracy: 0.8536585420370102\n",
      "Epoch 321, Loss: 0.5133333690464497, Losses: [0.47 0.18 0.64 0.77]\n",
      "Epoch 321, Accuracy: 0.8536585420370102, Accuracies: [0.88 0.98 0.8  0.76]\n",
      "Epoch 331, Loss: 0.496844157576561, Accuracy: 0.8719512224197388\n",
      "Epoch 331, Loss: 0.496844157576561, Losses: [0.45 0.18 0.61 0.75]\n",
      "Epoch 331, Accuracy: 0.8719512224197388, Accuracies: [0.9  0.98 0.8  0.8 ]\n",
      "Epoch 341, Loss: 0.49101126194000244, Accuracy: 0.8475609719753265\n",
      "Epoch 341, Loss: 0.49101126194000244, Losses: [0.46 0.17 0.6  0.73]\n",
      "Epoch 341, Accuracy: 0.8475609719753265, Accuracies: [0.83 0.98 0.8  0.78]\n",
      "Epoch 351, Loss: 0.4688325859606266, Accuracy: 0.8719512224197388\n",
      "Epoch 351, Loss: 0.4688325859606266, Losses: [0.42 0.17 0.58 0.7 ]\n",
      "Epoch 351, Accuracy: 0.8719512224197388, Accuracies: [0.88 0.98 0.83 0.8 ]\n",
      "Epoch 361, Loss: 0.48617205023765564, Accuracy: 0.8414634168148041\n",
      "Epoch 361, Loss: 0.48617205023765564, Losses: [0.4  0.16 0.66 0.72]\n",
      "Epoch 361, Accuracy: 0.8414634168148041, Accuracies: [0.9  0.98 0.73 0.76]\n",
      "Epoch 371, Loss: 0.4486800730228424, Accuracy: 0.8902439028024673\n",
      "Epoch 371, Loss: 0.4486800730228424, Losses: [0.4  0.16 0.56 0.67]\n",
      "Epoch 371, Accuracy: 0.8902439028024673, Accuracies: [0.9  0.98 0.85 0.83]\n",
      "Epoch 381, Loss: 0.43351126089692116, Accuracy: 0.8902439177036285\n",
      "Epoch 381, Loss: 0.43351126089692116, Losses: [0.39 0.16 0.53 0.66]\n",
      "Epoch 381, Accuracy: 0.8902439177036285, Accuracies: [0.88 0.98 0.85 0.85]\n",
      "Epoch 391, Loss: 0.4213819243013859, Accuracy: 0.896341472864151\n",
      "Epoch 391, Loss: 0.4213819243013859, Losses: [0.38 0.16 0.51 0.63]\n",
      "Epoch 391, Accuracy: 0.896341472864151, Accuracies: [0.9  0.98 0.85 0.85]\n",
      "Epoch 401, Loss: 0.44084108620882034, Accuracy: 0.8841463476419449\n",
      "Epoch 401, Loss: 0.44084108620882034, Losses: [0.43 0.16 0.53 0.64]\n",
      "Epoch 401, Accuracy: 0.8841463476419449, Accuracies: [0.83 0.98 0.85 0.88]\n",
      "Epoch 411, Loss: 0.4136259965598583, Accuracy: 0.8841463476419449\n",
      "Epoch 411, Loss: 0.4136259965598583, Losses: [0.37 0.16 0.49 0.64]\n",
      "Epoch 411, Accuracy: 0.8841463476419449, Accuracies: [0.9  0.98 0.85 0.8 ]\n",
      "Epoch 421, Loss: 0.39267493039369583, Accuracy: 0.896341472864151\n",
      "Epoch 421, Loss: 0.39267493039369583, Losses: [0.35 0.15 0.47 0.59]\n",
      "Epoch 421, Accuracy: 0.896341472864151, Accuracies: [0.93 0.98 0.85 0.83]\n",
      "Epoch 431, Loss: 0.3793649822473526, Accuracy: 0.9024390429258347\n",
      "Epoch 431, Loss: 0.3793649822473526, Losses: [0.34 0.15 0.46 0.57]\n",
      "Epoch 431, Accuracy: 0.9024390429258347, Accuracies: [0.93 0.98 0.85 0.85]\n",
      "Epoch 441, Loss: 0.4031147249042988, Accuracy: 0.8719512373209\n",
      "Epoch 441, Loss: 0.4031147249042988, Losses: [0.33 0.15 0.44 0.69]\n",
      "Epoch 441, Accuracy: 0.8719512373209, Accuracies: [0.93 0.98 0.85 0.73]\n",
      "Epoch 451, Loss: 0.475258756428957, Accuracy: 0.8597560971975327\n",
      "Epoch 451, Loss: 0.475258756428957, Losses: [0.37 0.18 0.61 0.75]\n",
      "Epoch 451, Accuracy: 0.8597560971975327, Accuracies: [0.93 0.95 0.83 0.73]\n",
      "Epoch 461, Loss: 0.4005277082324028, Accuracy: 0.8841463476419449\n",
      "Epoch 461, Loss: 0.4005277082324028, Losses: [0.33 0.16 0.49 0.62]\n",
      "Epoch 461, Accuracy: 0.8841463476419449, Accuracies: [0.93 0.95 0.85 0.8 ]\n",
      "Epoch 471, Loss: 0.3734346553683281, Accuracy: 0.9085365980863571\n",
      "Epoch 471, Loss: 0.3734346553683281, Losses: [0.32 0.15 0.46 0.57]\n",
      "Epoch 471, Accuracy: 0.9085365980863571, Accuracies: [0.95 0.98 0.85 0.85]\n",
      "Epoch 481, Loss: 0.35721950232982635, Accuracy: 0.9085365980863571\n",
      "Epoch 481, Loss: 0.35721950232982635, Losses: [0.31 0.14 0.44 0.54]\n",
      "Epoch 481, Accuracy: 0.9085365980863571, Accuracies: [0.95 0.98 0.85 0.85]\n",
      "Epoch 491, Loss: 0.34514617919921875, Accuracy: 0.9085365980863571\n",
      "Epoch 491, Loss: 0.34514617919921875, Losses: [0.3  0.14 0.42 0.52]\n",
      "Epoch 491, Accuracy: 0.9085365980863571, Accuracies: [0.95 0.98 0.85 0.85]\n",
      "Epoch 501, Loss: 0.3351943679153919, Accuracy: 0.9146341532468796\n",
      "Epoch 501, Loss: 0.3351943679153919, Losses: [0.29 0.14 0.4  0.51]\n",
      "Epoch 501, Accuracy: 0.9146341532468796, Accuracies: [0.95 0.98 0.85 0.88]\n",
      "Epoch 511, Loss: 0.3259969465434551, Accuracy: 0.920731708407402\n",
      "Epoch 511, Loss: 0.3259969465434551, Losses: [0.29 0.14 0.39 0.49]\n",
      "Epoch 511, Accuracy: 0.920731708407402, Accuracies: [0.95 0.98 0.85 0.9 ]\n",
      "Epoch 521, Loss: 0.3174171969294548, Accuracy: 0.920731708407402\n",
      "Epoch 521, Loss: 0.3174171969294548, Losses: [0.28 0.14 0.38 0.48]\n",
      "Epoch 521, Accuracy: 0.920731708407402, Accuracies: [0.95 0.98 0.85 0.9 ]\n",
      "Epoch 531, Loss: 0.3101160004734993, Accuracy: 0.9268292784690857\n",
      "Epoch 531, Loss: 0.3101160004734993, Losses: [0.27 0.14 0.37 0.47]\n",
      "Epoch 531, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.85 0.9 ]\n",
      "Epoch 541, Loss: 0.309187825769186, Accuracy: 0.9329268336296082\n",
      "Epoch 541, Loss: 0.309187825769186, Losses: [0.28 0.14 0.37 0.45]\n",
      "Epoch 541, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.88 0.9 ]\n",
      "Epoch 551, Loss: 0.2953857220709324, Accuracy: 0.9268292784690857\n",
      "Epoch 551, Loss: 0.2953857220709324, Losses: [0.26 0.13 0.35 0.44]\n",
      "Epoch 551, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.85 0.9 ]\n",
      "Epoch 561, Loss: 0.2884604036808014, Accuracy: 0.9329268336296082\n",
      "Epoch 561, Loss: 0.2884604036808014, Losses: [0.25 0.13 0.34 0.43]\n",
      "Epoch 561, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.88 0.9 ]\n",
      "Epoch 571, Loss: 0.28334251418709755, Accuracy: 0.9390244036912918\n",
      "Epoch 571, Loss: 0.28334251418709755, Losses: [0.25 0.13 0.33 0.43]\n",
      "Epoch 571, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.88 0.93]\n",
      "Epoch 581, Loss: 0.2774840407073498, Accuracy: 0.9329268485307693\n",
      "Epoch 581, Loss: 0.2774840407073498, Losses: [0.24 0.13 0.32 0.41]\n",
      "Epoch 581, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 591, Loss: 0.2679598107933998, Accuracy: 0.9451219588518143\n",
      "Epoch 591, Loss: 0.2679598107933998, Losses: [0.23 0.13 0.31 0.4 ]\n",
      "Epoch 591, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.98 0.88 0.95]\n",
      "Epoch 601, Loss: 0.2609843797981739, Accuracy: 0.9451219588518143\n",
      "Epoch 601, Loss: 0.2609843797981739, Losses: [0.23 0.13 0.3  0.39]\n",
      "Epoch 601, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.98 0.88 0.95]\n",
      "Epoch 611, Loss: 0.25431879237294197, Accuracy: 0.9512195140123367\n",
      "Epoch 611, Loss: 0.25431879237294197, Losses: [0.22 0.13 0.29 0.38]\n",
      "Epoch 611, Accuracy: 0.9512195140123367, Accuracies: [0.98 0.98 0.9  0.95]\n",
      "Epoch 621, Loss: 0.27964697405695915, Accuracy: 0.9390244036912918\n",
      "Epoch 621, Loss: 0.27964697405695915, Losses: [0.22 0.13 0.37 0.4 ]\n",
      "Epoch 621, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 631, Loss: 0.26902860775589943, Accuracy: 0.9268292784690857\n",
      "Epoch 631, Loss: 0.26902860775589943, Losses: [0.22 0.14 0.27 0.44]\n",
      "Epoch 631, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.95 0.93 0.85]\n",
      "Epoch 641, Loss: 0.2463369406759739, Accuracy: 0.9390243887901306\n",
      "Epoch 641, Loss: 0.2463369406759739, Losses: [0.21 0.13 0.27 0.38]\n",
      "Epoch 641, Accuracy: 0.9390243887901306, Accuracies: [0.98 0.95 0.9  0.93]\n",
      "Epoch 651, Loss: 0.2353179007768631, Accuracy: 0.9512195140123367\n",
      "Epoch 651, Loss: 0.2353179007768631, Losses: [0.2  0.13 0.26 0.35]\n",
      "Epoch 651, Accuracy: 0.9512195140123367, Accuracies: [0.98 0.98 0.9  0.95]\n",
      "Epoch 661, Loss: 0.22779486142098904, Accuracy: 0.9512195140123367\n",
      "Epoch 661, Loss: 0.22779486142098904, Losses: [0.2  0.12 0.26 0.33]\n",
      "Epoch 661, Accuracy: 0.9512195140123367, Accuracies: [0.98 0.98 0.9  0.95]\n",
      "Epoch 671, Loss: 0.22268813848495483, Accuracy: 0.9512195140123367\n",
      "Epoch 671, Loss: 0.22268813848495483, Losses: [0.19 0.12 0.25 0.33]\n",
      "Epoch 671, Accuracy: 0.9512195140123367, Accuracies: [0.98 0.95 0.93 0.95]\n",
      "Epoch 681, Loss: 0.37006061151623726, Accuracy: 0.8780487775802612\n",
      "Epoch 681, Loss: 0.37006061151623726, Losses: [0.21 0.14 0.52 0.61]\n",
      "Epoch 681, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.95 0.8  0.78]\n",
      "Epoch 691, Loss: 0.2620907388627529, Accuracy: 0.932926818728447\n",
      "Epoch 691, Loss: 0.2620907388627529, Losses: [0.2  0.13 0.31 0.41]\n",
      "Epoch 691, Accuracy: 0.932926818728447, Accuracies: [0.98 0.95 0.9  0.9 ]\n",
      "Epoch 701, Loss: 0.23947844840586185, Accuracy: 0.9634146392345428\n",
      "Epoch 701, Loss: 0.23947844840586185, Losses: [0.19 0.12 0.28 0.36]\n",
      "Epoch 701, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.95 0.98 0.95]\n",
      "Epoch 711, Loss: 0.22690866887569427, Accuracy: 0.9634146392345428\n",
      "Epoch 711, Loss: 0.22690866887569427, Losses: [0.19 0.12 0.26 0.34]\n",
      "Epoch 711, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.95 0.95]\n",
      "Epoch 721, Loss: 0.21815693192183971, Accuracy: 0.9634146392345428\n",
      "Epoch 721, Loss: 0.21815693192183971, Losses: [0.18 0.12 0.25 0.33]\n",
      "Epoch 721, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.95 0.95]\n",
      "Epoch 731, Loss: 0.21110793389379978, Accuracy: 0.9695122092962265\n",
      "Epoch 731, Loss: 0.21110793389379978, Losses: [0.18 0.12 0.24 0.32]\n",
      "Epoch 731, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Epoch 741, Loss: 0.20503085851669312, Accuracy: 0.9695122092962265\n",
      "Epoch 741, Loss: 0.20503085851669312, Losses: [0.17 0.12 0.23 0.31]\n",
      "Epoch 741, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Epoch 751, Loss: 0.19949667155742645, Accuracy: 0.9695122092962265\n",
      "Epoch 751, Loss: 0.19949667155742645, Losses: [0.16 0.12 0.22 0.3 ]\n",
      "Epoch 751, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Epoch 761, Loss: 0.19433177635073662, Accuracy: 0.9695122092962265\n",
      "Epoch 761, Loss: 0.19433177635073662, Losses: [0.16 0.12 0.21 0.29]\n",
      "Epoch 761, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Epoch 771, Loss: 0.18984932266175747, Accuracy: 0.9695122092962265\n",
      "Epoch 771, Loss: 0.18984932266175747, Losses: [0.16 0.12 0.21 0.28]\n",
      "Epoch 771, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Epoch 781, Loss: 0.1857496164739132, Accuracy: 0.9634146392345428\n",
      "Epoch 781, Loss: 0.1857496164739132, Losses: [0.15 0.12 0.2  0.27]\n",
      "Epoch 781, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.95 0.95 0.98]\n",
      "Epoch 791, Loss: 0.18688540533185005, Accuracy: 0.9695122092962265\n",
      "Epoch 791, Loss: 0.18688540533185005, Losses: [0.16 0.12 0.19 0.27]\n",
      "Epoch 791, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Early stopping criteria met\n",
      "Training RNNA...\n",
      "Epoch 1, Loss: 2.187743902206421, Accuracy: 0.0\n",
      "Epoch 1, Loss: 2.187743902206421, Losses: [2.18 2.19 2.19 2.19]\n",
      "Epoch 1, Accuracy: 0.0, Accuracies: [0. 0. 0. 0.]\n",
      "Epoch 11, Loss: 2.0081039667129517, Accuracy: 0.1768292635679245\n",
      "Epoch 11, Loss: 2.0081039667129517, Losses: [2.06 1.99 1.98 2.  ]\n",
      "Epoch 11, Accuracy: 0.1768292635679245, Accuracies: [0.2  0.15 0.15 0.22]\n",
      "Epoch 21, Loss: 1.9394602477550507, Accuracy: 0.18292682617902756\n",
      "Epoch 21, Loss: 1.9394602477550507, Losses: [2.07 1.9  1.88 1.9 ]\n",
      "Epoch 21, Accuracy: 0.18292682617902756, Accuracies: [0.2  0.15 0.15 0.24]\n",
      "Epoch 31, Loss: 1.918378621339798, Accuracy: 0.2073170766234398\n",
      "Epoch 31, Loss: 1.918378621339798, Losses: [2.09 1.87 1.85 1.86]\n",
      "Epoch 31, Accuracy: 0.2073170766234398, Accuracies: [0.22 0.12 0.24 0.24]\n",
      "Epoch 41, Loss: 1.9069939851760864, Accuracy: 0.19512194767594337\n",
      "Epoch 41, Loss: 1.9069939851760864, Losses: [2.07 1.86 1.84 1.86]\n",
      "Epoch 41, Accuracy: 0.19512194767594337, Accuracies: [0.22 0.15 0.22 0.2 ]\n",
      "Epoch 51, Loss: 1.8962499797344208, Accuracy: 0.25\n",
      "Epoch 51, Loss: 1.8962499797344208, Losses: [2.06 1.86 1.82 1.85]\n",
      "Epoch 51, Accuracy: 0.25, Accuracies: [0.24 0.2  0.34 0.22]\n",
      "Epoch 61, Loss: 1.8838180899620056, Accuracy: 0.24390244111418724\n",
      "Epoch 61, Loss: 1.8838180899620056, Losses: [2.04 1.85 1.81 1.84]\n",
      "Epoch 61, Accuracy: 0.24390244111418724, Accuracies: [0.24 0.17 0.34 0.22]\n",
      "Epoch 71, Loss: 1.8662309348583221, Accuracy: 0.25609756633639336\n",
      "Epoch 71, Loss: 1.8662309348583221, Losses: [2.01 1.84 1.79 1.82]\n",
      "Epoch 71, Accuracy: 0.25609756633639336, Accuracies: [0.24 0.17 0.34 0.27]\n",
      "Epoch 81, Loss: 1.8423287570476532, Accuracy: 0.2621951177716255\n",
      "Epoch 81, Loss: 1.8423287570476532, Losses: [1.97 1.82 1.77 1.81]\n",
      "Epoch 81, Accuracy: 0.2621951177716255, Accuracies: [0.22 0.2  0.32 0.32]\n",
      "Epoch 91, Loss: 1.8078328371047974, Accuracy: 0.28658536076545715\n",
      "Epoch 91, Loss: 1.8078328371047974, Losses: [1.92 1.76 1.76 1.8 ]\n",
      "Epoch 91, Accuracy: 0.28658536076545715, Accuracies: [0.2  0.32 0.32 0.32]\n",
      "Epoch 101, Loss: 1.7568185031414032, Accuracy: 0.3048780485987663\n",
      "Epoch 101, Loss: 1.7568185031414032, Losses: [1.85 1.66 1.74 1.78]\n",
      "Epoch 101, Accuracy: 0.3048780485987663, Accuracies: [0.2  0.34 0.32 0.37]\n",
      "Epoch 111, Loss: 1.7099473476409912, Accuracy: 0.3109756112098694\n",
      "Epoch 111, Loss: 1.7099473476409912, Losses: [1.81 1.53 1.72 1.77]\n",
      "Epoch 111, Accuracy: 0.3109756112098694, Accuracies: [0.24 0.34 0.37 0.29]\n",
      "Epoch 121, Loss: 1.6664043962955475, Accuracy: 0.39024391025304794\n",
      "Epoch 121, Loss: 1.6664043962955475, Losses: [1.78 1.39 1.72 1.78]\n",
      "Epoch 121, Accuracy: 0.39024391025304794, Accuracies: [0.24 0.66 0.32 0.34]\n",
      "Epoch 131, Loss: 1.6203624904155731, Accuracy: 0.4268292635679245\n",
      "Epoch 131, Loss: 1.6203624904155731, Losses: [1.74 1.26 1.71 1.77]\n",
      "Epoch 131, Accuracy: 0.4268292635679245, Accuracies: [0.24 0.83 0.24 0.39]\n",
      "Epoch 141, Loss: 1.5747195482254028, Accuracy: 0.4268292710185051\n",
      "Epoch 141, Loss: 1.5747195482254028, Losses: [1.7  1.15 1.68 1.77]\n",
      "Epoch 141, Accuracy: 0.4268292710185051, Accuracies: [0.27 0.83 0.24 0.37]\n",
      "Epoch 151, Loss: 1.5315287411212921, Accuracy: 0.4390243887901306\n",
      "Epoch 151, Loss: 1.5315287411212921, Losses: [1.64 1.07 1.65 1.77]\n",
      "Epoch 151, Accuracy: 0.4390243887901306, Accuracies: [0.32 0.83 0.27 0.34]\n",
      "Epoch 161, Loss: 1.4881190955638885, Accuracy: 0.46341462433338165\n",
      "Epoch 161, Loss: 1.4881190955638885, Losses: [1.55 1.01 1.63 1.76]\n",
      "Epoch 161, Accuracy: 0.46341462433338165, Accuracies: [0.41 0.83 0.29 0.32]\n",
      "Epoch 171, Loss: 1.4487605392932892, Accuracy: 0.49390242993831635\n",
      "Epoch 171, Loss: 1.4487605392932892, Losses: [1.48 0.95 1.61 1.76]\n",
      "Epoch 171, Accuracy: 0.49390242993831635, Accuracies: [0.51 0.83 0.32 0.32]\n",
      "Epoch 181, Loss: 1.4086601585149765, Accuracy: 0.49390243738889694\n",
      "Epoch 181, Loss: 1.4086601585149765, Losses: [1.39 0.9  1.59 1.76]\n",
      "Epoch 181, Accuracy: 0.49390243738889694, Accuracies: [0.49 0.83 0.34 0.32]\n",
      "Epoch 191, Loss: 1.3693675994873047, Accuracy: 0.5182926803827286\n",
      "Epoch 191, Loss: 1.3693675994873047, Losses: [1.31 0.85 1.57 1.75]\n",
      "Epoch 191, Accuracy: 0.5182926803827286, Accuracies: [0.56 0.83 0.34 0.34]\n",
      "Epoch 201, Loss: 1.3449528366327286, Accuracy: 0.5731707364320755\n",
      "Epoch 201, Loss: 1.3449528366327286, Losses: [1.27 0.81 1.55 1.75]\n",
      "Epoch 201, Accuracy: 0.5731707364320755, Accuracies: [0.66 0.95 0.34 0.34]\n",
      "Epoch 211, Loss: 1.301995187997818, Accuracy: 0.5731707289814949\n",
      "Epoch 211, Loss: 1.301995187997818, Losses: [1.17 0.77 1.54 1.74]\n",
      "Epoch 211, Accuracy: 0.5731707289814949, Accuracies: [0.63 0.95 0.34 0.37]\n",
      "Epoch 221, Loss: 1.2996876537799835, Accuracy: 0.5731707364320755\n",
      "Epoch 221, Loss: 1.2996876537799835, Losses: [1.2  0.72 1.52 1.75]\n",
      "Epoch 221, Accuracy: 0.5731707364320755, Accuracies: [0.63 0.98 0.37 0.32]\n",
      "Epoch 231, Loss: 1.263510286808014, Accuracy: 0.5975609794259071\n",
      "Epoch 231, Loss: 1.263510286808014, Losses: [1.12 0.7  1.51 1.73]\n",
      "Epoch 231, Accuracy: 0.5975609794259071, Accuracies: [0.68 0.98 0.39 0.34]\n",
      "Epoch 241, Loss: 1.2305325418710709, Accuracy: 0.585365854203701\n",
      "Epoch 241, Loss: 1.2305325418710709, Losses: [1.04 0.67 1.5  1.72]\n",
      "Epoch 241, Accuracy: 0.585365854203701, Accuracies: [0.63 0.98 0.39 0.34]\n",
      "Epoch 251, Loss: 1.2028845101594925, Accuracy: 0.5975609794259071\n",
      "Epoch 251, Loss: 1.2028845101594925, Losses: [0.98 0.64 1.48 1.71]\n",
      "Epoch 251, Accuracy: 0.5975609794259071, Accuracies: [0.68 0.98 0.39 0.34]\n",
      "Epoch 261, Loss: 1.1801194101572037, Accuracy: 0.6036585494875908\n",
      "Epoch 261, Loss: 1.1801194101572037, Losses: [0.93 0.61 1.47 1.71]\n",
      "Epoch 261, Accuracy: 0.6036585494875908, Accuracies: [0.73 0.98 0.37 0.34]\n",
      "Epoch 271, Loss: 1.1595672070980072, Accuracy: 0.6341463476419449\n",
      "Epoch 271, Loss: 1.1595672070980072, Losses: [0.89 0.58 1.46 1.71]\n",
      "Epoch 271, Accuracy: 0.6341463476419449, Accuracies: [0.76 0.98 0.46 0.34]\n",
      "Epoch 281, Loss: 1.1604230254888535, Accuracy: 0.6036585420370102\n",
      "Epoch 281, Loss: 1.1604230254888535, Losses: [0.92 0.56 1.45 1.72]\n",
      "Epoch 281, Accuracy: 0.6036585420370102, Accuracies: [0.63 0.98 0.46 0.34]\n",
      "Epoch 291, Loss: 1.1256749480962753, Accuracy: 0.6402439102530479\n",
      "Epoch 291, Loss: 1.1256749480962753, Losses: [0.82 0.54 1.44 1.69]\n",
      "Epoch 291, Accuracy: 0.6402439102530479, Accuracies: [0.76 0.98 0.46 0.37]\n",
      "Epoch 301, Loss: 1.1094553768634796, Accuracy: 0.6341463476419449\n",
      "Epoch 301, Loss: 1.1094553768634796, Losses: [0.79 0.52 1.43 1.69]\n",
      "Epoch 301, Accuracy: 0.6341463476419449, Accuracies: [0.76 0.98 0.46 0.34]\n",
      "Epoch 311, Loss: 1.0951218754053116, Accuracy: 0.6341463476419449\n",
      "Epoch 311, Loss: 1.0951218754053116, Losses: [0.76 0.5  1.42 1.69]\n",
      "Epoch 311, Accuracy: 0.6341463476419449, Accuracies: [0.76 0.98 0.46 0.34]\n",
      "Epoch 321, Loss: 1.0812274515628815, Accuracy: 0.6341463476419449\n",
      "Epoch 321, Loss: 1.0812274515628815, Losses: [0.74 0.49 1.42 1.68]\n",
      "Epoch 321, Accuracy: 0.6341463476419449, Accuracies: [0.76 0.98 0.46 0.34]\n",
      "Epoch 331, Loss: 1.068617083132267, Accuracy: 0.6341463401913643\n",
      "Epoch 331, Loss: 1.068617083132267, Losses: [0.72 0.47 1.41 1.68]\n",
      "Epoch 331, Accuracy: 0.6341463401913643, Accuracies: [0.78 0.98 0.46 0.32]\n",
      "Epoch 341, Loss: 1.0556307807564735, Accuracy: 0.6280487850308418\n",
      "Epoch 341, Loss: 1.0556307807564735, Losses: [0.69 0.46 1.4  1.67]\n",
      "Epoch 341, Accuracy: 0.6280487850308418, Accuracies: [0.76 0.98 0.44 0.34]\n",
      "Epoch 351, Loss: 1.0431045293807983, Accuracy: 0.6280487850308418\n",
      "Epoch 351, Loss: 1.0431045293807983, Losses: [0.67 0.45 1.39 1.66]\n",
      "Epoch 351, Accuracy: 0.6280487850308418, Accuracies: [0.76 0.98 0.44 0.34]\n",
      "Epoch 361, Loss: 1.0308369919657707, Accuracy: 0.6280487775802612\n",
      "Epoch 361, Loss: 1.0308369919657707, Losses: [0.65 0.43 1.38 1.66]\n",
      "Epoch 361, Accuracy: 0.6280487775802612, Accuracies: [0.78 0.98 0.41 0.34]\n",
      "Epoch 371, Loss: 1.018111266195774, Accuracy: 0.6341463476419449\n",
      "Epoch 371, Loss: 1.018111266195774, Losses: [0.62 0.42 1.38 1.65]\n",
      "Epoch 371, Accuracy: 0.6341463476419449, Accuracies: [0.8  0.98 0.41 0.34]\n",
      "Epoch 381, Loss: 1.0053156912326813, Accuracy: 0.6463414654135704\n",
      "Epoch 381, Loss: 1.0053156912326813, Losses: [0.6  0.41 1.37 1.64]\n",
      "Epoch 381, Accuracy: 0.6463414654135704, Accuracies: [0.83 0.98 0.44 0.34]\n",
      "Epoch 391, Loss: 0.9921532422304153, Accuracy: 0.6585365906357765\n",
      "Epoch 391, Loss: 0.9921532422304153, Losses: [0.57 0.4  1.37 1.63]\n",
      "Epoch 391, Accuracy: 0.6585365906357765, Accuracies: [0.88 0.98 0.44 0.34]\n",
      "Epoch 401, Loss: 1.2506830766797066, Accuracy: 0.579268291592598\n",
      "Epoch 401, Loss: 1.2506830766797066, Losses: [1.59 0.41 1.37 1.63]\n",
      "Epoch 401, Accuracy: 0.579268291592598, Accuracies: [0.59 0.98 0.44 0.32]\n",
      "Epoch 411, Loss: 1.0290186181664467, Accuracy: 0.6036585420370102\n",
      "Epoch 411, Loss: 1.0290186181664467, Losses: [0.72 0.39 1.38 1.63]\n",
      "Epoch 411, Accuracy: 0.6036585420370102, Accuracies: [0.66 0.95 0.46 0.34]\n",
      "Epoch 421, Loss: 0.9766100943088531, Accuracy: 0.6402439102530479\n",
      "Epoch 421, Loss: 0.9766100943088531, Losses: [0.57 0.37 1.35 1.62]\n",
      "Epoch 421, Accuracy: 0.6402439102530479, Accuracies: [0.8  0.98 0.44 0.34]\n",
      "Epoch 431, Loss: 0.9594171345233917, Accuracy: 0.6524390354752541\n",
      "Epoch 431, Loss: 0.9594171345233917, Losses: [0.52 0.36 1.34 1.61]\n",
      "Epoch 431, Accuracy: 0.6524390354752541, Accuracies: [0.85 0.98 0.44 0.34]\n",
      "Epoch 441, Loss: 0.9471489116549492, Accuracy: 0.6585365906357765\n",
      "Epoch 441, Loss: 0.9471489116549492, Losses: [0.5  0.35 1.33 1.6 ]\n",
      "Epoch 441, Accuracy: 0.6585365906357765, Accuracies: [0.88 0.98 0.44 0.34]\n",
      "Epoch 451, Loss: 0.935988612473011, Accuracy: 0.6585365906357765\n",
      "Epoch 451, Loss: 0.935988612473011, Losses: [0.48 0.35 1.33 1.59]\n",
      "Epoch 451, Accuracy: 0.6585365906357765, Accuracies: [0.88 0.98 0.44 0.34]\n",
      "Epoch 461, Loss: 0.9254346489906311, Accuracy: 0.664634145796299\n",
      "Epoch 461, Loss: 0.9254346489906311, Losses: [0.46 0.34 1.32 1.58]\n",
      "Epoch 461, Accuracy: 0.664634145796299, Accuracies: [0.9  0.98 0.44 0.34]\n",
      "Epoch 471, Loss: 0.9150051325559616, Accuracy: 0.6707317158579826\n",
      "Epoch 471, Loss: 0.9150051325559616, Losses: [0.44 0.33 1.32 1.58]\n",
      "Epoch 471, Accuracy: 0.6707317158579826, Accuracies: [0.93 0.98 0.41 0.37]\n",
      "Epoch 481, Loss: 0.904378816485405, Accuracy: 0.6829268336296082\n",
      "Epoch 481, Loss: 0.904378816485405, Losses: [0.41 0.33 1.31 1.57]\n",
      "Epoch 481, Accuracy: 0.6829268336296082, Accuracies: [0.93 0.98 0.44 0.39]\n",
      "Epoch 491, Loss: 0.9099732786417007, Accuracy: 0.6585365906357765\n",
      "Epoch 491, Loss: 0.9099732786417007, Losses: [0.45 0.32 1.31 1.56]\n",
      "Epoch 491, Accuracy: 0.6585365906357765, Accuracies: [0.88 0.98 0.44 0.34]\n",
      "Epoch 501, Loss: 0.8874644413590431, Accuracy: 0.6890243962407112\n",
      "Epoch 501, Loss: 0.8874644413590431, Losses: [0.39 0.31 1.29 1.56]\n",
      "Epoch 501, Accuracy: 0.6890243962407112, Accuracies: [0.93 0.98 0.44 0.41]\n",
      "Epoch 511, Loss: 0.8986988738179207, Accuracy: 0.670731708407402\n",
      "Epoch 511, Loss: 0.8986988738179207, Losses: [0.45 0.31 1.29 1.54]\n",
      "Epoch 511, Accuracy: 0.670731708407402, Accuracies: [0.88 0.98 0.44 0.39]\n",
      "Epoch 521, Loss: 0.9121413081884384, Accuracy: 0.6768292784690857\n",
      "Epoch 521, Loss: 0.9121413081884384, Losses: [0.51 0.3  1.3  1.54]\n",
      "Epoch 521, Accuracy: 0.6768292784690857, Accuracies: [0.85 0.98 0.46 0.41]\n",
      "Epoch 531, Loss: 0.8741379678249359, Accuracy: 0.6829268261790276\n",
      "Epoch 531, Loss: 0.8741379678249359, Losses: [0.4  0.29 1.27 1.53]\n",
      "Epoch 531, Accuracy: 0.6829268261790276, Accuracies: [0.9  0.98 0.46 0.39]\n",
      "Epoch 541, Loss: 0.8583791553974152, Accuracy: 0.6890243887901306\n",
      "Epoch 541, Loss: 0.8583791553974152, Losses: [0.36 0.29 1.27 1.52]\n",
      "Epoch 541, Accuracy: 0.6890243887901306, Accuracies: [0.95 0.98 0.44 0.39]\n",
      "Epoch 551, Loss: 0.8482439741492271, Accuracy: 0.6951219514012337\n",
      "Epoch 551, Loss: 0.8482439741492271, Losses: [0.33 0.28 1.26 1.52]\n",
      "Epoch 551, Accuracy: 0.6951219514012337, Accuracies: [0.95 0.98 0.46 0.39]\n",
      "Epoch 561, Loss: 0.8381112813949585, Accuracy: 0.7012195214629173\n",
      "Epoch 561, Loss: 0.8381112813949585, Losses: [0.31 0.28 1.25 1.51]\n",
      "Epoch 561, Accuracy: 0.7012195214629173, Accuracies: [0.98 0.98 0.46 0.39]\n",
      "Epoch 571, Loss: 0.828174777328968, Accuracy: 0.7012195214629173\n",
      "Epoch 571, Loss: 0.828174777328968, Losses: [0.3  0.27 1.24 1.5 ]\n",
      "Epoch 571, Accuracy: 0.7012195214629173, Accuracies: [0.98 0.98 0.46 0.39]\n",
      "Epoch 581, Loss: 0.8190845549106598, Accuracy: 0.7012195214629173\n",
      "Epoch 581, Loss: 0.8190845549106598, Losses: [0.28 0.27 1.24 1.49]\n",
      "Epoch 581, Accuracy: 0.7012195214629173, Accuracies: [0.98 0.98 0.46 0.39]\n",
      "Epoch 591, Loss: 0.813357912003994, Accuracy: 0.7073170840740204\n",
      "Epoch 591, Loss: 0.813357912003994, Losses: [0.27 0.26 1.23 1.49]\n",
      "Epoch 591, Accuracy: 0.7073170840740204, Accuracies: [0.98 0.98 0.46 0.41]\n",
      "Epoch 601, Loss: 1.0940745994448662, Accuracy: 0.646341472864151\n",
      "Epoch 601, Loss: 1.0940745994448662, Losses: [1.21 0.27 1.33 1.57]\n",
      "Epoch 601, Accuracy: 0.646341472864151, Accuracies: [0.68 0.98 0.54 0.39]\n",
      "Epoch 611, Loss: 0.9647700376808643, Accuracy: 0.6402439028024673\n",
      "Epoch 611, Loss: 0.9647700376808643, Losses: [0.86 0.25 1.24 1.51]\n",
      "Epoch 611, Accuracy: 0.6402439028024673, Accuracies: [0.76 0.98 0.41 0.41]\n",
      "Epoch 621, Loss: 0.9187500476837158, Accuracy: 0.6524390280246735\n",
      "Epoch 621, Loss: 0.9187500476837158, Losses: [0.71 0.25 1.23 1.48]\n",
      "Epoch 621, Accuracy: 0.6524390280246735, Accuracies: [0.76 0.98 0.46 0.41]\n",
      "Epoch 631, Loss: 0.8737567216157913, Accuracy: 0.6768292784690857\n",
      "Epoch 631, Loss: 0.8737567216157913, Losses: [0.56 0.25 1.22 1.47]\n",
      "Epoch 631, Accuracy: 0.6768292784690857, Accuracies: [0.85 0.98 0.49 0.39]\n",
      "Epoch 641, Loss: 0.8312386088073254, Accuracy: 0.6951219514012337\n",
      "Epoch 641, Loss: 0.8312386088073254, Losses: [0.41 0.24 1.21 1.46]\n",
      "Epoch 641, Accuracy: 0.6951219514012337, Accuracies: [0.9  0.98 0.49 0.41]\n",
      "Epoch 651, Loss: 0.8180618733167648, Accuracy: 0.7012195214629173\n",
      "Epoch 651, Loss: 0.8180618733167648, Losses: [0.37 0.24 1.2  1.45]\n",
      "Epoch 651, Accuracy: 0.7012195214629173, Accuracies: [0.93 0.98 0.49 0.41]\n",
      "Epoch 661, Loss: 0.8056270554661751, Accuracy: 0.6951219514012337\n",
      "Epoch 661, Loss: 0.8056270554661751, Losses: [0.34 0.24 1.2  1.44]\n",
      "Epoch 661, Accuracy: 0.6951219514012337, Accuracies: [0.9  0.98 0.49 0.41]\n",
      "Epoch 671, Loss: 0.7943820655345917, Accuracy: 0.6951219514012337\n",
      "Epoch 671, Loss: 0.7943820655345917, Losses: [0.32 0.23 1.19 1.44]\n",
      "Epoch 671, Accuracy: 0.6951219514012337, Accuracies: [0.9  0.98 0.49 0.41]\n",
      "Epoch 681, Loss: 0.7846317999064922, Accuracy: 0.7073170766234398\n",
      "Epoch 681, Loss: 0.7846317999064922, Losses: [0.3  0.23 1.19 1.43]\n",
      "Epoch 681, Accuracy: 0.7073170766234398, Accuracies: [0.93 0.98 0.51 0.41]\n",
      "Epoch 691, Loss: 0.7758420668542385, Accuracy: 0.7073170766234398\n",
      "Epoch 691, Loss: 0.7758420668542385, Losses: [0.28 0.23 1.18 1.42]\n",
      "Epoch 691, Accuracy: 0.7073170766234398, Accuracies: [0.93 0.98 0.51 0.41]\n",
      "Epoch 701, Loss: 0.7672837302088737, Accuracy: 0.7073170766234398\n",
      "Epoch 701, Loss: 0.7672837302088737, Losses: [0.26 0.23 1.17 1.41]\n",
      "Epoch 701, Accuracy: 0.7073170766234398, Accuracies: [0.93 0.98 0.51 0.41]\n",
      "Epoch 711, Loss: 0.7599472403526306, Accuracy: 0.7195122018456459\n",
      "Epoch 711, Loss: 0.7599472403526306, Losses: [0.25 0.22 1.16 1.4 ]\n",
      "Epoch 711, Accuracy: 0.7195122018456459, Accuracies: [0.95 0.98 0.54 0.41]\n",
      "Epoch 721, Loss: 0.7529245838522911, Accuracy: 0.7195121943950653\n",
      "Epoch 721, Loss: 0.7529245838522911, Losses: [0.24 0.22 1.15 1.4 ]\n",
      "Epoch 721, Accuracy: 0.7195121943950653, Accuracies: [0.95 0.98 0.51 0.44]\n",
      "Epoch 731, Loss: 0.7462105415761471, Accuracy: 0.7195121943950653\n",
      "Epoch 731, Loss: 0.7462105415761471, Losses: [0.23 0.22 1.15 1.39]\n",
      "Epoch 731, Accuracy: 0.7195121943950653, Accuracies: [0.95 0.98 0.51 0.44]\n",
      "Epoch 741, Loss: 0.7400255426764488, Accuracy: 0.7195121943950653\n",
      "Epoch 741, Loss: 0.7400255426764488, Losses: [0.22 0.21 1.14 1.38]\n",
      "Epoch 741, Accuracy: 0.7195121943950653, Accuracies: [0.95 0.98 0.51 0.44]\n",
      "Epoch 751, Loss: 0.7338016219437122, Accuracy: 0.7195121943950653\n",
      "Epoch 751, Loss: 0.7338016219437122, Losses: [0.22 0.21 1.13 1.38]\n",
      "Epoch 751, Accuracy: 0.7195121943950653, Accuracies: [0.95 0.98 0.51 0.44]\n",
      "Epoch 761, Loss: 0.7278767637908459, Accuracy: 0.7134146392345428\n",
      "Epoch 761, Loss: 0.7278767637908459, Losses: [0.21 0.21 1.12 1.37]\n",
      "Epoch 761, Accuracy: 0.7134146392345428, Accuracies: [0.95 0.98 0.49 0.44]\n",
      "Epoch 771, Loss: 0.7219936959445477, Accuracy: 0.7134146392345428\n",
      "Epoch 771, Loss: 0.7219936959445477, Losses: [0.2  0.2  1.11 1.37]\n",
      "Epoch 771, Accuracy: 0.7134146392345428, Accuracies: [0.95 0.98 0.49 0.44]\n",
      "Epoch 781, Loss: 0.7161156795918941, Accuracy: 0.7134146317839622\n",
      "Epoch 781, Loss: 0.7161156795918941, Losses: [0.2  0.2  1.11 1.36]\n",
      "Epoch 781, Accuracy: 0.7134146317839622, Accuracies: [0.95 0.98 0.51 0.41]\n",
      "Epoch 791, Loss: 0.710472110658884, Accuracy: 0.7134146317839622\n",
      "Epoch 791, Loss: 0.710472110658884, Losses: [0.19 0.2  1.1  1.35]\n",
      "Epoch 791, Accuracy: 0.7134146317839622, Accuracies: [0.95 0.98 0.51 0.41]\n",
      "Epoch 801, Loss: 0.7050042748451233, Accuracy: 0.7256097570061684\n",
      "Epoch 801, Loss: 0.7050042748451233, Losses: [0.19 0.2  1.09 1.35]\n",
      "Epoch 801, Accuracy: 0.7256097570061684, Accuracies: [0.95 0.98 0.56 0.41]\n",
      "Epoch 811, Loss: 0.6992867849767208, Accuracy: 0.7256097570061684\n",
      "Epoch 811, Loss: 0.6992867849767208, Losses: [0.18 0.2  1.08 1.34]\n",
      "Epoch 811, Accuracy: 0.7256097570061684, Accuracies: [0.95 0.98 0.56 0.41]\n",
      "Epoch 821, Loss: 0.6938459537923336, Accuracy: 0.7256097570061684\n",
      "Epoch 821, Loss: 0.6938459537923336, Losses: [0.18 0.19 1.08 1.33]\n",
      "Epoch 821, Accuracy: 0.7256097570061684, Accuracies: [0.95 0.98 0.56 0.41]\n",
      "Epoch 831, Loss: 0.6886807680130005, Accuracy: 0.7317073121666908\n",
      "Epoch 831, Loss: 0.6886807680130005, Losses: [0.17 0.19 1.07 1.32]\n",
      "Epoch 831, Accuracy: 0.7317073121666908, Accuracies: [0.95 0.98 0.59 0.41]\n",
      "Epoch 841, Loss: 0.684182059019804, Accuracy: 0.7256097570061684\n",
      "Epoch 841, Loss: 0.684182059019804, Losses: [0.17 0.19 1.06 1.32]\n",
      "Epoch 841, Accuracy: 0.7256097570061684, Accuracies: [0.95 0.98 0.56 0.41]\n",
      "Epoch 851, Loss: 0.6776691153645515, Accuracy: 0.7500000149011612\n",
      "Epoch 851, Loss: 0.6776691153645515, Losses: [0.16 0.19 1.05 1.31]\n",
      "Epoch 851, Accuracy: 0.7500000149011612, Accuracies: [0.98 0.98 0.61 0.44]\n",
      "Epoch 861, Loss: 0.6723028607666492, Accuracy: 0.7500000149011612\n",
      "Epoch 861, Loss: 0.6723028607666492, Losses: [0.16 0.18 1.04 1.3 ]\n",
      "Epoch 861, Accuracy: 0.7500000149011612, Accuracies: [0.98 0.98 0.61 0.44]\n",
      "Epoch 871, Loss: 0.6671033948659897, Accuracy: 0.7560975700616837\n",
      "Epoch 871, Loss: 0.6671033948659897, Losses: [0.15 0.18 1.03 1.3 ]\n",
      "Epoch 871, Accuracy: 0.7560975700616837, Accuracies: [0.98 0.98 0.63 0.44]\n",
      "Epoch 881, Loss: 0.6665942892432213, Accuracy: 0.7560975700616837\n",
      "Epoch 881, Loss: 0.6665942892432213, Losses: [0.15 0.18 1.03 1.3 ]\n",
      "Epoch 881, Accuracy: 0.7560975700616837, Accuracies: [0.98 0.98 0.63 0.44]\n",
      "Epoch 891, Loss: 0.660987563431263, Accuracy: 0.7560975775122643\n",
      "Epoch 891, Loss: 0.660987563431263, Losses: [0.15 0.17 1.03 1.3 ]\n",
      "Epoch 891, Accuracy: 0.7560975775122643, Accuracies: [0.98 0.98 0.61 0.46]\n",
      "Epoch 901, Loss: 0.6525562778115273, Accuracy: 0.7560975700616837\n",
      "Epoch 901, Loss: 0.6525562778115273, Losses: [0.14 0.18 1.01 1.28]\n",
      "Epoch 901, Accuracy: 0.7560975700616837, Accuracies: [0.98 0.98 0.63 0.44]\n",
      "Epoch 911, Loss: 0.648404985666275, Accuracy: 0.7560975700616837\n",
      "Epoch 911, Loss: 0.648404985666275, Losses: [0.14 0.17 1.   1.28]\n",
      "Epoch 911, Accuracy: 0.7560975700616837, Accuracies: [0.98 0.98 0.63 0.44]\n",
      "Epoch 921, Loss: 0.6428650990128517, Accuracy: 0.7682926952838898\n",
      "Epoch 921, Loss: 0.6428650990128517, Losses: [0.14 0.17 1.   1.27]\n",
      "Epoch 921, Accuracy: 0.7682926952838898, Accuracies: [0.98 0.98 0.68 0.44]\n",
      "Epoch 931, Loss: 0.6407226771116257, Accuracy: 0.75\n",
      "Epoch 931, Loss: 0.6407226771116257, Losses: [0.13 0.17 0.99 1.26]\n",
      "Epoch 931, Accuracy: 0.75, Accuracies: [1.   0.98 0.59 0.44]\n",
      "Epoch 941, Loss: 0.6341033019125462, Accuracy: 0.7682926952838898\n",
      "Epoch 941, Loss: 0.6341033019125462, Losses: [0.13 0.17 0.98 1.26]\n",
      "Epoch 941, Accuracy: 0.7682926952838898, Accuracies: [0.98 0.98 0.68 0.44]\n",
      "Epoch 951, Loss: 0.6284791119396687, Accuracy: 0.7743902578949928\n",
      "Epoch 951, Loss: 0.6284791119396687, Losses: [0.12 0.17 0.98 1.25]\n",
      "Epoch 951, Accuracy: 0.7743902578949928, Accuracies: [0.98 0.98 0.68 0.46]\n",
      "Epoch 961, Loss: 0.6238494291901588, Accuracy: 0.7743902578949928\n",
      "Epoch 961, Loss: 0.6238494291901588, Losses: [0.12 0.16 0.97 1.24]\n",
      "Epoch 961, Accuracy: 0.7743902578949928, Accuracies: [0.98 0.98 0.68 0.46]\n",
      "Epoch 971, Loss: 0.6213415376842022, Accuracy: 0.7865853756666183\n",
      "Epoch 971, Loss: 0.6213415376842022, Losses: [0.12 0.16 0.96 1.25]\n",
      "Epoch 971, Accuracy: 0.7865853756666183, Accuracies: [0.98 0.98 0.68 0.51]\n",
      "Epoch 981, Loss: 0.6143795270472765, Accuracy: 0.7865853756666183\n",
      "Epoch 981, Loss: 0.6143795270472765, Losses: [0.12 0.16 0.95 1.23]\n",
      "Epoch 981, Accuracy: 0.7865853756666183, Accuracies: [0.98 0.98 0.68 0.51]\n",
      "Epoch 991, Loss: 0.613008527085185, Accuracy: 0.7804878205060959\n",
      "Epoch 991, Loss: 0.613008527085185, Losses: [0.11 0.16 0.95 1.24]\n",
      "Epoch 991, Accuracy: 0.7804878205060959, Accuracies: [0.98 0.98 0.66 0.51]\n",
      "Epoch 1001, Loss: 0.6062479056417942, Accuracy: 0.792682945728302\n",
      "Epoch 1001, Loss: 0.6062479056417942, Losses: [0.11 0.15 0.94 1.22]\n",
      "Epoch 1001, Accuracy: 0.792682945728302, Accuracies: [0.98 0.98 0.68 0.54]\n",
      "Epoch 1011, Loss: 0.6008338592946529, Accuracy: 0.792682945728302\n",
      "Epoch 1011, Loss: 0.6008338592946529, Losses: [0.11 0.15 0.93 1.21]\n",
      "Epoch 1011, Accuracy: 0.792682945728302, Accuracies: [0.98 0.98 0.68 0.54]\n",
      "Epoch 1021, Loss: 0.5966038908809423, Accuracy: 0.792682945728302\n",
      "Epoch 1021, Loss: 0.5966038908809423, Losses: [0.1  0.15 0.92 1.21]\n",
      "Epoch 1021, Accuracy: 0.792682945728302, Accuracies: [0.98 0.98 0.68 0.54]\n",
      "Epoch 1031, Loss: 0.6123183816671371, Accuracy: 0.7743902653455734\n",
      "Epoch 1031, Loss: 0.6123183816671371, Losses: [0.1  0.15 0.94 1.25]\n",
      "Epoch 1031, Accuracy: 0.7743902653455734, Accuracies: [0.98 0.98 0.66 0.49]\n",
      "Epoch 1041, Loss: 0.5966231524944305, Accuracy: 0.7926829308271408\n",
      "Epoch 1041, Loss: 0.5966231524944305, Losses: [0.11 0.14 0.92 1.21]\n",
      "Epoch 1041, Accuracy: 0.7926829308271408, Accuracies: [0.98 0.98 0.71 0.51]\n",
      "Epoch 1051, Loss: 0.5854232497513294, Accuracy: 0.7987805008888245\n",
      "Epoch 1051, Loss: 0.5854232497513294, Losses: [0.1  0.15 0.9  1.19]\n",
      "Epoch 1051, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1061, Loss: 0.5799307022243738, Accuracy: 0.7987805008888245\n",
      "Epoch 1061, Loss: 0.5799307022243738, Losses: [0.1  0.14 0.89 1.19]\n",
      "Epoch 1061, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1071, Loss: 0.5764611233025789, Accuracy: 0.7987805008888245\n",
      "Epoch 1071, Loss: 0.5764611233025789, Losses: [0.09 0.14 0.89 1.18]\n",
      "Epoch 1071, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1081, Loss: 0.5713789816945791, Accuracy: 0.7987805008888245\n",
      "Epoch 1081, Loss: 0.5713789816945791, Losses: [0.09 0.14 0.88 1.18]\n",
      "Epoch 1081, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1091, Loss: 0.566913990303874, Accuracy: 0.7987805008888245\n",
      "Epoch 1091, Loss: 0.566913990303874, Losses: [0.09 0.14 0.87 1.17]\n",
      "Epoch 1091, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1101, Loss: 0.5625166911631823, Accuracy: 0.7987805008888245\n",
      "Epoch 1101, Loss: 0.5625166911631823, Losses: [0.09 0.14 0.86 1.16]\n",
      "Epoch 1101, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1111, Loss: 0.5585623383522034, Accuracy: 0.7987805008888245\n",
      "Epoch 1111, Loss: 0.5585623383522034, Losses: [0.09 0.13 0.85 1.16]\n",
      "Epoch 1111, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1121, Loss: 0.5536883231252432, Accuracy: 0.7987805008888245\n",
      "Epoch 1121, Loss: 0.5536883231252432, Losses: [0.08 0.13 0.84 1.15]\n",
      "Epoch 1121, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.71 0.54]\n",
      "Epoch 1131, Loss: 0.5704352427273989, Accuracy: 0.7987805008888245\n",
      "Epoch 1131, Loss: 0.5704352427273989, Losses: [0.08 0.14 0.91 1.15]\n",
      "Epoch 1131, Accuracy: 0.7987805008888245, Accuracies: [1.   0.98 0.68 0.54]\n",
      "Epoch 1141, Loss: 1.1677617207169533, Accuracy: 0.6158536747097969\n",
      "Epoch 1141, Loss: 1.1677617207169533, Losses: [2.18 0.18 0.93 1.39]\n",
      "Epoch 1141, Accuracy: 0.6158536747097969, Accuracies: [0.46 0.98 0.66 0.37]\n",
      "Epoch 1151, Loss: 0.8842479810118675, Accuracy: 0.6829268336296082\n",
      "Epoch 1151, Loss: 0.8842479810118675, Losses: [1.22 0.16 0.9  1.25]\n",
      "Epoch 1151, Accuracy: 0.6829268336296082, Accuracies: [0.61 0.98 0.71 0.44]\n",
      "Epoch 1161, Loss: 0.7753532640635967, Accuracy: 0.7134146466851234\n",
      "Epoch 1161, Loss: 0.7753532640635967, Losses: [0.87 0.16 0.88 1.19]\n",
      "Epoch 1161, Accuracy: 0.7134146466851234, Accuracies: [0.73 0.98 0.68 0.46]\n",
      "Epoch 1171, Loss: 0.7365399301052094, Accuracy: 0.7378048747777939\n",
      "Epoch 1171, Loss: 0.7365399301052094, Losses: [0.74 0.16 0.87 1.18]\n",
      "Epoch 1171, Accuracy: 0.7378048747777939, Accuracies: [0.78 0.98 0.68 0.51]\n",
      "Epoch 1181, Loss: 0.7133599147200584, Accuracy: 0.7378048747777939\n",
      "Epoch 1181, Loss: 0.7133599147200584, Losses: [0.67 0.15 0.86 1.17]\n",
      "Epoch 1181, Accuracy: 0.7378048747777939, Accuracies: [0.78 0.98 0.68 0.51]\n",
      "Epoch 1191, Loss: 0.6936563737690449, Accuracy: 0.7439024299383163\n",
      "Epoch 1191, Loss: 0.6936563737690449, Losses: [0.6  0.15 0.86 1.16]\n",
      "Epoch 1191, Accuracy: 0.7439024299383163, Accuracies: [0.78 0.98 0.71 0.51]\n",
      "Epoch 1201, Loss: 0.6773194298148155, Accuracy: 0.75\n",
      "Epoch 1201, Loss: 0.6773194298148155, Losses: [0.55 0.15 0.85 1.16]\n",
      "Epoch 1201, Accuracy: 0.75, Accuracies: [0.8  0.98 0.71 0.51]\n",
      "Epoch 1211, Loss: 0.6638336069881916, Accuracy: 0.75\n",
      "Epoch 1211, Loss: 0.6638336069881916, Losses: [0.5  0.15 0.84 1.15]\n",
      "Epoch 1211, Accuracy: 0.75, Accuracies: [0.8  0.98 0.71 0.51]\n",
      "Epoch 1221, Loss: 0.6518864780664444, Accuracy: 0.75\n",
      "Epoch 1221, Loss: 0.6518864780664444, Losses: [0.47 0.15 0.84 1.15]\n",
      "Epoch 1221, Accuracy: 0.75, Accuracies: [0.8  0.98 0.71 0.51]\n",
      "Epoch 1231, Loss: 0.6421196796000004, Accuracy: 0.7560975700616837\n",
      "Epoch 1231, Loss: 0.6421196796000004, Losses: [0.44 0.15 0.83 1.14]\n",
      "Epoch 1231, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.73 0.51]\n",
      "Epoch 1241, Loss: 0.6336843967437744, Accuracy: 0.7560975700616837\n",
      "Epoch 1241, Loss: 0.6336843967437744, Losses: [0.42 0.14 0.83 1.14]\n",
      "Epoch 1241, Accuracy: 0.7560975700616837, Accuracies: [0.8  0.98 0.73 0.51]\n",
      "Epoch 1251, Loss: 0.6258940100669861, Accuracy: 0.7682926952838898\n",
      "Epoch 1251, Loss: 0.6258940100669861, Losses: [0.4  0.14 0.82 1.14]\n",
      "Epoch 1251, Accuracy: 0.7682926952838898, Accuracies: [0.83 0.98 0.73 0.54]\n",
      "Epoch 1261, Loss: 0.6185658164322376, Accuracy: 0.7743902653455734\n",
      "Epoch 1261, Loss: 0.6185658164322376, Losses: [0.38 0.14 0.82 1.13]\n",
      "Epoch 1261, Accuracy: 0.7743902653455734, Accuracies: [0.85 0.98 0.73 0.54]\n",
      "Epoch 1271, Loss: 0.6116307154297829, Accuracy: 0.7743902653455734\n",
      "Epoch 1271, Loss: 0.6116307154297829, Losses: [0.37 0.13 0.82 1.13]\n",
      "Epoch 1271, Accuracy: 0.7743902653455734, Accuracies: [0.85 0.98 0.73 0.54]\n",
      "Epoch 1281, Loss: 0.6053751967847347, Accuracy: 0.7865853756666183\n",
      "Epoch 1281, Loss: 0.6053751967847347, Losses: [0.35 0.13 0.81 1.13]\n",
      "Epoch 1281, Accuracy: 0.7865853756666183, Accuracies: [0.88 0.98 0.73 0.56]\n",
      "Epoch 1291, Loss: 0.598565187305212, Accuracy: 0.7804878205060959\n",
      "Epoch 1291, Loss: 0.598565187305212, Losses: [0.34 0.13 0.81 1.12]\n",
      "Epoch 1291, Accuracy: 0.7804878205060959, Accuracies: [0.88 0.98 0.73 0.54]\n",
      "Epoch 1301, Loss: 0.5922223404049873, Accuracy: 0.7865853756666183\n",
      "Epoch 1301, Loss: 0.5922223404049873, Losses: [0.32 0.13 0.8  1.12]\n",
      "Epoch 1301, Accuracy: 0.7865853756666183, Accuracies: [0.88 0.98 0.73 0.56]\n",
      "Epoch 1311, Loss: 0.5851921178400517, Accuracy: 0.7865853756666183\n",
      "Epoch 1311, Loss: 0.5851921178400517, Losses: [0.3  0.13 0.8  1.12]\n",
      "Epoch 1311, Accuracy: 0.7865853756666183, Accuracies: [0.9  0.98 0.73 0.54]\n",
      "Epoch 1321, Loss: 0.5781563930213451, Accuracy: 0.792682945728302\n",
      "Epoch 1321, Loss: 0.5781563930213451, Losses: [0.28 0.13 0.79 1.11]\n",
      "Epoch 1321, Accuracy: 0.792682945728302, Accuracies: [0.93 0.98 0.73 0.54]\n",
      "Epoch 1331, Loss: 0.5712407603859901, Accuracy: 0.792682945728302\n",
      "Epoch 1331, Loss: 0.5712407603859901, Losses: [0.27 0.12 0.79 1.11]\n",
      "Epoch 1331, Accuracy: 0.792682945728302, Accuracies: [0.93 0.98 0.73 0.54]\n",
      "Epoch 1341, Loss: 0.5648636817932129, Accuracy: 0.7987805008888245\n",
      "Epoch 1341, Loss: 0.5648636817932129, Losses: [0.25 0.12 0.78 1.1 ]\n",
      "Epoch 1341, Accuracy: 0.7987805008888245, Accuracies: [0.95 0.98 0.73 0.54]\n",
      "Epoch 1351, Loss: 0.5587854497134686, Accuracy: 0.8048780560493469\n",
      "Epoch 1351, Loss: 0.5587854497134686, Losses: [0.24 0.12 0.77 1.1 ]\n",
      "Epoch 1351, Accuracy: 0.8048780560493469, Accuracies: [0.95 0.98 0.73 0.56]\n",
      "Epoch 1361, Loss: 0.5528431870043278, Accuracy: 0.8109756261110306\n",
      "Epoch 1361, Loss: 0.5528431870043278, Losses: [0.22 0.12 0.77 1.1 ]\n",
      "Epoch 1361, Accuracy: 0.8109756261110306, Accuracies: [0.98 0.98 0.73 0.56]\n",
      "Epoch 1371, Loss: 0.5474223773926497, Accuracy: 0.8048780709505081\n",
      "Epoch 1371, Loss: 0.5474223773926497, Losses: [0.21 0.12 0.76 1.09]\n",
      "Epoch 1371, Accuracy: 0.8048780709505081, Accuracies: [0.98 0.98 0.73 0.54]\n",
      "Epoch 1381, Loss: 0.5420408435165882, Accuracy: 0.8109756261110306\n",
      "Epoch 1381, Loss: 0.5420408435165882, Losses: [0.2  0.12 0.76 1.09]\n",
      "Epoch 1381, Accuracy: 0.8109756261110306, Accuracies: [0.98 0.98 0.73 0.56]\n",
      "Epoch 1391, Loss: 0.5369932781904936, Accuracy: 0.8109756261110306\n",
      "Epoch 1391, Loss: 0.5369932781904936, Losses: [0.19 0.12 0.75 1.09]\n",
      "Epoch 1391, Accuracy: 0.8109756261110306, Accuracies: [0.98 0.98 0.73 0.56]\n",
      "Epoch 1401, Loss: 0.5322958268225193, Accuracy: 0.8048780709505081\n",
      "Epoch 1401, Loss: 0.5322958268225193, Losses: [0.18 0.12 0.74 1.09]\n",
      "Epoch 1401, Accuracy: 0.8048780709505081, Accuracies: [0.98 0.98 0.73 0.54]\n",
      "Epoch 1411, Loss: 0.5272194538265467, Accuracy: 0.8048780709505081\n",
      "Epoch 1411, Loss: 0.5272194538265467, Losses: [0.17 0.12 0.74 1.08]\n",
      "Epoch 1411, Accuracy: 0.8048780709505081, Accuracies: [0.98 0.98 0.73 0.54]\n",
      "Epoch 1421, Loss: 0.522797554731369, Accuracy: 0.8109756261110306\n",
      "Epoch 1421, Loss: 0.522797554731369, Losses: [0.17 0.12 0.73 1.08]\n",
      "Epoch 1421, Accuracy: 0.8109756261110306, Accuracies: [0.98 0.98 0.73 0.56]\n",
      "Epoch 1431, Loss: 0.5181647222489119, Accuracy: 0.817073181271553\n",
      "Epoch 1431, Loss: 0.5181647222489119, Losses: [0.16 0.12 0.72 1.08]\n",
      "Epoch 1431, Accuracy: 0.817073181271553, Accuracies: [1.   0.98 0.73 0.56]\n",
      "Epoch 1441, Loss: 0.5135469101369381, Accuracy: 0.8231707364320755\n",
      "Epoch 1441, Loss: 0.5135469101369381, Losses: [0.15 0.12 0.71 1.07]\n",
      "Epoch 1441, Accuracy: 0.8231707364320755, Accuracies: [1.   0.98 0.76 0.56]\n",
      "Epoch 1451, Loss: 0.5090850908309221, Accuracy: 0.8231707364320755\n",
      "Epoch 1451, Loss: 0.5090850908309221, Losses: [0.14 0.12 0.71 1.07]\n",
      "Epoch 1451, Accuracy: 0.8231707364320755, Accuracies: [1.   0.98 0.76 0.56]\n",
      "Epoch 1461, Loss: 0.5043014232069254, Accuracy: 0.8231707364320755\n",
      "Epoch 1461, Loss: 0.5043014232069254, Losses: [0.13 0.11 0.7  1.07]\n",
      "Epoch 1461, Accuracy: 0.8231707364320755, Accuracies: [1.   0.98 0.76 0.56]\n",
      "Epoch 1471, Loss: 0.5030276514589787, Accuracy: 0.8231707364320755\n",
      "Epoch 1471, Loss: 0.5030276514589787, Losses: [0.14 0.11 0.69 1.06]\n",
      "Epoch 1471, Accuracy: 0.8231707364320755, Accuracies: [1.   0.98 0.76 0.56]\n",
      "Epoch 1481, Loss: 0.496051425114274, Accuracy: 0.8231707364320755\n",
      "Epoch 1481, Loss: 0.496051425114274, Losses: [0.12 0.11 0.69 1.06]\n",
      "Epoch 1481, Accuracy: 0.8231707364320755, Accuracies: [1.   0.98 0.78 0.54]\n",
      "Epoch 1491, Loss: 0.4909362532198429, Accuracy: 0.829268291592598\n",
      "Epoch 1491, Loss: 0.4909362532198429, Losses: [0.12 0.11 0.67 1.06]\n",
      "Epoch 1491, Accuracy: 0.829268291592598, Accuracies: [1.   0.98 0.78 0.56]\n",
      "Epoch 1501, Loss: 0.48671935498714447, Accuracy: 0.829268291592598\n",
      "Epoch 1501, Loss: 0.48671935498714447, Losses: [0.11 0.11 0.67 1.05]\n",
      "Epoch 1501, Accuracy: 0.829268291592598, Accuracies: [1.   0.98 0.78 0.56]\n",
      "Epoch 1511, Loss: 0.48242479003965855, Accuracy: 0.829268291592598\n",
      "Epoch 1511, Loss: 0.48242479003965855, Losses: [0.11 0.11 0.66 1.05]\n",
      "Epoch 1511, Accuracy: 0.829268291592598, Accuracies: [1.   0.98 0.78 0.56]\n",
      "Epoch 1521, Loss: 0.4784857723861933, Accuracy: 0.829268291592598\n",
      "Epoch 1521, Loss: 0.4784857723861933, Losses: [0.1  0.11 0.65 1.05]\n",
      "Epoch 1521, Accuracy: 0.829268291592598, Accuracies: [1.   0.98 0.78 0.56]\n",
      "Epoch 1531, Loss: 0.47436021640896797, Accuracy: 0.8414634168148041\n",
      "Epoch 1531, Loss: 0.47436021640896797, Losses: [0.1  0.11 0.65 1.04]\n",
      "Epoch 1531, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.8  0.59]\n",
      "Epoch 1541, Loss: 0.47047937847673893, Accuracy: 0.8414634168148041\n",
      "Epoch 1541, Loss: 0.47047937847673893, Losses: [0.09 0.11 0.64 1.04]\n",
      "Epoch 1541, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.8  0.59]\n",
      "Epoch 1551, Loss: 0.4668510276824236, Accuracy: 0.8475609868764877\n",
      "Epoch 1551, Loss: 0.4668510276824236, Losses: [0.09 0.11 0.63 1.03]\n",
      "Epoch 1551, Accuracy: 0.8475609868764877, Accuracies: [1.   0.98 0.8  0.61]\n",
      "Epoch 1561, Loss: 0.4631620515137911, Accuracy: 0.8414634168148041\n",
      "Epoch 1561, Loss: 0.4631620515137911, Losses: [0.09 0.11 0.62 1.03]\n",
      "Epoch 1561, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.8  0.59]\n",
      "Epoch 1571, Loss: 0.45958450995385647, Accuracy: 0.8414634168148041\n",
      "Epoch 1571, Loss: 0.45958450995385647, Losses: [0.08 0.11 0.62 1.03]\n",
      "Epoch 1571, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.8  0.59]\n",
      "Epoch 1581, Loss: 0.4563786443322897, Accuracy: 0.8475609719753265\n",
      "Epoch 1581, Loss: 0.4563786443322897, Losses: [0.08 0.11 0.61 1.02]\n",
      "Epoch 1581, Accuracy: 0.8475609719753265, Accuracies: [1.   0.98 0.83 0.59]\n",
      "Epoch 1591, Loss: 0.4530636053532362, Accuracy: 0.8475609719753265\n",
      "Epoch 1591, Loss: 0.4530636053532362, Losses: [0.08 0.11 0.61 1.02]\n",
      "Epoch 1591, Accuracy: 0.8475609719753265, Accuracies: [1.   0.98 0.83 0.59]\n",
      "Epoch 1601, Loss: 0.4539812710136175, Accuracy: 0.8414634317159653\n",
      "Epoch 1601, Loss: 0.4539812710136175, Losses: [0.08 0.11 0.62 1.01]\n",
      "Epoch 1601, Accuracy: 0.8414634317159653, Accuracies: [1.   0.98 0.85 0.54]\n",
      "Epoch 1611, Loss: 0.4500057026743889, Accuracy: 0.8292683064937592\n",
      "Epoch 1611, Loss: 0.4500057026743889, Losses: [0.07 0.11 0.61 1.01]\n",
      "Epoch 1611, Accuracy: 0.8292683064937592, Accuracies: [1.   0.98 0.8  0.54]\n",
      "Epoch 1621, Loss: 0.44494176283478737, Accuracy: 0.8475609719753265\n",
      "Epoch 1621, Loss: 0.44494176283478737, Losses: [0.07 0.11 0.6  1.01]\n",
      "Epoch 1621, Accuracy: 0.8475609719753265, Accuracies: [1.   0.98 0.83 0.59]\n",
      "Epoch 1631, Loss: 0.4409803431481123, Accuracy: 0.8475609719753265\n",
      "Epoch 1631, Loss: 0.4409803431481123, Losses: [0.07 0.11 0.59 1.  ]\n",
      "Epoch 1631, Accuracy: 0.8475609719753265, Accuracies: [1.   0.98 0.83 0.59]\n",
      "Epoch 1641, Loss: 0.43791540153324604, Accuracy: 0.8536585420370102\n",
      "Epoch 1641, Loss: 0.43791540153324604, Losses: [0.07 0.1  0.59 0.99]\n",
      "Epoch 1641, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.83 0.61]\n",
      "Epoch 1651, Loss: 0.4349580183625221, Accuracy: 0.8536585420370102\n",
      "Epoch 1651, Loss: 0.4349580183625221, Losses: [0.06 0.1  0.58 0.99]\n",
      "Epoch 1651, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.83 0.61]\n",
      "Epoch 1661, Loss: 0.43301925994455814, Accuracy: 0.8353658616542816\n",
      "Epoch 1661, Loss: 0.43301925994455814, Losses: [0.06 0.1  0.58 0.98]\n",
      "Epoch 1661, Accuracy: 0.8353658616542816, Accuracies: [1.   0.98 0.8  0.56]\n",
      "Epoch 1671, Loss: 0.43100603111088276, Accuracy: 0.8475609719753265\n",
      "Epoch 1671, Loss: 0.43100603111088276, Losses: [0.06 0.1  0.58 0.98]\n",
      "Epoch 1671, Accuracy: 0.8475609719753265, Accuracies: [1.   0.98 0.83 0.59]\n",
      "Epoch 1681, Loss: 0.4268525466322899, Accuracy: 0.8597561120986938\n",
      "Epoch 1681, Loss: 0.4268525466322899, Losses: [0.06 0.1  0.58 0.97]\n",
      "Epoch 1681, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.85 0.61]\n",
      "Epoch 1691, Loss: 0.4234424773603678, Accuracy: 0.8536585420370102\n",
      "Epoch 1691, Loss: 0.4234424773603678, Losses: [0.06 0.1  0.57 0.97]\n",
      "Epoch 1691, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.83 0.61]\n",
      "Epoch 1701, Loss: 0.42050490714609623, Accuracy: 0.8536585420370102\n",
      "Epoch 1701, Loss: 0.42050490714609623, Losses: [0.06 0.1  0.57 0.96]\n",
      "Epoch 1701, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.83 0.61]\n",
      "Epoch 1711, Loss: 0.41797683387994766, Accuracy: 0.8597561120986938\n",
      "Epoch 1711, Loss: 0.41797683387994766, Losses: [0.05 0.1  0.56 0.95]\n",
      "Epoch 1711, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.85 0.61]\n",
      "Epoch 1721, Loss: 0.41694314777851105, Accuracy: 0.8597561120986938\n",
      "Epoch 1721, Loss: 0.41694314777851105, Losses: [0.05 0.1  0.56 0.95]\n",
      "Epoch 1721, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.85 0.61]\n",
      "Epoch 1731, Loss: 0.43051479663699865, Accuracy: 0.8414634168148041\n",
      "Epoch 1731, Loss: 0.43051479663699865, Losses: [0.06 0.1  0.6  0.95]\n",
      "Epoch 1731, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.8  0.59]\n",
      "Epoch 1741, Loss: 0.42397213634103537, Accuracy: 0.8475609868764877\n",
      "Epoch 1741, Loss: 0.42397213634103537, Losses: [0.05 0.1  0.56 0.98]\n",
      "Epoch 1741, Accuracy: 0.8475609868764877, Accuracies: [1.   0.98 0.85 0.56]\n",
      "Epoch 1751, Loss: 0.4139124481007457, Accuracy: 0.8597561120986938\n",
      "Epoch 1751, Loss: 0.4139124481007457, Losses: [0.05 0.1  0.56 0.95]\n",
      "Epoch 1751, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.85 0.61]\n",
      "Epoch 1761, Loss: 0.4052636055275798, Accuracy: 0.8658536672592163\n",
      "Epoch 1761, Loss: 0.4052636055275798, Losses: [0.05 0.1  0.54 0.93]\n",
      "Epoch 1761, Accuracy: 0.8658536672592163, Accuracies: [1.   0.98 0.88 0.61]\n",
      "Epoch 1771, Loss: 0.40181458555161953, Accuracy: 0.8536585420370102\n",
      "Epoch 1771, Loss: 0.40181458555161953, Losses: [0.05 0.1  0.54 0.92]\n",
      "Epoch 1771, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.85 0.59]\n",
      "Epoch 1781, Loss: 0.39889046270400286, Accuracy: 0.8597561120986938\n",
      "Epoch 1781, Loss: 0.39889046270400286, Losses: [0.05 0.1  0.54 0.92]\n",
      "Epoch 1781, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.85 0.61]\n",
      "Epoch 1791, Loss: 0.4004938527941704, Accuracy: 0.8719512224197388\n",
      "Epoch 1791, Loss: 0.4004938527941704, Losses: [0.04 0.1  0.54 0.92]\n",
      "Epoch 1791, Accuracy: 0.8719512224197388, Accuracies: [1.   0.98 0.88 0.63]\n",
      "Epoch 1801, Loss: 0.39425044786185026, Accuracy: 0.8536585420370102\n",
      "Epoch 1801, Loss: 0.39425044786185026, Losses: [0.04 0.1  0.53 0.91]\n",
      "Epoch 1801, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.85 0.59]\n",
      "Epoch 1811, Loss: 0.39369416050612926, Accuracy: 0.8780487775802612\n",
      "Epoch 1811, Loss: 0.39369416050612926, Losses: [0.04 0.1  0.53 0.9 ]\n",
      "Epoch 1811, Accuracy: 0.8780487775802612, Accuracies: [1.   0.98 0.9  0.63]\n",
      "Epoch 1821, Loss: 0.3899112641811371, Accuracy: 0.8780487775802612\n",
      "Epoch 1821, Loss: 0.3899112641811371, Losses: [0.04 0.1  0.53 0.9 ]\n",
      "Epoch 1821, Accuracy: 0.8780487775802612, Accuracies: [1.   0.98 0.9  0.63]\n",
      "Epoch 1831, Loss: 0.4165988117456436, Accuracy: 0.8292683064937592\n",
      "Epoch 1831, Loss: 0.4165988117456436, Losses: [0.09 0.1  0.53 0.95]\n",
      "Epoch 1831, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.83 0.54]\n",
      "Epoch 1841, Loss: 0.3884196151047945, Accuracy: 0.8658536672592163\n",
      "Epoch 1841, Loss: 0.3884196151047945, Losses: [0.05 0.1  0.52 0.89]\n",
      "Epoch 1841, Accuracy: 0.8658536672592163, Accuracies: [1.   0.98 0.88 0.61]\n",
      "Epoch 1851, Loss: 0.3826973019167781, Accuracy: 0.8658536672592163\n",
      "Epoch 1851, Loss: 0.3826973019167781, Losses: [0.04 0.1  0.51 0.88]\n",
      "Epoch 1851, Accuracy: 0.8658536672592163, Accuracies: [1.   0.98 0.85 0.63]\n",
      "Epoch 1861, Loss: 0.37991731986403465, Accuracy: 0.8719512224197388\n",
      "Epoch 1861, Loss: 0.37991731986403465, Losses: [0.04 0.09 0.51 0.87]\n",
      "Epoch 1861, Accuracy: 0.8719512224197388, Accuracies: [1.   0.98 0.88 0.63]\n",
      "Epoch 1871, Loss: 0.37775697745382786, Accuracy: 0.8780487924814224\n",
      "Epoch 1871, Loss: 0.37775697745382786, Losses: [0.04 0.09 0.51 0.87]\n",
      "Epoch 1871, Accuracy: 0.8780487924814224, Accuracies: [1.   0.98 0.88 0.66]\n",
      "Epoch 1881, Loss: 0.37372616305947304, Accuracy: 0.8780487924814224\n",
      "Epoch 1881, Loss: 0.37372616305947304, Losses: [0.04 0.09 0.5  0.86]\n",
      "Epoch 1881, Accuracy: 0.8780487924814224, Accuracies: [1.   0.98 0.85 0.68]\n",
      "Epoch 1891, Loss: 0.3722889730706811, Accuracy: 0.8780487924814224\n",
      "Epoch 1891, Loss: 0.3722889730706811, Losses: [0.04 0.09 0.5  0.86]\n",
      "Epoch 1891, Accuracy: 0.8780487924814224, Accuracies: [1.   0.98 0.88 0.66]\n",
      "Epoch 1901, Loss: 0.3702747132629156, Accuracy: 0.8780487924814224\n",
      "Epoch 1901, Loss: 0.3702747132629156, Losses: [0.04 0.09 0.5  0.85]\n",
      "Epoch 1901, Accuracy: 0.8780487924814224, Accuracies: [1.   0.98 0.88 0.66]\n",
      "Epoch 1911, Loss: 0.38365456089377403, Accuracy: 0.8719512373209\n",
      "Epoch 1911, Loss: 0.38365456089377403, Losses: [0.04 0.09 0.52 0.89]\n",
      "Epoch 1911, Accuracy: 0.8719512373209, Accuracies: [1.   0.98 0.85 0.66]\n",
      "Epoch 1921, Loss: 0.3837545122951269, Accuracy: 0.8719512373209\n",
      "Epoch 1921, Loss: 0.3837545122951269, Losses: [0.05 0.09 0.55 0.85]\n",
      "Epoch 1921, Accuracy: 0.8719512373209, Accuracies: [1.   0.98 0.85 0.66]\n",
      "Epoch 1931, Loss: 0.3932408671826124, Accuracy: 0.8475609868764877\n",
      "Epoch 1931, Loss: 0.3932408671826124, Losses: [0.07 0.1  0.53 0.87]\n",
      "Epoch 1931, Accuracy: 0.8475609868764877, Accuracies: [1.   0.98 0.8  0.61]\n",
      "Epoch 1941, Loss: 0.36384177953004837, Accuracy: 0.8780487924814224\n",
      "Epoch 1941, Loss: 0.36384177953004837, Losses: [0.04 0.09 0.49 0.84]\n",
      "Epoch 1941, Accuracy: 0.8780487924814224, Accuracies: [1.   0.98 0.85 0.68]\n",
      "Epoch 1951, Loss: 0.35918991453945637, Accuracy: 0.8841463476419449\n",
      "Epoch 1951, Loss: 0.35918991453945637, Losses: [0.03 0.09 0.48 0.83]\n",
      "Epoch 1951, Accuracy: 0.8841463476419449, Accuracies: [1.   0.98 0.88 0.68]\n",
      "Epoch 1961, Loss: 0.3559457529336214, Accuracy: 0.8902439028024673\n",
      "Epoch 1961, Loss: 0.3559457529336214, Losses: [0.03 0.09 0.48 0.82]\n",
      "Epoch 1961, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 1971, Loss: 0.35328713711351156, Accuracy: 0.8963414579629898\n",
      "Epoch 1971, Loss: 0.35328713711351156, Losses: [0.03 0.09 0.48 0.82]\n",
      "Epoch 1971, Accuracy: 0.8963414579629898, Accuracies: [1.   0.98 0.9  0.71]\n",
      "Epoch 1981, Loss: 0.3505561798810959, Accuracy: 0.9024390280246735\n",
      "Epoch 1981, Loss: 0.3505561798810959, Losses: [0.03 0.09 0.47 0.81]\n",
      "Epoch 1981, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.9  0.73]\n",
      "Epoch 1991, Loss: 0.3484436636790633, Accuracy: 0.896341472864151\n",
      "Epoch 1991, Loss: 0.3484436636790633, Losses: [0.03 0.09 0.47 0.8 ]\n",
      "Epoch 1991, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.88 0.73]\n",
      "Epoch 2001, Loss: 0.3501805365085602, Accuracy: 0.8902439028024673\n",
      "Epoch 2001, Loss: 0.3501805365085602, Losses: [0.03 0.09 0.48 0.8 ]\n",
      "Epoch 2001, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 2011, Loss: 0.34435503277927637, Accuracy: 0.8902439028024673\n",
      "Epoch 2011, Loss: 0.34435503277927637, Losses: [0.03 0.09 0.47 0.79]\n",
      "Epoch 2011, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 2021, Loss: 0.3542859489098191, Accuracy: 0.8841463476419449\n",
      "Epoch 2021, Loss: 0.3542859489098191, Losses: [0.06 0.09 0.47 0.8 ]\n",
      "Epoch 2021, Accuracy: 0.8841463476419449, Accuracies: [1.   0.98 0.88 0.68]\n",
      "Epoch 2031, Loss: 0.3996368292719126, Accuracy: 0.8597560971975327\n",
      "Epoch 2031, Loss: 0.3996368292719126, Losses: [0.13 0.09 0.59 0.79]\n",
      "Epoch 2031, Accuracy: 0.8597560971975327, Accuracies: [0.98 0.98 0.78 0.71]\n",
      "Epoch 2041, Loss: 0.3429217394441366, Accuracy: 0.896341472864151\n",
      "Epoch 2041, Loss: 0.3429217394441366, Losses: [0.03 0.09 0.46 0.79]\n",
      "Epoch 2041, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.88 0.73]\n",
      "Epoch 2051, Loss: 0.33591947378590703, Accuracy: 0.8902439028024673\n",
      "Epoch 2051, Loss: 0.33591947378590703, Losses: [0.03 0.09 0.45 0.77]\n",
      "Epoch 2051, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 2061, Loss: 0.33421570248901844, Accuracy: 0.9024390280246735\n",
      "Epoch 2061, Loss: 0.33421570248901844, Losses: [0.03 0.09 0.45 0.77]\n",
      "Epoch 2061, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.9  0.73]\n",
      "Epoch 2071, Loss: 0.3388792993500829, Accuracy: 0.8902439028024673\n",
      "Epoch 2071, Loss: 0.3388792993500829, Losses: [0.03 0.09 0.48 0.76]\n",
      "Epoch 2071, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 2081, Loss: 0.3318502800539136, Accuracy: 0.8902439028024673\n",
      "Epoch 2081, Loss: 0.3318502800539136, Losses: [0.03 0.09 0.44 0.76]\n",
      "Epoch 2081, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.88 0.71]\n",
      "Epoch 2091, Loss: 0.3262884858995676, Accuracy: 0.9146341532468796\n",
      "Epoch 2091, Loss: 0.3262884858995676, Losses: [0.02 0.09 0.44 0.75]\n",
      "Epoch 2091, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2101, Loss: 0.32373614935204387, Accuracy: 0.9024390280246735\n",
      "Epoch 2101, Loss: 0.32373614935204387, Losses: [0.03 0.09 0.44 0.74]\n",
      "Epoch 2101, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.93 0.71]\n",
      "Epoch 2111, Loss: 0.32598145958036184, Accuracy: 0.8841463476419449\n",
      "Epoch 2111, Loss: 0.32598145958036184, Losses: [0.03 0.09 0.44 0.75]\n",
      "Epoch 2111, Accuracy: 0.8841463476419449, Accuracies: [1.   0.98 0.88 0.68]\n",
      "Epoch 2121, Loss: 0.3272132654674351, Accuracy: 0.9024390280246735\n",
      "Epoch 2121, Loss: 0.3272132654674351, Losses: [0.02 0.09 0.45 0.75]\n",
      "Epoch 2121, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.9  0.73]\n",
      "Epoch 2131, Loss: 0.3161446452140808, Accuracy: 0.9024390280246735\n",
      "Epoch 2131, Loss: 0.3161446452140808, Losses: [0.02 0.09 0.43 0.72]\n",
      "Epoch 2131, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.9  0.73]\n",
      "Epoch 2141, Loss: 0.3131026988849044, Accuracy: 0.9146341532468796\n",
      "Epoch 2141, Loss: 0.3131026988849044, Losses: [0.02 0.09 0.42 0.72]\n",
      "Epoch 2141, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2151, Loss: 0.3112283465452492, Accuracy: 0.9146341532468796\n",
      "Epoch 2151, Loss: 0.3112283465452492, Losses: [0.02 0.09 0.42 0.71]\n",
      "Epoch 2151, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2161, Loss: 0.30902615236118436, Accuracy: 0.920731708407402\n",
      "Epoch 2161, Loss: 0.30902615236118436, Losses: [0.02 0.09 0.42 0.71]\n",
      "Epoch 2161, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.93 0.78]\n",
      "Epoch 2171, Loss: 0.31356408540159464, Accuracy: 0.9146341532468796\n",
      "Epoch 2171, Loss: 0.31356408540159464, Losses: [0.03 0.09 0.42 0.72]\n",
      "Epoch 2171, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2181, Loss: 0.30639720894396305, Accuracy: 0.9085365980863571\n",
      "Epoch 2181, Loss: 0.30639720894396305, Losses: [0.02 0.09 0.42 0.7 ]\n",
      "Epoch 2181, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.93 0.73]\n",
      "Epoch 2191, Loss: 0.30045576207339764, Accuracy: 0.9146341383457184\n",
      "Epoch 2191, Loss: 0.30045576207339764, Losses: [0.02 0.09 0.41 0.69]\n",
      "Epoch 2191, Accuracy: 0.9146341383457184, Accuracies: [1.   0.98 0.9  0.78]\n",
      "Epoch 2201, Loss: 0.2974406247958541, Accuracy: 0.9146341532468796\n",
      "Epoch 2201, Loss: 0.2974406247958541, Losses: [0.02 0.09 0.4  0.68]\n",
      "Epoch 2201, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2211, Loss: 0.29552297573536634, Accuracy: 0.920731708407402\n",
      "Epoch 2211, Loss: 0.29552297573536634, Losses: [0.02 0.08 0.4  0.68]\n",
      "Epoch 2211, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.93 0.78]\n",
      "Epoch 2221, Loss: 0.34481143206357956, Accuracy: 0.8963414579629898\n",
      "Epoch 2221, Loss: 0.34481143206357956, Losses: [0.02 0.1  0.55 0.71]\n",
      "Epoch 2221, Accuracy: 0.8963414579629898, Accuracies: [1.   0.98 0.83 0.78]\n",
      "Epoch 2231, Loss: 0.4249250292778015, Accuracy: 0.8536585420370102\n",
      "Epoch 2231, Loss: 0.4249250292778015, Losses: [0.37 0.09 0.53 0.71]\n",
      "Epoch 2231, Accuracy: 0.8536585420370102, Accuracies: [0.9  0.98 0.8  0.73]\n",
      "Epoch 2241, Loss: 0.3007806334644556, Accuracy: 0.9146341532468796\n",
      "Epoch 2241, Loss: 0.3007806334644556, Losses: [0.05 0.09 0.4  0.66]\n",
      "Epoch 2241, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.93 0.76]\n",
      "Epoch 2251, Loss: 0.29088278952986, Accuracy: 0.920731708407402\n",
      "Epoch 2251, Loss: 0.29088278952986, Losses: [0.03 0.09 0.39 0.66]\n",
      "Epoch 2251, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.9  0.8 ]\n",
      "Epoch 2261, Loss: 0.28693419601768255, Accuracy: 0.9268292784690857\n",
      "Epoch 2261, Loss: 0.28693419601768255, Losses: [0.03 0.09 0.38 0.65]\n",
      "Epoch 2261, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.93 0.8 ]\n",
      "Epoch 2271, Loss: 0.2839497188106179, Accuracy: 0.9268292784690857\n",
      "Epoch 2271, Loss: 0.2839497188106179, Losses: [0.02 0.09 0.38 0.64]\n",
      "Epoch 2271, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.93 0.8 ]\n",
      "Epoch 2281, Loss: 0.2809477741830051, Accuracy: 0.9329268336296082\n",
      "Epoch 2281, Loss: 0.2809477741830051, Losses: [0.02 0.08 0.38 0.64]\n",
      "Epoch 2281, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.93 0.83]\n",
      "Epoch 2291, Loss: 0.27838142216205597, Accuracy: 0.9390244036912918\n",
      "Epoch 2291, Loss: 0.27838142216205597, Losses: [0.02 0.09 0.38 0.63]\n",
      "Epoch 2291, Accuracy: 0.9390244036912918, Accuracies: [1.   0.98 0.93 0.85]\n",
      "Epoch 2301, Loss: 0.2766393721103668, Accuracy: 0.9451219588518143\n",
      "Epoch 2301, Loss: 0.2766393721103668, Losses: [0.02 0.08 0.38 0.63]\n",
      "Epoch 2301, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.93 0.88]\n",
      "Epoch 2311, Loss: 0.27754389541223645, Accuracy: 0.9329268336296082\n",
      "Epoch 2311, Loss: 0.27754389541223645, Losses: [0.02 0.09 0.37 0.63]\n",
      "Epoch 2311, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.93 0.83]\n",
      "Epoch 2321, Loss: 0.27081537432968616, Accuracy: 0.9451219588518143\n",
      "Epoch 2321, Loss: 0.27081537432968616, Losses: [0.02 0.08 0.37 0.61]\n",
      "Epoch 2321, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.93 0.88]\n",
      "Epoch 2331, Loss: 0.2680763849057257, Accuracy: 0.9451219588518143\n",
      "Epoch 2331, Loss: 0.2680763849057257, Losses: [0.02 0.08 0.36 0.61]\n",
      "Epoch 2331, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.93 0.88]\n",
      "Epoch 2341, Loss: 0.2653350527398288, Accuracy: 0.9451219588518143\n",
      "Epoch 2341, Loss: 0.2653350527398288, Losses: [0.02 0.08 0.36 0.6 ]\n",
      "Epoch 2341, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.93 0.88]\n",
      "Epoch 2351, Loss: 0.2628249730914831, Accuracy: 0.9451219588518143\n",
      "Epoch 2351, Loss: 0.2628249730914831, Losses: [0.02 0.08 0.36 0.6 ]\n",
      "Epoch 2351, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.93 0.88]\n",
      "Epoch 2361, Loss: 0.2774935238994658, Accuracy: 0.9390244036912918\n",
      "Epoch 2361, Loss: 0.2774935238994658, Losses: [0.03 0.09 0.39 0.6 ]\n",
      "Epoch 2361, Accuracy: 0.9390244036912918, Accuracies: [1.   0.98 0.93 0.85]\n",
      "Epoch 2371, Loss: 0.2684584534727037, Accuracy: 0.9329268336296082\n",
      "Epoch 2371, Loss: 0.2684584534727037, Losses: [0.02 0.08 0.36 0.6 ]\n",
      "Epoch 2371, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.9  0.85]\n",
      "Epoch 2381, Loss: 0.2618150310590863, Accuracy: 0.9512195140123367\n",
      "Epoch 2381, Loss: 0.2618150310590863, Losses: [0.02 0.09 0.36 0.58]\n",
      "Epoch 2381, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2391, Loss: 0.2548229889944196, Accuracy: 0.9512195140123367\n",
      "Epoch 2391, Loss: 0.2548229889944196, Losses: [0.02 0.08 0.34 0.58]\n",
      "Epoch 2391, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2401, Loss: 0.25179192423820496, Accuracy: 0.9512195140123367\n",
      "Epoch 2401, Loss: 0.25179192423820496, Losses: [0.02 0.08 0.34 0.57]\n",
      "Epoch 2401, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2411, Loss: 0.24914660677313805, Accuracy: 0.9512195140123367\n",
      "Epoch 2411, Loss: 0.24914660677313805, Losses: [0.02 0.08 0.33 0.56]\n",
      "Epoch 2411, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2421, Loss: 0.24674620619043708, Accuracy: 0.9512195140123367\n",
      "Epoch 2421, Loss: 0.24674620619043708, Losses: [0.02 0.08 0.33 0.56]\n",
      "Epoch 2421, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2431, Loss: 0.24444246548227966, Accuracy: 0.9573170691728592\n",
      "Epoch 2431, Loss: 0.24444246548227966, Losses: [0.01 0.08 0.33 0.55]\n",
      "Epoch 2431, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2441, Loss: 0.2420626066159457, Accuracy: 0.9573170691728592\n",
      "Epoch 2441, Loss: 0.2420626066159457, Losses: [0.01 0.08 0.32 0.55]\n",
      "Epoch 2441, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2451, Loss: 0.23960399581119418, Accuracy: 0.9573170691728592\n",
      "Epoch 2451, Loss: 0.23960399581119418, Losses: [0.01 0.08 0.32 0.54]\n",
      "Epoch 2451, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2461, Loss: 0.23814586037769914, Accuracy: 0.9573170691728592\n",
      "Epoch 2461, Loss: 0.23814586037769914, Losses: [0.02 0.08 0.32 0.54]\n",
      "Epoch 2461, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2471, Loss: 0.23660593782551587, Accuracy: 0.9573170691728592\n",
      "Epoch 2471, Loss: 0.23660593782551587, Losses: [0.01 0.08 0.32 0.53]\n",
      "Epoch 2471, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2481, Loss: 0.2371150585822761, Accuracy: 0.9573170691728592\n",
      "Epoch 2481, Loss: 0.2371150585822761, Losses: [0.02 0.08 0.31 0.53]\n",
      "Epoch 2481, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2491, Loss: 0.23266800679266453, Accuracy: 0.9573170691728592\n",
      "Epoch 2491, Loss: 0.23266800679266453, Losses: [0.02 0.08 0.31 0.52]\n",
      "Epoch 2491, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2501, Loss: 0.2523867175914347, Accuracy: 0.9268292784690857\n",
      "Epoch 2501, Loss: 0.2523867175914347, Losses: [0.01 0.09 0.33 0.57]\n",
      "Epoch 2501, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.93 0.8 ]\n",
      "Epoch 2511, Loss: 0.23913182225078344, Accuracy: 0.9512195140123367\n",
      "Epoch 2511, Loss: 0.23913182225078344, Losses: [0.03 0.08 0.33 0.52]\n",
      "Epoch 2511, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.95 0.88]\n",
      "Epoch 2521, Loss: 0.25153805362060666, Accuracy: 0.9451219588518143\n",
      "Epoch 2521, Loss: 0.25153805362060666, Losses: [0.02 0.08 0.36 0.54]\n",
      "Epoch 2521, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.95 0.85]\n",
      "Epoch 2531, Loss: 0.26542649557814, Accuracy: 0.9268292784690857\n",
      "Epoch 2531, Loss: 0.26542649557814, Losses: [0.02 0.08 0.43 0.53]\n",
      "Epoch 2531, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 2541, Loss: 0.44650351628661156, Accuracy: 0.8231707215309143\n",
      "Epoch 2541, Loss: 0.44650351628661156, Losses: [0.47 0.1  0.55 0.67]\n",
      "Epoch 2541, Accuracy: 0.8231707215309143, Accuracies: [0.78 0.98 0.76 0.78]\n",
      "Epoch 2551, Loss: 0.23731578839942813, Accuracy: 0.9390244036912918\n",
      "Epoch 2551, Loss: 0.23731578839942813, Losses: [0.02 0.09 0.32 0.52]\n",
      "Epoch 2551, Accuracy: 0.9390244036912918, Accuracies: [1.   0.98 0.93 0.85]\n",
      "Epoch 2561, Loss: 0.22701337467879057, Accuracy: 0.9512195140123367\n",
      "Epoch 2561, Loss: 0.22701337467879057, Losses: [0.02 0.08 0.3  0.51]\n",
      "Epoch 2561, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.93 0.9 ]\n",
      "Epoch 2571, Loss: 0.22297750925645232, Accuracy: 0.9573170691728592\n",
      "Epoch 2571, Loss: 0.22297750925645232, Losses: [0.02 0.08 0.29 0.5 ]\n",
      "Epoch 2571, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2581, Loss: 0.2200959143228829, Accuracy: 0.9573170691728592\n",
      "Epoch 2581, Loss: 0.2200959143228829, Losses: [0.02 0.08 0.29 0.49]\n",
      "Epoch 2581, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2591, Loss: 0.21786315203644335, Accuracy: 0.9573170691728592\n",
      "Epoch 2591, Loss: 0.21786315203644335, Losses: [0.01 0.08 0.29 0.49]\n",
      "Epoch 2591, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2601, Loss: 0.21587627986446023, Accuracy: 0.9573170691728592\n",
      "Epoch 2601, Loss: 0.21587627986446023, Losses: [0.01 0.08 0.28 0.48]\n",
      "Epoch 2601, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2611, Loss: 0.21417762991040945, Accuracy: 0.9573170691728592\n",
      "Epoch 2611, Loss: 0.21417762991040945, Losses: [0.01 0.08 0.28 0.48]\n",
      "Epoch 2611, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2621, Loss: 0.21230984688736498, Accuracy: 0.9573170691728592\n",
      "Epoch 2621, Loss: 0.21230984688736498, Losses: [0.01 0.08 0.28 0.48]\n",
      "Epoch 2621, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2631, Loss: 0.2105984336230904, Accuracy: 0.9573170691728592\n",
      "Epoch 2631, Loss: 0.2105984336230904, Losses: [0.01 0.08 0.28 0.47]\n",
      "Epoch 2631, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2641, Loss: 0.20894386828877032, Accuracy: 0.9573170691728592\n",
      "Epoch 2641, Loss: 0.20894386828877032, Losses: [0.01 0.08 0.28 0.47]\n",
      "Epoch 2641, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2651, Loss: 0.20739743625745177, Accuracy: 0.9573170691728592\n",
      "Epoch 2651, Loss: 0.20739743625745177, Losses: [0.01 0.08 0.27 0.46]\n",
      "Epoch 2651, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2661, Loss: 0.20577707537449896, Accuracy: 0.9573170691728592\n",
      "Epoch 2661, Loss: 0.20577707537449896, Losses: [0.01 0.08 0.27 0.46]\n",
      "Epoch 2661, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2671, Loss: 0.20429235673509538, Accuracy: 0.9573170691728592\n",
      "Epoch 2671, Loss: 0.20429235673509538, Losses: [0.01 0.08 0.27 0.46]\n",
      "Epoch 2671, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2681, Loss: 0.202650306513533, Accuracy: 0.9573170691728592\n",
      "Epoch 2681, Loss: 0.202650306513533, Losses: [0.01 0.08 0.27 0.45]\n",
      "Epoch 2681, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2691, Loss: 0.20107204210944474, Accuracy: 0.9573170691728592\n",
      "Epoch 2691, Loss: 0.20107204210944474, Losses: [0.01 0.08 0.27 0.45]\n",
      "Epoch 2691, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2701, Loss: 0.19963615015149117, Accuracy: 0.9573170691728592\n",
      "Epoch 2701, Loss: 0.19963615015149117, Losses: [0.01 0.08 0.26 0.45]\n",
      "Epoch 2701, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2711, Loss: 0.19811119115911424, Accuracy: 0.9573170691728592\n",
      "Epoch 2711, Loss: 0.19811119115911424, Losses: [0.01 0.08 0.26 0.44]\n",
      "Epoch 2711, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2721, Loss: 0.19652303075417876, Accuracy: 0.9573170691728592\n",
      "Epoch 2721, Loss: 0.19652303075417876, Losses: [0.01 0.08 0.26 0.44]\n",
      "Epoch 2721, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2731, Loss: 0.19492524326778948, Accuracy: 0.9573170691728592\n",
      "Epoch 2731, Loss: 0.19492524326778948, Losses: [0.01 0.08 0.26 0.43]\n",
      "Epoch 2731, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2741, Loss: 0.19352298136800528, Accuracy: 0.9573170691728592\n",
      "Epoch 2741, Loss: 0.19352298136800528, Losses: [0.01 0.08 0.26 0.43]\n",
      "Epoch 2741, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2751, Loss: 0.19201548490673304, Accuracy: 0.9573170691728592\n",
      "Epoch 2751, Loss: 0.19201548490673304, Losses: [0.01 0.08 0.25 0.43]\n",
      "Epoch 2751, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2761, Loss: 0.19033108511939645, Accuracy: 0.9573170691728592\n",
      "Epoch 2761, Loss: 0.19033108511939645, Losses: [0.01 0.08 0.25 0.42]\n",
      "Epoch 2761, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2771, Loss: 0.1879257911350578, Accuracy: 0.9573170691728592\n",
      "Epoch 2771, Loss: 0.1879257911350578, Losses: [0.01 0.07 0.25 0.42]\n",
      "Epoch 2771, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2781, Loss: 0.18640176812186837, Accuracy: 0.9573170691728592\n",
      "Epoch 2781, Loss: 0.18640176812186837, Losses: [0.01 0.07 0.25 0.42]\n",
      "Epoch 2781, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2791, Loss: 0.21891825646162033, Accuracy: 0.9573170691728592\n",
      "Epoch 2791, Loss: 0.21891825646162033, Losses: [0.02 0.11 0.3  0.44]\n",
      "Epoch 2791, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.95 0.9 ]\n",
      "Epoch 2801, Loss: 0.18997943960130215, Accuracy: 0.9634146392345428\n",
      "Epoch 2801, Loss: 0.18997943960130215, Losses: [0.01 0.08 0.25 0.42]\n",
      "Epoch 2801, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2811, Loss: 0.18509057257324457, Accuracy: 0.9634146392345428\n",
      "Epoch 2811, Loss: 0.18509057257324457, Losses: [0.01 0.08 0.24 0.41]\n",
      "Epoch 2811, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2821, Loss: 0.18293145578354597, Accuracy: 0.9634146392345428\n",
      "Epoch 2821, Loss: 0.18293145578354597, Losses: [0.01 0.08 0.24 0.41]\n",
      "Epoch 2821, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2831, Loss: 0.18099515489302576, Accuracy: 0.9634146392345428\n",
      "Epoch 2831, Loss: 0.18099515489302576, Losses: [0.01 0.08 0.24 0.4 ]\n",
      "Epoch 2831, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2841, Loss: 0.17918962356634438, Accuracy: 0.9634146392345428\n",
      "Epoch 2841, Loss: 0.17918962356634438, Losses: [0.01 0.08 0.23 0.4 ]\n",
      "Epoch 2841, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2851, Loss: 0.17755169491283596, Accuracy: 0.9634146392345428\n",
      "Epoch 2851, Loss: 0.17755169491283596, Losses: [0.01 0.08 0.23 0.39]\n",
      "Epoch 2851, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.98 0.9 ]\n",
      "Epoch 2861, Loss: 0.17596536059863865, Accuracy: 0.9695122092962265\n",
      "Epoch 2861, Loss: 0.17596536059863865, Losses: [0.01 0.08 0.23 0.39]\n",
      "Epoch 2861, Accuracy: 0.9695122092962265, Accuracies: [1.   0.98 0.98 0.93]\n",
      "Epoch 2871, Loss: 0.17436444363556802, Accuracy: 0.9695122092962265\n",
      "Epoch 2871, Loss: 0.17436444363556802, Losses: [0.01 0.08 0.23 0.39]\n",
      "Epoch 2871, Accuracy: 0.9695122092962265, Accuracies: [1.   0.98 0.98 0.93]\n",
      "Epoch 2881, Loss: 0.17283779755234718, Accuracy: 0.9695122092962265\n",
      "Epoch 2881, Loss: 0.17283779755234718, Losses: [0.01 0.08 0.22 0.38]\n",
      "Epoch 2881, Accuracy: 0.9695122092962265, Accuracies: [1.   0.98 0.98 0.93]\n",
      "Epoch 2891, Loss: 0.1712645273655653, Accuracy: 0.9695122092962265\n",
      "Epoch 2891, Loss: 0.1712645273655653, Losses: [0.01 0.08 0.22 0.38]\n",
      "Epoch 2891, Accuracy: 0.9695122092962265, Accuracies: [1.   0.98 0.98 0.93]\n",
      "Epoch 2901, Loss: 0.16959750675596297, Accuracy: 0.9695122092962265\n",
      "Epoch 2901, Loss: 0.16959750675596297, Losses: [0.01 0.08 0.22 0.37]\n",
      "Epoch 2901, Accuracy: 0.9695122092962265, Accuracies: [1.   0.98 0.98 0.93]\n",
      "Early stopping criteria met\n",
      "Training LSTM...\n",
      "Epoch 1, Loss: 2.0635464787483215, Accuracy: 0.17073170468211174\n",
      "Epoch 1, Loss: 2.0635464787483215, Losses: [2.07 2.07 2.09 2.02]\n",
      "Epoch 1, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.15 0.12 0.22]\n",
      "Epoch 11, Loss: 2.0266985297203064, Accuracy: 0.1768292672932148\n",
      "Epoch 11, Loss: 2.0266985297203064, Losses: [2.04 2.02 2.05 1.99]\n",
      "Epoch 11, Accuracy: 0.1768292672932148, Accuracies: [0.22 0.17 0.15 0.17]\n",
      "Epoch 21, Loss: 1.973751962184906, Accuracy: 0.17073170468211174\n",
      "Epoch 21, Loss: 1.973751962184906, Losses: [2.01 1.96 1.98 1.95]\n",
      "Epoch 21, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 31, Loss: 1.9368807673454285, Accuracy: 0.17073170468211174\n",
      "Epoch 31, Loss: 1.9368807673454285, Losses: [2.01 1.9  1.91 1.92]\n",
      "Epoch 31, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 41, Loss: 1.9155898988246918, Accuracy: 0.19512194767594337\n",
      "Epoch 41, Loss: 1.9155898988246918, Losses: [2.03 1.87 1.87 1.9 ]\n",
      "Epoch 41, Accuracy: 0.19512194767594337, Accuracies: [0.29 0.17 0.15 0.17]\n",
      "Epoch 51, Loss: 1.899929165840149, Accuracy: 0.219512190669775\n",
      "Epoch 51, Loss: 1.899929165840149, Losses: [2.02 1.85 1.85 1.88]\n",
      "Epoch 51, Accuracy: 0.219512190669775, Accuracies: [0.39 0.17 0.15 0.17]\n",
      "Epoch 61, Loss: 1.883946567773819, Accuracy: 0.16463414579629898\n",
      "Epoch 61, Loss: 1.883946567773819, Losses: [2.01 1.83 1.83 1.87]\n",
      "Epoch 61, Accuracy: 0.16463414579629898, Accuracies: [0.2  0.17 0.12 0.17]\n",
      "Epoch 71, Loss: 1.8644132018089294, Accuracy: 0.19512194767594337\n",
      "Epoch 71, Loss: 1.8644132018089294, Losses: [1.98 1.8  1.82 1.86]\n",
      "Epoch 71, Accuracy: 0.19512194767594337, Accuracies: [0.2  0.2  0.17 0.22]\n",
      "Epoch 81, Loss: 1.838218629360199, Accuracy: 0.25609755516052246\n",
      "Epoch 81, Loss: 1.838218629360199, Losses: [1.95 1.77 1.8  1.84]\n",
      "Epoch 81, Accuracy: 0.25609755516052246, Accuracies: [0.2  0.34 0.2  0.29]\n",
      "Epoch 91, Loss: 1.8055651485919952, Accuracy: 0.2621951177716255\n",
      "Epoch 91, Loss: 1.8055651485919952, Losses: [1.91 1.72 1.77 1.83]\n",
      "Epoch 91, Accuracy: 0.2621951177716255, Accuracies: [0.2  0.34 0.22 0.29]\n",
      "Epoch 101, Loss: 1.7649042010307312, Accuracy: 0.3231707289814949\n",
      "Epoch 101, Loss: 1.7649042010307312, Losses: [1.85 1.67 1.73 1.81]\n",
      "Epoch 101, Accuracy: 0.3231707289814949, Accuracies: [0.22 0.37 0.39 0.32]\n",
      "Epoch 111, Loss: 1.7192752957344055, Accuracy: 0.3414634093642235\n",
      "Epoch 111, Loss: 1.7192752957344055, Losses: [1.79 1.61 1.69 1.79]\n",
      "Epoch 111, Accuracy: 0.3414634093642235, Accuracies: [0.24 0.51 0.32 0.29]\n",
      "Epoch 121, Loss: 1.6760395169258118, Accuracy: 0.3719512149691582\n",
      "Epoch 121, Loss: 1.6760395169258118, Losses: [1.74 1.54 1.65 1.77]\n",
      "Epoch 121, Accuracy: 0.3719512149691582, Accuracies: [0.32 0.51 0.34 0.32]\n",
      "Epoch 131, Loss: 1.6370607316493988, Accuracy: 0.4390243962407112\n",
      "Epoch 131, Loss: 1.6370607316493988, Losses: [1.68 1.49 1.62 1.75]\n",
      "Epoch 131, Accuracy: 0.4390243962407112, Accuracies: [0.39 0.66 0.37 0.34]\n",
      "Epoch 141, Loss: 1.6056668758392334, Accuracy: 0.4390243962407112\n",
      "Epoch 141, Loss: 1.6056668758392334, Losses: [1.63 1.45 1.6  1.74]\n",
      "Epoch 141, Accuracy: 0.4390243962407112, Accuracies: [0.39 0.66 0.34 0.37]\n",
      "Epoch 151, Loss: 1.5707676708698273, Accuracy: 0.46341463923454285\n",
      "Epoch 151, Loss: 1.5707676708698273, Losses: [1.59 1.4  1.57 1.73]\n",
      "Epoch 151, Accuracy: 0.46341463923454285, Accuracies: [0.44 0.66 0.37 0.39]\n",
      "Epoch 161, Loss: 1.54727903008461, Accuracy: 0.4451219439506531\n",
      "Epoch 161, Loss: 1.54727903008461, Losses: [1.55 1.36 1.56 1.72]\n",
      "Epoch 161, Accuracy: 0.4451219439506531, Accuracies: [0.46 0.51 0.41 0.39]\n",
      "Epoch 171, Loss: 1.525774598121643, Accuracy: 0.46341463178396225\n",
      "Epoch 171, Loss: 1.525774598121643, Losses: [1.51 1.32 1.56 1.71]\n",
      "Epoch 171, Accuracy: 0.46341463178396225, Accuracies: [0.49 0.63 0.34 0.39]\n",
      "Epoch 181, Loss: 1.4944173693656921, Accuracy: 0.47560975700616837\n",
      "Epoch 181, Loss: 1.4944173693656921, Losses: [1.47 1.29 1.51 1.7 ]\n",
      "Epoch 181, Accuracy: 0.47560975700616837, Accuracies: [0.49 0.63 0.37 0.41]\n",
      "Epoch 191, Loss: 1.4799846410751343, Accuracy: 0.4695121943950653\n",
      "Epoch 191, Loss: 1.4799846410751343, Losses: [1.45 1.27 1.5  1.7 ]\n",
      "Epoch 191, Accuracy: 0.4695121943950653, Accuracies: [0.49 0.63 0.39 0.37]\n",
      "Epoch 201, Loss: 1.4560514390468597, Accuracy: 0.4695121943950653\n",
      "Epoch 201, Loss: 1.4560514390468597, Losses: [1.4  1.24 1.49 1.69]\n",
      "Epoch 201, Accuracy: 0.4695121943950653, Accuracies: [0.49 0.63 0.34 0.41]\n",
      "Epoch 211, Loss: 1.432407945394516, Accuracy: 0.4999999925494194\n",
      "Epoch 211, Loss: 1.432407945394516, Losses: [1.37 1.21 1.46 1.69]\n",
      "Epoch 211, Accuracy: 0.4999999925494194, Accuracies: [0.51 0.63 0.44 0.41]\n",
      "Epoch 221, Loss: 1.4182283282279968, Accuracy: 0.5426829308271408\n",
      "Epoch 221, Loss: 1.4182283282279968, Losses: [1.34 1.18 1.48 1.68]\n",
      "Epoch 221, Accuracy: 0.5426829308271408, Accuracies: [0.61 0.73 0.44 0.39]\n",
      "Epoch 231, Loss: 1.3959848284721375, Accuracy: 0.5487804859876633\n",
      "Epoch 231, Loss: 1.3959848284721375, Losses: [1.29 1.15 1.48 1.66]\n",
      "Epoch 231, Accuracy: 0.5487804859876633, Accuracies: [0.66 0.78 0.37 0.39]\n",
      "Epoch 241, Loss: 1.3619299530982971, Accuracy: 0.6219512224197388\n",
      "Epoch 241, Loss: 1.3619299530982971, Losses: [1.24 1.12 1.42 1.66]\n",
      "Epoch 241, Accuracy: 0.6219512224197388, Accuracies: [0.66 0.88 0.56 0.39]\n",
      "Epoch 251, Loss: 1.3398416638374329, Accuracy: 0.5853658616542816\n",
      "Epoch 251, Loss: 1.3398416638374329, Losses: [1.2  1.09 1.41 1.65]\n",
      "Epoch 251, Accuracy: 0.5853658616542816, Accuracies: [0.66 0.76 0.56 0.37]\n",
      "Epoch 261, Loss: 1.3120579421520233, Accuracy: 0.6219512224197388\n",
      "Epoch 261, Loss: 1.3120579421520233, Losses: [1.16 1.07 1.4  1.63]\n",
      "Epoch 261, Accuracy: 0.6219512224197388, Accuracies: [0.68 0.9  0.54 0.37]\n",
      "Epoch 271, Loss: 1.293233960866928, Accuracy: 0.6097560897469521\n",
      "Epoch 271, Loss: 1.293233960866928, Losses: [1.11 1.03 1.4  1.63]\n",
      "Epoch 271, Accuracy: 0.6097560897469521, Accuracies: [0.59 0.93 0.59 0.34]\n",
      "Epoch 281, Loss: 1.2589503675699234, Accuracy: 0.6158536672592163\n",
      "Epoch 281, Loss: 1.2589503675699234, Losses: [1.06 0.99 1.38 1.61]\n",
      "Epoch 281, Accuracy: 0.6158536672592163, Accuracies: [0.66 0.93 0.51 0.37]\n",
      "Epoch 291, Loss: 1.256132796406746, Accuracy: 0.6097561046481133\n",
      "Epoch 291, Loss: 1.256132796406746, Losses: [1.03 0.97 1.42 1.61]\n",
      "Epoch 291, Accuracy: 0.6097561046481133, Accuracies: [0.68 0.93 0.49 0.34]\n",
      "Epoch 301, Loss: 1.2209112346172333, Accuracy: 0.6219512224197388\n",
      "Epoch 301, Loss: 1.2209112346172333, Losses: [1.   0.94 1.35 1.59]\n",
      "Epoch 301, Accuracy: 0.6219512224197388, Accuracies: [0.71 0.93 0.54 0.32]\n",
      "Epoch 311, Loss: 1.1997067779302597, Accuracy: 0.6158536672592163\n",
      "Epoch 311, Loss: 1.1997067779302597, Losses: [0.98 0.91 1.34 1.58]\n",
      "Epoch 311, Accuracy: 0.6158536672592163, Accuracies: [0.73 0.93 0.49 0.32]\n",
      "Epoch 321, Loss: 1.1933677345514297, Accuracy: 0.6341463401913643\n",
      "Epoch 321, Loss: 1.1933677345514297, Losses: [0.95 0.88 1.36 1.58]\n",
      "Epoch 321, Accuracy: 0.6341463401913643, Accuracies: [0.73 0.95 0.56 0.29]\n",
      "Epoch 331, Loss: 1.173907071352005, Accuracy: 0.6280487850308418\n",
      "Epoch 331, Loss: 1.173907071352005, Losses: [0.93 0.87 1.33 1.57]\n",
      "Epoch 331, Accuracy: 0.6280487850308418, Accuracies: [0.73 0.95 0.49 0.34]\n",
      "Epoch 341, Loss: 1.1510440856218338, Accuracy: 0.6280487701296806\n",
      "Epoch 341, Loss: 1.1510440856218338, Losses: [0.91 0.84 1.31 1.55]\n",
      "Epoch 341, Accuracy: 0.6280487701296806, Accuracies: [0.76 0.95 0.51 0.29]\n",
      "Epoch 351, Loss: 1.1365403980016708, Accuracy: 0.6402439028024673\n",
      "Epoch 351, Loss: 1.1365403980016708, Losses: [0.89 0.81 1.3  1.54]\n",
      "Epoch 351, Accuracy: 0.6402439028024673, Accuracies: [0.76 0.95 0.54 0.32]\n",
      "Epoch 361, Loss: 1.1249641627073288, Accuracy: 0.6585365831851959\n",
      "Epoch 361, Loss: 1.1249641627073288, Losses: [0.88 0.8  1.29 1.54]\n",
      "Epoch 361, Accuracy: 0.6585365831851959, Accuracies: [0.8  0.95 0.56 0.32]\n",
      "Epoch 371, Loss: 1.1104007959365845, Accuracy: 0.6585365906357765\n",
      "Epoch 371, Loss: 1.1104007959365845, Losses: [0.85 0.78 1.29 1.52]\n",
      "Epoch 371, Accuracy: 0.6585365906357765, Accuracies: [0.8  0.95 0.54 0.34]\n",
      "Epoch 381, Loss: 1.093660682439804, Accuracy: 0.6768292561173439\n",
      "Epoch 381, Loss: 1.093660682439804, Losses: [0.84 0.76 1.27 1.51]\n",
      "Epoch 381, Accuracy: 0.6768292561173439, Accuracies: [0.83 0.95 0.59 0.34]\n",
      "Epoch 391, Loss: 1.081265702843666, Accuracy: 0.670731708407402\n",
      "Epoch 391, Loss: 1.081265702843666, Losses: [0.82 0.74 1.26 1.51]\n",
      "Epoch 391, Accuracy: 0.670731708407402, Accuracies: [0.83 0.95 0.54 0.37]\n",
      "Epoch 401, Loss: 1.0674835443496704, Accuracy: 0.6829268261790276\n",
      "Epoch 401, Loss: 1.0674835443496704, Losses: [0.81 0.72 1.25 1.49]\n",
      "Epoch 401, Accuracy: 0.6829268261790276, Accuracies: [0.83 0.95 0.61 0.34]\n",
      "Epoch 411, Loss: 1.076583817601204, Accuracy: 0.6524390280246735\n",
      "Epoch 411, Loss: 1.076583817601204, Losses: [0.81 0.7  1.27 1.53]\n",
      "Epoch 411, Accuracy: 0.6524390280246735, Accuracies: [0.8  0.95 0.54 0.32]\n",
      "Epoch 421, Loss: 1.0466814190149307, Accuracy: 0.682926818728447\n",
      "Epoch 421, Loss: 1.0466814190149307, Losses: [0.78 0.69 1.25 1.47]\n",
      "Epoch 421, Accuracy: 0.682926818728447, Accuracies: [0.83 0.95 0.59 0.37]\n",
      "Epoch 431, Loss: 1.0255436599254608, Accuracy: 0.6951219588518143\n",
      "Epoch 431, Loss: 1.0255436599254608, Losses: [0.77 0.66 1.23 1.45]\n",
      "Epoch 431, Accuracy: 0.6951219588518143, Accuracies: [0.85 0.95 0.61 0.37]\n",
      "Epoch 441, Loss: 1.0134415030479431, Accuracy: 0.6951219588518143\n",
      "Epoch 441, Loss: 1.0134415030479431, Losses: [0.76 0.64 1.22 1.44]\n",
      "Epoch 441, Accuracy: 0.6951219588518143, Accuracies: [0.85 0.95 0.61 0.37]\n",
      "Epoch 451, Loss: 1.0037905871868134, Accuracy: 0.7073170766234398\n",
      "Epoch 451, Loss: 1.0037905871868134, Losses: [0.76 0.62 1.21 1.42]\n",
      "Epoch 451, Accuracy: 0.7073170766234398, Accuracies: [0.8  0.95 0.66 0.41]\n",
      "Epoch 461, Loss: 1.0163714587688446, Accuracy: 0.6829268261790276\n",
      "Epoch 461, Loss: 1.0163714587688446, Losses: [0.76 0.62 1.21 1.48]\n",
      "Epoch 461, Accuracy: 0.6829268261790276, Accuracies: [0.83 0.95 0.61 0.34]\n",
      "Epoch 471, Loss: 0.9851189851760864, Accuracy: 0.7134146243333817\n",
      "Epoch 471, Loss: 0.9851189851760864, Losses: [0.74 0.6  1.2  1.4 ]\n",
      "Epoch 471, Accuracy: 0.7134146243333817, Accuracies: [0.83 0.95 0.63 0.44]\n",
      "Epoch 481, Loss: 0.9615601897239685, Accuracy: 0.7256097719073296\n",
      "Epoch 481, Loss: 0.9615601897239685, Losses: [0.71 0.58 1.18 1.37]\n",
      "Epoch 481, Accuracy: 0.7256097719073296, Accuracies: [0.85 0.98 0.66 0.41]\n",
      "Epoch 491, Loss: 1.0262928009033203, Accuracy: 0.670731708407402\n",
      "Epoch 491, Loss: 1.0262928009033203, Losses: [0.72 0.62 1.26 1.5 ]\n",
      "Epoch 491, Accuracy: 0.670731708407402, Accuracies: [0.83 0.95 0.54 0.37]\n",
      "Epoch 501, Loss: 0.9592124372720718, Accuracy: 0.7073170766234398\n",
      "Epoch 501, Loss: 0.9592124372720718, Losses: [0.71 0.56 1.19 1.38]\n",
      "Epoch 501, Accuracy: 0.7073170766234398, Accuracies: [0.83 0.98 0.61 0.41]\n",
      "Epoch 511, Loss: 0.9362984001636505, Accuracy: 0.7195122018456459\n",
      "Epoch 511, Loss: 0.9362984001636505, Losses: [0.68 0.54 1.16 1.36]\n",
      "Epoch 511, Accuracy: 0.7195122018456459, Accuracies: [0.85 0.98 0.63 0.41]\n",
      "Epoch 521, Loss: 0.9211829155683517, Accuracy: 0.7195122092962265\n",
      "Epoch 521, Loss: 0.9211829155683517, Losses: [0.67 0.53 1.15 1.33]\n",
      "Epoch 521, Accuracy: 0.7195122092962265, Accuracies: [0.85 0.98 0.66 0.39]\n",
      "Epoch 531, Loss: 0.9292731732130051, Accuracy: 0.7073170766234398\n",
      "Epoch 531, Loss: 0.9292731732130051, Losses: [0.66 0.52 1.17 1.36]\n",
      "Epoch 531, Accuracy: 0.7073170766234398, Accuracies: [0.88 0.98 0.63 0.34]\n",
      "Epoch 541, Loss: 0.9113533645868301, Accuracy: 0.7439024522900581\n",
      "Epoch 541, Loss: 0.9113533645868301, Losses: [0.65 0.51 1.14 1.35]\n",
      "Epoch 541, Accuracy: 0.7439024522900581, Accuracies: [0.88 0.98 0.66 0.46]\n",
      "Epoch 551, Loss: 0.9016891270875931, Accuracy: 0.7256097719073296\n",
      "Epoch 551, Loss: 0.9016891270875931, Losses: [0.67 0.5  1.13 1.31]\n",
      "Epoch 551, Accuracy: 0.7256097719073296, Accuracies: [0.85 0.98 0.66 0.41]\n",
      "Epoch 561, Loss: 0.8843417018651962, Accuracy: 0.731707327067852\n",
      "Epoch 561, Loss: 0.8843417018651962, Losses: [0.62 0.49 1.12 1.3 ]\n",
      "Epoch 561, Accuracy: 0.731707327067852, Accuracies: [0.88 0.98 0.66 0.41]\n",
      "Epoch 571, Loss: 0.8909671604633331, Accuracy: 0.7378048822283745\n",
      "Epoch 571, Loss: 0.8909671604633331, Losses: [0.61 0.49 1.12 1.34]\n",
      "Epoch 571, Accuracy: 0.7378048822283745, Accuracies: [0.88 0.95 0.66 0.46]\n",
      "Epoch 581, Loss: 0.8658103421330452, Accuracy: 0.7378048822283745\n",
      "Epoch 581, Loss: 0.8658103421330452, Losses: [0.59 0.48 1.1  1.29]\n",
      "Epoch 581, Accuracy: 0.7378048822283745, Accuracies: [0.88 0.98 0.63 0.46]\n",
      "Epoch 591, Loss: 0.8517386242747307, Accuracy: 0.7439024373888969\n",
      "Epoch 591, Loss: 0.8517386242747307, Losses: [0.58 0.47 1.09 1.27]\n",
      "Epoch 591, Accuracy: 0.7439024373888969, Accuracies: [0.9  0.98 0.63 0.46]\n",
      "Epoch 601, Loss: 0.8612804263830185, Accuracy: 0.7256097421050072\n",
      "Epoch 601, Loss: 0.8612804263830185, Losses: [0.59 0.47 1.1  1.29]\n",
      "Epoch 601, Accuracy: 0.7256097421050072, Accuracies: [0.9  0.95 0.63 0.41]\n",
      "Epoch 611, Loss: 0.8412338942289352, Accuracy: 0.731707327067852\n",
      "Epoch 611, Loss: 0.8412338942289352, Losses: [0.56 0.45 1.07 1.27]\n",
      "Epoch 611, Accuracy: 0.731707327067852, Accuracies: [0.88 0.98 0.66 0.41]\n",
      "Epoch 621, Loss: 0.8314558118581772, Accuracy: 0.7439024448394775\n",
      "Epoch 621, Loss: 0.8314558118581772, Losses: [0.56 0.44 1.06 1.26]\n",
      "Epoch 621, Accuracy: 0.7439024448394775, Accuracies: [0.9  0.98 0.66 0.44]\n",
      "Epoch 631, Loss: 0.8214744552969933, Accuracy: 0.7378048822283745\n",
      "Epoch 631, Loss: 0.8214744552969933, Losses: [0.54 0.44 1.06 1.25]\n",
      "Epoch 631, Accuracy: 0.7378048822283745, Accuracies: [0.9  0.98 0.66 0.41]\n",
      "Epoch 641, Loss: 0.8319152817130089, Accuracy: 0.7195121794939041\n",
      "Epoch 641, Loss: 0.8319152817130089, Losses: [0.54 0.44 1.06 1.28]\n",
      "Epoch 641, Accuracy: 0.7195121794939041, Accuracies: [0.9  0.95 0.63 0.39]\n",
      "Epoch 651, Loss: 0.8050660565495491, Accuracy: 0.7499999850988388\n",
      "Epoch 651, Loss: 0.8050660565495491, Losses: [0.52 0.43 1.03 1.24]\n",
      "Epoch 651, Accuracy: 0.7499999850988388, Accuracies: [0.9  0.95 0.63 0.51]\n",
      "Epoch 661, Loss: 0.7927388697862625, Accuracy: 0.75\n",
      "Epoch 661, Loss: 0.7927388697862625, Losses: [0.51 0.42 1.02 1.22]\n",
      "Epoch 661, Accuracy: 0.75, Accuracies: [0.9  0.98 0.63 0.49]\n",
      "Epoch 671, Loss: 0.7869858071208, Accuracy: 0.7682926803827286\n",
      "Epoch 671, Loss: 0.7869858071208, Losses: [0.51 0.41 1.01 1.22]\n",
      "Epoch 671, Accuracy: 0.7682926803827286, Accuracies: [0.9  0.98 0.63 0.56]\n",
      "Epoch 681, Loss: 0.7810677066445351, Accuracy: 0.7439024522900581\n",
      "Epoch 681, Loss: 0.7810677066445351, Losses: [0.5  0.41 1.   1.21]\n",
      "Epoch 681, Accuracy: 0.7439024522900581, Accuracies: [0.88 0.98 0.66 0.46]\n",
      "Epoch 691, Loss: 0.7666431963443756, Accuracy: 0.75\n",
      "Epoch 691, Loss: 0.7666431963443756, Losses: [0.48 0.41 0.99 1.19]\n",
      "Epoch 691, Accuracy: 0.75, Accuracies: [0.9  0.98 0.63 0.49]\n",
      "Epoch 701, Loss: 0.8117225915193558, Accuracy: 0.7378048822283745\n",
      "Epoch 701, Loss: 0.8117225915193558, Losses: [0.53 0.45 1.07 1.2 ]\n",
      "Epoch 701, Accuracy: 0.7378048822283745, Accuracies: [0.9  0.98 0.61 0.46]\n",
      "Epoch 711, Loss: 0.7749745324254036, Accuracy: 0.7499999850988388\n",
      "Epoch 711, Loss: 0.7749745324254036, Losses: [0.48 0.4  1.01 1.2 ]\n",
      "Epoch 711, Accuracy: 0.7499999850988388, Accuracies: [0.9  0.95 0.63 0.51]\n",
      "Epoch 721, Loss: 0.7528616413474083, Accuracy: 0.7682926952838898\n",
      "Epoch 721, Loss: 0.7528616413474083, Losses: [0.46 0.39 0.97 1.18]\n",
      "Epoch 721, Accuracy: 0.7682926952838898, Accuracies: [0.9  0.98 0.66 0.54]\n",
      "Epoch 731, Loss: 0.7456253692507744, Accuracy: 0.7560975775122643\n",
      "Epoch 731, Loss: 0.7456253692507744, Losses: [0.47 0.39 0.96 1.17]\n",
      "Epoch 731, Accuracy: 0.7560975775122643, Accuracies: [0.93 0.98 0.66 0.46]\n",
      "Epoch 741, Loss: 0.7376292422413826, Accuracy: 0.7439024373888969\n",
      "Epoch 741, Loss: 0.7376292422413826, Losses: [0.46 0.38 0.95 1.16]\n",
      "Epoch 741, Accuracy: 0.7439024373888969, Accuracies: [0.9  0.98 0.63 0.46]\n",
      "Epoch 751, Loss: 0.7477623820304871, Accuracy: 0.7865853607654572\n",
      "Epoch 751, Loss: 0.7477623820304871, Losses: [0.44 0.38 0.95 1.22]\n",
      "Epoch 751, Accuracy: 0.7865853607654572, Accuracies: [0.9  1.   0.68 0.56]\n",
      "Epoch 761, Loss: 0.7581616267561913, Accuracy: 0.7378048822283745\n",
      "Epoch 761, Loss: 0.7581616267561913, Losses: [0.47 0.38 0.98 1.21]\n",
      "Epoch 761, Accuracy: 0.7378048822283745, Accuracies: [0.88 0.95 0.66 0.46]\n",
      "Epoch 771, Loss: 0.7210384532809258, Accuracy: 0.7682926952838898\n",
      "Epoch 771, Loss: 0.7210384532809258, Losses: [0.44 0.36 0.94 1.15]\n",
      "Epoch 771, Accuracy: 0.7682926952838898, Accuracies: [0.93 0.98 0.66 0.51]\n",
      "Epoch 781, Loss: 0.7088499590754509, Accuracy: 0.7682926952838898\n",
      "Epoch 781, Loss: 0.7088499590754509, Losses: [0.42 0.36 0.92 1.13]\n",
      "Epoch 781, Accuracy: 0.7682926952838898, Accuracies: [0.93 0.98 0.66 0.51]\n",
      "Epoch 791, Loss: 0.7199929505586624, Accuracy: 0.7439024448394775\n",
      "Epoch 791, Loss: 0.7199929505586624, Losses: [0.43 0.36 0.96 1.13]\n",
      "Epoch 791, Accuracy: 0.7439024448394775, Accuracies: [0.9  0.98 0.61 0.49]\n",
      "Epoch 801, Loss: 0.724572591483593, Accuracy: 0.7804878056049347\n",
      "Epoch 801, Loss: 0.724572591483593, Losses: [0.43 0.35 0.94 1.17]\n",
      "Epoch 801, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.68 0.56]\n",
      "Epoch 811, Loss: 0.6947876140475273, Accuracy: 0.7743902504444122\n",
      "Epoch 811, Loss: 0.6947876140475273, Losses: [0.41 0.35 0.9  1.12]\n",
      "Epoch 811, Accuracy: 0.7743902504444122, Accuracies: [0.9  0.98 0.66 0.56]\n",
      "Epoch 821, Loss: 0.6837789192795753, Accuracy: 0.7743902653455734\n",
      "Epoch 821, Loss: 0.6837789192795753, Losses: [0.4  0.34 0.89 1.1 ]\n",
      "Epoch 821, Accuracy: 0.7743902653455734, Accuracies: [0.93 0.98 0.66 0.54]\n",
      "Epoch 831, Loss: 0.6768596991896629, Accuracy: 0.7621951401233673\n",
      "Epoch 831, Loss: 0.6768596991896629, Losses: [0.39 0.34 0.88 1.09]\n",
      "Epoch 831, Accuracy: 0.7621951401233673, Accuracies: [0.93 0.98 0.66 0.49]\n",
      "Epoch 841, Loss: 0.7016721218824387, Accuracy: 0.7682926803827286\n",
      "Epoch 841, Loss: 0.7016721218824387, Losses: [0.41 0.35 0.91 1.14]\n",
      "Epoch 841, Accuracy: 0.7682926803827286, Accuracies: [0.9  0.98 0.63 0.56]\n",
      "Epoch 851, Loss: 0.6730546802282333, Accuracy: 0.7804878056049347\n",
      "Epoch 851, Loss: 0.6730546802282333, Losses: [0.39 0.33 0.88 1.1 ]\n",
      "Epoch 851, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.66 0.59]\n",
      "Epoch 861, Loss: 0.6604520231485367, Accuracy: 0.7804878205060959\n",
      "Epoch 861, Loss: 0.6604520231485367, Losses: [0.38 0.33 0.87 1.07]\n",
      "Epoch 861, Accuracy: 0.7804878205060959, Accuracies: [0.93 0.98 0.66 0.56]\n",
      "Epoch 871, Loss: 0.6566497832536697, Accuracy: 0.7743902653455734\n",
      "Epoch 871, Loss: 0.6566497832536697, Losses: [0.38 0.32 0.86 1.06]\n",
      "Epoch 871, Accuracy: 0.7743902653455734, Accuracies: [0.93 0.98 0.66 0.54]\n",
      "Epoch 881, Loss: 0.6777467057108879, Accuracy: 0.7682926952838898\n",
      "Epoch 881, Loss: 0.6777467057108879, Losses: [0.4  0.32 0.9  1.09]\n",
      "Epoch 881, Accuracy: 0.7682926952838898, Accuracies: [0.93 0.98 0.68 0.49]\n",
      "Epoch 891, Loss: 0.6481243297457695, Accuracy: 0.7926829308271408\n",
      "Epoch 891, Loss: 0.6481243297457695, Losses: [0.37 0.32 0.85 1.06]\n",
      "Epoch 891, Accuracy: 0.7926829308271408, Accuracies: [0.93 0.98 0.68 0.59]\n",
      "Epoch 901, Loss: 0.6447805166244507, Accuracy: 0.7926829308271408\n",
      "Epoch 901, Loss: 0.6447805166244507, Losses: [0.36 0.33 0.84 1.04]\n",
      "Epoch 901, Accuracy: 0.7926829308271408, Accuracies: [0.93 1.   0.68 0.56]\n",
      "Epoch 911, Loss: 0.6345909610390663, Accuracy: 0.7926829159259796\n",
      "Epoch 911, Loss: 0.6345909610390663, Losses: [0.36 0.31 0.84 1.04]\n",
      "Epoch 911, Accuracy: 0.7926829159259796, Accuracies: [0.9  0.98 0.71 0.59]\n",
      "Epoch 921, Loss: 0.6627781391143799, Accuracy: 0.7926829308271408\n",
      "Epoch 921, Loss: 0.6627781391143799, Losses: [0.37 0.31 0.9  1.07]\n",
      "Epoch 921, Accuracy: 0.7926829308271408, Accuracies: [0.93 0.98 0.68 0.59]\n",
      "Epoch 931, Loss: 0.6262915059924126, Accuracy: 0.7926829308271408\n",
      "Epoch 931, Loss: 0.6262915059924126, Losses: [0.34 0.3  0.83 1.04]\n",
      "Epoch 931, Accuracy: 0.7926829308271408, Accuracies: [0.93 0.98 0.71 0.56]\n",
      "Epoch 941, Loss: 0.6113160476088524, Accuracy: 0.7926829308271408\n",
      "Epoch 941, Loss: 0.6113160476088524, Losses: [0.32 0.3  0.82 1.02]\n",
      "Epoch 941, Accuracy: 0.7926829308271408, Accuracies: [0.95 0.98 0.68 0.56]\n",
      "Epoch 951, Loss: 0.6029593348503113, Accuracy: 0.7987805008888245\n",
      "Epoch 951, Loss: 0.6029593348503113, Losses: [0.31 0.29 0.81 1.  ]\n",
      "Epoch 951, Accuracy: 0.7987805008888245, Accuracies: [0.98 0.98 0.68 0.56]\n",
      "Epoch 961, Loss: 0.5994677618145943, Accuracy: 0.7987804859876633\n",
      "Epoch 961, Loss: 0.5994677618145943, Losses: [0.31 0.29 0.81 1.  ]\n",
      "Epoch 961, Accuracy: 0.7987804859876633, Accuracies: [0.95 0.98 0.71 0.56]\n",
      "Epoch 971, Loss: 0.6937297582626343, Accuracy: 0.7743902504444122\n",
      "Epoch 971, Loss: 0.6937297582626343, Losses: [0.39 0.31 0.85 1.23]\n",
      "Epoch 971, Accuracy: 0.7743902504444122, Accuracies: [0.93 0.98 0.71 0.49]\n",
      "Epoch 981, Loss: 0.6193086877465248, Accuracy: 0.7865853607654572\n",
      "Epoch 981, Loss: 0.6193086877465248, Losses: [0.31 0.28 0.81 1.08]\n",
      "Epoch 981, Accuracy: 0.7865853607654572, Accuracies: [0.95 0.98 0.71 0.51]\n",
      "Epoch 991, Loss: 0.6019313409924507, Accuracy: 0.7987804859876633\n",
      "Epoch 991, Loss: 0.6019313409924507, Losses: [0.3  0.29 0.81 1.01]\n",
      "Epoch 991, Accuracy: 0.7987804859876633, Accuracies: [0.95 1.   0.66 0.59]\n",
      "Epoch 1001, Loss: 0.6422751843929291, Accuracy: 0.7743902504444122\n",
      "Epoch 1001, Loss: 0.6422751843929291, Losses: [0.3  0.38 0.84 1.05]\n",
      "Epoch 1001, Accuracy: 0.7743902504444122, Accuracies: [0.95 0.98 0.63 0.54]\n",
      "Epoch 1011, Loss: 0.5919222384691238, Accuracy: 0.7865853756666183\n",
      "Epoch 1011, Loss: 0.5919222384691238, Losses: [0.29 0.28 0.8  1.  ]\n",
      "Epoch 1011, Accuracy: 0.7865853756666183, Accuracies: [0.95 0.98 0.68 0.54]\n",
      "Epoch 1021, Loss: 0.5801738277077675, Accuracy: 0.7926829308271408\n",
      "Epoch 1021, Loss: 0.5801738277077675, Losses: [0.28 0.28 0.78 0.98]\n",
      "Epoch 1021, Accuracy: 0.7926829308271408, Accuracies: [0.95 0.98 0.71 0.54]\n",
      "Epoch 1031, Loss: 0.5717843249440193, Accuracy: 0.7987804859876633\n",
      "Epoch 1031, Loss: 0.5717843249440193, Losses: [0.28 0.27 0.77 0.96]\n",
      "Epoch 1031, Accuracy: 0.7987804859876633, Accuracies: [0.95 0.98 0.71 0.56]\n",
      "Epoch 1041, Loss: 0.5647274032235146, Accuracy: 0.8048780560493469\n",
      "Epoch 1041, Loss: 0.5647274032235146, Losses: [0.27 0.27 0.76 0.95]\n",
      "Epoch 1041, Accuracy: 0.8048780560493469, Accuracies: [0.98 0.98 0.71 0.56]\n",
      "Epoch 1051, Loss: 0.5580728128552437, Accuracy: 0.8109756261110306\n",
      "Epoch 1051, Loss: 0.5580728128552437, Losses: [0.27 0.26 0.75 0.95]\n",
      "Epoch 1051, Accuracy: 0.8109756261110306, Accuracies: [0.98 0.98 0.73 0.56]\n",
      "Epoch 1061, Loss: 0.5566779151558876, Accuracy: 0.8231707513332367\n",
      "Epoch 1061, Loss: 0.5566779151558876, Losses: [0.27 0.27 0.75 0.94]\n",
      "Epoch 1061, Accuracy: 0.8231707513332367, Accuracies: [0.98 0.98 0.73 0.61]\n",
      "Epoch 1071, Loss: 0.5689729005098343, Accuracy: 0.7926829308271408\n",
      "Epoch 1071, Loss: 0.5689729005098343, Losses: [0.28 0.26 0.78 0.96]\n",
      "Epoch 1071, Accuracy: 0.7926829308271408, Accuracies: [0.95 0.98 0.68 0.56]\n",
      "Epoch 1081, Loss: 0.549845926463604, Accuracy: 0.817073181271553\n",
      "Epoch 1081, Loss: 0.549845926463604, Losses: [0.26 0.26 0.74 0.94]\n",
      "Epoch 1081, Accuracy: 0.817073181271553, Accuracies: [0.98 0.98 0.71 0.61]\n",
      "Epoch 1091, Loss: 0.5419264361262321, Accuracy: 0.817073181271553\n",
      "Epoch 1091, Loss: 0.5419264361262321, Losses: [0.25 0.25 0.74 0.92]\n",
      "Epoch 1091, Accuracy: 0.817073181271553, Accuracies: [0.98 0.98 0.71 0.61]\n",
      "Epoch 1101, Loss: 0.5332455150783062, Accuracy: 0.8231707513332367\n",
      "Epoch 1101, Loss: 0.5332455150783062, Losses: [0.24 0.25 0.73 0.91]\n",
      "Epoch 1101, Accuracy: 0.8231707513332367, Accuracies: [0.98 0.98 0.73 0.61]\n",
      "Epoch 1111, Loss: 0.529605507850647, Accuracy: 0.817073181271553\n",
      "Epoch 1111, Loss: 0.529605507850647, Losses: [0.24 0.25 0.73 0.9 ]\n",
      "Epoch 1111, Accuracy: 0.817073181271553, Accuracies: [0.98 0.98 0.71 0.61]\n",
      "Epoch 1121, Loss: 0.5520727932453156, Accuracy: 0.8048780560493469\n",
      "Epoch 1121, Loss: 0.5520727932453156, Losses: [0.24 0.26 0.78 0.93]\n",
      "Epoch 1121, Accuracy: 0.8048780560493469, Accuracies: [0.98 0.98 0.63 0.63]\n",
      "Epoch 1131, Loss: 0.5275945477187634, Accuracy: 0.8231707364320755\n",
      "Epoch 1131, Loss: 0.5275945477187634, Losses: [0.23 0.25 0.73 0.91]\n",
      "Epoch 1131, Accuracy: 0.8231707364320755, Accuracies: [0.98 0.98 0.71 0.63]\n",
      "Epoch 1141, Loss: 0.5866139493882656, Accuracy: 0.8048780560493469\n",
      "Epoch 1141, Loss: 0.5866139493882656, Losses: [0.24 0.29 0.75 1.07]\n",
      "Epoch 1141, Accuracy: 0.8048780560493469, Accuracies: [0.98 0.98 0.71 0.56]\n",
      "Epoch 1151, Loss: 0.5196452103555202, Accuracy: 0.8353658765554428\n",
      "Epoch 1151, Loss: 0.5196452103555202, Losses: [0.22 0.24 0.72 0.9 ]\n",
      "Epoch 1151, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 1161, Loss: 0.5109590850770473, Accuracy: 0.8292683064937592\n",
      "Epoch 1161, Loss: 0.5109590850770473, Losses: [0.21 0.25 0.7  0.88]\n",
      "Epoch 1161, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.73 0.63]\n",
      "Epoch 1171, Loss: 0.5112406834959984, Accuracy: 0.8414634317159653\n",
      "Epoch 1171, Loss: 0.5112406834959984, Losses: [0.22 0.23 0.71 0.89]\n",
      "Epoch 1171, Accuracy: 0.8414634317159653, Accuracies: [0.98 0.98 0.76 0.66]\n",
      "Epoch 1181, Loss: 0.5490100309252739, Accuracy: 0.7987805008888245\n",
      "Epoch 1181, Loss: 0.5490100309252739, Losses: [0.25 0.26 0.79 0.9 ]\n",
      "Epoch 1181, Accuracy: 0.7987805008888245, Accuracies: [0.95 0.98 0.66 0.61]\n",
      "Epoch 1191, Loss: 0.5067937485873699, Accuracy: 0.817073181271553\n",
      "Epoch 1191, Loss: 0.5067937485873699, Losses: [0.2  0.24 0.7  0.88]\n",
      "Epoch 1191, Accuracy: 0.817073181271553, Accuracies: [0.98 0.98 0.73 0.59]\n",
      "Epoch 1201, Loss: 0.4995811991393566, Accuracy: 0.8353658765554428\n",
      "Epoch 1201, Loss: 0.4995811991393566, Losses: [0.2  0.24 0.69 0.87]\n",
      "Epoch 1201, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 1211, Loss: 0.4914323352277279, Accuracy: 0.8353658765554428\n",
      "Epoch 1211, Loss: 0.4914323352277279, Losses: [0.19 0.23 0.68 0.86]\n",
      "Epoch 1211, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 1221, Loss: 0.4852243959903717, Accuracy: 0.8475609868764877\n",
      "Epoch 1221, Loss: 0.4852243959903717, Losses: [0.19 0.23 0.68 0.85]\n",
      "Epoch 1221, Accuracy: 0.8475609868764877, Accuracies: [0.98 0.98 0.78 0.66]\n",
      "Epoch 1231, Loss: 0.4795053154230118, Accuracy: 0.8536585420370102\n",
      "Epoch 1231, Loss: 0.4795053154230118, Losses: [0.19 0.23 0.67 0.84]\n",
      "Epoch 1231, Accuracy: 0.8536585420370102, Accuracies: [0.98 0.98 0.78 0.68]\n",
      "Epoch 1241, Loss: 0.5418920144438744, Accuracy: 0.829268291592598\n",
      "Epoch 1241, Loss: 0.5418920144438744, Losses: [0.22 0.26 0.7  0.98]\n",
      "Epoch 1241, Accuracy: 0.829268291592598, Accuracies: [0.95 0.98 0.76 0.63]\n",
      "Epoch 1251, Loss: 0.47970909252762794, Accuracy: 0.8475609868764877\n",
      "Epoch 1251, Loss: 0.47970909252762794, Losses: [0.19 0.22 0.67 0.84]\n",
      "Epoch 1251, Accuracy: 0.8475609868764877, Accuracies: [0.98 0.98 0.73 0.71]\n",
      "Epoch 1261, Loss: 0.4818100407719612, Accuracy: 0.8353658616542816\n",
      "Epoch 1261, Loss: 0.4818100407719612, Losses: [0.19 0.23 0.67 0.83]\n",
      "Epoch 1261, Accuracy: 0.8353658616542816, Accuracies: [0.98 0.98 0.71 0.68]\n",
      "Epoch 1271, Loss: 0.4682546742260456, Accuracy: 0.8536585420370102\n",
      "Epoch 1271, Loss: 0.4682546742260456, Losses: [0.18 0.22 0.65 0.82]\n",
      "Epoch 1271, Accuracy: 0.8536585420370102, Accuracies: [0.98 0.98 0.76 0.71]\n",
      "Epoch 1281, Loss: 0.479881152510643, Accuracy: 0.8597560971975327\n",
      "Epoch 1281, Loss: 0.479881152510643, Losses: [0.19 0.23 0.68 0.82]\n",
      "Epoch 1281, Accuracy: 0.8597560971975327, Accuracies: [0.98 1.   0.78 0.68]\n",
      "Epoch 1291, Loss: 0.45895586535334587, Accuracy: 0.8536585420370102\n",
      "Epoch 1291, Loss: 0.45895586535334587, Losses: [0.17 0.22 0.64 0.81]\n",
      "Epoch 1291, Accuracy: 0.8536585420370102, Accuracies: [0.98 0.98 0.76 0.71]\n",
      "Epoch 1301, Loss: 0.4739835597574711, Accuracy: 0.8353658765554428\n",
      "Epoch 1301, Loss: 0.4739835597574711, Losses: [0.17 0.22 0.66 0.85]\n",
      "Epoch 1301, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 1311, Loss: 0.45993463322520256, Accuracy: 0.8536585569381714\n",
      "Epoch 1311, Loss: 0.45993463322520256, Losses: [0.17 0.21 0.65 0.81]\n",
      "Epoch 1311, Accuracy: 0.8536585569381714, Accuracies: [0.98 0.98 0.73 0.73]\n",
      "Epoch 1321, Loss: 0.4636603742837906, Accuracy: 0.8597561120986938\n",
      "Epoch 1321, Loss: 0.4636603742837906, Losses: [0.16 0.21 0.67 0.81]\n",
      "Epoch 1321, Accuracy: 0.8597561120986938, Accuracies: [0.98 0.98 0.76 0.73]\n",
      "Epoch 1331, Loss: 0.45924900099635124, Accuracy: 0.8414634168148041\n",
      "Epoch 1331, Loss: 0.45924900099635124, Losses: [0.17 0.22 0.64 0.81]\n",
      "Epoch 1331, Accuracy: 0.8414634168148041, Accuracies: [0.98 0.98 0.71 0.71]\n",
      "Epoch 1341, Loss: 0.44746197015047073, Accuracy: 0.8536585420370102\n",
      "Epoch 1341, Loss: 0.44746197015047073, Losses: [0.16 0.22 0.62 0.79]\n",
      "Epoch 1341, Accuracy: 0.8536585420370102, Accuracies: [0.98 1.   0.76 0.68]\n",
      "Epoch 1351, Loss: 0.4408039413392544, Accuracy: 0.8475609868764877\n",
      "Epoch 1351, Loss: 0.4408039413392544, Losses: [0.16 0.21 0.62 0.78]\n",
      "Epoch 1351, Accuracy: 0.8475609868764877, Accuracies: [0.98 0.98 0.76 0.68]\n",
      "Epoch 1361, Loss: 0.43458669632673264, Accuracy: 0.8719512224197388\n",
      "Epoch 1361, Loss: 0.43458669632673264, Losses: [0.15 0.21 0.61 0.77]\n",
      "Epoch 1361, Accuracy: 0.8719512224197388, Accuracies: [0.98 0.98 0.76 0.78]\n",
      "Epoch 1371, Loss: 0.4726504050195217, Accuracy: 0.8658536523580551\n",
      "Epoch 1371, Loss: 0.4726504050195217, Losses: [0.16 0.31 0.63 0.79]\n",
      "Epoch 1371, Accuracy: 0.8658536523580551, Accuracies: [0.98 0.93 0.78 0.78]\n",
      "Epoch 1381, Loss: 0.43221527338027954, Accuracy: 0.8597561120986938\n",
      "Epoch 1381, Loss: 0.43221527338027954, Losses: [0.15 0.21 0.61 0.76]\n",
      "Epoch 1381, Accuracy: 0.8597561120986938, Accuracies: [0.98 0.98 0.76 0.73]\n",
      "Epoch 1391, Loss: 0.4475846700370312, Accuracy: 0.8719512224197388\n",
      "Epoch 1391, Loss: 0.4475846700370312, Losses: [0.15 0.22 0.64 0.78]\n",
      "Epoch 1391, Accuracy: 0.8719512224197388, Accuracies: [0.98 1.   0.73 0.78]\n",
      "Epoch 1401, Loss: 0.43062278628349304, Accuracy: 0.8658536672592163\n",
      "Epoch 1401, Loss: 0.43062278628349304, Losses: [0.16 0.21 0.61 0.76]\n",
      "Epoch 1401, Accuracy: 0.8658536672592163, Accuracies: [0.98 0.98 0.73 0.78]\n",
      "Epoch 1411, Loss: 0.4247393310070038, Accuracy: 0.8597561120986938\n",
      "Epoch 1411, Loss: 0.4247393310070038, Losses: [0.14 0.21 0.59 0.75]\n",
      "Epoch 1411, Accuracy: 0.8597561120986938, Accuracies: [0.98 0.98 0.76 0.73]\n",
      "Epoch 1421, Loss: 0.4713771753013134, Accuracy: 0.8414634168148041\n",
      "Epoch 1421, Loss: 0.4713771753013134, Losses: [0.26 0.24 0.62 0.76]\n",
      "Epoch 1421, Accuracy: 0.8414634168148041, Accuracies: [0.93 0.95 0.76 0.73]\n",
      "Epoch 1431, Loss: 0.5155541636049747, Accuracy: 0.8048780560493469\n",
      "Epoch 1431, Loss: 0.5155541636049747, Losses: [0.18 0.24 0.64 1.01]\n",
      "Epoch 1431, Accuracy: 0.8048780560493469, Accuracies: [0.98 0.98 0.71 0.56]\n",
      "Epoch 1441, Loss: 0.4296840466558933, Accuracy: 0.8597561120986938\n",
      "Epoch 1441, Loss: 0.4296840466558933, Losses: [0.14 0.2  0.59 0.78]\n",
      "Epoch 1441, Accuracy: 0.8597561120986938, Accuracies: [0.98 0.98 0.76 0.73]\n",
      "Epoch 1451, Loss: 0.4137628972530365, Accuracy: 0.8780487924814224\n",
      "Epoch 1451, Loss: 0.4137628972530365, Losses: [0.14 0.2  0.59 0.74]\n",
      "Epoch 1451, Accuracy: 0.8780487924814224, Accuracies: [0.98 0.98 0.76 0.8 ]\n",
      "Epoch 1461, Loss: 0.41035597771406174, Accuracy: 0.8658536672592163\n",
      "Epoch 1461, Loss: 0.41035597771406174, Losses: [0.13 0.2  0.59 0.72]\n",
      "Epoch 1461, Accuracy: 0.8658536672592163, Accuracies: [0.98 0.98 0.73 0.78]\n",
      "Epoch 1471, Loss: 0.4008527360856533, Accuracy: 0.8841463476419449\n",
      "Epoch 1471, Loss: 0.4008527360856533, Losses: [0.13 0.19 0.56 0.72]\n",
      "Epoch 1471, Accuracy: 0.8841463476419449, Accuracies: [0.98 0.98 0.78 0.8 ]\n",
      "Epoch 1481, Loss: 0.3998551294207573, Accuracy: 0.8841463476419449\n",
      "Epoch 1481, Loss: 0.3998551294207573, Losses: [0.13 0.2  0.57 0.71]\n",
      "Epoch 1481, Accuracy: 0.8841463476419449, Accuracies: [0.98 1.   0.76 0.8 ]\n",
      "Epoch 1491, Loss: 0.40685635805130005, Accuracy: 0.8780487775802612\n",
      "Epoch 1491, Loss: 0.40685635805130005, Losses: [0.13 0.19 0.57 0.74]\n",
      "Epoch 1491, Accuracy: 0.8780487775802612, Accuracies: [0.98 1.   0.76 0.78]\n",
      "Epoch 1501, Loss: 0.41347769275307655, Accuracy: 0.8719512224197388\n",
      "Epoch 1501, Loss: 0.41347769275307655, Losses: [0.17 0.22 0.57 0.7 ]\n",
      "Epoch 1501, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.73 0.83]\n",
      "Epoch 1511, Loss: 0.4043031148612499, Accuracy: 0.8780487775802612\n",
      "Epoch 1511, Loss: 0.4043031148612499, Losses: [0.13 0.19 0.55 0.74]\n",
      "Epoch 1511, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.98 0.78 0.78]\n",
      "Epoch 1521, Loss: 0.38792118802666664, Accuracy: 0.8902439177036285\n",
      "Epoch 1521, Loss: 0.38792118802666664, Losses: [0.13 0.19 0.54 0.69]\n",
      "Epoch 1521, Accuracy: 0.8902439177036285, Accuracies: [0.98 0.98 0.8  0.8 ]\n",
      "Epoch 1531, Loss: 0.38089541159570217, Accuracy: 0.8902439028024673\n",
      "Epoch 1531, Loss: 0.38089541159570217, Losses: [0.12 0.19 0.54 0.68]\n",
      "Epoch 1531, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.98 0.83 0.78]\n",
      "Epoch 1541, Loss: 0.3822623398154974, Accuracy: 0.8902439177036285\n",
      "Epoch 1541, Loss: 0.3822623398154974, Losses: [0.12 0.2  0.54 0.67]\n",
      "Epoch 1541, Accuracy: 0.8902439177036285, Accuracies: [0.98 0.98 0.8  0.8 ]\n",
      "Epoch 1551, Loss: 0.42142387852072716, Accuracy: 0.8658536672592163\n",
      "Epoch 1551, Loss: 0.42142387852072716, Losses: [0.14 0.21 0.65 0.68]\n",
      "Epoch 1551, Accuracy: 0.8658536672592163, Accuracies: [0.98 1.   0.76 0.73]\n",
      "Epoch 1561, Loss: 0.3820137698203325, Accuracy: 0.8841463476419449\n",
      "Epoch 1561, Loss: 0.3820137698203325, Losses: [0.12 0.19 0.53 0.68]\n",
      "Epoch 1561, Accuracy: 0.8841463476419449, Accuracies: [0.98 0.98 0.8  0.78]\n",
      "Epoch 1571, Loss: 0.37074271589517593, Accuracy: 0.8902439028024673\n",
      "Epoch 1571, Loss: 0.37074271589517593, Losses: [0.12 0.19 0.52 0.66]\n",
      "Epoch 1571, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.98 0.83 0.78]\n",
      "Epoch 1581, Loss: 0.3731823302805424, Accuracy: 0.9024390280246735\n",
      "Epoch 1581, Loss: 0.3731823302805424, Losses: [0.12 0.2  0.52 0.65]\n",
      "Epoch 1581, Accuracy: 0.9024390280246735, Accuracies: [0.98 1.   0.83 0.8 ]\n",
      "Epoch 1591, Loss: 0.3767797164618969, Accuracy: 0.8902439028024673\n",
      "Epoch 1591, Loss: 0.3767797164618969, Losses: [0.11 0.23 0.52 0.65]\n",
      "Epoch 1591, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.95 0.83 0.8 ]\n",
      "Epoch 1601, Loss: 0.36733662709593773, Accuracy: 0.8780487775802612\n",
      "Epoch 1601, Loss: 0.36733662709593773, Losses: [0.11 0.19 0.52 0.65]\n",
      "Epoch 1601, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.98 0.78 0.78]\n",
      "Epoch 1611, Loss: 0.36038384586572647, Accuracy: 0.896341472864151\n",
      "Epoch 1611, Loss: 0.36038384586572647, Losses: [0.11 0.18 0.51 0.64]\n",
      "Epoch 1611, Accuracy: 0.896341472864151, Accuracies: [0.98 0.98 0.8  0.83]\n",
      "Epoch 1621, Loss: 0.3538565281778574, Accuracy: 0.9024390280246735\n",
      "Epoch 1621, Loss: 0.3538565281778574, Losses: [0.11 0.18 0.5  0.63]\n",
      "Epoch 1621, Accuracy: 0.9024390280246735, Accuracies: [0.98 0.98 0.83 0.83]\n",
      "Epoch 1631, Loss: 0.3654146231710911, Accuracy: 0.8902439028024673\n",
      "Epoch 1631, Loss: 0.3654146231710911, Losses: [0.11 0.18 0.55 0.62]\n",
      "Epoch 1631, Accuracy: 0.8902439028024673, Accuracies: [0.98 1.   0.78 0.8 ]\n",
      "Epoch 1641, Loss: 0.36780134588479996, Accuracy: 0.8780487775802612\n",
      "Epoch 1641, Loss: 0.36780134588479996, Losses: [0.13 0.18 0.53 0.62]\n",
      "Epoch 1641, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.76 0.83]\n",
      "Epoch 1651, Loss: 0.36026962473988533, Accuracy: 0.8841463476419449\n",
      "Epoch 1651, Loss: 0.36026962473988533, Losses: [0.11 0.2  0.5  0.63]\n",
      "Epoch 1651, Accuracy: 0.8841463476419449, Accuracies: [0.98 0.98 0.8  0.78]\n",
      "Epoch 1661, Loss: 0.3425415977835655, Accuracy: 0.9085365980863571\n",
      "Epoch 1661, Loss: 0.3425415977835655, Losses: [0.1  0.18 0.49 0.6 ]\n",
      "Epoch 1661, Accuracy: 0.9085365980863571, Accuracies: [0.98 0.98 0.83 0.85]\n",
      "Epoch 1671, Loss: 0.34227459132671356, Accuracy: 0.9024390280246735\n",
      "Epoch 1671, Loss: 0.34227459132671356, Losses: [0.1  0.17 0.5  0.6 ]\n",
      "Epoch 1671, Accuracy: 0.9024390280246735, Accuracies: [0.98 0.98 0.83 0.83]\n",
      "Epoch 1681, Loss: 0.33596028201282024, Accuracy: 0.9146341532468796\n",
      "Epoch 1681, Loss: 0.33596028201282024, Losses: [0.09 0.18 0.49 0.59]\n",
      "Epoch 1681, Accuracy: 0.9146341532468796, Accuracies: [0.98 1.   0.83 0.85]\n",
      "Epoch 1691, Loss: 0.33033558167517185, Accuracy: 0.9146341532468796\n",
      "Epoch 1691, Loss: 0.33033558167517185, Losses: [0.09 0.17 0.48 0.58]\n",
      "Epoch 1691, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.83 0.85]\n",
      "Epoch 1701, Loss: 0.32806762494146824, Accuracy: 0.9146341532468796\n",
      "Epoch 1701, Loss: 0.32806762494146824, Losses: [0.09 0.17 0.48 0.58]\n",
      "Epoch 1701, Accuracy: 0.9146341532468796, Accuracies: [1.   1.   0.8  0.85]\n",
      "Epoch 1711, Loss: 0.4495200291275978, Accuracy: 0.8414634019136429\n",
      "Epoch 1711, Loss: 0.4495200291275978, Losses: [0.32 0.18 0.51 0.78]\n",
      "Epoch 1711, Accuracy: 0.8414634019136429, Accuracies: [0.9  1.   0.78 0.68]\n",
      "Epoch 1721, Loss: 0.33853484131395817, Accuracy: 0.8902439028024673\n",
      "Epoch 1721, Loss: 0.33853484131395817, Losses: [0.11 0.17 0.48 0.59]\n",
      "Epoch 1721, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.98 0.83 0.78]\n",
      "Epoch 1731, Loss: 0.32440610975027084, Accuracy: 0.9085365831851959\n",
      "Epoch 1731, Loss: 0.32440610975027084, Losses: [0.09 0.17 0.47 0.57]\n",
      "Epoch 1731, Accuracy: 0.9085365831851959, Accuracies: [1.   0.98 0.83 0.83]\n",
      "Epoch 1741, Loss: 0.31932087056338787, Accuracy: 0.9085365980863571\n",
      "Epoch 1741, Loss: 0.31932087056338787, Losses: [0.08 0.17 0.47 0.56]\n",
      "Epoch 1741, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1751, Loss: 0.3151492141187191, Accuracy: 0.9146341532468796\n",
      "Epoch 1751, Loss: 0.3151492141187191, Losses: [0.08 0.17 0.46 0.55]\n",
      "Epoch 1751, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.8  0.88]\n",
      "Epoch 1761, Loss: 0.31565372087061405, Accuracy: 0.9085365980863571\n",
      "Epoch 1761, Loss: 0.31565372087061405, Losses: [0.08 0.17 0.46 0.55]\n",
      "Epoch 1761, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1771, Loss: 0.33795010671019554, Accuracy: 0.9146341383457184\n",
      "Epoch 1771, Loss: 0.33795010671019554, Losses: [0.08 0.22 0.46 0.59]\n",
      "Epoch 1771, Accuracy: 0.9146341383457184, Accuracies: [1.   0.95 0.88 0.83]\n",
      "Epoch 1781, Loss: 0.31202454678714275, Accuracy: 0.920731708407402\n",
      "Epoch 1781, Loss: 0.31202454678714275, Losses: [0.08 0.17 0.46 0.54]\n",
      "Epoch 1781, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.83 0.88]\n",
      "Epoch 1791, Loss: 0.3066499438136816, Accuracy: 0.9146341532468796\n",
      "Epoch 1791, Loss: 0.3066499438136816, Losses: [0.07 0.17 0.45 0.53]\n",
      "Epoch 1791, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.83 0.85]\n",
      "Epoch 1801, Loss: 0.30319567397236824, Accuracy: 0.9329268336296082\n",
      "Epoch 1801, Loss: 0.30319567397236824, Losses: [0.07 0.16 0.45 0.53]\n",
      "Epoch 1801, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.85 0.9 ]\n",
      "Epoch 1811, Loss: 0.299612196162343, Accuracy: 0.9329268336296082\n",
      "Epoch 1811, Loss: 0.299612196162343, Losses: [0.07 0.16 0.44 0.52]\n",
      "Epoch 1811, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.88 0.88]\n",
      "Epoch 1821, Loss: 0.296907477080822, Accuracy: 0.9329268336296082\n",
      "Epoch 1821, Loss: 0.296907477080822, Losses: [0.07 0.16 0.44 0.51]\n",
      "Epoch 1821, Accuracy: 0.9329268336296082, Accuracies: [1.   1.   0.85 0.88]\n",
      "Epoch 1831, Loss: 0.29256722517311573, Accuracy: 0.9329268336296082\n",
      "Epoch 1831, Loss: 0.29256722517311573, Losses: [0.07 0.16 0.43 0.51]\n",
      "Epoch 1831, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.88 0.88]\n",
      "Epoch 1841, Loss: 0.2990062143653631, Accuracy: 0.9268292784690857\n",
      "Epoch 1841, Loss: 0.2990062143653631, Losses: [0.09 0.16 0.45 0.51]\n",
      "Epoch 1841, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.8  0.93]\n",
      "Epoch 1851, Loss: 0.3448265139013529, Accuracy: 0.8780487924814224\n",
      "Epoch 1851, Loss: 0.3448265139013529, Losses: [0.1  0.17 0.53 0.58]\n",
      "Epoch 1851, Accuracy: 0.8780487924814224, Accuracies: [0.98 0.98 0.76 0.8 ]\n",
      "Epoch 1861, Loss: 0.3273968789726496, Accuracy: 0.9024390280246735\n",
      "Epoch 1861, Loss: 0.3273968789726496, Losses: [0.08 0.16 0.46 0.61]\n",
      "Epoch 1861, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.8  0.83]\n",
      "Epoch 1871, Loss: 0.296063557267189, Accuracy: 0.9207317233085632\n",
      "Epoch 1871, Loss: 0.296063557267189, Losses: [0.07 0.17 0.44 0.51]\n",
      "Epoch 1871, Accuracy: 0.9207317233085632, Accuracies: [1.   0.98 0.85 0.85]\n",
      "Epoch 1881, Loss: 0.28884184546768665, Accuracy: 0.9268292784690857\n",
      "Epoch 1881, Loss: 0.28884184546768665, Losses: [0.07 0.16 0.43 0.5 ]\n",
      "Epoch 1881, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.85 0.88]\n",
      "Epoch 1891, Loss: 0.2837523352354765, Accuracy: 0.9512195140123367\n",
      "Epoch 1891, Loss: 0.2837523352354765, Losses: [0.06 0.16 0.42 0.49]\n",
      "Epoch 1891, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.93 0.9 ]\n",
      "Epoch 1901, Loss: 0.27987839840352535, Accuracy: 0.9512195140123367\n",
      "Epoch 1901, Loss: 0.27987839840352535, Losses: [0.06 0.16 0.42 0.48]\n",
      "Epoch 1901, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.9  0.93]\n",
      "Epoch 1911, Loss: 0.27659657038748264, Accuracy: 0.9634146392345428\n",
      "Epoch 1911, Loss: 0.27659657038748264, Losses: [0.06 0.15 0.42 0.48]\n",
      "Epoch 1911, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.93 0.95]\n",
      "Epoch 1921, Loss: 0.2785922670736909, Accuracy: 0.9451219588518143\n",
      "Epoch 1921, Loss: 0.2785922670736909, Losses: [0.06 0.16 0.42 0.47]\n",
      "Epoch 1921, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.88 0.93]\n",
      "Epoch 1931, Loss: 0.2833961257711053, Accuracy: 0.9451219439506531\n",
      "Epoch 1931, Loss: 0.2833961257711053, Losses: [0.06 0.15 0.41 0.51]\n",
      "Epoch 1931, Accuracy: 0.9451219439506531, Accuracies: [1.   0.98 0.9  0.9 ]\n",
      "Epoch 1941, Loss: 0.26948302797973156, Accuracy: 0.9512195140123367\n",
      "Epoch 1941, Loss: 0.26948302797973156, Losses: [0.06 0.15 0.41 0.46]\n",
      "Epoch 1941, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.9  0.93]\n",
      "Epoch 1951, Loss: 0.2876596748828888, Accuracy: 0.9329268336296082\n",
      "Epoch 1951, Loss: 0.2876596748828888, Losses: [0.06 0.16 0.47 0.46]\n",
      "Epoch 1951, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.83 0.93]\n",
      "Epoch 1961, Loss: 0.26721157878637314, Accuracy: 0.9573170691728592\n",
      "Epoch 1961, Loss: 0.26721157878637314, Losses: [0.06 0.16 0.4  0.45]\n",
      "Epoch 1961, Accuracy: 0.9573170691728592, Accuracies: [1.   1.   0.9  0.93]\n",
      "Epoch 1971, Loss: 0.2618043189868331, Accuracy: 0.9634146392345428\n",
      "Epoch 1971, Loss: 0.2618043189868331, Losses: [0.06 0.15 0.4  0.45]\n",
      "Epoch 1971, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.93 0.95]\n",
      "Epoch 1981, Loss: 0.284239599481225, Accuracy: 0.9329268336296082\n",
      "Epoch 1981, Loss: 0.284239599481225, Losses: [0.06 0.15 0.44 0.5 ]\n",
      "Epoch 1981, Accuracy: 0.9329268336296082, Accuracies: [1.   1.   0.88 0.85]\n",
      "Epoch 1991, Loss: 0.2641392694786191, Accuracy: 0.9451219439506531\n",
      "Epoch 1991, Loss: 0.2641392694786191, Losses: [0.05 0.15 0.4  0.45]\n",
      "Epoch 1991, Accuracy: 0.9451219439506531, Accuracies: [1.   0.98 0.9  0.9 ]\n",
      "Epoch 2001, Loss: 0.2866954654455185, Accuracy: 0.9390243887901306\n",
      "Epoch 2001, Loss: 0.2866954654455185, Losses: [0.11 0.2  0.4  0.44]\n",
      "Epoch 2001, Accuracy: 0.9390243887901306, Accuracies: [0.98 0.95 0.9  0.93]\n",
      "Epoch 2011, Loss: 0.26373095996677876, Accuracy: 0.9268292784690857\n",
      "Epoch 2011, Loss: 0.26373095996677876, Losses: [0.05 0.15 0.4  0.45]\n",
      "Epoch 2011, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 2021, Loss: 0.26203478686511517, Accuracy: 0.9573170691728592\n",
      "Epoch 2021, Loss: 0.26203478686511517, Losses: [0.05 0.15 0.41 0.43]\n",
      "Epoch 2021, Accuracy: 0.9573170691728592, Accuracies: [1.   1.   0.88 0.95]\n",
      "Epoch 2031, Loss: 0.2538809832185507, Accuracy: 0.9512195140123367\n",
      "Epoch 2031, Loss: 0.2538809832185507, Losses: [0.05 0.15 0.39 0.43]\n",
      "Epoch 2031, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.9  0.93]\n",
      "Epoch 2041, Loss: 0.2477698689326644, Accuracy: 0.9634146392345428\n",
      "Epoch 2041, Loss: 0.2477698689326644, Losses: [0.05 0.15 0.38 0.42]\n",
      "Epoch 2041, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.93 0.95]\n",
      "Epoch 2051, Loss: 0.24670248478651047, Accuracy: 0.9634146392345428\n",
      "Epoch 2051, Loss: 0.24670248478651047, Losses: [0.05 0.15 0.37 0.41]\n",
      "Epoch 2051, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.93 0.95]\n",
      "Epoch 2061, Loss: 0.24312264006584883, Accuracy: 0.9634146392345428\n",
      "Epoch 2061, Loss: 0.24312264006584883, Losses: [0.05 0.14 0.37 0.41]\n",
      "Epoch 2061, Accuracy: 0.9634146392345428, Accuracies: [1.   0.98 0.93 0.95]\n",
      "Epoch 2071, Loss: 0.24208713695406914, Accuracy: 0.9573170691728592\n",
      "Epoch 2071, Loss: 0.24208713695406914, Losses: [0.05 0.14 0.37 0.4 ]\n",
      "Epoch 2071, Accuracy: 0.9573170691728592, Accuracies: [1.   0.98 0.9  0.95]\n",
      "Epoch 2081, Loss: 0.24324234668165445, Accuracy: 0.9695121943950653\n",
      "Epoch 2081, Loss: 0.24324234668165445, Losses: [0.05 0.15 0.37 0.4 ]\n",
      "Epoch 2081, Accuracy: 0.9695121943950653, Accuracies: [1.   1.   0.9  0.98]\n",
      "Early stopping criteria met\n",
      "Training LSTMA...\n",
      "Epoch 1, Loss: 2.1494290828704834, Accuracy: 0.060975611209869385\n",
      "Epoch 1, Loss: 2.1494290828704834, Losses: [2.09 2.18 2.14 2.19]\n",
      "Epoch 1, Accuracy: 0.060975611209869385, Accuracies: [0.24 0.   0.   0.  ]\n",
      "Epoch 11, Loss: 2.081777334213257, Accuracy: 0.060975611209869385\n",
      "Epoch 11, Loss: 2.081777334213257, Losses: [2.03 2.11 2.08 2.11]\n",
      "Epoch 11, Accuracy: 0.060975611209869385, Accuracies: [0.24 0.   0.   0.  ]\n",
      "Epoch 21, Loss: 1.9867256879806519, Accuracy: 0.17073170468211174\n",
      "Epoch 21, Loss: 1.9867256879806519, Losses: [1.97 2.   1.98 2.  ]\n",
      "Epoch 21, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.15 0.12 0.22]\n",
      "Epoch 31, Loss: 1.9297368824481964, Accuracy: 0.18292682990431786\n",
      "Epoch 31, Loss: 1.9297368824481964, Losses: [1.99 1.92 1.9  1.92]\n",
      "Epoch 31, Accuracy: 0.18292682990431786, Accuracies: [0.22 0.17 0.17 0.17]\n",
      "Epoch 41, Loss: 1.9134994447231293, Accuracy: 0.19512195140123367\n",
      "Epoch 41, Loss: 1.9134994447231293, Losses: [2.02 1.89 1.87 1.88]\n",
      "Epoch 41, Accuracy: 0.19512195140123367, Accuracies: [0.22 0.15 0.17 0.24]\n",
      "Epoch 51, Loss: 1.9067387580871582, Accuracy: 0.19512195512652397\n",
      "Epoch 51, Loss: 1.9067387580871582, Losses: [2.03 1.87 1.85 1.87]\n",
      "Epoch 51, Accuracy: 0.19512195512652397, Accuracies: [0.24 0.12 0.17 0.24]\n",
      "Epoch 61, Loss: 1.9007230401039124, Accuracy: 0.21341463550925255\n",
      "Epoch 61, Loss: 1.9007230401039124, Losses: [2.03 1.87 1.85 1.85]\n",
      "Epoch 61, Accuracy: 0.21341463550925255, Accuracies: [0.24 0.17 0.2  0.24]\n",
      "Epoch 71, Loss: 1.8955217897891998, Accuracy: 0.19512195140123367\n",
      "Epoch 71, Loss: 1.8955217897891998, Losses: [2.03 1.87 1.84 1.85]\n",
      "Epoch 71, Accuracy: 0.19512195140123367, Accuracies: [0.22 0.17 0.17 0.22]\n",
      "Epoch 81, Loss: 1.8895837664604187, Accuracy: 0.20121951028704643\n",
      "Epoch 81, Loss: 1.8895837664604187, Losses: [2.03 1.86 1.83 1.83]\n",
      "Epoch 81, Accuracy: 0.20121951028704643, Accuracies: [0.22 0.17 0.2  0.22]\n",
      "Epoch 91, Loss: 1.884171038866043, Accuracy: 0.20121951028704643\n",
      "Epoch 91, Loss: 1.884171038866043, Losses: [2.02 1.86 1.83 1.82]\n",
      "Epoch 91, Accuracy: 0.20121951028704643, Accuracies: [0.22 0.17 0.2  0.22]\n",
      "Epoch 101, Loss: 1.8775224089622498, Accuracy: 0.21341463178396225\n",
      "Epoch 101, Loss: 1.8775224089622498, Losses: [2.01 1.86 1.82 1.82]\n",
      "Epoch 101, Accuracy: 0.21341463178396225, Accuracies: [0.22 0.2  0.22 0.22]\n",
      "Epoch 111, Loss: 1.8672128915786743, Accuracy: 0.2073170691728592\n",
      "Epoch 111, Loss: 1.8672128915786743, Losses: [1.98 1.86 1.81 1.81]\n",
      "Epoch 111, Accuracy: 0.2073170691728592, Accuracies: [0.22 0.2  0.22 0.2 ]\n",
      "Epoch 121, Loss: 1.847976803779602, Accuracy: 0.2073170728981495\n",
      "Epoch 121, Loss: 1.847976803779602, Losses: [1.94 1.85 1.8  1.8 ]\n",
      "Epoch 121, Accuracy: 0.2073170728981495, Accuracies: [0.22 0.17 0.24 0.2 ]\n",
      "Epoch 131, Loss: 1.8263718485832214, Accuracy: 0.2073170691728592\n",
      "Epoch 131, Loss: 1.8263718485832214, Losses: [1.91 1.83 1.79 1.78]\n",
      "Epoch 131, Accuracy: 0.2073170691728592, Accuracies: [0.24 0.2  0.2  0.2 ]\n",
      "Epoch 141, Loss: 1.7938103377819061, Accuracy: 0.24390244483947754\n",
      "Epoch 141, Loss: 1.7938103377819061, Losses: [1.87 1.79 1.74 1.77]\n",
      "Epoch 141, Accuracy: 0.24390244483947754, Accuracies: [0.24 0.22 0.27 0.24]\n",
      "Epoch 151, Loss: 1.7516853511333466, Accuracy: 0.3231707364320755\n",
      "Epoch 151, Loss: 1.7516853511333466, Losses: [1.82 1.74 1.7  1.75]\n",
      "Epoch 151, Accuracy: 0.3231707364320755, Accuracies: [0.24 0.37 0.44 0.24]\n",
      "Epoch 161, Loss: 1.7070664167404175, Accuracy: 0.3658536598086357\n",
      "Epoch 161, Loss: 1.7070664167404175, Losses: [1.75 1.69 1.65 1.73]\n",
      "Epoch 161, Accuracy: 0.3658536598086357, Accuracies: [0.24 0.46 0.46 0.29]\n",
      "Epoch 171, Loss: 1.664649337530136, Accuracy: 0.3536585345864296\n",
      "Epoch 171, Loss: 1.664649337530136, Losses: [1.67 1.65 1.63 1.71]\n",
      "Epoch 171, Accuracy: 0.3536585345864296, Accuracies: [0.24 0.41 0.44 0.32]\n",
      "Epoch 181, Loss: 1.6262266039848328, Accuracy: 0.3658536598086357\n",
      "Epoch 181, Loss: 1.6262266039848328, Losses: [1.59 1.61 1.61 1.7 ]\n",
      "Epoch 181, Accuracy: 0.3658536598086357, Accuracies: [0.24 0.49 0.41 0.32]\n",
      "Epoch 191, Loss: 1.5920571088790894, Accuracy: 0.3963414579629898\n",
      "Epoch 191, Loss: 1.5920571088790894, Losses: [1.53 1.57 1.58 1.68]\n",
      "Epoch 191, Accuracy: 0.3963414579629898, Accuracies: [0.32 0.51 0.46 0.29]\n",
      "Epoch 201, Loss: 1.5618618428707123, Accuracy: 0.40243902802467346\n",
      "Epoch 201, Loss: 1.5618618428707123, Losses: [1.47 1.53 1.57 1.68]\n",
      "Epoch 201, Accuracy: 0.40243902802467346, Accuracies: [0.37 0.54 0.41 0.29]\n",
      "Epoch 211, Loss: 1.5422681868076324, Accuracy: 0.4146341532468796\n",
      "Epoch 211, Loss: 1.5422681868076324, Losses: [1.43 1.51 1.56 1.67]\n",
      "Epoch 211, Accuracy: 0.4146341532468796, Accuracies: [0.46 0.54 0.39 0.27]\n",
      "Epoch 221, Loss: 1.5210573971271515, Accuracy: 0.4268292710185051\n",
      "Epoch 221, Loss: 1.5210573971271515, Losses: [1.39 1.48 1.54 1.67]\n",
      "Epoch 221, Accuracy: 0.4268292710185051, Accuracies: [0.46 0.54 0.41 0.29]\n",
      "Epoch 231, Loss: 1.5025656819343567, Accuracy: 0.4146341383457184\n",
      "Epoch 231, Loss: 1.5025656819343567, Losses: [1.36 1.45 1.53 1.66]\n",
      "Epoch 231, Accuracy: 0.4146341383457184, Accuracies: [0.44 0.51 0.41 0.29]\n",
      "Epoch 241, Loss: 1.4827963709831238, Accuracy: 0.4268292635679245\n",
      "Epoch 241, Loss: 1.4827963709831238, Losses: [1.34 1.43 1.52 1.65]\n",
      "Epoch 241, Accuracy: 0.4268292635679245, Accuracies: [0.46 0.51 0.41 0.32]\n",
      "Epoch 251, Loss: 1.4634206891059875, Accuracy: 0.43292682617902756\n",
      "Epoch 251, Loss: 1.4634206891059875, Losses: [1.31 1.41 1.49 1.64]\n",
      "Epoch 251, Accuracy: 0.43292682617902756, Accuracies: [0.49 0.51 0.41 0.32]\n",
      "Epoch 261, Loss: 1.4482067227363586, Accuracy: 0.43292681872844696\n",
      "Epoch 261, Loss: 1.4482067227363586, Losses: [1.3  1.38 1.49 1.63]\n",
      "Epoch 261, Accuracy: 0.43292681872844696, Accuracies: [0.51 0.51 0.41 0.29]\n",
      "Epoch 271, Loss: 1.4301834106445312, Accuracy: 0.45121949911117554\n",
      "Epoch 271, Loss: 1.4301834106445312, Losses: [1.27 1.36 1.47 1.62]\n",
      "Epoch 271, Accuracy: 0.45121949911117554, Accuracies: [0.59 0.51 0.41 0.29]\n",
      "Epoch 281, Loss: 1.412979781627655, Accuracy: 0.4695121943950653\n",
      "Epoch 281, Loss: 1.412979781627655, Losses: [1.25 1.33 1.46 1.6 ]\n",
      "Epoch 281, Accuracy: 0.4695121943950653, Accuracies: [0.63 0.49 0.44 0.32]\n",
      "Epoch 291, Loss: 1.3974137604236603, Accuracy: 0.46341463178396225\n",
      "Epoch 291, Loss: 1.3974137604236603, Losses: [1.23 1.31 1.45 1.59]\n",
      "Epoch 291, Accuracy: 0.46341463178396225, Accuracies: [0.63 0.49 0.44 0.29]\n",
      "Epoch 301, Loss: 1.382942408323288, Accuracy: 0.46341463178396225\n",
      "Epoch 301, Loss: 1.382942408323288, Losses: [1.21 1.29 1.44 1.58]\n",
      "Epoch 301, Accuracy: 0.46341463178396225, Accuracies: [0.63 0.46 0.44 0.32]\n",
      "Epoch 311, Loss: 1.3705554604530334, Accuracy: 0.4878048896789551\n",
      "Epoch 311, Loss: 1.3705554604530334, Losses: [1.2  1.28 1.44 1.57]\n",
      "Epoch 311, Accuracy: 0.4878048896789551, Accuracies: [0.66 0.49 0.44 0.37]\n",
      "Epoch 321, Loss: 1.357073187828064, Accuracy: 0.481707327067852\n",
      "Epoch 321, Loss: 1.357073187828064, Losses: [1.18 1.26 1.43 1.56]\n",
      "Epoch 321, Accuracy: 0.481707327067852, Accuracies: [0.66 0.46 0.44 0.37]\n",
      "Epoch 331, Loss: 1.345572143793106, Accuracy: 0.49390245229005814\n",
      "Epoch 331, Loss: 1.345572143793106, Losses: [1.17 1.25 1.42 1.55]\n",
      "Epoch 331, Accuracy: 0.49390245229005814, Accuracies: [0.66 0.49 0.46 0.37]\n",
      "Epoch 341, Loss: 1.3349236845970154, Accuracy: 0.49390244483947754\n",
      "Epoch 341, Loss: 1.3349236845970154, Losses: [1.15 1.23 1.41 1.54]\n",
      "Epoch 341, Accuracy: 0.49390244483947754, Accuracies: [0.66 0.49 0.44 0.39]\n",
      "Epoch 351, Loss: 1.3247602581977844, Accuracy: 0.5000000074505806\n",
      "Epoch 351, Loss: 1.3247602581977844, Losses: [1.14 1.22 1.4  1.54]\n",
      "Epoch 351, Accuracy: 0.5000000074505806, Accuracies: [0.66 0.49 0.46 0.39]\n",
      "Epoch 361, Loss: 1.315022051334381, Accuracy: 0.5000000074505806\n",
      "Epoch 361, Loss: 1.315022051334381, Losses: [1.13 1.2  1.4  1.53]\n",
      "Epoch 361, Accuracy: 0.5000000074505806, Accuracies: [0.66 0.49 0.46 0.39]\n",
      "Epoch 371, Loss: 1.3057250082492828, Accuracy: 0.5000000074505806\n",
      "Epoch 371, Loss: 1.3057250082492828, Losses: [1.11 1.19 1.39 1.52]\n",
      "Epoch 371, Accuracy: 0.5000000074505806, Accuracies: [0.66 0.49 0.46 0.39]\n",
      "Epoch 381, Loss: 1.2976437509059906, Accuracy: 0.49390244483947754\n",
      "Epoch 381, Loss: 1.2976437509059906, Losses: [1.1  1.18 1.39 1.52]\n",
      "Epoch 381, Accuracy: 0.49390244483947754, Accuracies: [0.66 0.46 0.46 0.39]\n",
      "Epoch 391, Loss: 1.287265807390213, Accuracy: 0.5000000074505806\n",
      "Epoch 391, Loss: 1.287265807390213, Losses: [1.09 1.17 1.38 1.51]\n",
      "Epoch 391, Accuracy: 0.5000000074505806, Accuracies: [0.66 0.49 0.46 0.39]\n",
      "Epoch 401, Loss: 1.2784551680088043, Accuracy: 0.5060975700616837\n",
      "Epoch 401, Loss: 1.2784551680088043, Losses: [1.07 1.16 1.38 1.5 ]\n",
      "Epoch 401, Accuracy: 0.5060975700616837, Accuracies: [0.66 0.49 0.46 0.41]\n",
      "Epoch 411, Loss: 1.2745299339294434, Accuracy: 0.49390243738889694\n",
      "Epoch 411, Loss: 1.2745299339294434, Losses: [1.06 1.14 1.38 1.52]\n",
      "Epoch 411, Accuracy: 0.49390243738889694, Accuracies: [0.63 0.49 0.51 0.34]\n",
      "Epoch 421, Loss: 1.2549924850463867, Accuracy: 0.5000000074505806\n",
      "Epoch 421, Loss: 1.2549924850463867, Losses: [1.04 1.12 1.38 1.49]\n",
      "Epoch 421, Accuracy: 0.5000000074505806, Accuracies: [0.66 0.49 0.46 0.39]\n",
      "Epoch 431, Loss: 1.2381059527397156, Accuracy: 0.5121951252222061\n",
      "Epoch 431, Loss: 1.2381059527397156, Losses: [1.02 1.08 1.38 1.48]\n",
      "Epoch 431, Accuracy: 0.5121951252222061, Accuracies: [0.68 0.51 0.49 0.37]\n",
      "Epoch 441, Loss: 1.2223152369260788, Accuracy: 0.5548780485987663\n",
      "Epoch 441, Loss: 1.2223152369260788, Losses: [1.   1.05 1.37 1.47]\n",
      "Epoch 441, Accuracy: 0.5548780485987663, Accuracies: [0.68 0.63 0.49 0.41]\n",
      "Epoch 451, Loss: 1.206589326262474, Accuracy: 0.5548780485987663\n",
      "Epoch 451, Loss: 1.206589326262474, Losses: [0.98 1.01 1.37 1.46]\n",
      "Epoch 451, Accuracy: 0.5548780485987663, Accuracies: [0.68 0.63 0.49 0.41]\n",
      "Epoch 461, Loss: 1.1928198635578156, Accuracy: 0.5731707364320755\n",
      "Epoch 461, Loss: 1.1928198635578156, Losses: [0.97 0.98 1.37 1.45]\n",
      "Epoch 461, Accuracy: 0.5731707364320755, Accuracies: [0.73 0.63 0.49 0.44]\n",
      "Epoch 471, Loss: 1.1964111775159836, Accuracy: 0.5609756037592888\n",
      "Epoch 471, Loss: 1.1964111775159836, Losses: [0.97 0.95 1.42 1.44]\n",
      "Epoch 471, Accuracy: 0.5609756037592888, Accuracies: [0.68 0.71 0.44 0.41]\n",
      "Epoch 481, Loss: 1.1959016025066376, Accuracy: 0.5426829382777214\n",
      "Epoch 481, Loss: 1.1959016025066376, Losses: [0.94 0.94 1.38 1.53]\n",
      "Epoch 481, Accuracy: 0.5426829382777214, Accuracies: [0.68 0.68 0.54 0.27]\n",
      "Epoch 491, Loss: 1.1551470309495926, Accuracy: 0.5853658616542816\n",
      "Epoch 491, Loss: 1.1551470309495926, Losses: [0.93 0.9  1.37 1.42]\n",
      "Epoch 491, Accuracy: 0.5853658616542816, Accuracies: [0.73 0.68 0.49 0.44]\n",
      "Epoch 501, Loss: 1.1435246914625168, Accuracy: 0.603658527135849\n",
      "Epoch 501, Loss: 1.1435246914625168, Losses: [0.91 0.88 1.37 1.41]\n",
      "Epoch 501, Accuracy: 0.603658527135849, Accuracies: [0.76 0.71 0.51 0.44]\n",
      "Epoch 511, Loss: 1.136113479733467, Accuracy: 0.6097560897469521\n",
      "Epoch 511, Loss: 1.136113479733467, Losses: [0.9  0.86 1.37 1.41]\n",
      "Epoch 511, Accuracy: 0.6097560897469521, Accuracies: [0.78 0.73 0.51 0.41]\n",
      "Epoch 521, Loss: 1.1362673789262772, Accuracy: 0.5914634168148041\n",
      "Epoch 521, Loss: 1.1362673789262772, Losses: [0.89 0.87 1.36 1.42]\n",
      "Epoch 521, Accuracy: 0.5914634168148041, Accuracies: [0.78 0.66 0.54 0.39]\n",
      "Epoch 531, Loss: 1.1183399856090546, Accuracy: 0.6097560971975327\n",
      "Epoch 531, Loss: 1.1183399856090546, Losses: [0.89 0.84 1.35 1.39]\n",
      "Epoch 531, Accuracy: 0.6097560971975327, Accuracies: [0.68 0.88 0.46 0.41]\n",
      "Epoch 541, Loss: 1.1158690452575684, Accuracy: 0.6463414579629898\n",
      "Epoch 541, Loss: 1.1158690452575684, Losses: [0.87 0.82 1.35 1.42]\n",
      "Epoch 541, Accuracy: 0.6463414579629898, Accuracies: [0.8  0.9  0.46 0.41]\n",
      "Epoch 551, Loss: 1.1098965108394623, Accuracy: 0.6341463401913643\n",
      "Epoch 551, Loss: 1.1098965108394623, Losses: [0.86 0.82 1.35 1.41]\n",
      "Epoch 551, Accuracy: 0.6341463401913643, Accuracies: [0.8  0.83 0.49 0.41]\n",
      "Epoch 561, Loss: 1.0888689309358597, Accuracy: 0.6341463401913643\n",
      "Epoch 561, Loss: 1.0888689309358597, Losses: [0.85 0.79 1.34 1.37]\n",
      "Epoch 561, Accuracy: 0.6341463401913643, Accuracies: [0.83 0.85 0.46 0.39]\n",
      "Epoch 571, Loss: 1.0797939747571945, Accuracy: 0.6524390205740929\n",
      "Epoch 571, Loss: 1.0797939747571945, Losses: [0.84 0.78 1.34 1.37]\n",
      "Epoch 571, Accuracy: 0.6524390205740929, Accuracies: [0.83 0.85 0.51 0.41]\n",
      "Epoch 581, Loss: 1.0771243572235107, Accuracy: 0.6890243738889694\n",
      "Epoch 581, Loss: 1.0771243572235107, Losses: [0.83 0.77 1.33 1.37]\n",
      "Epoch 581, Accuracy: 0.6890243738889694, Accuracies: [0.83 0.9  0.51 0.51]\n",
      "Epoch 591, Loss: 1.0673807710409164, Accuracy: 0.6524390131235123\n",
      "Epoch 591, Loss: 1.0673807710409164, Losses: [0.82 0.76 1.34 1.36]\n",
      "Epoch 591, Accuracy: 0.6524390131235123, Accuracies: [0.83 0.9  0.49 0.39]\n",
      "Epoch 601, Loss: 1.0581179708242416, Accuracy: 0.6768292635679245\n",
      "Epoch 601, Loss: 1.0581179708242416, Losses: [0.81 0.74 1.33 1.35]\n",
      "Epoch 601, Accuracy: 0.6768292635679245, Accuracies: [0.83 0.9  0.54 0.44]\n",
      "Epoch 611, Loss: 1.0599549561738968, Accuracy: 0.6219512149691582\n",
      "Epoch 611, Loss: 1.0599549561738968, Losses: [0.81 0.73 1.33 1.37]\n",
      "Epoch 611, Accuracy: 0.6219512149691582, Accuracies: [0.78 0.85 0.46 0.39]\n",
      "Epoch 621, Loss: 1.0467087775468826, Accuracy: 0.6524390205740929\n",
      "Epoch 621, Loss: 1.0467087775468826, Losses: [0.8  0.72 1.32 1.35]\n",
      "Epoch 621, Accuracy: 0.6524390205740929, Accuracies: [0.8  0.88 0.51 0.41]\n",
      "Epoch 631, Loss: 1.037163957953453, Accuracy: 0.6463414505124092\n",
      "Epoch 631, Loss: 1.037163957953453, Losses: [0.79 0.71 1.32 1.33]\n",
      "Epoch 631, Accuracy: 0.6463414505124092, Accuracies: [0.83 0.9  0.46 0.39]\n",
      "Epoch 641, Loss: 1.0330121368169785, Accuracy: 0.6646341308951378\n",
      "Epoch 641, Loss: 1.0330121368169785, Losses: [0.78 0.7  1.31 1.34]\n",
      "Epoch 641, Accuracy: 0.6646341308951378, Accuracies: [0.83 0.9  0.51 0.41]\n",
      "Epoch 651, Loss: 1.0235271602869034, Accuracy: 0.682926818728447\n",
      "Epoch 651, Loss: 1.0235271602869034, Losses: [0.77 0.69 1.31 1.32]\n",
      "Epoch 651, Accuracy: 0.682926818728447, Accuracies: [0.83 0.9  0.51 0.49]\n",
      "Epoch 661, Loss: 1.0170916020870209, Accuracy: 0.6890243738889694\n",
      "Epoch 661, Loss: 1.0170916020870209, Losses: [0.76 0.68 1.31 1.32]\n",
      "Epoch 661, Accuracy: 0.6890243738889694, Accuracies: [0.83 0.9  0.51 0.51]\n",
      "Epoch 671, Loss: 1.0103890150785446, Accuracy: 0.6768292635679245\n",
      "Epoch 671, Loss: 1.0103890150785446, Losses: [0.76 0.67 1.3  1.31]\n",
      "Epoch 671, Accuracy: 0.6768292635679245, Accuracies: [0.83 0.88 0.51 0.49]\n",
      "Epoch 681, Loss: 1.0038792937994003, Accuracy: 0.6890243887901306\n",
      "Epoch 681, Loss: 1.0038792937994003, Losses: [0.75 0.66 1.3  1.31]\n",
      "Epoch 681, Accuracy: 0.6890243887901306, Accuracies: [0.83 0.93 0.51 0.49]\n",
      "Epoch 691, Loss: 1.0031532943248749, Accuracy: 0.707317054271698\n",
      "Epoch 691, Loss: 1.0031532943248749, Losses: [0.74 0.65 1.29 1.32]\n",
      "Epoch 691, Accuracy: 0.707317054271698, Accuracies: [0.83 0.9  0.51 0.59]\n",
      "Epoch 701, Loss: 0.9950143843889236, Accuracy: 0.7134146243333817\n",
      "Epoch 701, Loss: 0.9950143843889236, Losses: [0.74 0.65 1.3  1.3 ]\n",
      "Epoch 701, Accuracy: 0.7134146243333817, Accuracies: [0.83 0.95 0.49 0.59]\n",
      "Epoch 711, Loss: 0.9866631329059601, Accuracy: 0.7012194991111755\n",
      "Epoch 711, Loss: 0.9866631329059601, Losses: [0.73 0.63 1.29 1.29]\n",
      "Epoch 711, Accuracy: 0.7012194991111755, Accuracies: [0.83 0.9  0.51 0.56]\n",
      "Epoch 721, Loss: 0.9862433820962906, Accuracy: 0.6707317009568214\n",
      "Epoch 721, Loss: 0.9862433820962906, Losses: [0.72 0.63 1.29 1.31]\n",
      "Epoch 721, Accuracy: 0.6707317009568214, Accuracies: [0.83 0.9  0.46 0.49]\n",
      "Epoch 731, Loss: 0.9874667078256607, Accuracy: 0.6890243887901306\n",
      "Epoch 731, Loss: 0.9874667078256607, Losses: [0.71 0.62 1.3  1.31]\n",
      "Epoch 731, Accuracy: 0.6890243887901306, Accuracies: [0.83 0.9  0.49 0.54]\n",
      "Epoch 741, Loss: 0.977367028594017, Accuracy: 0.6890243887901306\n",
      "Epoch 741, Loss: 0.977367028594017, Losses: [0.71 0.62 1.28 1.3 ]\n",
      "Epoch 741, Accuracy: 0.6890243887901306, Accuracies: [0.83 0.88 0.51 0.54]\n",
      "Epoch 751, Loss: 0.9758957773447037, Accuracy: 0.7134146243333817\n",
      "Epoch 751, Loss: 0.9758957773447037, Losses: [0.7  0.62 1.28 1.3 ]\n",
      "Epoch 751, Accuracy: 0.7134146243333817, Accuracies: [0.83 0.9  0.51 0.61]\n",
      "Epoch 761, Loss: 0.993394210934639, Accuracy: 0.7134146243333817\n",
      "Epoch 761, Loss: 0.993394210934639, Losses: [0.7  0.62 1.35 1.3 ]\n",
      "Epoch 761, Accuracy: 0.7134146243333817, Accuracies: [0.8  0.95 0.51 0.59]\n",
      "Epoch 771, Loss: 0.9656845927238464, Accuracy: 0.7134146243333817\n",
      "Epoch 771, Loss: 0.9656845927238464, Losses: [0.68 0.6  1.28 1.3 ]\n",
      "Epoch 771, Accuracy: 0.7134146243333817, Accuracies: [0.83 0.95 0.51 0.56]\n",
      "Epoch 781, Loss: 0.9482310712337494, Accuracy: 0.7195121943950653\n",
      "Epoch 781, Loss: 0.9482310712337494, Losses: [0.67 0.59 1.27 1.27]\n",
      "Epoch 781, Accuracy: 0.7195121943950653, Accuracies: [0.83 0.95 0.54 0.56]\n",
      "Epoch 791, Loss: 0.9409652948379517, Accuracy: 0.7012195140123367\n",
      "Epoch 791, Loss: 0.9409652948379517, Losses: [0.66 0.58 1.26 1.26]\n",
      "Epoch 791, Accuracy: 0.7012195140123367, Accuracies: [0.85 0.93 0.51 0.51]\n",
      "Epoch 801, Loss: 0.9356657117605209, Accuracy: 0.725609764456749\n",
      "Epoch 801, Loss: 0.9356657117605209, Losses: [0.65 0.57 1.26 1.26]\n",
      "Epoch 801, Accuracy: 0.725609764456749, Accuracies: [0.85 0.98 0.51 0.56]\n",
      "Epoch 811, Loss: 0.9300110191106796, Accuracy: 0.725609764456749\n",
      "Epoch 811, Loss: 0.9300110191106796, Losses: [0.64 0.56 1.26 1.25]\n",
      "Epoch 811, Accuracy: 0.725609764456749, Accuracies: [0.85 0.95 0.54 0.56]\n",
      "Epoch 821, Loss: 0.9277710169553757, Accuracy: 0.7256097793579102\n",
      "Epoch 821, Loss: 0.9277710169553757, Losses: [0.64 0.56 1.26 1.26]\n",
      "Epoch 821, Accuracy: 0.7256097793579102, Accuracies: [0.85 0.98 0.54 0.54]\n",
      "Epoch 831, Loss: 0.9259800910949707, Accuracy: 0.7378048896789551\n",
      "Epoch 831, Loss: 0.9259800910949707, Losses: [0.63 0.56 1.26 1.26]\n",
      "Epoch 831, Accuracy: 0.7378048896789551, Accuracies: [0.85 0.98 0.56 0.56]\n",
      "Epoch 841, Loss: 0.9188381731510162, Accuracy: 0.7317073196172714\n",
      "Epoch 841, Loss: 0.9188381731510162, Losses: [0.63 0.54 1.25 1.26]\n",
      "Epoch 841, Accuracy: 0.7317073196172714, Accuracies: [0.88 0.98 0.59 0.49]\n",
      "Epoch 851, Loss: 0.9078079462051392, Accuracy: 0.7439024448394775\n",
      "Epoch 851, Loss: 0.9078079462051392, Losses: [0.62 0.54 1.24 1.24]\n",
      "Epoch 851, Accuracy: 0.7439024448394775, Accuracies: [0.88 0.98 0.56 0.56]\n",
      "Epoch 861, Loss: 0.9016374796628952, Accuracy: 0.75\n",
      "Epoch 861, Loss: 0.9016374796628952, Losses: [0.61 0.53 1.24 1.23]\n",
      "Epoch 861, Accuracy: 0.75, Accuracies: [0.88 1.   0.56 0.56]\n",
      "Epoch 871, Loss: 0.9353056848049164, Accuracy: 0.725609764456749\n",
      "Epoch 871, Loss: 0.9353056848049164, Losses: [0.6  0.53 1.31 1.3 ]\n",
      "Epoch 871, Accuracy: 0.725609764456749, Accuracies: [0.88 0.98 0.54 0.51]\n",
      "Epoch 881, Loss: 0.9225776344537735, Accuracy: 0.7256097495555878\n",
      "Epoch 881, Loss: 0.9225776344537735, Losses: [0.61 0.53 1.23 1.33]\n",
      "Epoch 881, Accuracy: 0.7256097495555878, Accuracies: [0.88 0.95 0.59 0.49]\n",
      "Epoch 891, Loss: 0.8900613933801651, Accuracy: 0.7439024448394775\n",
      "Epoch 891, Loss: 0.8900613933801651, Losses: [0.59 0.52 1.23 1.22]\n",
      "Epoch 891, Accuracy: 0.7439024448394775, Accuracies: [0.88 0.98 0.59 0.54]\n",
      "Epoch 901, Loss: 0.8820942640304565, Accuracy: 0.75\n",
      "Epoch 901, Loss: 0.8820942640304565, Losses: [0.58 0.51 1.22 1.21]\n",
      "Epoch 901, Accuracy: 0.75, Accuracies: [0.88 1.   0.59 0.54]\n",
      "Epoch 911, Loss: 0.8777425587177277, Accuracy: 0.75\n",
      "Epoch 911, Loss: 0.8777425587177277, Losses: [0.58 0.5  1.22 1.21]\n",
      "Epoch 911, Accuracy: 0.75, Accuracies: [0.88 1.   0.59 0.54]\n",
      "Epoch 921, Loss: 0.8712918534874916, Accuracy: 0.7560975700616837\n",
      "Epoch 921, Loss: 0.8712918534874916, Losses: [0.57 0.5  1.21 1.2 ]\n",
      "Epoch 921, Accuracy: 0.7560975700616837, Accuracies: [0.88 1.   0.61 0.54]\n",
      "Epoch 931, Loss: 0.8663434311747551, Accuracy: 0.75\n",
      "Epoch 931, Loss: 0.8663434311747551, Losses: [0.57 0.5  1.21 1.19]\n",
      "Epoch 931, Accuracy: 0.75, Accuracies: [0.88 1.   0.61 0.51]\n",
      "Epoch 941, Loss: 0.8641558587551117, Accuracy: 0.7560975700616837\n",
      "Epoch 941, Loss: 0.8641558587551117, Losses: [0.58 0.49 1.2  1.19]\n",
      "Epoch 941, Accuracy: 0.7560975700616837, Accuracies: [0.88 1.   0.61 0.54]\n",
      "Epoch 951, Loss: 0.8602073267102242, Accuracy: 0.7439024299383163\n",
      "Epoch 951, Loss: 0.8602073267102242, Losses: [0.56 0.48 1.21 1.18]\n",
      "Epoch 951, Accuracy: 0.7439024299383163, Accuracies: [0.88 1.   0.59 0.51]\n",
      "Epoch 961, Loss: 0.8518371433019638, Accuracy: 0.7439024448394775\n",
      "Epoch 961, Loss: 0.8518371433019638, Losses: [0.56 0.48 1.2  1.17]\n",
      "Epoch 961, Accuracy: 0.7439024448394775, Accuracies: [0.88 0.98 0.61 0.51]\n",
      "Epoch 971, Loss: 0.8789819628000259, Accuracy: 0.7073170766234398\n",
      "Epoch 971, Loss: 0.8789819628000259, Losses: [0.55 0.48 1.23 1.26]\n",
      "Epoch 971, Accuracy: 0.7073170766234398, Accuracies: [0.88 0.95 0.54 0.46]\n",
      "Epoch 981, Loss: 0.8505817726254463, Accuracy: 0.7378048747777939\n",
      "Epoch 981, Loss: 0.8505817726254463, Losses: [0.55 0.47 1.2  1.19]\n",
      "Epoch 981, Accuracy: 0.7378048747777939, Accuracies: [0.88 0.98 0.59 0.51]\n",
      "Epoch 991, Loss: 0.8379023522138596, Accuracy: 0.7439024299383163\n",
      "Epoch 991, Loss: 0.8379023522138596, Losses: [0.54 0.46 1.17 1.17]\n",
      "Epoch 991, Accuracy: 0.7439024299383163, Accuracies: [0.88 1.   0.59 0.51]\n",
      "Epoch 1001, Loss: 0.8545909821987152, Accuracy: 0.75\n",
      "Epoch 1001, Loss: 0.8545909821987152, Losses: [0.54 0.46 1.19 1.23]\n",
      "Epoch 1001, Accuracy: 0.75, Accuracies: [0.88 0.98 0.59 0.56]\n",
      "Epoch 1011, Loss: 0.8278808295726776, Accuracy: 0.7378048896789551\n",
      "Epoch 1011, Loss: 0.8278808295726776, Losses: [0.53 0.45 1.17 1.16]\n",
      "Epoch 1011, Accuracy: 0.7378048896789551, Accuracies: [0.88 0.98 0.56 0.54]\n",
      "Epoch 1021, Loss: 0.8259269222617149, Accuracy: 0.7378048896789551\n",
      "Epoch 1021, Loss: 0.8259269222617149, Losses: [0.53 0.45 1.16 1.16]\n",
      "Epoch 1021, Accuracy: 0.7378048896789551, Accuracies: [0.88 0.98 0.61 0.49]\n",
      "Epoch 1031, Loss: 0.8218163698911667, Accuracy: 0.7317073196172714\n",
      "Epoch 1031, Loss: 0.8218163698911667, Losses: [0.52 0.45 1.17 1.15]\n",
      "Epoch 1031, Accuracy: 0.7317073196172714, Accuracies: [0.88 0.98 0.56 0.51]\n",
      "Epoch 1041, Loss: 0.8170385137200356, Accuracy: 0.7378048896789551\n",
      "Epoch 1041, Loss: 0.8170385137200356, Losses: [0.53 0.44 1.15 1.15]\n",
      "Epoch 1041, Accuracy: 0.7378048896789551, Accuracies: [0.85 0.98 0.61 0.51]\n",
      "Epoch 1051, Loss: 0.8068268150091171, Accuracy: 0.75\n",
      "Epoch 1051, Loss: 0.8068268150091171, Losses: [0.51 0.44 1.14 1.14]\n",
      "Epoch 1051, Accuracy: 0.75, Accuracies: [0.88 0.98 0.59 0.56]\n",
      "Epoch 1061, Loss: 0.8125999271869659, Accuracy: 0.75\n",
      "Epoch 1061, Loss: 0.8125999271869659, Losses: [0.51 0.44 1.16 1.14]\n",
      "Epoch 1061, Accuracy: 0.75, Accuracies: [0.88 0.98 0.59 0.56]\n",
      "Epoch 1071, Loss: 0.8974566161632538, Accuracy: 0.7073170766234398\n",
      "Epoch 1071, Loss: 0.8974566161632538, Losses: [0.51 0.46 1.26 1.37]\n",
      "Epoch 1071, Accuracy: 0.7073170766234398, Accuracies: [0.88 0.98 0.51 0.46]\n",
      "Epoch 1081, Loss: 0.7959384098649025, Accuracy: 0.7317073196172714\n",
      "Epoch 1081, Loss: 0.7959384098649025, Losses: [0.5  0.43 1.13 1.12]\n",
      "Epoch 1081, Accuracy: 0.7317073196172714, Accuracies: [0.88 0.98 0.56 0.51]\n",
      "Epoch 1091, Loss: 0.7955333963036537, Accuracy: 0.7500000149011612\n",
      "Epoch 1091, Loss: 0.7955333963036537, Losses: [0.49 0.43 1.13 1.13]\n",
      "Epoch 1091, Accuracy: 0.7500000149011612, Accuracies: [0.88 0.98 0.61 0.54]\n",
      "Epoch 1101, Loss: 0.8225313350558281, Accuracy: 0.7317073121666908\n",
      "Epoch 1101, Loss: 0.8225313350558281, Losses: [0.5  0.43 1.17 1.2 ]\n",
      "Epoch 1101, Accuracy: 0.7317073121666908, Accuracies: [0.88 1.   0.59 0.46]\n",
      "Epoch 1111, Loss: 0.7904389500617981, Accuracy: 0.7317073196172714\n",
      "Epoch 1111, Loss: 0.7904389500617981, Losses: [0.49 0.42 1.12 1.14]\n",
      "Epoch 1111, Accuracy: 0.7317073196172714, Accuracies: [0.88 0.98 0.59 0.49]\n",
      "Epoch 1121, Loss: 0.7907933667302132, Accuracy: 0.7378048747777939\n",
      "Epoch 1121, Loss: 0.7907933667302132, Losses: [0.48 0.43 1.14 1.12]\n",
      "Epoch 1121, Accuracy: 0.7378048747777939, Accuracies: [0.88 0.98 0.59 0.51]\n",
      "Epoch 1131, Loss: 0.7734303772449493, Accuracy: 0.7560975700616837\n",
      "Epoch 1131, Loss: 0.7734303772449493, Losses: [0.48 0.42 1.1  1.1 ]\n",
      "Epoch 1131, Accuracy: 0.7560975700616837, Accuracies: [0.88 0.98 0.61 0.56]\n",
      "Epoch 1141, Loss: 0.7707285284996033, Accuracy: 0.75\n",
      "Epoch 1141, Loss: 0.7707285284996033, Losses: [0.47 0.42 1.1  1.09]\n",
      "Epoch 1141, Accuracy: 0.75, Accuracies: [0.88 0.98 0.59 0.56]\n",
      "Epoch 1151, Loss: 0.7662183567881584, Accuracy: 0.7500000149011612\n",
      "Epoch 1151, Loss: 0.7662183567881584, Losses: [0.47 0.41 1.09 1.09]\n",
      "Epoch 1151, Accuracy: 0.7500000149011612, Accuracies: [0.88 0.98 0.61 0.54]\n",
      "Epoch 1161, Loss: 0.7652824819087982, Accuracy: 0.7560975700616837\n",
      "Epoch 1161, Loss: 0.7652824819087982, Losses: [0.47 0.41 1.09 1.1 ]\n",
      "Epoch 1161, Accuracy: 0.7560975700616837, Accuracies: [0.88 0.98 0.61 0.56]\n",
      "Epoch 1171, Loss: 0.7804697006940842, Accuracy: 0.75\n",
      "Epoch 1171, Loss: 0.7804697006940842, Losses: [0.49 0.41 1.11 1.11]\n",
      "Epoch 1171, Accuracy: 0.75, Accuracies: [0.85 0.98 0.59 0.59]\n",
      "Epoch 1181, Loss: 0.7899879515171051, Accuracy: 0.7439024448394775\n",
      "Epoch 1181, Loss: 0.7899879515171051, Losses: [0.46 0.42 1.15 1.13]\n",
      "Epoch 1181, Accuracy: 0.7439024448394775, Accuracies: [0.88 0.98 0.56 0.56]\n",
      "Epoch 1191, Loss: 0.7497722879052162, Accuracy: 0.7621951252222061\n",
      "Epoch 1191, Loss: 0.7497722879052162, Losses: [0.45 0.41 1.07 1.07]\n",
      "Epoch 1191, Accuracy: 0.7621951252222061, Accuracies: [0.88 0.98 0.61 0.59]\n",
      "Epoch 1201, Loss: 0.7540532574057579, Accuracy: 0.7621951252222061\n",
      "Epoch 1201, Loss: 0.7540532574057579, Losses: [0.45 0.4  1.08 1.08]\n",
      "Epoch 1201, Accuracy: 0.7621951252222061, Accuracies: [0.88 0.98 0.59 0.61]\n",
      "Epoch 1211, Loss: 0.754036471247673, Accuracy: 0.7621951252222061\n",
      "Epoch 1211, Loss: 0.754036471247673, Losses: [0.45 0.4  1.06 1.1 ]\n",
      "Epoch 1211, Accuracy: 0.7621951252222061, Accuracies: [0.88 0.98 0.63 0.56]\n",
      "Epoch 1221, Loss: 0.7370472475886345, Accuracy: 0.75\n",
      "Epoch 1221, Loss: 0.7370472475886345, Losses: [0.44 0.4  1.06 1.05]\n",
      "Epoch 1221, Accuracy: 0.75, Accuracies: [0.88 0.98 0.59 0.56]\n",
      "Epoch 1231, Loss: 0.7343892157077789, Accuracy: 0.7682926803827286\n",
      "Epoch 1231, Loss: 0.7343892157077789, Losses: [0.44 0.39 1.06 1.05]\n",
      "Epoch 1231, Accuracy: 0.7682926803827286, Accuracies: [0.88 0.98 0.63 0.59]\n",
      "Epoch 1241, Loss: 0.7345566302537918, Accuracy: 0.7682926803827286\n",
      "Epoch 1241, Loss: 0.7345566302537918, Losses: [0.44 0.39 1.06 1.05]\n",
      "Epoch 1241, Accuracy: 0.7682926803827286, Accuracies: [0.88 0.98 0.63 0.59]\n",
      "Epoch 1251, Loss: 0.7228666692972183, Accuracy: 0.7621951252222061\n",
      "Epoch 1251, Loss: 0.7228666692972183, Losses: [0.43 0.39 1.04 1.03]\n",
      "Epoch 1251, Accuracy: 0.7621951252222061, Accuracies: [0.88 0.98 0.61 0.59]\n",
      "Epoch 1261, Loss: 0.7260303944349289, Accuracy: 0.7560975700616837\n",
      "Epoch 1261, Loss: 0.7260303944349289, Losses: [0.43 0.39 1.03 1.06]\n",
      "Epoch 1261, Accuracy: 0.7560975700616837, Accuracies: [0.88 0.98 0.61 0.56]\n",
      "Epoch 1271, Loss: 0.7283809036016464, Accuracy: 0.7560975700616837\n",
      "Epoch 1271, Loss: 0.7283809036016464, Losses: [0.43 0.38 1.06 1.05]\n",
      "Epoch 1271, Accuracy: 0.7560975700616837, Accuracies: [0.88 0.98 0.61 0.56]\n",
      "Epoch 1281, Loss: 0.7321175932884216, Accuracy: 0.7804878056049347\n",
      "Epoch 1281, Loss: 0.7321175932884216, Losses: [0.43 0.38 1.06 1.06]\n",
      "Epoch 1281, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.63 0.61]\n",
      "Epoch 1291, Loss: 0.7107883170247078, Accuracy: 0.7865853607654572\n",
      "Epoch 1291, Loss: 0.7107883170247078, Losses: [0.42 0.37 1.04 1.01]\n",
      "Epoch 1291, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1301, Loss: 0.7040897458791733, Accuracy: 0.7804878056049347\n",
      "Epoch 1301, Loss: 0.7040897458791733, Losses: [0.41 0.37 1.02 1.01]\n",
      "Epoch 1301, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.63 0.61]\n",
      "Epoch 1311, Loss: 0.7103366404771805, Accuracy: 0.7804878056049347\n",
      "Epoch 1311, Loss: 0.7103366404771805, Losses: [0.41 0.37 1.03 1.04]\n",
      "Epoch 1311, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.63 0.61]\n",
      "Epoch 1321, Loss: 0.7854316160082817, Accuracy: 0.7378048747777939\n",
      "Epoch 1321, Loss: 0.7854316160082817, Losses: [0.4  0.39 1.19 1.16]\n",
      "Epoch 1321, Accuracy: 0.7378048747777939, Accuracies: [0.9  0.98 0.56 0.51]\n",
      "Epoch 1331, Loss: 0.6919567734003067, Accuracy: 0.7682926803827286\n",
      "Epoch 1331, Loss: 0.6919567734003067, Losses: [0.4  0.36 1.01 1.  ]\n",
      "Epoch 1331, Accuracy: 0.7682926803827286, Accuracies: [0.9  0.98 0.61 0.59]\n",
      "Epoch 1341, Loss: 0.685855969786644, Accuracy: 0.7804878056049347\n",
      "Epoch 1341, Loss: 0.685855969786644, Losses: [0.39 0.36 1.01 0.99]\n",
      "Epoch 1341, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.61 0.63]\n",
      "Epoch 1351, Loss: 0.6866434514522552, Accuracy: 0.7865853607654572\n",
      "Epoch 1351, Loss: 0.6866434514522552, Losses: [0.39 0.35 1.02 0.98]\n",
      "Epoch 1351, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1361, Loss: 0.6771593913435936, Accuracy: 0.7804878056049347\n",
      "Epoch 1361, Loss: 0.6771593913435936, Losses: [0.38 0.35 1.   0.98]\n",
      "Epoch 1361, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.61 0.63]\n",
      "Epoch 1371, Loss: 0.6741486862301826, Accuracy: 0.7804877907037735\n",
      "Epoch 1371, Loss: 0.6741486862301826, Losses: [0.38 0.34 1.   0.97]\n",
      "Epoch 1371, Accuracy: 0.7804877907037735, Accuracies: [0.9  1.   0.59 0.63]\n",
      "Epoch 1381, Loss: 0.6701365783810616, Accuracy: 0.7865853756666183\n",
      "Epoch 1381, Loss: 0.6701365783810616, Losses: [0.39 0.34 0.99 0.96]\n",
      "Epoch 1381, Accuracy: 0.7865853756666183, Accuracies: [0.88 0.98 0.63 0.66]\n",
      "Epoch 1391, Loss: 0.6800267174839973, Accuracy: 0.7682926654815674\n",
      "Epoch 1391, Loss: 0.6800267174839973, Losses: [0.37 0.34 1.   1.01]\n",
      "Epoch 1391, Accuracy: 0.7682926654815674, Accuracies: [0.9  1.   0.59 0.59]\n",
      "Epoch 1401, Loss: 0.664689190685749, Accuracy: 0.7865853607654572\n",
      "Epoch 1401, Loss: 0.664689190685749, Losses: [0.37 0.33 1.01 0.95]\n",
      "Epoch 1401, Accuracy: 0.7865853607654572, Accuracies: [0.9  1.   0.59 0.66]\n",
      "Epoch 1411, Loss: 0.662903867661953, Accuracy: 0.7865853607654572\n",
      "Epoch 1411, Loss: 0.662903867661953, Losses: [0.37 0.33 1.   0.96]\n",
      "Epoch 1411, Accuracy: 0.7865853607654572, Accuracies: [0.9  1.   0.59 0.66]\n",
      "Epoch 1421, Loss: 0.6673394441604614, Accuracy: 0.7926829308271408\n",
      "Epoch 1421, Loss: 0.6673394441604614, Losses: [0.36 0.32 1.02 0.96]\n",
      "Epoch 1421, Accuracy: 0.7926829308271408, Accuracies: [0.9  1.   0.61 0.66]\n",
      "Epoch 1431, Loss: 0.6515880525112152, Accuracy: 0.7926829308271408\n",
      "Epoch 1431, Loss: 0.6515880525112152, Losses: [0.37 0.32 0.97 0.95]\n",
      "Epoch 1431, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.63 0.66]\n",
      "Epoch 1441, Loss: 0.6438125893473625, Accuracy: 0.7987804859876633\n",
      "Epoch 1441, Loss: 0.6438125893473625, Losses: [0.36 0.32 0.97 0.93]\n",
      "Epoch 1441, Accuracy: 0.7987804859876633, Accuracies: [0.9  0.98 0.63 0.68]\n",
      "Epoch 1451, Loss: 0.6404817923903465, Accuracy: 0.7987804859876633\n",
      "Epoch 1451, Loss: 0.6404817923903465, Losses: [0.35 0.31 0.96 0.93]\n",
      "Epoch 1451, Accuracy: 0.7987804859876633, Accuracies: [0.9  0.98 0.63 0.68]\n",
      "Epoch 1461, Loss: 0.6374098286032677, Accuracy: 0.8048780411481857\n",
      "Epoch 1461, Loss: 0.6374098286032677, Losses: [0.35 0.31 0.97 0.92]\n",
      "Epoch 1461, Accuracy: 0.8048780411481857, Accuracies: [0.9  0.98 0.63 0.71]\n",
      "Epoch 1471, Loss: 0.642193429172039, Accuracy: 0.7804877907037735\n",
      "Epoch 1471, Loss: 0.642193429172039, Losses: [0.35 0.3  0.97 0.95]\n",
      "Epoch 1471, Accuracy: 0.7804877907037735, Accuracies: [0.9  1.   0.63 0.59]\n",
      "Epoch 1481, Loss: 0.6283307820558548, Accuracy: 0.7987804859876633\n",
      "Epoch 1481, Loss: 0.6283307820558548, Losses: [0.34 0.3  0.96 0.91]\n",
      "Epoch 1481, Accuracy: 0.7987804859876633, Accuracies: [0.9  0.98 0.63 0.68]\n",
      "Epoch 1491, Loss: 0.6439113318920135, Accuracy: 0.7804878056049347\n",
      "Epoch 1491, Loss: 0.6439113318920135, Losses: [0.34 0.3  1.01 0.92]\n",
      "Epoch 1491, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.61 0.63]\n",
      "Epoch 1501, Loss: 0.6525781005620956, Accuracy: 0.7621951103210449\n",
      "Epoch 1501, Loss: 0.6525781005620956, Losses: [0.34 0.3  0.97 0.99]\n",
      "Epoch 1501, Accuracy: 0.7621951103210449, Accuracies: [0.9  1.   0.59 0.56]\n",
      "Epoch 1511, Loss: 0.6216259002685547, Accuracy: 0.7865853607654572\n",
      "Epoch 1511, Loss: 0.6216259002685547, Losses: [0.35 0.28 0.94 0.91]\n",
      "Epoch 1511, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1521, Loss: 0.6118217036128044, Accuracy: 0.7926829308271408\n",
      "Epoch 1521, Loss: 0.6118217036128044, Losses: [0.33 0.26 0.95 0.9 ]\n",
      "Epoch 1521, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.66 0.63]\n",
      "Epoch 1531, Loss: 0.6036179736256599, Accuracy: 0.7865853607654572\n",
      "Epoch 1531, Loss: 0.6036179736256599, Losses: [0.33 0.26 0.93 0.89]\n",
      "Epoch 1531, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1541, Loss: 0.5998076871037483, Accuracy: 0.7926829308271408\n",
      "Epoch 1541, Loss: 0.5998076871037483, Losses: [0.33 0.24 0.94 0.89]\n",
      "Epoch 1541, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.66 0.63]\n",
      "Epoch 1551, Loss: 0.5993784703314304, Accuracy: 0.7926829308271408\n",
      "Epoch 1551, Loss: 0.5993784703314304, Losses: [0.33 0.24 0.94 0.89]\n",
      "Epoch 1551, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.66 0.63]\n",
      "Epoch 1561, Loss: 0.591445904225111, Accuracy: 0.7865853607654572\n",
      "Epoch 1561, Loss: 0.591445904225111, Losses: [0.33 0.24 0.92 0.88]\n",
      "Epoch 1561, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1571, Loss: 0.5955401994287968, Accuracy: 0.7926829308271408\n",
      "Epoch 1571, Loss: 0.5955401994287968, Losses: [0.32 0.23 0.93 0.9 ]\n",
      "Epoch 1571, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.66 0.63]\n",
      "Epoch 1581, Loss: 0.5821678191423416, Accuracy: 0.7926829308271408\n",
      "Epoch 1581, Loss: 0.5821678191423416, Losses: [0.33 0.23 0.9  0.86]\n",
      "Epoch 1581, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.63 0.66]\n",
      "Epoch 1591, Loss: 0.5755227878689766, Accuracy: 0.7865853607654572\n",
      "Epoch 1591, Loss: 0.5755227878689766, Losses: [0.32 0.23 0.9  0.86]\n",
      "Epoch 1591, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1601, Loss: 0.5716762766242027, Accuracy: 0.7865853607654572\n",
      "Epoch 1601, Loss: 0.5716762766242027, Losses: [0.31 0.22 0.89 0.86]\n",
      "Epoch 1601, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1611, Loss: 0.5805987790226936, Accuracy: 0.7926829308271408\n",
      "Epoch 1611, Loss: 0.5805987790226936, Losses: [0.31 0.23 0.91 0.88]\n",
      "Epoch 1611, Accuracy: 0.7926829308271408, Accuracies: [0.9  0.98 0.66 0.63]\n",
      "Epoch 1621, Loss: 0.5816853269934654, Accuracy: 0.7987805008888245\n",
      "Epoch 1621, Loss: 0.5816853269934654, Losses: [0.31 0.22 0.89 0.9 ]\n",
      "Epoch 1621, Accuracy: 0.7987805008888245, Accuracies: [0.9  0.98 0.66 0.66]\n",
      "Epoch 1631, Loss: 0.5675706267356873, Accuracy: 0.7865853607654572\n",
      "Epoch 1631, Loss: 0.5675706267356873, Losses: [0.31 0.22 0.88 0.86]\n",
      "Epoch 1631, Accuracy: 0.7865853607654572, Accuracies: [0.9  0.98 0.63 0.63]\n",
      "Epoch 1641, Loss: 0.559661790728569, Accuracy: 0.7987804859876633\n",
      "Epoch 1641, Loss: 0.559661790728569, Losses: [0.3  0.21 0.87 0.84]\n",
      "Epoch 1641, Accuracy: 0.7987804859876633, Accuracies: [0.9  0.98 0.63 0.68]\n",
      "Epoch 1651, Loss: 0.5569062121212482, Accuracy: 0.7987805008888245\n",
      "Epoch 1651, Loss: 0.5569062121212482, Losses: [0.31 0.21 0.88 0.83]\n",
      "Epoch 1651, Accuracy: 0.7987805008888245, Accuracies: [0.9  0.98 0.66 0.66]\n",
      "Epoch 1661, Loss: 0.6063233055174351, Accuracy: 0.7804878056049347\n",
      "Epoch 1661, Loss: 0.6063233055174351, Losses: [0.31 0.22 1.01 0.89]\n",
      "Epoch 1661, Accuracy: 0.7804878056049347, Accuracies: [0.9  0.98 0.61 0.63]\n",
      "Epoch 1671, Loss: 0.5693770721554756, Accuracy: 0.8048780411481857\n",
      "Epoch 1671, Loss: 0.5693770721554756, Losses: [0.3  0.21 0.92 0.84]\n",
      "Epoch 1671, Accuracy: 0.8048780411481857, Accuracies: [0.9  0.98 0.63 0.71]\n",
      "Epoch 1681, Loss: 0.5461629293859005, Accuracy: 0.7987805008888245\n",
      "Epoch 1681, Loss: 0.5461629293859005, Losses: [0.3  0.2  0.86 0.83]\n",
      "Epoch 1681, Accuracy: 0.7987805008888245, Accuracies: [0.9  0.98 0.66 0.66]\n",
      "Epoch 1691, Loss: 0.544536117464304, Accuracy: 0.8109756112098694\n",
      "Epoch 1691, Loss: 0.544536117464304, Losses: [0.29 0.2  0.86 0.83]\n",
      "Epoch 1691, Accuracy: 0.8109756112098694, Accuracies: [0.9  0.98 0.66 0.71]\n",
      "Epoch 1701, Loss: 0.5371474139392376, Accuracy: 0.8048780560493469\n",
      "Epoch 1701, Loss: 0.5371474139392376, Losses: [0.29 0.2  0.84 0.81]\n",
      "Epoch 1701, Accuracy: 0.8048780560493469, Accuracies: [0.9  0.98 0.66 0.68]\n",
      "Epoch 1711, Loss: 0.5363012887537479, Accuracy: 0.8048780560493469\n",
      "Epoch 1711, Loss: 0.5363012887537479, Losses: [0.29 0.2  0.84 0.82]\n",
      "Epoch 1711, Accuracy: 0.8048780560493469, Accuracies: [0.9  0.98 0.68 0.66]\n",
      "Epoch 1721, Loss: 0.5336089096963406, Accuracy: 0.8292683064937592\n",
      "Epoch 1721, Loss: 0.5336089096963406, Losses: [0.29 0.19 0.85 0.8 ]\n",
      "Epoch 1721, Accuracy: 0.8292683064937592, Accuracies: [0.93 0.98 0.68 0.73]\n",
      "Epoch 1731, Loss: 0.5291745103895664, Accuracy: 0.8109756261110306\n",
      "Epoch 1731, Loss: 0.5291745103895664, Losses: [0.28 0.19 0.83 0.81]\n",
      "Epoch 1731, Accuracy: 0.8109756261110306, Accuracies: [0.93 0.98 0.68 0.66]\n",
      "Epoch 1741, Loss: 0.5401293449103832, Accuracy: 0.8414634168148041\n",
      "Epoch 1741, Loss: 0.5401293449103832, Losses: [0.28 0.19 0.89 0.8 ]\n",
      "Epoch 1741, Accuracy: 0.8414634168148041, Accuracies: [0.93 0.98 0.71 0.76]\n",
      "Epoch 1751, Loss: 0.6373272128403187, Accuracy: 0.7926829308271408\n",
      "Epoch 1751, Loss: 0.6373272128403187, Losses: [0.29 0.23 1.18 0.85]\n",
      "Epoch 1751, Accuracy: 0.7926829308271408, Accuracies: [0.93 0.98 0.59 0.68]\n",
      "Epoch 1761, Loss: 0.5259897373616695, Accuracy: 0.8048780709505081\n",
      "Epoch 1761, Loss: 0.5259897373616695, Losses: [0.28 0.19 0.83 0.81]\n",
      "Epoch 1761, Accuracy: 0.8048780709505081, Accuracies: [0.93 0.98 0.66 0.66]\n",
      "Epoch 1771, Loss: 0.5160931348800659, Accuracy: 0.8292683064937592\n",
      "Epoch 1771, Loss: 0.5160931348800659, Losses: [0.28 0.18 0.82 0.78]\n",
      "Epoch 1771, Accuracy: 0.8292683064937592, Accuracies: [0.93 0.98 0.68 0.73]\n",
      "Epoch 1781, Loss: 0.5144012868404388, Accuracy: 0.8353658616542816\n",
      "Epoch 1781, Loss: 0.5144012868404388, Losses: [0.27 0.18 0.81 0.79]\n",
      "Epoch 1781, Accuracy: 0.8353658616542816, Accuracies: [0.93 0.98 0.71 0.73]\n",
      "Epoch 1791, Loss: 0.5110348872840405, Accuracy: 0.8414634168148041\n",
      "Epoch 1791, Loss: 0.5110348872840405, Losses: [0.28 0.18 0.81 0.78]\n",
      "Epoch 1791, Accuracy: 0.8414634168148041, Accuracies: [0.95 0.98 0.68 0.76]\n",
      "Epoch 1801, Loss: 0.5065976679325104, Accuracy: 0.8353658616542816\n",
      "Epoch 1801, Loss: 0.5065976679325104, Losses: [0.27 0.18 0.8  0.77]\n",
      "Epoch 1801, Accuracy: 0.8353658616542816, Accuracies: [0.93 0.98 0.71 0.73]\n",
      "Epoch 1811, Loss: 0.5545343458652496, Accuracy: 0.817073181271553\n",
      "Epoch 1811, Loss: 0.5545343458652496, Losses: [0.27 0.18 0.93 0.84]\n",
      "Epoch 1811, Accuracy: 0.817073181271553, Accuracies: [0.93 0.98 0.63 0.73]\n",
      "Epoch 1821, Loss: 0.5077278167009354, Accuracy: 0.8231707364320755\n",
      "Epoch 1821, Loss: 0.5077278167009354, Losses: [0.27 0.17 0.8  0.79]\n",
      "Epoch 1821, Accuracy: 0.8231707364320755, Accuracies: [0.95 0.98 0.68 0.68]\n",
      "Epoch 1831, Loss: 0.49304550886154175, Accuracy: 0.853658527135849\n",
      "Epoch 1831, Loss: 0.49304550886154175, Losses: [0.26 0.17 0.79 0.76]\n",
      "Epoch 1831, Accuracy: 0.853658527135849, Accuracies: [0.95 0.98 0.71 0.78]\n",
      "Epoch 1841, Loss: 0.5237283520400524, Accuracy: 0.8048780560493469\n",
      "Epoch 1841, Loss: 0.5237283520400524, Losses: [0.31 0.17 0.79 0.83]\n",
      "Epoch 1841, Accuracy: 0.8048780560493469, Accuracies: [0.93 0.98 0.68 0.63]\n",
      "Epoch 1851, Loss: 0.5003523379564285, Accuracy: 0.8658536523580551\n",
      "Epoch 1851, Loss: 0.5003523379564285, Losses: [0.25 0.17 0.8  0.78]\n",
      "Epoch 1851, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1861, Loss: 0.5133247897028923, Accuracy: 0.8048780560493469\n",
      "Epoch 1861, Loss: 0.5133247897028923, Losses: [0.24 0.17 0.83 0.81]\n",
      "Epoch 1861, Accuracy: 0.8048780560493469, Accuracies: [0.95 0.98 0.63 0.66]\n",
      "Epoch 1871, Loss: 0.4727526679635048, Accuracy: 0.8658536672592163\n",
      "Epoch 1871, Loss: 0.4727526679635048, Losses: [0.23 0.17 0.76 0.72]\n",
      "Epoch 1871, Accuracy: 0.8658536672592163, Accuracies: [0.95 0.98 0.73 0.8 ]\n",
      "Epoch 1881, Loss: 0.46585048362612724, Accuracy: 0.8719512224197388\n",
      "Epoch 1881, Loss: 0.46585048362612724, Losses: [0.23 0.17 0.76 0.71]\n",
      "Epoch 1881, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.73 0.83]\n",
      "Epoch 1891, Loss: 0.4611073099076748, Accuracy: 0.8658536523580551\n",
      "Epoch 1891, Loss: 0.4611073099076748, Losses: [0.22 0.17 0.75 0.71]\n",
      "Epoch 1891, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1901, Loss: 0.4696117788553238, Accuracy: 0.8597560971975327\n",
      "Epoch 1901, Loss: 0.4696117788553238, Losses: [0.22 0.17 0.74 0.75]\n",
      "Epoch 1901, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.76 0.76]\n",
      "Epoch 1911, Loss: 0.45364960283041, Accuracy: 0.8658536523580551\n",
      "Epoch 1911, Loss: 0.45364960283041, Losses: [0.21 0.16 0.74 0.7 ]\n",
      "Epoch 1911, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1921, Loss: 0.46111852303147316, Accuracy: 0.8414634168148041\n",
      "Epoch 1921, Loss: 0.46111852303147316, Losses: [0.22 0.16 0.74 0.73]\n",
      "Epoch 1921, Accuracy: 0.8414634168148041, Accuracies: [0.95 0.98 0.71 0.73]\n",
      "Epoch 1931, Loss: 0.4914125129580498, Accuracy: 0.8536585420370102\n",
      "Epoch 1931, Loss: 0.4914125129580498, Losses: [0.23 0.17 0.79 0.78]\n",
      "Epoch 1931, Accuracy: 0.8536585420370102, Accuracies: [0.95 0.98 0.73 0.76]\n",
      "Epoch 1941, Loss: 0.45369381830096245, Accuracy: 0.8597560971975327\n",
      "Epoch 1941, Loss: 0.45369381830096245, Losses: [0.21 0.16 0.75 0.7 ]\n",
      "Epoch 1941, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.76 0.76]\n",
      "Epoch 1951, Loss: 0.44078628346323967, Accuracy: 0.8658536523580551\n",
      "Epoch 1951, Loss: 0.44078628346323967, Losses: [0.2  0.16 0.72 0.69]\n",
      "Epoch 1951, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1961, Loss: 0.4359701834619045, Accuracy: 0.8658536523580551\n",
      "Epoch 1961, Loss: 0.4359701834619045, Losses: [0.2  0.15 0.71 0.68]\n",
      "Epoch 1961, Accuracy: 0.8658536523580551, Accuracies: [0.95 0.98 0.76 0.78]\n",
      "Epoch 1971, Loss: 0.45615801960229874, Accuracy: 0.8536585420370102\n",
      "Epoch 1971, Loss: 0.45615801960229874, Losses: [0.2  0.15 0.72 0.75]\n",
      "Epoch 1971, Accuracy: 0.8536585420370102, Accuracies: [0.95 0.98 0.68 0.8 ]\n",
      "Epoch 1981, Loss: 0.45710329711437225, Accuracy: 0.8475609719753265\n",
      "Epoch 1981, Loss: 0.45710329711437225, Losses: [0.2  0.15 0.72 0.75]\n",
      "Epoch 1981, Accuracy: 0.8475609719753265, Accuracies: [0.95 0.98 0.68 0.78]\n",
      "Epoch 1991, Loss: 0.42987822741270065, Accuracy: 0.8658536672592163\n",
      "Epoch 1991, Loss: 0.42987822741270065, Losses: [0.2  0.15 0.69 0.68]\n",
      "Epoch 1991, Accuracy: 0.8658536672592163, Accuracies: [0.95 0.98 0.73 0.8 ]\n",
      "Epoch 2001, Loss: 0.4260008931159973, Accuracy: 0.8719512224197388\n",
      "Epoch 2001, Loss: 0.4260008931159973, Losses: [0.19 0.15 0.69 0.68]\n",
      "Epoch 2001, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.73 0.83]\n",
      "Epoch 2011, Loss: 0.4299561604857445, Accuracy: 0.8597560971975327\n",
      "Epoch 2011, Loss: 0.4299561604857445, Losses: [0.19 0.15 0.69 0.69]\n",
      "Epoch 2011, Accuracy: 0.8597560971975327, Accuracies: [0.95 0.98 0.78 0.73]\n",
      "Epoch 2021, Loss: 0.4181799925863743, Accuracy: 0.8719512224197388\n",
      "Epoch 2021, Loss: 0.4181799925863743, Losses: [0.19 0.14 0.67 0.67]\n",
      "Epoch 2021, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.73 0.83]\n",
      "Epoch 2031, Loss: 0.41083766520023346, Accuracy: 0.8841463327407837\n",
      "Epoch 2031, Loss: 0.41083766520023346, Losses: [0.18 0.14 0.66 0.65]\n",
      "Epoch 2031, Accuracy: 0.8841463327407837, Accuracies: [0.95 0.98 0.78 0.83]\n",
      "Epoch 2041, Loss: 0.4145280309021473, Accuracy: 0.8780487775802612\n",
      "Epoch 2041, Loss: 0.4145280309021473, Losses: [0.19 0.14 0.66 0.66]\n",
      "Epoch 2041, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.78 0.8 ]\n",
      "Epoch 2051, Loss: 0.4084145948290825, Accuracy: 0.8719512224197388\n",
      "Epoch 2051, Loss: 0.4084145948290825, Losses: [0.18 0.14 0.65 0.66]\n",
      "Epoch 2051, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.76 0.8 ]\n",
      "Epoch 2061, Loss: 0.4002714827656746, Accuracy: 0.8719512224197388\n",
      "Epoch 2061, Loss: 0.4002714827656746, Losses: [0.18 0.14 0.64 0.64]\n",
      "Epoch 2061, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.76 0.8 ]\n",
      "Epoch 2071, Loss: 0.3963526822626591, Accuracy: 0.8780487775802612\n",
      "Epoch 2071, Loss: 0.3963526822626591, Losses: [0.18 0.14 0.63 0.64]\n",
      "Epoch 2071, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.76 0.83]\n",
      "Epoch 2081, Loss: 0.3957493416965008, Accuracy: 0.8658536672592163\n",
      "Epoch 2081, Loss: 0.3957493416965008, Losses: [0.17 0.14 0.63 0.64]\n",
      "Epoch 2081, Accuracy: 0.8658536672592163, Accuracies: [0.95 0.98 0.73 0.8 ]\n",
      "Epoch 2091, Loss: 0.3895287998020649, Accuracy: 0.8841463476419449\n",
      "Epoch 2091, Loss: 0.3895287998020649, Losses: [0.18 0.14 0.62 0.63]\n",
      "Epoch 2091, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 2101, Loss: 0.39575057476758957, Accuracy: 0.8719512224197388\n",
      "Epoch 2101, Loss: 0.39575057476758957, Losses: [0.17 0.13 0.63 0.65]\n",
      "Epoch 2101, Accuracy: 0.8719512224197388, Accuracies: [0.95 0.98 0.73 0.83]\n",
      "Epoch 2111, Loss: 0.38227302208542824, Accuracy: 0.8963414579629898\n",
      "Epoch 2111, Loss: 0.38227302208542824, Losses: [0.17 0.13 0.61 0.61]\n",
      "Epoch 2111, Accuracy: 0.8963414579629898, Accuracies: [0.95 0.98 0.83 0.83]\n",
      "Epoch 2121, Loss: 0.3772600367665291, Accuracy: 0.9024390280246735\n",
      "Epoch 2121, Loss: 0.3772600367665291, Losses: [0.17 0.13 0.6  0.61]\n",
      "Epoch 2121, Accuracy: 0.9024390280246735, Accuracies: [0.95 0.98 0.83 0.85]\n",
      "Epoch 2131, Loss: 0.37402530014514923, Accuracy: 0.896341472864151\n",
      "Epoch 2131, Loss: 0.37402530014514923, Losses: [0.17 0.13 0.6  0.6 ]\n",
      "Epoch 2131, Accuracy: 0.896341472864151, Accuracies: [0.95 0.98 0.8  0.85]\n",
      "Epoch 2141, Loss: 0.3716016635298729, Accuracy: 0.896341472864151\n",
      "Epoch 2141, Loss: 0.3716016635298729, Losses: [0.16 0.13 0.59 0.6 ]\n",
      "Epoch 2141, Accuracy: 0.896341472864151, Accuracies: [0.95 0.98 0.8  0.85]\n",
      "Epoch 2151, Loss: 0.3809858188033104, Accuracy: 0.8902439028024673\n",
      "Epoch 2151, Loss: 0.3809858188033104, Losses: [0.17 0.13 0.63 0.6 ]\n",
      "Epoch 2151, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.78 0.85]\n",
      "Epoch 2161, Loss: 0.38333719596266747, Accuracy: 0.8780487775802612\n",
      "Epoch 2161, Loss: 0.38333719596266747, Losses: [0.16 0.13 0.59 0.65]\n",
      "Epoch 2161, Accuracy: 0.8780487775802612, Accuracies: [0.95 0.98 0.78 0.8 ]\n",
      "Epoch 2171, Loss: 0.36718306690454483, Accuracy: 0.8841463327407837\n",
      "Epoch 2171, Loss: 0.36718306690454483, Losses: [0.16 0.13 0.59 0.58]\n",
      "Epoch 2171, Accuracy: 0.8841463327407837, Accuracies: [0.95 0.98 0.78 0.83]\n",
      "Epoch 2181, Loss: 0.3618885539472103, Accuracy: 0.896341472864151\n",
      "Epoch 2181, Loss: 0.3618885539472103, Losses: [0.16 0.13 0.59 0.58]\n",
      "Epoch 2181, Accuracy: 0.896341472864151, Accuracies: [0.95 0.98 0.8  0.85]\n",
      "Epoch 2191, Loss: 0.3693603649735451, Accuracy: 0.9085365831851959\n",
      "Epoch 2191, Loss: 0.3693603649735451, Losses: [0.16 0.13 0.59 0.6 ]\n",
      "Epoch 2191, Accuracy: 0.9085365831851959, Accuracies: [0.98 0.98 0.78 0.9 ]\n",
      "Epoch 2201, Loss: 0.35564878955483437, Accuracy: 0.8902439028024673\n",
      "Epoch 2201, Loss: 0.35564878955483437, Losses: [0.15 0.13 0.57 0.57]\n",
      "Epoch 2201, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.8  0.83]\n",
      "Epoch 2211, Loss: 0.35554998368024826, Accuracy: 0.896341472864151\n",
      "Epoch 2211, Loss: 0.35554998368024826, Losses: [0.16 0.13 0.56 0.57]\n",
      "Epoch 2211, Accuracy: 0.896341472864151, Accuracies: [0.98 0.98 0.8  0.83]\n",
      "Epoch 2221, Loss: 0.3535574711859226, Accuracy: 0.8841463476419449\n",
      "Epoch 2221, Loss: 0.3535574711859226, Losses: [0.16 0.13 0.56 0.56]\n",
      "Epoch 2221, Accuracy: 0.8841463476419449, Accuracies: [0.95 0.98 0.8  0.8 ]\n",
      "Epoch 2231, Loss: 0.5932098366320133, Accuracy: 0.7682926952838898\n",
      "Epoch 2231, Loss: 0.5932098366320133, Losses: [0.18 0.18 0.95 1.06]\n",
      "Epoch 2231, Accuracy: 0.7682926952838898, Accuracies: [0.98 0.98 0.59 0.54]\n",
      "Epoch 2241, Loss: 0.36063795536756516, Accuracy: 0.9024390131235123\n",
      "Epoch 2241, Loss: 0.36063795536756516, Losses: [0.16 0.13 0.59 0.57]\n",
      "Epoch 2241, Accuracy: 0.9024390131235123, Accuracies: [0.95 0.98 0.78 0.9 ]\n",
      "Epoch 2251, Loss: 0.34631040692329407, Accuracy: 0.8902439028024673\n",
      "Epoch 2251, Loss: 0.34631040692329407, Losses: [0.15 0.13 0.56 0.55]\n",
      "Epoch 2251, Accuracy: 0.8902439028024673, Accuracies: [0.95 0.98 0.76 0.88]\n",
      "Epoch 2261, Loss: 0.3424740731716156, Accuracy: 0.9085365831851959\n",
      "Epoch 2261, Loss: 0.3424740731716156, Losses: [0.15 0.13 0.55 0.55]\n",
      "Epoch 2261, Accuracy: 0.9085365831851959, Accuracies: [0.98 0.98 0.78 0.9 ]\n",
      "Epoch 2271, Loss: 0.35773753747344017, Accuracy: 0.8902439028024673\n",
      "Epoch 2271, Loss: 0.35773753747344017, Losses: [0.15 0.13 0.57 0.59]\n",
      "Epoch 2271, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.98 0.78 0.83]\n",
      "Epoch 2281, Loss: 0.33677294105291367, Accuracy: 0.9085365831851959\n",
      "Epoch 2281, Loss: 0.33677294105291367, Losses: [0.14 0.12 0.54 0.54]\n",
      "Epoch 2281, Accuracy: 0.9085365831851959, Accuracies: [0.98 0.98 0.78 0.9 ]\n",
      "Epoch 2291, Loss: 0.3340266551822424, Accuracy: 0.9146341532468796\n",
      "Epoch 2291, Loss: 0.3340266551822424, Losses: [0.14 0.12 0.54 0.54]\n",
      "Epoch 2291, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.8  0.9 ]\n",
      "Epoch 2301, Loss: 0.3319034017622471, Accuracy: 0.9085365831851959\n",
      "Epoch 2301, Loss: 0.3319034017622471, Losses: [0.14 0.12 0.53 0.53]\n",
      "Epoch 2301, Accuracy: 0.9085365831851959, Accuracies: [0.98 0.98 0.78 0.9 ]\n",
      "Epoch 2311, Loss: 0.32838277518749237, Accuracy: 0.9085365831851959\n",
      "Epoch 2311, Loss: 0.32838277518749237, Losses: [0.14 0.12 0.53 0.53]\n",
      "Epoch 2311, Accuracy: 0.9085365831851959, Accuracies: [0.98 0.98 0.78 0.9 ]\n",
      "Epoch 2321, Loss: 0.3286100309342146, Accuracy: 0.9085365980863571\n",
      "Epoch 2321, Loss: 0.3286100309342146, Losses: [0.14 0.12 0.53 0.53]\n",
      "Epoch 2321, Accuracy: 0.9085365980863571, Accuracies: [0.98 0.98 0.8  0.88]\n",
      "Epoch 2331, Loss: 0.3261419516056776, Accuracy: 0.920731708407402\n",
      "Epoch 2331, Loss: 0.3261419516056776, Losses: [0.14 0.12 0.53 0.52]\n",
      "Epoch 2331, Accuracy: 0.920731708407402, Accuracies: [0.98 0.98 0.83 0.9 ]\n",
      "Epoch 2341, Loss: 0.3211126271635294, Accuracy: 0.9146341532468796\n",
      "Epoch 2341, Loss: 0.3211126271635294, Losses: [0.14 0.12 0.52 0.51]\n",
      "Epoch 2341, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.8  0.9 ]\n",
      "Epoch 2351, Loss: 0.3184827584773302, Accuracy: 0.920731708407402\n",
      "Epoch 2351, Loss: 0.3184827584773302, Losses: [0.13 0.12 0.51 0.51]\n",
      "Epoch 2351, Accuracy: 0.920731708407402, Accuracies: [0.98 0.98 0.83 0.9 ]\n",
      "Epoch 2361, Loss: 0.31660182401537895, Accuracy: 0.9268292784690857\n",
      "Epoch 2361, Loss: 0.31660182401537895, Losses: [0.13 0.11 0.51 0.51]\n",
      "Epoch 2361, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.83 0.93]\n",
      "Epoch 2371, Loss: 0.3146422244608402, Accuracy: 0.9207317233085632\n",
      "Epoch 2371, Loss: 0.3146422244608402, Losses: [0.13 0.11 0.51 0.5 ]\n",
      "Epoch 2371, Accuracy: 0.9207317233085632, Accuracies: [0.98 0.98 0.8  0.93]\n",
      "Epoch 2381, Loss: 0.31504546850919724, Accuracy: 0.9207317233085632\n",
      "Epoch 2381, Loss: 0.31504546850919724, Losses: [0.13 0.11 0.52 0.5 ]\n",
      "Epoch 2381, Accuracy: 0.9207317233085632, Accuracies: [0.98 0.98 0.8  0.93]\n",
      "Epoch 2391, Loss: 0.41813703440129757, Accuracy: 0.8719512224197388\n",
      "Epoch 2391, Loss: 0.41813703440129757, Losses: [0.53 0.11 0.51 0.52]\n",
      "Epoch 2391, Accuracy: 0.8719512224197388, Accuracies: [0.83 0.98 0.8  0.88]\n",
      "Epoch 2401, Loss: 0.3129335641860962, Accuracy: 0.9146341383457184\n",
      "Epoch 2401, Loss: 0.3129335641860962, Losses: [0.14 0.11 0.5  0.5 ]\n",
      "Epoch 2401, Accuracy: 0.9146341383457184, Accuracies: [0.95 0.98 0.83 0.9 ]\n",
      "Epoch 2411, Loss: 0.30828610993921757, Accuracy: 0.920731708407402\n",
      "Epoch 2411, Loss: 0.30828610993921757, Losses: [0.13 0.11 0.49 0.49]\n",
      "Epoch 2411, Accuracy: 0.920731708407402, Accuracies: [0.95 0.98 0.83 0.93]\n",
      "Epoch 2421, Loss: 0.30476084537804127, Accuracy: 0.9268292784690857\n",
      "Epoch 2421, Loss: 0.30476084537804127, Losses: [0.13 0.11 0.49 0.49]\n",
      "Epoch 2421, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.83 0.93]\n",
      "Epoch 2431, Loss: 0.30472712963819504, Accuracy: 0.9207317233085632\n",
      "Epoch 2431, Loss: 0.30472712963819504, Losses: [0.13 0.11 0.5  0.48]\n",
      "Epoch 2431, Accuracy: 0.9207317233085632, Accuracies: [0.98 0.98 0.8  0.93]\n",
      "Epoch 2441, Loss: 0.30223571695387363, Accuracy: 0.9268292784690857\n",
      "Epoch 2441, Loss: 0.30223571695387363, Losses: [0.13 0.11 0.49 0.48]\n",
      "Epoch 2441, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.83 0.93]\n",
      "Epoch 2451, Loss: 0.33743105083703995, Accuracy: 0.9024390280246735\n",
      "Epoch 2451, Loss: 0.33743105083703995, Losses: [0.13 0.12 0.6  0.51]\n",
      "Epoch 2451, Accuracy: 0.9024390280246735, Accuracies: [0.98 0.98 0.76 0.9 ]\n",
      "Epoch 2461, Loss: 0.31083020381629467, Accuracy: 0.9146341383457184\n",
      "Epoch 2461, Loss: 0.31083020381629467, Losses: [0.13 0.11 0.49 0.51]\n",
      "Epoch 2461, Accuracy: 0.9146341383457184, Accuracies: [0.95 0.98 0.83 0.9 ]\n",
      "Epoch 2471, Loss: 0.29802630096673965, Accuracy: 0.9146341383457184\n",
      "Epoch 2471, Loss: 0.29802630096673965, Losses: [0.13 0.11 0.48 0.47]\n",
      "Epoch 2471, Accuracy: 0.9146341383457184, Accuracies: [0.95 0.98 0.83 0.9 ]\n",
      "Epoch 2481, Loss: 0.2937286328524351, Accuracy: 0.9329268485307693\n",
      "Epoch 2481, Loss: 0.2937286328524351, Losses: [0.13 0.11 0.47 0.47]\n",
      "Epoch 2481, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 2491, Loss: 0.2904143873602152, Accuracy: 0.9329268485307693\n",
      "Epoch 2491, Loss: 0.2904143873602152, Losses: [0.12 0.11 0.47 0.47]\n",
      "Epoch 2491, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 2501, Loss: 0.28870074078440666, Accuracy: 0.9329268485307693\n",
      "Epoch 2501, Loss: 0.28870074078440666, Losses: [0.12 0.1  0.47 0.46]\n",
      "Epoch 2501, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 2511, Loss: 0.2863913718611002, Accuracy: 0.9390244036912918\n",
      "Epoch 2511, Loss: 0.2863913718611002, Losses: [0.12 0.1  0.46 0.46]\n",
      "Epoch 2511, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2521, Loss: 0.28439541533589363, Accuracy: 0.9390244036912918\n",
      "Epoch 2521, Loss: 0.28439541533589363, Losses: [0.12 0.1  0.46 0.46]\n",
      "Epoch 2521, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2531, Loss: 0.282181603834033, Accuracy: 0.9390244036912918\n",
      "Epoch 2531, Loss: 0.282181603834033, Losses: [0.12 0.1  0.46 0.45]\n",
      "Epoch 2531, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2541, Loss: 0.28012626245617867, Accuracy: 0.9390244036912918\n",
      "Epoch 2541, Loss: 0.28012626245617867, Losses: [0.12 0.1  0.45 0.45]\n",
      "Epoch 2541, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2551, Loss: 0.28069487400352955, Accuracy: 0.9329268336296082\n",
      "Epoch 2551, Loss: 0.28069487400352955, Losses: [0.12 0.1  0.46 0.45]\n",
      "Epoch 2551, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.83 0.95]\n",
      "Epoch 2561, Loss: 0.2779473941773176, Accuracy: 0.9329268336296082\n",
      "Epoch 2561, Loss: 0.2779473941773176, Losses: [0.12 0.1  0.45 0.44]\n",
      "Epoch 2561, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.83 0.95]\n",
      "Epoch 2571, Loss: 0.2857676614075899, Accuracy: 0.9146341532468796\n",
      "Epoch 2571, Loss: 0.2857676614075899, Losses: [0.11 0.1  0.45 0.48]\n",
      "Epoch 2571, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.83 0.88]\n",
      "Epoch 2581, Loss: 0.2722494713962078, Accuracy: 0.9390244036912918\n",
      "Epoch 2581, Loss: 0.2722494713962078, Losses: [0.11 0.1  0.44 0.44]\n",
      "Epoch 2581, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2591, Loss: 0.27053537778556347, Accuracy: 0.9390244036912918\n",
      "Epoch 2591, Loss: 0.27053537778556347, Losses: [0.11 0.1  0.44 0.43]\n",
      "Epoch 2591, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2601, Loss: 0.2751114256680012, Accuracy: 0.9329268336296082\n",
      "Epoch 2601, Loss: 0.2751114256680012, Losses: [0.11 0.1  0.45 0.44]\n",
      "Epoch 2601, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.83 0.95]\n",
      "Epoch 2611, Loss: 0.286431260406971, Accuracy: 0.9207317233085632\n",
      "Epoch 2611, Loss: 0.286431260406971, Losses: [0.11 0.1  0.44 0.5 ]\n",
      "Epoch 2611, Accuracy: 0.9207317233085632, Accuracies: [0.98 0.98 0.85 0.88]\n",
      "Epoch 2621, Loss: 0.36537340842187405, Accuracy: 0.8658536672592163\n",
      "Epoch 2621, Loss: 0.36537340842187405, Losses: [0.27 0.12 0.48 0.58]\n",
      "Epoch 2621, Accuracy: 0.8658536672592163, Accuracies: [0.88 0.98 0.8  0.8 ]\n",
      "Epoch 2631, Loss: 0.27369318157434464, Accuracy: 0.9390244036912918\n",
      "Epoch 2631, Loss: 0.27369318157434464, Losses: [0.12 0.1  0.44 0.44]\n",
      "Epoch 2631, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2641, Loss: 0.265728410333395, Accuracy: 0.9390244036912918\n",
      "Epoch 2641, Loss: 0.265728410333395, Losses: [0.11 0.1  0.43 0.42]\n",
      "Epoch 2641, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2651, Loss: 0.2621996160596609, Accuracy: 0.9390244036912918\n",
      "Epoch 2651, Loss: 0.2621996160596609, Losses: [0.11 0.1  0.42 0.42]\n",
      "Epoch 2651, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2661, Loss: 0.2597522269934416, Accuracy: 0.9390244036912918\n",
      "Epoch 2661, Loss: 0.2597522269934416, Losses: [0.11 0.1  0.42 0.42]\n",
      "Epoch 2661, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2671, Loss: 0.25774181820452213, Accuracy: 0.9390244036912918\n",
      "Epoch 2671, Loss: 0.25774181820452213, Losses: [0.11 0.09 0.42 0.41]\n",
      "Epoch 2671, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2681, Loss: 0.25592266768217087, Accuracy: 0.9390244036912918\n",
      "Epoch 2681, Loss: 0.25592266768217087, Losses: [0.11 0.09 0.41 0.41]\n",
      "Epoch 2681, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2691, Loss: 0.25409308820962906, Accuracy: 0.9390244036912918\n",
      "Epoch 2691, Loss: 0.25409308820962906, Losses: [0.1  0.09 0.41 0.41]\n",
      "Epoch 2691, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2701, Loss: 0.2523793149739504, Accuracy: 0.9390244036912918\n",
      "Epoch 2701, Loss: 0.2523793149739504, Losses: [0.1  0.09 0.41 0.4 ]\n",
      "Epoch 2701, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2711, Loss: 0.2522091679275036, Accuracy: 0.9329268485307693\n",
      "Epoch 2711, Loss: 0.2522091679275036, Losses: [0.1  0.09 0.41 0.41]\n",
      "Epoch 2711, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 2721, Loss: 0.2511795926839113, Accuracy: 0.9329268336296082\n",
      "Epoch 2721, Loss: 0.2511795926839113, Losses: [0.1  0.09 0.4  0.41]\n",
      "Epoch 2721, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.83 0.95]\n",
      "Epoch 2731, Loss: 0.30205294489860535, Accuracy: 0.9085365831851959\n",
      "Epoch 2731, Loss: 0.30205294489860535, Losses: [0.26 0.1  0.41 0.44]\n",
      "Epoch 2731, Accuracy: 0.9085365831851959, Accuracies: [0.9  0.98 0.85 0.9 ]\n",
      "Epoch 2741, Loss: 0.5341125316917896, Accuracy: 0.8170731514692307\n",
      "Epoch 2741, Loss: 0.5341125316917896, Losses: [0.73 0.12 0.73 0.55]\n",
      "Epoch 2741, Accuracy: 0.8170731514692307, Accuracies: [0.78 0.95 0.71 0.83]\n",
      "Epoch 2751, Loss: 0.3528437912464142, Accuracy: 0.8597560971975327\n",
      "Epoch 2751, Loss: 0.3528437912464142, Losses: [0.18 0.11 0.47 0.65]\n",
      "Epoch 2751, Accuracy: 0.8597560971975327, Accuracies: [0.93 0.98 0.76 0.78]\n",
      "Epoch 2761, Loss: 0.2664049565792084, Accuracy: 0.9146341532468796\n",
      "Epoch 2761, Loss: 0.2664049565792084, Losses: [0.12 0.1  0.41 0.43]\n",
      "Epoch 2761, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.83 0.88]\n",
      "Epoch 2771, Loss: 0.25400478206574917, Accuracy: 0.9268292784690857\n",
      "Epoch 2771, Loss: 0.25400478206574917, Losses: [0.11 0.1  0.4  0.41]\n",
      "Epoch 2771, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.85 0.9 ]\n",
      "Epoch 2781, Loss: 0.2502459716051817, Accuracy: 0.9268292784690857\n",
      "Epoch 2781, Loss: 0.2502459716051817, Losses: [0.1 0.1 0.4 0.4]\n",
      "Epoch 2781, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.85 0.9 ]\n",
      "Epoch 2791, Loss: 0.24746683798730373, Accuracy: 0.9268292784690857\n",
      "Epoch 2791, Loss: 0.24746683798730373, Losses: [0.1  0.09 0.39 0.4 ]\n",
      "Epoch 2791, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.85 0.9 ]\n",
      "Epoch 2801, Loss: 0.24426057748496532, Accuracy: 0.9390244036912918\n",
      "Epoch 2801, Loss: 0.24426057748496532, Losses: [0.1  0.09 0.39 0.39]\n",
      "Epoch 2801, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2811, Loss: 0.24155730195343494, Accuracy: 0.9390244036912918\n",
      "Epoch 2811, Loss: 0.24155730195343494, Losses: [0.1  0.09 0.39 0.38]\n",
      "Epoch 2811, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2821, Loss: 0.23954440839588642, Accuracy: 0.9390244036912918\n",
      "Epoch 2821, Loss: 0.23954440839588642, Losses: [0.1  0.09 0.39 0.38]\n",
      "Epoch 2821, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2831, Loss: 0.23779388330876827, Accuracy: 0.9390244036912918\n",
      "Epoch 2831, Loss: 0.23779388330876827, Losses: [0.1  0.09 0.38 0.38]\n",
      "Epoch 2831, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2841, Loss: 0.23603533580899239, Accuracy: 0.9390244036912918\n",
      "Epoch 2841, Loss: 0.23603533580899239, Losses: [0.1  0.09 0.38 0.37]\n",
      "Epoch 2841, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2851, Loss: 0.2344957049936056, Accuracy: 0.9390244036912918\n",
      "Epoch 2851, Loss: 0.2344957049936056, Losses: [0.1  0.09 0.38 0.37]\n",
      "Epoch 2851, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2861, Loss: 0.23271591030061245, Accuracy: 0.9390244036912918\n",
      "Epoch 2861, Loss: 0.23271591030061245, Losses: [0.1  0.09 0.38 0.37]\n",
      "Epoch 2861, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 2871, Loss: 0.23110142722725868, Accuracy: 0.9451219737529755\n",
      "Epoch 2871, Loss: 0.23110142722725868, Losses: [0.1  0.09 0.38 0.36]\n",
      "Epoch 2871, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2881, Loss: 0.2295360304415226, Accuracy: 0.9451219737529755\n",
      "Epoch 2881, Loss: 0.2295360304415226, Losses: [0.1  0.09 0.37 0.36]\n",
      "Epoch 2881, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2891, Loss: 0.22824999317526817, Accuracy: 0.9451219737529755\n",
      "Epoch 2891, Loss: 0.22824999317526817, Losses: [0.09 0.09 0.37 0.36]\n",
      "Epoch 2891, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2901, Loss: 0.22674289159476757, Accuracy: 0.9451219737529755\n",
      "Epoch 2901, Loss: 0.22674289159476757, Losses: [0.09 0.09 0.37 0.36]\n",
      "Epoch 2901, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2911, Loss: 0.227843614295125, Accuracy: 0.9329268336296082\n",
      "Epoch 2911, Loss: 0.227843614295125, Losses: [0.09 0.09 0.37 0.36]\n",
      "Epoch 2911, Accuracy: 0.9329268336296082, Accuracies: [0.98 0.98 0.83 0.95]\n",
      "Epoch 2921, Loss: 0.2236633151769638, Accuracy: 0.9451219737529755\n",
      "Epoch 2921, Loss: 0.2236633151769638, Losses: [0.09 0.09 0.37 0.35]\n",
      "Epoch 2921, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2931, Loss: 0.22201377898454666, Accuracy: 0.9451219737529755\n",
      "Epoch 2931, Loss: 0.22201377898454666, Losses: [0.09 0.08 0.36 0.35]\n",
      "Epoch 2931, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2941, Loss: 0.2260311357676983, Accuracy: 0.9512195289134979\n",
      "Epoch 2941, Loss: 0.2260311357676983, Losses: [0.09 0.08 0.37 0.35]\n",
      "Epoch 2941, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 2951, Loss: 0.21862227842211723, Accuracy: 0.9451219737529755\n",
      "Epoch 2951, Loss: 0.21862227842211723, Losses: [0.09 0.08 0.36 0.34]\n",
      "Epoch 2951, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2961, Loss: 0.21690665744245052, Accuracy: 0.9451219737529755\n",
      "Epoch 2961, Loss: 0.21690665744245052, Losses: [0.09 0.08 0.36 0.34]\n",
      "Epoch 2961, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2971, Loss: 0.2169352900236845, Accuracy: 0.9451219737529755\n",
      "Epoch 2971, Loss: 0.2169352900236845, Losses: [0.09 0.08 0.36 0.34]\n",
      "Epoch 2971, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 2981, Loss: 0.2395022101700306, Accuracy: 0.9268292784690857\n",
      "Epoch 2981, Loss: 0.2395022101700306, Losses: [0.1  0.08 0.4  0.37]\n",
      "Epoch 2981, Accuracy: 0.9268292784690857, Accuracies: [0.98 0.98 0.83 0.93]\n",
      "Epoch 2991, Loss: 0.270537905395031, Accuracy: 0.9146341681480408\n",
      "Epoch 2991, Loss: 0.270537905395031, Losses: [0.1  0.09 0.41 0.48]\n",
      "Epoch 2991, Accuracy: 0.9146341681480408, Accuracies: [0.98 0.98 0.85 0.85]\n",
      "Epoch 3001, Loss: 0.6487923841923475, Accuracy: 0.817073181271553\n",
      "Epoch 3001, Loss: 0.6487923841923475, Losses: [0.14 0.1  1.48 0.88]\n",
      "Epoch 3001, Accuracy: 0.817073181271553, Accuracies: [0.95 0.98 0.68 0.66]\n",
      "Epoch 3011, Loss: 0.2427404820919037, Accuracy: 0.9329268485307693\n",
      "Epoch 3011, Loss: 0.2427404820919037, Losses: [0.1  0.09 0.38 0.4 ]\n",
      "Epoch 3011, Accuracy: 0.9329268485307693, Accuracies: [0.98 0.98 0.85 0.93]\n",
      "Epoch 3021, Loss: 0.21966150403022766, Accuracy: 0.9390244036912918\n",
      "Epoch 3021, Loss: 0.21966150403022766, Losses: [0.09 0.09 0.35 0.35]\n",
      "Epoch 3021, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 3031, Loss: 0.2144321296364069, Accuracy: 0.9390244036912918\n",
      "Epoch 3031, Loss: 0.2144321296364069, Losses: [0.09 0.09 0.35 0.34]\n",
      "Epoch 3031, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 3041, Loss: 0.21168620511889458, Accuracy: 0.9451219737529755\n",
      "Epoch 3041, Loss: 0.21168620511889458, Losses: [0.09 0.08 0.35 0.33]\n",
      "Epoch 3041, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3051, Loss: 0.20963184721767902, Accuracy: 0.9451219737529755\n",
      "Epoch 3051, Loss: 0.20963184721767902, Losses: [0.09 0.08 0.34 0.33]\n",
      "Epoch 3051, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3061, Loss: 0.20785536617040634, Accuracy: 0.9451219737529755\n",
      "Epoch 3061, Loss: 0.20785536617040634, Losses: [0.09 0.08 0.34 0.32]\n",
      "Epoch 3061, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3071, Loss: 0.20632641948759556, Accuracy: 0.9451219737529755\n",
      "Epoch 3071, Loss: 0.20632641948759556, Losses: [0.08 0.08 0.34 0.32]\n",
      "Epoch 3071, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3081, Loss: 0.20489701256155968, Accuracy: 0.9451219737529755\n",
      "Epoch 3081, Loss: 0.20489701256155968, Losses: [0.08 0.08 0.34 0.32]\n",
      "Epoch 3081, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3091, Loss: 0.20347633212804794, Accuracy: 0.9451219737529755\n",
      "Epoch 3091, Loss: 0.20347633212804794, Losses: [0.08 0.08 0.33 0.32]\n",
      "Epoch 3091, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3101, Loss: 0.2020890899002552, Accuracy: 0.9451219737529755\n",
      "Epoch 3101, Loss: 0.2020890899002552, Losses: [0.08 0.08 0.33 0.31]\n",
      "Epoch 3101, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3111, Loss: 0.20076114125549793, Accuracy: 0.9451219737529755\n",
      "Epoch 3111, Loss: 0.20076114125549793, Losses: [0.08 0.08 0.33 0.31]\n",
      "Epoch 3111, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3121, Loss: 0.19937463104724884, Accuracy: 0.9451219737529755\n",
      "Epoch 3121, Loss: 0.19937463104724884, Losses: [0.08 0.08 0.33 0.31]\n",
      "Epoch 3121, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3131, Loss: 0.19804633781313896, Accuracy: 0.9451219737529755\n",
      "Epoch 3131, Loss: 0.19804633781313896, Losses: [0.08 0.08 0.33 0.31]\n",
      "Epoch 3131, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3141, Loss: 0.19675970822572708, Accuracy: 0.9451219737529755\n",
      "Epoch 3141, Loss: 0.19675970822572708, Losses: [0.08 0.08 0.32 0.3 ]\n",
      "Epoch 3141, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3151, Loss: 0.19541454873979092, Accuracy: 0.9451219737529755\n",
      "Epoch 3151, Loss: 0.19541454873979092, Losses: [0.08 0.08 0.32 0.3 ]\n",
      "Epoch 3151, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3161, Loss: 0.19414575956761837, Accuracy: 0.9451219737529755\n",
      "Epoch 3161, Loss: 0.19414575956761837, Losses: [0.08 0.08 0.32 0.3 ]\n",
      "Epoch 3161, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3171, Loss: 0.19317416287958622, Accuracy: 0.9451219737529755\n",
      "Epoch 3171, Loss: 0.19317416287958622, Losses: [0.08 0.08 0.32 0.3 ]\n",
      "Epoch 3171, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3181, Loss: 0.19464450515806675, Accuracy: 0.9451219588518143\n",
      "Epoch 3181, Loss: 0.19464450515806675, Losses: [0.08 0.08 0.32 0.31]\n",
      "Epoch 3181, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.98 0.88 0.95]\n",
      "Epoch 3191, Loss: 0.203724917024374, Accuracy: 0.9390244036912918\n",
      "Epoch 3191, Loss: 0.203724917024374, Losses: [0.08 0.08 0.32 0.34]\n",
      "Epoch 3191, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.88 0.93]\n",
      "Epoch 3201, Loss: 0.1931942980736494, Accuracy: 0.9512195289134979\n",
      "Epoch 3201, Loss: 0.1931942980736494, Losses: [0.08 0.07 0.32 0.3 ]\n",
      "Epoch 3201, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3211, Loss: 0.18887113966047764, Accuracy: 0.9512195289134979\n",
      "Epoch 3211, Loss: 0.18887113966047764, Losses: [0.08 0.07 0.31 0.29]\n",
      "Epoch 3211, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3221, Loss: 0.18696784414350986, Accuracy: 0.9451219737529755\n",
      "Epoch 3221, Loss: 0.18696784414350986, Losses: [0.08 0.07 0.31 0.29]\n",
      "Epoch 3221, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3231, Loss: 0.18569520488381386, Accuracy: 0.9512195289134979\n",
      "Epoch 3231, Loss: 0.18569520488381386, Losses: [0.08 0.07 0.31 0.29]\n",
      "Epoch 3231, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3241, Loss: 0.18437371589243412, Accuracy: 0.9512195289134979\n",
      "Epoch 3241, Loss: 0.18437371589243412, Losses: [0.08 0.07 0.31 0.28]\n",
      "Epoch 3241, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3251, Loss: 0.18308423645794392, Accuracy: 0.9512195289134979\n",
      "Epoch 3251, Loss: 0.18308423645794392, Losses: [0.07 0.07 0.31 0.28]\n",
      "Epoch 3251, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3261, Loss: 0.1817841399461031, Accuracy: 0.9512195289134979\n",
      "Epoch 3261, Loss: 0.1817841399461031, Losses: [0.07 0.07 0.3  0.28]\n",
      "Epoch 3261, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3271, Loss: 0.18039439246058464, Accuracy: 0.9512195289134979\n",
      "Epoch 3271, Loss: 0.18039439246058464, Losses: [0.07 0.07 0.3  0.28]\n",
      "Epoch 3271, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3281, Loss: 0.17942574247717857, Accuracy: 0.9512195289134979\n",
      "Epoch 3281, Loss: 0.17942574247717857, Losses: [0.07 0.07 0.3  0.28]\n",
      "Epoch 3281, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3291, Loss: 0.18375428020954132, Accuracy: 0.9451219588518143\n",
      "Epoch 3291, Loss: 0.18375428020954132, Losses: [0.07 0.07 0.3  0.29]\n",
      "Epoch 3291, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.98 0.88 0.95]\n",
      "Epoch 3301, Loss: 0.17833212018013, Accuracy: 0.9512195289134979\n",
      "Epoch 3301, Loss: 0.17833212018013, Losses: [0.07 0.07 0.3  0.28]\n",
      "Epoch 3301, Accuracy: 0.9512195289134979, Accuracies: [0.98 0.98 0.88 0.98]\n",
      "Epoch 3311, Loss: 0.1753782294690609, Accuracy: 0.9573170840740204\n",
      "Epoch 3311, Loss: 0.1753782294690609, Losses: [0.07 0.07 0.29 0.27]\n",
      "Epoch 3311, Accuracy: 0.9573170840740204, Accuracies: [0.98 0.98 0.88 1.  ]\n",
      "Epoch 3321, Loss: 0.19431726448237896, Accuracy: 0.9451219588518143\n",
      "Epoch 3321, Loss: 0.19431726448237896, Losses: [0.07 0.1  0.31 0.3 ]\n",
      "Epoch 3321, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.95 0.93 0.93]\n",
      "Epoch 3331, Loss: 0.2188252992928028, Accuracy: 0.9451219439506531\n",
      "Epoch 3331, Loss: 0.2188252992928028, Losses: [0.23 0.07 0.3  0.27]\n",
      "Epoch 3331, Accuracy: 0.9451219439506531, Accuracies: [0.9  0.98 0.9  1.  ]\n",
      "Epoch 3341, Loss: 0.17819788493216038, Accuracy: 0.9634146392345428\n",
      "Epoch 3341, Loss: 0.17819788493216038, Losses: [0.08 0.07 0.29 0.27]\n",
      "Epoch 3341, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3351, Loss: 0.21215628273785114, Accuracy: 0.9451219588518143\n",
      "Epoch 3351, Loss: 0.21215628273785114, Losses: [0.07 0.07 0.3  0.41]\n",
      "Epoch 3351, Accuracy: 0.9451219588518143, Accuracies: [0.98 0.98 0.9  0.93]\n",
      "Epoch 3361, Loss: 0.1729387678205967, Accuracy: 0.9573170840740204\n",
      "Epoch 3361, Loss: 0.1729387678205967, Losses: [0.07 0.07 0.29 0.26]\n",
      "Epoch 3361, Accuracy: 0.9573170840740204, Accuracies: [0.98 0.98 0.88 1.  ]\n",
      "Epoch 3371, Loss: 0.16895260103046894, Accuracy: 0.9634146392345428\n",
      "Epoch 3371, Loss: 0.16895260103046894, Losses: [0.07 0.07 0.28 0.26]\n",
      "Epoch 3371, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3381, Loss: 0.16752963326871395, Accuracy: 0.9573170840740204\n",
      "Epoch 3381, Loss: 0.16752963326871395, Losses: [0.07 0.07 0.28 0.26]\n",
      "Epoch 3381, Accuracy: 0.9573170840740204, Accuracies: [0.98 0.98 0.88 1.  ]\n",
      "Epoch 3391, Loss: 0.1664565596729517, Accuracy: 0.9634146392345428\n",
      "Epoch 3391, Loss: 0.1664565596729517, Losses: [0.07 0.07 0.28 0.25]\n",
      "Epoch 3391, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3401, Loss: 0.16564109735190868, Accuracy: 0.9573170840740204\n",
      "Epoch 3401, Loss: 0.16564109735190868, Losses: [0.07 0.07 0.28 0.25]\n",
      "Epoch 3401, Accuracy: 0.9573170840740204, Accuracies: [0.98 0.98 0.88 1.  ]\n",
      "Epoch 3411, Loss: 0.1738201640546322, Accuracy: 0.963414654135704\n",
      "Epoch 3411, Loss: 0.1738201640546322, Losses: [0.07 0.07 0.28 0.29]\n",
      "Epoch 3411, Accuracy: 0.963414654135704, Accuracies: [0.98 0.98 0.93 0.98]\n",
      "Epoch 3421, Loss: 0.3832680154591799, Accuracy: 0.8658536821603775\n",
      "Epoch 3421, Loss: 0.3832680154591799, Losses: [0.08 0.08 0.98 0.39]\n",
      "Epoch 3421, Accuracy: 0.8658536821603775, Accuracies: [0.98 0.98 0.66 0.85]\n",
      "Epoch 3431, Loss: 0.4249182529747486, Accuracy: 0.8658536672592163\n",
      "Epoch 3431, Loss: 0.4249182529747486, Losses: [0.08 0.1  0.52 1.01]\n",
      "Epoch 3431, Accuracy: 0.8658536672592163, Accuracies: [0.98 1.   0.8  0.68]\n",
      "Epoch 3441, Loss: 0.4254893958568573, Accuracy: 0.8658536672592163\n",
      "Epoch 3441, Loss: 0.4254893958568573, Losses: [0.73 0.08 0.47 0.42]\n",
      "Epoch 3441, Accuracy: 0.8658536672592163, Accuracies: [0.8  0.98 0.85 0.83]\n",
      "Epoch 3451, Loss: 0.18862898834049702, Accuracy: 0.9451219737529755\n",
      "Epoch 3451, Loss: 0.18862898834049702, Losses: [0.11 0.07 0.3  0.27]\n",
      "Epoch 3451, Accuracy: 0.9451219737529755, Accuracies: [0.98 0.98 0.85 0.98]\n",
      "Epoch 3461, Loss: 0.1748897098004818, Accuracy: 0.9573170840740204\n",
      "Epoch 3461, Loss: 0.1748897098004818, Losses: [0.09 0.07 0.29 0.25]\n",
      "Epoch 3461, Accuracy: 0.9573170840740204, Accuracies: [0.98 0.98 0.88 1.  ]\n",
      "Epoch 3471, Loss: 0.17020595632493496, Accuracy: 0.9634146392345428\n",
      "Epoch 3471, Loss: 0.17020595632493496, Losses: [0.08 0.07 0.28 0.25]\n",
      "Epoch 3471, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3481, Loss: 0.16748597845435143, Accuracy: 0.9634146392345428\n",
      "Epoch 3481, Loss: 0.16748597845435143, Losses: [0.08 0.07 0.28 0.25]\n",
      "Epoch 3481, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3491, Loss: 0.16546746715903282, Accuracy: 0.9634146392345428\n",
      "Epoch 3491, Loss: 0.16546746715903282, Losses: [0.08 0.07 0.28 0.24]\n",
      "Epoch 3491, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3501, Loss: 0.16368904151022434, Accuracy: 0.9634146392345428\n",
      "Epoch 3501, Loss: 0.16368904151022434, Losses: [0.07 0.07 0.27 0.24]\n",
      "Epoch 3501, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.9  1.  ]\n",
      "Epoch 3511, Loss: 0.16204642318189144, Accuracy: 0.9695122092962265\n",
      "Epoch 3511, Loss: 0.16204642318189144, Losses: [0.07 0.06 0.27 0.24]\n",
      "Epoch 3511, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3521, Loss: 0.1605193391442299, Accuracy: 0.9695122092962265\n",
      "Epoch 3521, Loss: 0.1605193391442299, Losses: [0.07 0.06 0.27 0.24]\n",
      "Epoch 3521, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3531, Loss: 0.15904239937663078, Accuracy: 0.9695122092962265\n",
      "Epoch 3531, Loss: 0.15904239937663078, Losses: [0.07 0.06 0.27 0.24]\n",
      "Epoch 3531, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3541, Loss: 0.15762610733509064, Accuracy: 0.9695122092962265\n",
      "Epoch 3541, Loss: 0.15762610733509064, Losses: [0.07 0.06 0.26 0.24]\n",
      "Epoch 3541, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3551, Loss: 0.1562466761097312, Accuracy: 0.9695122092962265\n",
      "Epoch 3551, Loss: 0.1562466761097312, Losses: [0.07 0.06 0.26 0.23]\n",
      "Epoch 3551, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3561, Loss: 0.15492770541459322, Accuracy: 0.9695122092962265\n",
      "Epoch 3561, Loss: 0.15492770541459322, Losses: [0.07 0.06 0.26 0.23]\n",
      "Epoch 3561, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3571, Loss: 0.1536618797108531, Accuracy: 0.9695122092962265\n",
      "Epoch 3571, Loss: 0.1536618797108531, Losses: [0.06 0.06 0.26 0.23]\n",
      "Epoch 3571, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3581, Loss: 0.15250350534915924, Accuracy: 0.9695122092962265\n",
      "Epoch 3581, Loss: 0.15250350534915924, Losses: [0.06 0.06 0.26 0.23]\n",
      "Epoch 3581, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3591, Loss: 0.15135930571705103, Accuracy: 0.9695122092962265\n",
      "Epoch 3591, Loss: 0.15135930571705103, Losses: [0.06 0.06 0.25 0.23]\n",
      "Epoch 3591, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3601, Loss: 0.15021609608083963, Accuracy: 0.9695122092962265\n",
      "Epoch 3601, Loss: 0.15021609608083963, Losses: [0.06 0.06 0.25 0.23]\n",
      "Epoch 3601, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3611, Loss: 0.14904462452977896, Accuracy: 0.9695122092962265\n",
      "Epoch 3611, Loss: 0.14904462452977896, Losses: [0.06 0.06 0.25 0.22]\n",
      "Epoch 3611, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3621, Loss: 0.1479548793286085, Accuracy: 0.9695122092962265\n",
      "Epoch 3621, Loss: 0.1479548793286085, Losses: [0.06 0.06 0.25 0.22]\n",
      "Epoch 3621, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3631, Loss: 0.14685309398919344, Accuracy: 0.9695122092962265\n",
      "Epoch 3631, Loss: 0.14685309398919344, Losses: [0.06 0.06 0.25 0.22]\n",
      "Epoch 3631, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3641, Loss: 0.14578627049922943, Accuracy: 0.9695122092962265\n",
      "Epoch 3641, Loss: 0.14578627049922943, Losses: [0.06 0.06 0.24 0.22]\n",
      "Epoch 3641, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3651, Loss: 0.14473887626081705, Accuracy: 0.9695122092962265\n",
      "Epoch 3651, Loss: 0.14473887626081705, Losses: [0.06 0.06 0.24 0.22]\n",
      "Epoch 3651, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3661, Loss: 0.14360781479626894, Accuracy: 0.9695122092962265\n",
      "Epoch 3661, Loss: 0.14360781479626894, Losses: [0.06 0.06 0.24 0.22]\n",
      "Epoch 3661, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Epoch 3671, Loss: 0.14265299960970879, Accuracy: 0.9695122092962265\n",
      "Epoch 3671, Loss: 0.14265299960970879, Losses: [0.06 0.06 0.24 0.22]\n",
      "Epoch 3671, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.93 1.  ]\n",
      "Early stopping criteria met\n",
      "Training GRU...\n",
      "Epoch 1, Loss: 2.1026984453201294, Accuracy: 0.17073170468211174\n",
      "Epoch 1, Loss: 2.1026984453201294, Losses: [2.14 2.07 2.1  2.1 ]\n",
      "Epoch 1, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 11, Loss: 2.0232678055763245, Accuracy: 0.17073170468211174\n",
      "Epoch 11, Loss: 2.0232678055763245, Losses: [2.06 1.99 2.01 2.03]\n",
      "Epoch 11, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 21, Loss: 1.9149482250213623, Accuracy: 0.21341462805867195\n",
      "Epoch 21, Loss: 1.9149482250213623, Losses: [2.02 1.85 1.88 1.92]\n",
      "Epoch 21, Accuracy: 0.21341462805867195, Accuracies: [0.29 0.2  0.17 0.2 ]\n",
      "Epoch 31, Loss: 1.8662210404872894, Accuracy: 0.27439024299383163\n",
      "Epoch 31, Loss: 1.8662210404872894, Losses: [2.05 1.75 1.82 1.85]\n",
      "Epoch 31, Accuracy: 0.27439024299383163, Accuracies: [0.29 0.34 0.2  0.27]\n",
      "Epoch 41, Loss: 1.8191454112529755, Accuracy: 0.34756097942590714\n",
      "Epoch 41, Loss: 1.8191454112529755, Losses: [2.02 1.66 1.78 1.83]\n",
      "Epoch 41, Accuracy: 0.34756097942590714, Accuracies: [0.29 0.49 0.27 0.34]\n",
      "Epoch 51, Loss: 1.7566580474376678, Accuracy: 0.4451219439506531\n",
      "Epoch 51, Loss: 1.7566580474376678, Losses: [1.99 1.5  1.72 1.81]\n",
      "Epoch 51, Accuracy: 0.4451219439506531, Accuracies: [0.29 0.83 0.37 0.29]\n",
      "Epoch 61, Loss: 1.6840698719024658, Accuracy: 0.4390243887901306\n",
      "Epoch 61, Loss: 1.6840698719024658, Losses: [1.94 1.32 1.67 1.8 ]\n",
      "Epoch 61, Accuracy: 0.4390243887901306, Accuracies: [0.29 0.83 0.37 0.27]\n",
      "Epoch 71, Loss: 1.612868756055832, Accuracy: 0.46341463923454285\n",
      "Epoch 71, Loss: 1.612868756055832, Losses: [1.88 1.14 1.62 1.81]\n",
      "Epoch 71, Accuracy: 0.46341463923454285, Accuracies: [0.29 0.98 0.34 0.24]\n",
      "Epoch 81, Loss: 1.5372225940227509, Accuracy: 0.4695122018456459\n",
      "Epoch 81, Loss: 1.5372225940227509, Losses: [1.78 0.98 1.57 1.82]\n",
      "Epoch 81, Accuracy: 0.4695122018456459, Accuracies: [0.29 0.98 0.37 0.24]\n",
      "Epoch 91, Loss: 1.4522554129362106, Accuracy: 0.5060975626111031\n",
      "Epoch 91, Loss: 1.4522554129362106, Losses: [1.61 0.83 1.53 1.83]\n",
      "Epoch 91, Accuracy: 0.5060975626111031, Accuracies: [0.41 0.98 0.39 0.24]\n",
      "Epoch 101, Loss: 1.3748168349266052, Accuracy: 0.5365853756666183\n",
      "Epoch 101, Loss: 1.3748168349266052, Losses: [1.45 0.72 1.47 1.85]\n",
      "Epoch 101, Accuracy: 0.5365853756666183, Accuracies: [0.46 0.98 0.44 0.27]\n",
      "Epoch 111, Loss: 1.3040605634450912, Accuracy: 0.5426829382777214\n",
      "Epoch 111, Loss: 1.3040605634450912, Losses: [1.34 0.63 1.41 1.84]\n",
      "Epoch 111, Accuracy: 0.5426829382777214, Accuracies: [0.46 0.98 0.46 0.27]\n",
      "Epoch 121, Loss: 1.2380697131156921, Accuracy: 0.5975609868764877\n",
      "Epoch 121, Loss: 1.2380697131156921, Losses: [1.23 0.55 1.36 1.81]\n",
      "Epoch 121, Accuracy: 0.5975609868764877, Accuracies: [0.61 0.98 0.49 0.32]\n",
      "Epoch 131, Loss: 1.174730472266674, Accuracy: 0.6036585494875908\n",
      "Epoch 131, Loss: 1.174730472266674, Losses: [1.15 0.49 1.31 1.75]\n",
      "Epoch 131, Accuracy: 0.6036585494875908, Accuracies: [0.61 0.98 0.49 0.34]\n",
      "Epoch 141, Loss: 1.1113032326102257, Accuracy: 0.6158536747097969\n",
      "Epoch 141, Loss: 1.1113032326102257, Losses: [1.06 0.44 1.26 1.69]\n",
      "Epoch 141, Accuracy: 0.6158536747097969, Accuracies: [0.66 0.98 0.49 0.34]\n",
      "Epoch 151, Loss: 1.049124151468277, Accuracy: 0.6219512298703194\n",
      "Epoch 151, Loss: 1.049124151468277, Losses: [1.01 0.39 1.2  1.6 ]\n",
      "Epoch 151, Accuracy: 0.6219512298703194, Accuracies: [0.68 0.98 0.49 0.34]\n",
      "Epoch 161, Loss: 0.9868186563253403, Accuracy: 0.6585365831851959\n",
      "Epoch 161, Loss: 0.9868186563253403, Losses: [0.93 0.36 1.14 1.51]\n",
      "Epoch 161, Accuracy: 0.6585365831851959, Accuracies: [0.71 0.98 0.51 0.44]\n",
      "Epoch 171, Loss: 0.9281498864293098, Accuracy: 0.6829268336296082\n",
      "Epoch 171, Loss: 0.9281498864293098, Losses: [0.87 0.32 1.08 1.43]\n",
      "Epoch 171, Accuracy: 0.6829268336296082, Accuracies: [0.73 0.98 0.59 0.44]\n",
      "Epoch 181, Loss: 0.8832462802529335, Accuracy: 0.6951219514012337\n",
      "Epoch 181, Loss: 0.8832462802529335, Losses: [0.83 0.29 1.07 1.34]\n",
      "Epoch 181, Accuracy: 0.6951219514012337, Accuracies: [0.78 0.98 0.61 0.41]\n",
      "Epoch 191, Loss: 0.8274199813604355, Accuracy: 0.7317073196172714\n",
      "Epoch 191, Loss: 0.8274199813604355, Losses: [0.78 0.27 0.98 1.28]\n",
      "Epoch 191, Accuracy: 0.7317073196172714, Accuracies: [0.78 0.98 0.68 0.49]\n",
      "Epoch 201, Loss: 0.77906733751297, Accuracy: 0.731707327067852\n",
      "Epoch 201, Loss: 0.77906733751297, Losses: [0.74 0.25 0.93 1.2 ]\n",
      "Epoch 201, Accuracy: 0.731707327067852, Accuracies: [0.8  0.98 0.68 0.46]\n",
      "Epoch 211, Loss: 0.7337899394333363, Accuracy: 0.75\n",
      "Epoch 211, Loss: 0.7337899394333363, Losses: [0.7  0.24 0.88 1.12]\n",
      "Epoch 211, Accuracy: 0.75, Accuracies: [0.8  0.98 0.71 0.51]\n",
      "Epoch 221, Loss: 0.6986464187502861, Accuracy: 0.7682926952838898\n",
      "Epoch 221, Loss: 0.6986464187502861, Losses: [0.67 0.23 0.85 1.05]\n",
      "Epoch 221, Accuracy: 0.7682926952838898, Accuracies: [0.83 0.98 0.73 0.54]\n",
      "Epoch 231, Loss: 0.6662952974438667, Accuracy: 0.7804878205060959\n",
      "Epoch 231, Loss: 0.6662952974438667, Losses: [0.64 0.21 0.81 1.01]\n",
      "Epoch 231, Accuracy: 0.7804878205060959, Accuracies: [0.8  0.98 0.68 0.66]\n",
      "Epoch 241, Loss: 0.623871486634016, Accuracy: 0.8048780560493469\n",
      "Epoch 241, Loss: 0.623871486634016, Losses: [0.6  0.2  0.76 0.93]\n",
      "Epoch 241, Accuracy: 0.8048780560493469, Accuracies: [0.83 0.98 0.73 0.68]\n",
      "Epoch 251, Loss: 0.5867110639810562, Accuracy: 0.8109756112098694\n",
      "Epoch 251, Loss: 0.5867110639810562, Losses: [0.57 0.19 0.71 0.87]\n",
      "Epoch 251, Accuracy: 0.8109756112098694, Accuracies: [0.83 0.98 0.73 0.71]\n",
      "Epoch 261, Loss: 0.5524784848093987, Accuracy: 0.8475609719753265\n",
      "Epoch 261, Loss: 0.5524784848093987, Losses: [0.54 0.18 0.67 0.82]\n",
      "Epoch 261, Accuracy: 0.8475609719753265, Accuracies: [0.9  0.98 0.78 0.73]\n",
      "Epoch 271, Loss: 0.5208321325480938, Accuracy: 0.8597560971975327\n",
      "Epoch 271, Loss: 0.5208321325480938, Losses: [0.51 0.17 0.64 0.76]\n",
      "Epoch 271, Accuracy: 0.8597560971975327, Accuracies: [0.9  0.98 0.76 0.8 ]\n",
      "Epoch 281, Loss: 0.4923911727964878, Accuracy: 0.8719512224197388\n",
      "Epoch 281, Loss: 0.4923911727964878, Losses: [0.49 0.16 0.6  0.71]\n",
      "Epoch 281, Accuracy: 0.8719512224197388, Accuracies: [0.9  0.98 0.8  0.8 ]\n",
      "Epoch 291, Loss: 0.4621517285704613, Accuracy: 0.8841463476419449\n",
      "Epoch 291, Loss: 0.4621517285704613, Losses: [0.46 0.16 0.56 0.67]\n",
      "Epoch 291, Accuracy: 0.8841463476419449, Accuracies: [0.9  0.98 0.85 0.8 ]\n",
      "Epoch 301, Loss: 0.44031964614987373, Accuracy: 0.896341472864151\n",
      "Epoch 301, Loss: 0.44031964614987373, Losses: [0.44 0.15 0.54 0.63]\n",
      "Epoch 301, Accuracy: 0.896341472864151, Accuracies: [0.9  0.98 0.85 0.85]\n",
      "Epoch 311, Loss: 0.4124523811042309, Accuracy: 0.9085365831851959\n",
      "Epoch 311, Loss: 0.4124523811042309, Losses: [0.42 0.14 0.51 0.58]\n",
      "Epoch 311, Accuracy: 0.9085365831851959, Accuracies: [0.9  0.98 0.85 0.9 ]\n",
      "Epoch 321, Loss: 0.39131566137075424, Accuracy: 0.9085365831851959\n",
      "Epoch 321, Loss: 0.39131566137075424, Losses: [0.39 0.14 0.48 0.55]\n",
      "Epoch 321, Accuracy: 0.9085365831851959, Accuracies: [0.9  0.98 0.88 0.88]\n",
      "Epoch 331, Loss: 0.3680241033434868, Accuracy: 0.9268292635679245\n",
      "Epoch 331, Loss: 0.3680241033434868, Losses: [0.37 0.13 0.46 0.51]\n",
      "Epoch 331, Accuracy: 0.9268292635679245, Accuracies: [0.9  0.98 0.9  0.93]\n",
      "Epoch 341, Loss: 0.3594839498400688, Accuracy: 0.896341472864151\n",
      "Epoch 341, Loss: 0.3594839498400688, Losses: [0.36 0.13 0.46 0.49]\n",
      "Epoch 341, Accuracy: 0.896341472864151, Accuracies: [0.9  0.98 0.85 0.85]\n",
      "Epoch 351, Loss: 0.330157745629549, Accuracy: 0.9268292635679245\n",
      "Epoch 351, Loss: 0.330157745629549, Losses: [0.33 0.12 0.41 0.45]\n",
      "Epoch 351, Accuracy: 0.9268292635679245, Accuracies: [0.9  0.98 0.9  0.93]\n",
      "Epoch 361, Loss: 0.309194415807724, Accuracy: 0.9268292635679245\n",
      "Epoch 361, Loss: 0.309194415807724, Losses: [0.31 0.12 0.39 0.42]\n",
      "Epoch 361, Accuracy: 0.9268292635679245, Accuracies: [0.9  0.98 0.9  0.93]\n",
      "Epoch 371, Loss: 0.29063387401401997, Accuracy: 0.9390243887901306\n",
      "Epoch 371, Loss: 0.29063387401401997, Losses: [0.29 0.12 0.37 0.38]\n",
      "Epoch 371, Accuracy: 0.9390243887901306, Accuracies: [0.9  0.98 0.95 0.93]\n",
      "Epoch 381, Loss: 0.2788793481886387, Accuracy: 0.9390243887901306\n",
      "Epoch 381, Loss: 0.2788793481886387, Losses: [0.28 0.11 0.35 0.37]\n",
      "Epoch 381, Accuracy: 0.9390243887901306, Accuracies: [0.9  0.98 0.95 0.93]\n",
      "Epoch 391, Loss: 0.2680008802562952, Accuracy: 0.9390243887901306\n",
      "Epoch 391, Loss: 0.2680008802562952, Losses: [0.27 0.11 0.34 0.35]\n",
      "Epoch 391, Accuracy: 0.9390243887901306, Accuracies: [0.9  0.98 0.95 0.93]\n",
      "Epoch 401, Loss: 0.24483404122292995, Accuracy: 0.9512195140123367\n",
      "Epoch 401, Loss: 0.24483404122292995, Losses: [0.24 0.11 0.32 0.31]\n",
      "Epoch 401, Accuracy: 0.9512195140123367, Accuracies: [0.93 0.98 0.95 0.95]\n",
      "Epoch 411, Loss: 0.23251932859420776, Accuracy: 0.9573170691728592\n",
      "Epoch 411, Loss: 0.23251932859420776, Losses: [0.23 0.11 0.3  0.29]\n",
      "Epoch 411, Accuracy: 0.9573170691728592, Accuracies: [0.95 0.98 0.95 0.95]\n",
      "Epoch 421, Loss: 0.2198903039097786, Accuracy: 0.9573170691728592\n",
      "Epoch 421, Loss: 0.2198903039097786, Losses: [0.22 0.1  0.29 0.27]\n",
      "Epoch 421, Accuracy: 0.9573170691728592, Accuracies: [0.95 0.98 0.95 0.95]\n",
      "Epoch 431, Loss: 0.21504688821732998, Accuracy: 0.9573170691728592\n",
      "Epoch 431, Loss: 0.21504688821732998, Losses: [0.21 0.1  0.28 0.27]\n",
      "Epoch 431, Accuracy: 0.9573170691728592, Accuracies: [0.95 0.98 0.95 0.95]\n",
      "Epoch 441, Loss: 0.20850458554923534, Accuracy: 0.9573170840740204\n",
      "Epoch 441, Loss: 0.20850458554923534, Losses: [0.2  0.1  0.27 0.26]\n",
      "Epoch 441, Accuracy: 0.9573170840740204, Accuracies: [0.93 0.98 0.95 0.98]\n",
      "Epoch 451, Loss: 0.19378706999123096, Accuracy: 0.9634146392345428\n",
      "Epoch 451, Loss: 0.19378706999123096, Losses: [0.19 0.1  0.25 0.23]\n",
      "Epoch 451, Accuracy: 0.9634146392345428, Accuracies: [0.98 0.98 0.95 0.95]\n",
      "Epoch 461, Loss: 0.18504405952990055, Accuracy: 0.9695122092962265\n",
      "Epoch 461, Loss: 0.18504405952990055, Losses: [0.18 0.1  0.24 0.22]\n",
      "Epoch 461, Accuracy: 0.9695122092962265, Accuracies: [0.98 0.98 0.95 0.98]\n",
      "Early stopping criteria met\n",
      "Training GRUA...\n",
      "Epoch 1, Loss: 2.0881690979003906, Accuracy: 0.12804877944290638\n",
      "Epoch 1, Loss: 2.0881690979003906, Losses: [2.09 2.09 2.12 2.06]\n",
      "Epoch 1, Accuracy: 0.12804877944290638, Accuracies: [0.07 0.15 0.12 0.17]\n",
      "Epoch 11, Loss: 2.004723995923996, Accuracy: 0.17073170468211174\n",
      "Epoch 11, Loss: 2.004723995923996, Losses: [2.04 2.   2.02 1.97]\n",
      "Epoch 11, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.17 0.15 0.17]\n",
      "Epoch 21, Loss: 1.9330894351005554, Accuracy: 0.17073170468211174\n",
      "Epoch 21, Loss: 1.9330894351005554, Losses: [2.02 1.91 1.9  1.9 ]\n",
      "Epoch 21, Accuracy: 0.17073170468211174, Accuracies: [0.2  0.15 0.12 0.22]\n",
      "Epoch 31, Loss: 1.9114669859409332, Accuracy: 0.19512195140123367\n",
      "Epoch 31, Loss: 1.9114669859409332, Losses: [2.05 1.88 1.85 1.87]\n",
      "Epoch 31, Accuracy: 0.19512195140123367, Accuracies: [0.22 0.17 0.22 0.17]\n",
      "Epoch 41, Loss: 1.9036507904529572, Accuracy: 0.19512195140123367\n",
      "Epoch 41, Loss: 1.9036507904529572, Losses: [2.05 1.87 1.84 1.86]\n",
      "Epoch 41, Accuracy: 0.19512195140123367, Accuracies: [0.22 0.15 0.24 0.17]\n",
      "Epoch 51, Loss: 1.8979866206645966, Accuracy: 0.2073170766234398\n",
      "Epoch 51, Loss: 1.8979866206645966, Losses: [2.05 1.86 1.83 1.85]\n",
      "Epoch 51, Accuracy: 0.2073170766234398, Accuracies: [0.24 0.17 0.24 0.17]\n",
      "Epoch 61, Loss: 1.8918722569942474, Accuracy: 0.21341463550925255\n",
      "Epoch 61, Loss: 1.8918722569942474, Losses: [2.03 1.86 1.83 1.84]\n",
      "Epoch 61, Accuracy: 0.21341463550925255, Accuracies: [0.27 0.15 0.24 0.2 ]\n",
      "Epoch 71, Loss: 1.8853111565113068, Accuracy: 0.20121951028704643\n",
      "Epoch 71, Loss: 1.8853111565113068, Losses: [2.03 1.86 1.82 1.83]\n",
      "Epoch 71, Accuracy: 0.20121951028704643, Accuracies: [0.22 0.15 0.24 0.2 ]\n",
      "Epoch 81, Loss: 1.874930590391159, Accuracy: 0.20121951028704643\n",
      "Epoch 81, Loss: 1.874930590391159, Losses: [2.   1.86 1.81 1.83]\n",
      "Epoch 81, Accuracy: 0.20121951028704643, Accuracies: [0.22 0.15 0.24 0.2 ]\n",
      "Epoch 91, Loss: 1.8537074327468872, Accuracy: 0.21341463550925255\n",
      "Epoch 91, Loss: 1.8537074327468872, Losses: [1.95 1.85 1.8  1.82]\n",
      "Epoch 91, Accuracy: 0.21341463550925255, Accuracies: [0.24 0.17 0.24 0.2 ]\n",
      "Epoch 101, Loss: 1.8078456223011017, Accuracy: 0.21341463550925255\n",
      "Epoch 101, Loss: 1.8078456223011017, Losses: [1.84 1.82 1.78 1.79]\n",
      "Epoch 101, Accuracy: 0.21341463550925255, Accuracies: [0.27 0.15 0.24 0.2 ]\n",
      "Epoch 111, Loss: 1.7675879001617432, Accuracy: 0.2682926803827286\n",
      "Epoch 111, Loss: 1.7675879001617432, Losses: [1.77 1.8  1.74 1.76]\n",
      "Epoch 111, Accuracy: 0.2682926803827286, Accuracies: [0.34 0.22 0.32 0.2 ]\n",
      "Epoch 121, Loss: 1.7253613770008087, Accuracy: 0.35975609719753265\n",
      "Epoch 121, Loss: 1.7253613770008087, Losses: [1.69 1.76 1.71 1.74]\n",
      "Epoch 121, Accuracy: 0.35975609719753265, Accuracies: [0.44 0.32 0.41 0.27]\n",
      "Epoch 131, Loss: 1.6379062235355377, Accuracy: 0.4268292710185051\n",
      "Epoch 131, Loss: 1.6379062235355377, Losses: [1.58 1.63 1.62 1.72]\n",
      "Epoch 131, Accuracy: 0.4268292710185051, Accuracies: [0.54 0.39 0.46 0.32]\n",
      "Epoch 141, Loss: 1.546022206544876, Accuracy: 0.414634145796299\n",
      "Epoch 141, Loss: 1.546022206544876, Losses: [1.44 1.48 1.55 1.72]\n",
      "Epoch 141, Accuracy: 0.414634145796299, Accuracies: [0.56 0.34 0.46 0.29]\n",
      "Epoch 151, Loss: 1.4812207520008087, Accuracy: 0.43292683362960815\n",
      "Epoch 151, Loss: 1.4812207520008087, Losses: [1.29 1.41 1.51 1.72]\n",
      "Epoch 151, Accuracy: 0.43292683362960815, Accuracies: [0.56 0.34 0.56 0.27]\n",
      "Epoch 161, Loss: 1.423949956893921, Accuracy: 0.4817073196172714\n",
      "Epoch 161, Loss: 1.423949956893921, Losses: [1.15 1.35 1.49 1.71]\n",
      "Epoch 161, Accuracy: 0.4817073196172714, Accuracies: [0.66 0.39 0.56 0.32]\n",
      "Epoch 171, Loss: 1.3724869787693024, Accuracy: 0.5060975551605225\n",
      "Epoch 171, Loss: 1.3724869787693024, Losses: [1.05 1.28 1.47 1.69]\n",
      "Epoch 171, Accuracy: 0.5060975551605225, Accuracies: [0.71 0.46 0.56 0.29]\n",
      "Epoch 181, Loss: 1.3314595967531204, Accuracy: 0.5487804934382439\n",
      "Epoch 181, Loss: 1.3314595967531204, Losses: [0.98 1.22 1.45 1.67]\n",
      "Epoch 181, Accuracy: 0.5487804934382439, Accuracies: [0.73 0.59 0.54 0.34]\n",
      "Epoch 191, Loss: 1.2848757058382034, Accuracy: 0.5487804859876633\n",
      "Epoch 191, Loss: 1.2848757058382034, Losses: [0.9  1.16 1.42 1.66]\n",
      "Epoch 191, Accuracy: 0.5487804859876633, Accuracies: [0.71 0.61 0.51 0.37]\n",
      "Epoch 201, Loss: 1.244703695178032, Accuracy: 0.5609756112098694\n",
      "Epoch 201, Loss: 1.244703695178032, Losses: [0.85 1.09 1.4  1.64]\n",
      "Epoch 201, Accuracy: 0.5609756112098694, Accuracies: [0.73 0.61 0.51 0.39]\n",
      "Epoch 211, Loss: 1.2087265998125076, Accuracy: 0.567073181271553\n",
      "Epoch 211, Loss: 1.2087265998125076, Losses: [0.81 1.03 1.38 1.61]\n",
      "Epoch 211, Accuracy: 0.567073181271553, Accuracies: [0.73 0.61 0.54 0.39]\n",
      "Epoch 221, Loss: 1.2073167264461517, Accuracy: 0.5548780560493469\n",
      "Epoch 221, Loss: 1.2073167264461517, Losses: [0.91 0.97 1.36 1.59]\n",
      "Epoch 221, Accuracy: 0.5548780560493469, Accuracies: [0.66 0.63 0.54 0.39]\n",
      "Epoch 231, Loss: 1.1492194533348083, Accuracy: 0.5670731663703918\n",
      "Epoch 231, Loss: 1.1492194533348083, Losses: [0.76 0.93 1.34 1.57]\n",
      "Epoch 231, Accuracy: 0.5670731663703918, Accuracies: [0.71 0.68 0.49 0.39]\n",
      "Epoch 241, Loss: 1.1181166023015976, Accuracy: 0.585365854203701\n",
      "Epoch 241, Loss: 1.1181166023015976, Losses: [0.72 0.88 1.32 1.55]\n",
      "Epoch 241, Accuracy: 0.585365854203701, Accuracies: [0.73 0.71 0.49 0.41]\n",
      "Epoch 251, Loss: 1.0904872715473175, Accuracy: 0.5914634168148041\n",
      "Epoch 251, Loss: 1.0904872715473175, Losses: [0.7  0.83 1.3  1.53]\n",
      "Epoch 251, Accuracy: 0.5914634168148041, Accuracies: [0.76 0.73 0.49 0.39]\n",
      "Epoch 261, Loss: 1.0625088512897491, Accuracy: 0.5975609719753265\n",
      "Epoch 261, Loss: 1.0625088512897491, Losses: [0.68 0.8  1.28 1.5 ]\n",
      "Epoch 261, Accuracy: 0.5975609719753265, Accuracies: [0.76 0.76 0.49 0.39]\n",
      "Epoch 271, Loss: 1.0333149582147598, Accuracy: 0.6463414654135704\n",
      "Epoch 271, Loss: 1.0333149582147598, Losses: [0.66 0.76 1.25 1.47]\n",
      "Epoch 271, Accuracy: 0.6463414654135704, Accuracies: [0.76 0.85 0.51 0.46]\n",
      "Epoch 281, Loss: 1.0161733627319336, Accuracy: 0.646341472864151\n",
      "Epoch 281, Loss: 1.0161733627319336, Losses: [0.68 0.73 1.22 1.43]\n",
      "Epoch 281, Accuracy: 0.646341472864151, Accuracies: [0.76 0.85 0.54 0.44]\n",
      "Epoch 291, Loss: 0.9766921699047089, Accuracy: 0.7073170691728592\n",
      "Epoch 291, Loss: 0.9766921699047089, Losses: [0.62 0.69 1.19 1.4 ]\n",
      "Epoch 291, Accuracy: 0.7073170691728592, Accuracies: [0.8  0.95 0.56 0.51]\n",
      "Epoch 301, Loss: 0.9508849680423737, Accuracy: 0.7195121943950653\n",
      "Epoch 301, Loss: 0.9508849680423737, Losses: [0.6  0.66 1.18 1.36]\n",
      "Epoch 301, Accuracy: 0.7195121943950653, Accuracies: [0.83 0.98 0.59 0.49]\n",
      "Epoch 311, Loss: 0.9260134696960449, Accuracy: 0.7195121943950653\n",
      "Epoch 311, Loss: 0.9260134696960449, Losses: [0.58 0.62 1.16 1.34]\n",
      "Epoch 311, Accuracy: 0.7195121943950653, Accuracies: [0.83 0.98 0.56 0.51]\n",
      "Epoch 321, Loss: 0.9007973372936249, Accuracy: 0.725609764456749\n",
      "Epoch 321, Loss: 0.9007973372936249, Losses: [0.56 0.59 1.14 1.31]\n",
      "Epoch 321, Accuracy: 0.725609764456749, Accuracies: [0.8  0.98 0.61 0.51]\n",
      "Epoch 331, Loss: 0.87922103703022, Accuracy: 0.7378048896789551\n",
      "Epoch 331, Loss: 0.87922103703022, Losses: [0.55 0.56 1.13 1.28]\n",
      "Epoch 331, Accuracy: 0.7378048896789551, Accuracies: [0.85 0.98 0.61 0.51]\n",
      "Epoch 341, Loss: 0.8588041067123413, Accuracy: 0.7317073345184326\n",
      "Epoch 341, Loss: 0.8588041067123413, Losses: [0.53 0.53 1.12 1.25]\n",
      "Epoch 341, Accuracy: 0.7317073345184326, Accuracies: [0.85 0.98 0.61 0.49]\n",
      "Epoch 351, Loss: 0.8479168266057968, Accuracy: 0.7378048747777939\n",
      "Epoch 351, Loss: 0.8479168266057968, Losses: [0.5  0.51 1.14 1.24]\n",
      "Epoch 351, Accuracy: 0.7378048747777939, Accuracies: [0.9  0.98 0.56 0.51]\n",
      "Epoch 361, Loss: 0.8265057057142258, Accuracy: 0.7682926803827286\n",
      "Epoch 361, Loss: 0.8265057057142258, Losses: [0.5  0.48 1.1  1.22]\n",
      "Epoch 361, Accuracy: 0.7682926803827286, Accuracies: [0.9  0.98 0.63 0.56]\n",
      "Epoch 371, Loss: 0.797939658164978, Accuracy: 0.75\n",
      "Epoch 371, Loss: 0.797939658164978, Losses: [0.46 0.46 1.07 1.2 ]\n",
      "Epoch 371, Accuracy: 0.75, Accuracies: [0.9  0.98 0.59 0.54]\n",
      "Epoch 381, Loss: 0.7853732705116272, Accuracy: 0.7560975700616837\n",
      "Epoch 381, Loss: 0.7853732705116272, Losses: [0.44 0.45 1.07 1.18]\n",
      "Epoch 381, Accuracy: 0.7560975700616837, Accuracies: [0.93 0.95 0.61 0.54]\n",
      "Epoch 391, Loss: 0.7746763452887535, Accuracy: 0.7743902504444122\n",
      "Epoch 391, Loss: 0.7746763452887535, Losses: [0.42 0.43 1.06 1.19]\n",
      "Epoch 391, Accuracy: 0.7743902504444122, Accuracies: [0.95 0.98 0.61 0.56]\n",
      "Epoch 401, Loss: 0.7514587491750717, Accuracy: 0.7682926952838898\n",
      "Epoch 401, Loss: 0.7514587491750717, Losses: [0.42 0.41 1.04 1.14]\n",
      "Epoch 401, Accuracy: 0.7682926952838898, Accuracies: [0.93 0.98 0.63 0.54]\n",
      "Epoch 411, Loss: 0.734453558921814, Accuracy: 0.7682926803827286\n",
      "Epoch 411, Loss: 0.734453558921814, Losses: [0.39 0.4  1.03 1.12]\n",
      "Epoch 411, Accuracy: 0.7682926803827286, Accuracies: [0.93 0.95 0.63 0.56]\n",
      "Epoch 421, Loss: 0.7808640226721764, Accuracy: 0.7682926803827286\n",
      "Epoch 421, Loss: 0.7808640226721764, Losses: [0.38 0.39 1.03 1.32]\n",
      "Epoch 421, Accuracy: 0.7682926803827286, Accuracies: [0.95 0.95 0.63 0.54]\n",
      "Epoch 431, Loss: 0.7116695791482925, Accuracy: 0.7987804859876633\n",
      "Epoch 431, Loss: 0.7116695791482925, Losses: [0.36 0.37 1.01 1.11]\n",
      "Epoch 431, Accuracy: 0.7987804859876633, Accuracies: [0.95 0.98 0.68 0.59]\n",
      "Epoch 441, Loss: 0.6960501149296761, Accuracy: 0.7987804859876633\n",
      "Epoch 441, Loss: 0.6960501149296761, Losses: [0.34 0.36 1.   1.08]\n",
      "Epoch 441, Accuracy: 0.7987804859876633, Accuracies: [0.95 0.98 0.68 0.59]\n",
      "Epoch 451, Loss: 0.6917424201965332, Accuracy: 0.7865853756666183\n",
      "Epoch 451, Loss: 0.6917424201965332, Losses: [0.33 0.35 1.01 1.07]\n",
      "Epoch 451, Accuracy: 0.7865853756666183, Accuracies: [0.95 0.98 0.66 0.56]\n",
      "Epoch 461, Loss: 0.6833691522479057, Accuracy: 0.7865853756666183\n",
      "Epoch 461, Loss: 0.6833691522479057, Losses: [0.32 0.35 0.99 1.08]\n",
      "Epoch 461, Accuracy: 0.7865853756666183, Accuracies: [0.95 0.98 0.66 0.56]\n",
      "Epoch 471, Loss: 0.6710070893168449, Accuracy: 0.7804878056049347\n",
      "Epoch 471, Loss: 0.6710070893168449, Losses: [0.31 0.34 1.   1.04]\n",
      "Epoch 471, Accuracy: 0.7804878056049347, Accuracies: [0.95 0.98 0.63 0.56]\n",
      "Epoch 481, Loss: 0.6446045711636543, Accuracy: 0.8170731663703918\n",
      "Epoch 481, Loss: 0.6446045711636543, Losses: [0.29 0.33 0.95 1.01]\n",
      "Epoch 481, Accuracy: 0.8170731663703918, Accuracies: [0.95 0.98 0.71 0.63]\n",
      "Epoch 491, Loss: 0.6320019364356995, Accuracy: 0.8170731663703918\n",
      "Epoch 491, Loss: 0.6320019364356995, Losses: [0.28 0.32 0.94 0.99]\n",
      "Epoch 491, Accuracy: 0.8170731663703918, Accuracies: [0.95 0.98 0.71 0.63]\n",
      "Epoch 501, Loss: 0.635418638586998, Accuracy: 0.7865853607654572\n",
      "Epoch 501, Loss: 0.635418638586998, Losses: [0.27 0.32 0.96 0.99]\n",
      "Epoch 501, Accuracy: 0.7865853607654572, Accuracies: [0.95 0.98 0.63 0.59]\n",
      "Epoch 511, Loss: 0.7706715539097786, Accuracy: 0.7804878205060959\n",
      "Epoch 511, Loss: 0.7706715539097786, Losses: [0.28 0.31 1.02 1.47]\n",
      "Epoch 511, Accuracy: 0.7804878205060959, Accuracies: [0.98 0.98 0.63 0.54]\n",
      "Epoch 521, Loss: 0.6284690797328949, Accuracy: 0.7987805008888245\n",
      "Epoch 521, Loss: 0.6284690797328949, Losses: [0.24 0.3  0.95 1.02]\n",
      "Epoch 521, Accuracy: 0.7987805008888245, Accuracies: [0.95 0.98 0.66 0.61]\n",
      "Epoch 531, Loss: 0.6018521748483181, Accuracy: 0.8048780709505081\n",
      "Epoch 531, Loss: 0.6018521748483181, Losses: [0.23 0.29 0.92 0.97]\n",
      "Epoch 531, Accuracy: 0.8048780709505081, Accuracies: [0.98 0.98 0.66 0.61]\n",
      "Epoch 541, Loss: 0.6955907493829727, Accuracy: 0.7804878056049347\n",
      "Epoch 541, Loss: 0.6955907493829727, Losses: [0.58 0.3  0.94 0.96]\n",
      "Epoch 541, Accuracy: 0.7804878056049347, Accuracies: [0.88 0.98 0.63 0.63]\n",
      "Epoch 551, Loss: 0.5993133708834648, Accuracy: 0.817073181271553\n",
      "Epoch 551, Loss: 0.5993133708834648, Losses: [0.28 0.28 0.91 0.93]\n",
      "Epoch 551, Accuracy: 0.817073181271553, Accuracies: [0.95 0.98 0.68 0.66]\n",
      "Epoch 561, Loss: 0.5806148312985897, Accuracy: 0.8231707364320755\n",
      "Epoch 561, Loss: 0.5806148312985897, Losses: [0.23 0.28 0.89 0.92]\n",
      "Epoch 561, Accuracy: 0.8231707364320755, Accuracies: [0.95 0.98 0.68 0.68]\n",
      "Epoch 571, Loss: 0.7407332733273506, Accuracy: 0.7743902504444122\n",
      "Epoch 571, Loss: 0.7407332733273506, Losses: [0.22 0.33 1.02 1.4 ]\n",
      "Epoch 571, Accuracy: 0.7743902504444122, Accuracies: [0.95 0.98 0.61 0.56]\n",
      "Epoch 581, Loss: 0.6736845336854458, Accuracy: 0.7865853607654572\n",
      "Epoch 581, Loss: 0.6736845336854458, Losses: [0.22 0.3  0.94 1.24]\n",
      "Epoch 581, Accuracy: 0.7865853607654572, Accuracies: [0.95 0.98 0.63 0.59]\n",
      "Epoch 591, Loss: 0.5807842761278152, Accuracy: 0.8353658616542816\n",
      "Epoch 591, Loss: 0.5807842761278152, Losses: [0.2  0.27 0.92 0.94]\n",
      "Epoch 591, Accuracy: 0.8353658616542816, Accuracies: [0.98 0.98 0.68 0.71]\n",
      "Epoch 601, Loss: 0.5575873032212257, Accuracy: 0.8231707513332367\n",
      "Epoch 601, Loss: 0.5575873032212257, Losses: [0.19 0.26 0.87 0.91]\n",
      "Epoch 601, Accuracy: 0.8231707513332367, Accuracies: [0.98 0.98 0.68 0.66]\n",
      "Epoch 611, Loss: 0.5521857962012291, Accuracy: 0.817073181271553\n",
      "Epoch 611, Loss: 0.5521857962012291, Losses: [0.18 0.26 0.87 0.9 ]\n",
      "Epoch 611, Accuracy: 0.817073181271553, Accuracies: [0.98 0.98 0.68 0.63]\n",
      "Epoch 621, Loss: 0.5417025610804558, Accuracy: 0.8292683064937592\n",
      "Epoch 621, Loss: 0.5417025610804558, Losses: [0.18 0.26 0.86 0.87]\n",
      "Epoch 621, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.71 0.66]\n",
      "Epoch 631, Loss: 0.537600189447403, Accuracy: 0.8292683064937592\n",
      "Epoch 631, Loss: 0.537600189447403, Losses: [0.17 0.26 0.85 0.87]\n",
      "Epoch 631, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.68 0.68]\n",
      "Epoch 641, Loss: 0.5248174518346786, Accuracy: 0.8292683064937592\n",
      "Epoch 641, Loss: 0.5248174518346786, Losses: [0.16 0.25 0.84 0.85]\n",
      "Epoch 641, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.71 0.66]\n",
      "Epoch 651, Loss: 0.5193242505192757, Accuracy: 0.8414634168148041\n",
      "Epoch 651, Loss: 0.5193242505192757, Losses: [0.16 0.25 0.82 0.85]\n",
      "Epoch 651, Accuracy: 0.8414634168148041, Accuracies: [1.   0.98 0.71 0.68]\n",
      "Epoch 661, Loss: 0.5866100341081619, Accuracy: 0.792682945728302\n",
      "Epoch 661, Loss: 0.5866100341081619, Losses: [0.17 0.25 0.9  1.03]\n",
      "Epoch 661, Accuracy: 0.792682945728302, Accuracies: [0.98 0.98 0.61 0.61]\n",
      "Epoch 671, Loss: 0.6444122791290283, Accuracy: 0.8048780560493469\n",
      "Epoch 671, Loss: 0.6444122791290283, Losses: [0.16 0.26 0.92 1.24]\n",
      "Epoch 671, Accuracy: 0.8048780560493469, Accuracies: [1.   0.98 0.68 0.56]\n",
      "Epoch 681, Loss: 0.5236022211611271, Accuracy: 0.8353658616542816\n",
      "Epoch 681, Loss: 0.5236022211611271, Losses: [0.15 0.23 0.84 0.87]\n",
      "Epoch 681, Accuracy: 0.8353658616542816, Accuracies: [0.98 0.98 0.71 0.68]\n",
      "Epoch 691, Loss: 0.5072624161839485, Accuracy: 0.8414634168148041\n",
      "Epoch 691, Loss: 0.5072624161839485, Losses: [0.14 0.23 0.81 0.84]\n",
      "Epoch 691, Accuracy: 0.8414634168148041, Accuracies: [0.98 0.98 0.71 0.71]\n",
      "Epoch 701, Loss: 0.49739351496100426, Accuracy: 0.8292683064937592\n",
      "Epoch 701, Loss: 0.49739351496100426, Losses: [0.14 0.23 0.8  0.82]\n",
      "Epoch 701, Accuracy: 0.8292683064937592, Accuracies: [1.   0.98 0.68 0.66]\n",
      "Epoch 711, Loss: 0.5064988248050213, Accuracy: 0.8414634168148041\n",
      "Epoch 711, Loss: 0.5064988248050213, Losses: [0.17 0.23 0.81 0.81]\n",
      "Epoch 711, Accuracy: 0.8414634168148041, Accuracies: [0.95 0.98 0.76 0.68]\n",
      "Epoch 721, Loss: 0.5783701576292515, Accuracy: 0.817073181271553\n",
      "Epoch 721, Loss: 0.5783701576292515, Losses: [0.14 0.24 0.9  1.04]\n",
      "Epoch 721, Accuracy: 0.817073181271553, Accuracies: [1.   0.98 0.68 0.61]\n",
      "Epoch 731, Loss: 0.493507020175457, Accuracy: 0.8353658765554428\n",
      "Epoch 731, Loss: 0.493507020175457, Losses: [0.13 0.22 0.81 0.81]\n",
      "Epoch 731, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 741, Loss: 0.48433927074074745, Accuracy: 0.8536585569381714\n",
      "Epoch 741, Loss: 0.48433927074074745, Losses: [0.13 0.22 0.8  0.79]\n",
      "Epoch 741, Accuracy: 0.8536585569381714, Accuracies: [0.98 0.98 0.73 0.73]\n",
      "Epoch 751, Loss: 0.49783235043287277, Accuracy: 0.8353658616542816\n",
      "Epoch 751, Loss: 0.49783235043287277, Losses: [0.12 0.22 0.85 0.79]\n",
      "Epoch 751, Accuracy: 0.8353658616542816, Accuracies: [1.   0.98 0.68 0.68]\n",
      "Epoch 761, Loss: 0.46854937076568604, Accuracy: 0.8475609868764877\n",
      "Epoch 761, Loss: 0.46854937076568604, Losses: [0.12 0.22 0.78 0.76]\n",
      "Epoch 761, Accuracy: 0.8475609868764877, Accuracies: [1.   0.98 0.73 0.68]\n",
      "Epoch 771, Loss: 0.4819574784487486, Accuracy: 0.8353658765554428\n",
      "Epoch 771, Loss: 0.4819574784487486, Losses: [0.12 0.22 0.8  0.8 ]\n",
      "Epoch 771, Accuracy: 0.8353658765554428, Accuracies: [0.98 0.98 0.73 0.66]\n",
      "Epoch 781, Loss: 0.4698852598667145, Accuracy: 0.8597561120986938\n",
      "Epoch 781, Loss: 0.4698852598667145, Losses: [0.14 0.21 0.78 0.75]\n",
      "Epoch 781, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.73 0.73]\n",
      "Epoch 791, Loss: 0.4647430516779423, Accuracy: 0.8536585420370102\n",
      "Epoch 791, Loss: 0.4647430516779423, Losses: [0.11 0.21 0.8  0.74]\n",
      "Epoch 791, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.68 0.76]\n",
      "Epoch 801, Loss: 0.4543751608580351, Accuracy: 0.8536585420370102\n",
      "Epoch 801, Loss: 0.4543751608580351, Losses: [0.11 0.21 0.78 0.72]\n",
      "Epoch 801, Accuracy: 0.8536585420370102, Accuracies: [1.   0.98 0.71 0.73]\n",
      "Epoch 811, Loss: 0.5004895590245724, Accuracy: 0.8292683064937592\n",
      "Epoch 811, Loss: 0.5004895590245724, Losses: [0.11 0.21 0.79 0.9 ]\n",
      "Epoch 811, Accuracy: 0.8292683064937592, Accuracies: [0.98 0.98 0.71 0.66]\n",
      "Epoch 821, Loss: 0.4374387450516224, Accuracy: 0.8658536672592163\n",
      "Epoch 821, Loss: 0.4374387450516224, Losses: [0.1  0.21 0.73 0.71]\n",
      "Epoch 821, Accuracy: 0.8658536672592163, Accuracies: [1.   0.98 0.73 0.76]\n",
      "Epoch 831, Loss: 0.439468277618289, Accuracy: 0.8597561120986938\n",
      "Epoch 831, Loss: 0.439468277618289, Losses: [0.11 0.2  0.74 0.71]\n",
      "Epoch 831, Accuracy: 0.8597561120986938, Accuracies: [1.   0.98 0.73 0.73]\n",
      "Epoch 841, Loss: 0.42849100567400455, Accuracy: 0.8719512224197388\n",
      "Epoch 841, Loss: 0.42849100567400455, Losses: [0.1  0.2  0.73 0.69]\n",
      "Epoch 841, Accuracy: 0.8719512224197388, Accuracies: [1.   0.98 0.73 0.78]\n",
      "Epoch 851, Loss: 0.42345738410949707, Accuracy: 0.8719512224197388\n",
      "Epoch 851, Loss: 0.42345738410949707, Losses: [0.09 0.2  0.72 0.68]\n",
      "Epoch 851, Accuracy: 0.8719512224197388, Accuracies: [1.   0.98 0.73 0.78]\n",
      "Epoch 861, Loss: 0.44552692770957947, Accuracy: 0.8597560971975327\n",
      "Epoch 861, Loss: 0.44552692770957947, Losses: [0.09 0.21 0.79 0.7 ]\n",
      "Epoch 861, Accuracy: 0.8597560971975327, Accuracies: [1.   0.98 0.68 0.78]\n",
      "Epoch 871, Loss: 0.6342346966266632, Accuracy: 0.817073181271553\n",
      "Epoch 871, Loss: 0.6342346966266632, Losses: [0.88 0.2  0.75 0.71]\n",
      "Epoch 871, Accuracy: 0.817073181271553, Accuracies: [0.8  0.98 0.73 0.76]\n",
      "Epoch 881, Loss: 0.4916043318808079, Accuracy: 0.8475609719753265\n",
      "Epoch 881, Loss: 0.4916043318808079, Losses: [0.38 0.2  0.71 0.68]\n",
      "Epoch 881, Accuracy: 0.8475609719753265, Accuracies: [0.88 0.98 0.76 0.78]\n",
      "Epoch 891, Loss: 0.4603036381304264, Accuracy: 0.8536585420370102\n",
      "Epoch 891, Loss: 0.4603036381304264, Losses: [0.28 0.2  0.71 0.66]\n",
      "Epoch 891, Accuracy: 0.8536585420370102, Accuracies: [0.93 0.98 0.76 0.76]\n",
      "Epoch 901, Loss: 0.44029825553297997, Accuracy: 0.8780487924814224\n",
      "Epoch 901, Loss: 0.44029825553297997, Losses: [0.16 0.2  0.74 0.66]\n",
      "Epoch 901, Accuracy: 0.8780487924814224, Accuracies: [0.98 0.98 0.76 0.8 ]\n",
      "Epoch 911, Loss: 0.4075370170176029, Accuracy: 0.8780487775802612\n",
      "Epoch 911, Loss: 0.4075370170176029, Losses: [0.12 0.2  0.68 0.63]\n",
      "Epoch 911, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.98 0.78 0.78]\n",
      "Epoch 921, Loss: 0.41405353508889675, Accuracy: 0.8719512224197388\n",
      "Epoch 921, Loss: 0.41405353508889675, Losses: [0.11 0.19 0.73 0.62]\n",
      "Epoch 921, Accuracy: 0.8719512224197388, Accuracies: [0.98 0.98 0.76 0.78]\n",
      "Epoch 931, Loss: 0.3953223191201687, Accuracy: 0.8780487775802612\n",
      "Epoch 931, Loss: 0.3953223191201687, Losses: [0.1  0.19 0.66 0.62]\n",
      "Epoch 931, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.98 0.78 0.78]\n",
      "Epoch 941, Loss: 0.38352298364043236, Accuracy: 0.8719512224197388\n",
      "Epoch 941, Loss: 0.38352298364043236, Losses: [0.1  0.19 0.64 0.6 ]\n",
      "Epoch 941, Accuracy: 0.8719512224197388, Accuracies: [0.98 0.98 0.78 0.76]\n",
      "Epoch 951, Loss: 0.3828809969127178, Accuracy: 0.8780487775802612\n",
      "Epoch 951, Loss: 0.3828809969127178, Losses: [0.1  0.19 0.64 0.6 ]\n",
      "Epoch 951, Accuracy: 0.8780487775802612, Accuracies: [0.98 0.98 0.78 0.78]\n",
      "Epoch 961, Loss: 0.4077803026884794, Accuracy: 0.8841463476419449\n",
      "Epoch 961, Loss: 0.4077803026884794, Losses: [0.09 0.19 0.68 0.68]\n",
      "Epoch 961, Accuracy: 0.8841463476419449, Accuracies: [1.   0.98 0.8  0.76]\n",
      "Epoch 971, Loss: 0.37000695802271366, Accuracy: 0.8902439028024673\n",
      "Epoch 971, Loss: 0.37000695802271366, Losses: [0.08 0.18 0.63 0.59]\n",
      "Epoch 971, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.8  0.78]\n",
      "Epoch 981, Loss: 0.3685742076486349, Accuracy: 0.896341472864151\n",
      "Epoch 981, Loss: 0.3685742076486349, Losses: [0.08 0.18 0.64 0.58]\n",
      "Epoch 981, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.8  0.8 ]\n",
      "Epoch 991, Loss: 0.35633939132094383, Accuracy: 0.9024390280246735\n",
      "Epoch 991, Loss: 0.35633939132094383, Losses: [0.07 0.18 0.61 0.56]\n",
      "Epoch 991, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.8  0.83]\n",
      "Epoch 1001, Loss: 0.3535281326621771, Accuracy: 0.9024390280246735\n",
      "Epoch 1001, Loss: 0.3535281326621771, Losses: [0.07 0.18 0.61 0.55]\n",
      "Epoch 1001, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.8  0.83]\n",
      "Epoch 1011, Loss: 0.34249800257384777, Accuracy: 0.896341472864151\n",
      "Epoch 1011, Loss: 0.34249800257384777, Losses: [0.07 0.18 0.58 0.54]\n",
      "Epoch 1011, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.8  0.8 ]\n",
      "Epoch 1021, Loss: 0.33644100837409496, Accuracy: 0.9024390280246735\n",
      "Epoch 1021, Loss: 0.33644100837409496, Losses: [0.07 0.17 0.58 0.53]\n",
      "Epoch 1021, Accuracy: 0.9024390280246735, Accuracies: [1.   0.98 0.8  0.83]\n",
      "Epoch 1031, Loss: 0.3384449165314436, Accuracy: 0.9085365980863571\n",
      "Epoch 1031, Loss: 0.3384449165314436, Losses: [0.07 0.17 0.58 0.53]\n",
      "Epoch 1031, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1041, Loss: 0.33783222176134586, Accuracy: 0.9146341532468796\n",
      "Epoch 1041, Loss: 0.33783222176134586, Losses: [0.11 0.17 0.56 0.51]\n",
      "Epoch 1041, Accuracy: 0.9146341532468796, Accuracies: [0.98 0.98 0.8  0.9 ]\n",
      "Epoch 1051, Loss: 0.3387292232364416, Accuracy: 0.8902439028024673\n",
      "Epoch 1051, Loss: 0.3387292232364416, Losses: [0.07 0.17 0.6  0.51]\n",
      "Epoch 1051, Accuracy: 0.8902439028024673, Accuracies: [1.   0.98 0.76 0.83]\n",
      "Epoch 1061, Loss: 0.3651601579040289, Accuracy: 0.896341472864151\n",
      "Epoch 1061, Loss: 0.3651601579040289, Losses: [0.06 0.17 0.66 0.57]\n",
      "Epoch 1061, Accuracy: 0.896341472864151, Accuracies: [1.   0.98 0.8  0.8 ]\n",
      "Epoch 1071, Loss: 0.32666227873414755, Accuracy: 0.9085365980863571\n",
      "Epoch 1071, Loss: 0.32666227873414755, Losses: [0.06 0.16 0.56 0.52]\n",
      "Epoch 1071, Accuracy: 0.9085365980863571, Accuracies: [1.   0.98 0.8  0.85]\n",
      "Epoch 1081, Loss: 0.30799109674990177, Accuracy: 0.920731708407402\n",
      "Epoch 1081, Loss: 0.30799109674990177, Losses: [0.06 0.16 0.54 0.48]\n",
      "Epoch 1081, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.83 0.88]\n",
      "Epoch 1091, Loss: 0.3006159085780382, Accuracy: 0.9268292635679245\n",
      "Epoch 1091, Loss: 0.3006159085780382, Losses: [0.06 0.16 0.53 0.46]\n",
      "Epoch 1091, Accuracy: 0.9268292635679245, Accuracies: [1.   0.98 0.83 0.9 ]\n",
      "Epoch 1101, Loss: 0.2945998404175043, Accuracy: 0.9268292635679245\n",
      "Epoch 1101, Loss: 0.2945998404175043, Losses: [0.05 0.16 0.52 0.45]\n",
      "Epoch 1101, Accuracy: 0.9268292635679245, Accuracies: [1.   0.98 0.83 0.9 ]\n",
      "Epoch 1111, Loss: 0.2889541871845722, Accuracy: 0.9268292635679245\n",
      "Epoch 1111, Loss: 0.2889541871845722, Losses: [0.05 0.16 0.51 0.44]\n",
      "Epoch 1111, Accuracy: 0.9268292635679245, Accuracies: [1.   0.98 0.83 0.9 ]\n",
      "Epoch 1121, Loss: 0.454989904537797, Accuracy: 0.8475609868764877\n",
      "Epoch 1121, Loss: 0.454989904537797, Losses: [0.09 0.23 0.69 0.82]\n",
      "Epoch 1121, Accuracy: 0.8475609868764877, Accuracies: [0.98 0.95 0.73 0.73]\n",
      "Epoch 1131, Loss: 0.7850278355181217, Accuracy: 0.7743902504444122\n",
      "Epoch 1131, Loss: 0.7850278355181217, Losses: [0.08 0.18 1.61 1.27]\n",
      "Epoch 1131, Accuracy: 0.7743902504444122, Accuracies: [1.   0.98 0.51 0.61]\n",
      "Epoch 1141, Loss: 0.4443157548084855, Accuracy: 0.8597560971975327\n",
      "Epoch 1141, Loss: 0.4443157548084855, Losses: [0.06 0.16 0.68 0.87]\n",
      "Epoch 1141, Accuracy: 0.8597560971975327, Accuracies: [1.   0.98 0.76 0.71]\n",
      "Epoch 1151, Loss: 0.35189778823405504, Accuracy: 0.8963414579629898\n",
      "Epoch 1151, Loss: 0.35189778823405504, Losses: [0.05 0.16 0.58 0.61]\n",
      "Epoch 1151, Accuracy: 0.8963414579629898, Accuracies: [1.   0.98 0.78 0.83]\n",
      "Epoch 1161, Loss: 0.32292686216533184, Accuracy: 0.8963414579629898\n",
      "Epoch 1161, Loss: 0.32292686216533184, Losses: [0.05 0.15 0.54 0.55]\n",
      "Epoch 1161, Accuracy: 0.8963414579629898, Accuracies: [1.   0.98 0.78 0.83]\n",
      "Epoch 1171, Loss: 0.3067445009946823, Accuracy: 0.9146341532468796\n",
      "Epoch 1171, Loss: 0.3067445009946823, Losses: [0.05 0.14 0.53 0.5 ]\n",
      "Epoch 1171, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.8  0.88]\n",
      "Epoch 1181, Loss: 0.29521814174950123, Accuracy: 0.9146341532468796\n",
      "Epoch 1181, Loss: 0.29521814174950123, Losses: [0.05 0.15 0.52 0.47]\n",
      "Epoch 1181, Accuracy: 0.9146341532468796, Accuracies: [1.   0.98 0.8  0.88]\n",
      "Epoch 1191, Loss: 0.28689414262771606, Accuracy: 0.920731708407402\n",
      "Epoch 1191, Loss: 0.28689414262771606, Losses: [0.05 0.15 0.51 0.45]\n",
      "Epoch 1191, Accuracy: 0.920731708407402, Accuracies: [1.   0.98 0.8  0.9 ]\n",
      "Epoch 1201, Loss: 0.27980442252010107, Accuracy: 0.9329268336296082\n",
      "Epoch 1201, Loss: 0.27980442252010107, Losses: [0.05 0.15 0.5  0.43]\n",
      "Epoch 1201, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.83 0.93]\n",
      "Epoch 1211, Loss: 0.27354442048817873, Accuracy: 0.9390243887901306\n",
      "Epoch 1211, Loss: 0.27354442048817873, Losses: [0.05 0.15 0.49 0.41]\n",
      "Epoch 1211, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1221, Loss: 0.26762954518198967, Accuracy: 0.9390243887901306\n",
      "Epoch 1221, Loss: 0.26762954518198967, Losses: [0.04 0.15 0.48 0.4 ]\n",
      "Epoch 1221, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1231, Loss: 0.2620842959731817, Accuracy: 0.9390243887901306\n",
      "Epoch 1231, Loss: 0.2620842959731817, Losses: [0.04 0.15 0.47 0.39]\n",
      "Epoch 1231, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1241, Loss: 0.2567581180483103, Accuracy: 0.9390243887901306\n",
      "Epoch 1241, Loss: 0.2567581180483103, Losses: [0.04 0.15 0.46 0.38]\n",
      "Epoch 1241, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1251, Loss: 0.25166541803628206, Accuracy: 0.9390243887901306\n",
      "Epoch 1251, Loss: 0.25166541803628206, Losses: [0.04 0.15 0.45 0.37]\n",
      "Epoch 1251, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1261, Loss: 0.24661001469939947, Accuracy: 0.9390243887901306\n",
      "Epoch 1261, Loss: 0.24661001469939947, Losses: [0.04 0.14 0.44 0.36]\n",
      "Epoch 1261, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1271, Loss: 0.24181209970265627, Accuracy: 0.9390243887901306\n",
      "Epoch 1271, Loss: 0.24181209970265627, Losses: [0.04 0.14 0.44 0.35]\n",
      "Epoch 1271, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1281, Loss: 0.23704923316836357, Accuracy: 0.9329268336296082\n",
      "Epoch 1281, Loss: 0.23704923316836357, Losses: [0.04 0.14 0.43 0.34]\n",
      "Epoch 1281, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.83 0.93]\n",
      "Epoch 1291, Loss: 0.23253567051142454, Accuracy: 0.9390243887901306\n",
      "Epoch 1291, Loss: 0.23253567051142454, Losses: [0.04 0.14 0.42 0.33]\n",
      "Epoch 1291, Accuracy: 0.9390243887901306, Accuracies: [1.   0.98 0.83 0.95]\n",
      "Epoch 1301, Loss: 0.22878238558769226, Accuracy: 0.9329268336296082\n",
      "Epoch 1301, Loss: 0.22878238558769226, Losses: [0.04 0.14 0.41 0.32]\n",
      "Epoch 1301, Accuracy: 0.9329268336296082, Accuracies: [1.   0.98 0.83 0.93]\n",
      "Epoch 1311, Loss: 0.32692062854766846, Accuracy: 0.8902439028024673\n",
      "Epoch 1311, Loss: 0.32692062854766846, Losses: [0.16 0.14 0.48 0.52]\n",
      "Epoch 1311, Accuracy: 0.8902439028024673, Accuracies: [0.98 0.98 0.78 0.83]\n",
      "Epoch 1321, Loss: 0.4484454207122326, Accuracy: 0.8414634168148041\n",
      "Epoch 1321, Loss: 0.4484454207122326, Losses: [0.53 0.18 0.52 0.56]\n",
      "Epoch 1321, Accuracy: 0.8414634168148041, Accuracies: [0.85 0.98 0.76 0.78]\n",
      "Epoch 1331, Loss: 0.3215477913618088, Accuracy: 0.9024390280246735\n",
      "Epoch 1331, Loss: 0.3215477913618088, Losses: [0.31 0.15 0.43 0.39]\n",
      "Epoch 1331, Accuracy: 0.9024390280246735, Accuracies: [0.88 0.98 0.83 0.93]\n",
      "Epoch 1341, Loss: 0.283983800560236, Accuracy: 0.9146341532468796\n",
      "Epoch 1341, Loss: 0.283983800560236, Losses: [0.23 0.14 0.41 0.35]\n",
      "Epoch 1341, Accuracy: 0.9146341532468796, Accuracies: [0.93 0.98 0.83 0.93]\n",
      "Epoch 1351, Loss: 0.2654983401298523, Accuracy: 0.9268292635679245\n",
      "Epoch 1351, Loss: 0.2654983401298523, Losses: [0.19 0.14 0.4  0.33]\n",
      "Epoch 1351, Accuracy: 0.9268292635679245, Accuracies: [0.95 0.98 0.83 0.95]\n",
      "Epoch 1361, Loss: 0.25364335626363754, Accuracy: 0.9268292635679245\n",
      "Epoch 1361, Loss: 0.25364335626363754, Losses: [0.16 0.14 0.39 0.32]\n",
      "Epoch 1361, Accuracy: 0.9268292635679245, Accuracies: [0.95 0.98 0.83 0.95]\n",
      "Epoch 1371, Loss: 0.24489828571677208, Accuracy: 0.9390244036912918\n",
      "Epoch 1371, Loss: 0.24489828571677208, Losses: [0.15 0.14 0.38 0.31]\n",
      "Epoch 1371, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 1381, Loss: 0.23788031935691833, Accuracy: 0.9390244036912918\n",
      "Epoch 1381, Loss: 0.23788031935691833, Losses: [0.13 0.14 0.38 0.3 ]\n",
      "Epoch 1381, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 1391, Loss: 0.23088792338967323, Accuracy: 0.9390244036912918\n",
      "Epoch 1391, Loss: 0.23088792338967323, Losses: [0.12 0.14 0.37 0.29]\n",
      "Epoch 1391, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 1401, Loss: 0.22438474744558334, Accuracy: 0.9512195140123367\n",
      "Epoch 1401, Loss: 0.22438474744558334, Losses: [0.11 0.13 0.37 0.29]\n",
      "Epoch 1401, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1411, Loss: 0.23356910794973373, Accuracy: 0.9390244036912918\n",
      "Epoch 1411, Loss: 0.23356910794973373, Losses: [0.1  0.14 0.39 0.31]\n",
      "Epoch 1411, Accuracy: 0.9390244036912918, Accuracies: [0.98 0.98 0.85 0.95]\n",
      "Epoch 1421, Loss: 0.21765446476638317, Accuracy: 0.9451219588518143\n",
      "Epoch 1421, Loss: 0.21765446476638317, Losses: [0.09 0.13 0.37 0.28]\n",
      "Epoch 1421, Accuracy: 0.9451219588518143, Accuracies: [1.   0.98 0.85 0.95]\n",
      "Epoch 1431, Loss: 0.2093439269810915, Accuracy: 0.9512195140123367\n",
      "Epoch 1431, Loss: 0.2093439269810915, Losses: [0.08 0.13 0.35 0.27]\n",
      "Epoch 1431, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1441, Loss: 0.20348079316318035, Accuracy: 0.9512195140123367\n",
      "Epoch 1441, Loss: 0.20348079316318035, Losses: [0.07 0.13 0.35 0.26]\n",
      "Epoch 1441, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1451, Loss: 0.19844487123191357, Accuracy: 0.9512195140123367\n",
      "Epoch 1451, Loss: 0.19844487123191357, Losses: [0.07 0.13 0.34 0.26]\n",
      "Epoch 1451, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1461, Loss: 0.19433151185512543, Accuracy: 0.9512195140123367\n",
      "Epoch 1461, Loss: 0.19433151185512543, Losses: [0.06 0.13 0.34 0.25]\n",
      "Epoch 1461, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1471, Loss: 0.19009633362293243, Accuracy: 0.9512195140123367\n",
      "Epoch 1471, Loss: 0.19009633362293243, Losses: [0.06 0.13 0.33 0.25]\n",
      "Epoch 1471, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1481, Loss: 0.1864074543118477, Accuracy: 0.9512195140123367\n",
      "Epoch 1481, Loss: 0.1864074543118477, Losses: [0.06 0.13 0.32 0.24]\n",
      "Epoch 1481, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1491, Loss: 0.18302713427692652, Accuracy: 0.9512195140123367\n",
      "Epoch 1491, Loss: 0.18302713427692652, Losses: [0.05 0.12 0.32 0.24]\n",
      "Epoch 1491, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1501, Loss: 0.18374794628471136, Accuracy: 0.9512195140123367\n",
      "Epoch 1501, Loss: 0.18374794628471136, Losses: [0.05 0.12 0.33 0.23]\n",
      "Epoch 1501, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1511, Loss: 0.26564527675509453, Accuracy: 0.9268292784690857\n",
      "Epoch 1511, Loss: 0.26564527675509453, Losses: [0.07 0.14 0.46 0.4 ]\n",
      "Epoch 1511, Accuracy: 0.9268292784690857, Accuracies: [1.   0.98 0.88 0.85]\n",
      "Epoch 1521, Loss: 0.19449185859411955, Accuracy: 0.9512195140123367\n",
      "Epoch 1521, Loss: 0.19449185859411955, Losses: [0.05 0.13 0.33 0.27]\n",
      "Epoch 1521, Accuracy: 0.9512195140123367, Accuracies: [1.   0.98 0.88 0.95]\n",
      "Epoch 1531, Loss: 0.17886677477508783, Accuracy: 0.9695121943950653\n",
      "Epoch 1531, Loss: 0.17886677477508783, Losses: [0.05 0.12 0.31 0.23]\n",
      "Epoch 1531, Accuracy: 0.9695121943950653, Accuracies: [1.   0.98 0.9  1.  ]\n",
      "Epoch 1541, Loss: 0.17384242825210094, Accuracy: 0.9695121943950653\n",
      "Epoch 1541, Loss: 0.17384242825210094, Losses: [0.05 0.12 0.31 0.22]\n",
      "Epoch 1541, Accuracy: 0.9695121943950653, Accuracies: [1.   0.98 0.9  1.  ]\n",
      "Epoch 1551, Loss: 0.16973324865102768, Accuracy: 0.9695121943950653\n",
      "Epoch 1551, Loss: 0.16973324865102768, Losses: [0.05 0.12 0.3  0.21]\n",
      "Epoch 1551, Accuracy: 0.9695121943950653, Accuracies: [1.   0.98 0.9  1.  ]\n",
      "Early stopping criteria met\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RNN\": RNN(),\n",
    "    \"RNNA\": RNNA(),  \n",
    "    \"LSTM\": LSTM(),\n",
    "    \"LSTMA\": LSTMA(),  \n",
    "    \"GRU\": GRU(),\n",
    "    \"GRUA\": GRUA() \n",
    "    \n",
    "}\n",
    "num_epochs = 5000\n",
    "number_of_Songs = 4\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    L, A = train_model(model, num_epochs, songStrings, number_of_Songs)\n",
    "    results[model_name] = {\"Accuracy\": A, \"Loss\": L}\n",
    "    #torch.save(model, f'model_{model_name}_songs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aa717c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RNN\n",
      "Final Accuracy: 0.2011\n",
      "Final Loss: 0.9756\n",
      "\n",
      "Model: RNNA\n",
      "Final Accuracy: 0.1380\n",
      "Final Loss: 0.9695\n",
      "\n",
      "Model: LSTM\n",
      "Final Accuracy: 0.2157\n",
      "Final Loss: 0.9756\n",
      "\n",
      "Model: LSTMA\n",
      "Final Accuracy: 0.5989\n",
      "Final Loss: 0.8049\n",
      "\n",
      "Model: GRU\n",
      "Final Accuracy: 0.2443\n",
      "Final Loss: 0.9756\n",
      "\n",
      "Model: GRUA\n",
      "Final Accuracy: 0.8190\n",
      "Final Loss: 0.7378\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Final Accuracy: {metrics['Accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Loss: {metrics['Loss'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653431",
   "metadata": {},
   "source": [
    "## Old shrinkingDecompositionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "25bc33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolEntropy(D, base=2):\n",
    "    value, counts = numpy.unique(D, return_counts=True)  # Find unique values and their frequency in D\n",
    "    return entropy(counts, base=base)  # Calculate and return the Shannon entropy\n",
    "\n",
    "# This function seems to compute a complex metric, possibly related to information theory, involving inputs I, hidden states H, and outputs O.\n",
    "def computeTransmissionHfast(I,H,O,maskC,maskNC,iMult=2,oMult=2):\n",
    "    # Create various combinations of Inputs (I), Hidden states (H), and Outputs (O) for analysis\n",
    "    # B, IB, AB, BO, IAB, IBO, ABO, IABO are different combinations of I, H, and O\n",
    "    # Calculate entropy for each combination using symbolEntropy\n",
    "    # Return a specific information metric combining these entropies\n",
    "\n",
    "\n",
    "    #print(\"I H O\",I.shape,H.shape,O.shape)\n",
    "    B=numpy.bitwise_and(H,maskNC)\n",
    "    IB=(B*iMult)+I\n",
    "    AB=H#numpy.bitwise_and(H,maskC+maskNC)\n",
    "    BO=(B*oMult)+O\n",
    "    IAB=(AB*iMult)+I\n",
    "    IBO=(B*(iMult*oMult))+(I*oMult)+O\n",
    "    ABO=(AB*oMult)+O\n",
    "    IABO=(AB*(iMult*oMult))+(I*oMult)+O\n",
    "    hB=symbolEntropy(B, base=2)\n",
    "    hIB=symbolEntropy(IB, base=2)\n",
    "    hAB=symbolEntropy(AB, base=2)\n",
    "    hBO=symbolEntropy(BO, base=2)\n",
    "    hIAB=symbolEntropy(IAB, base=2)\n",
    "    hIBO=symbolEntropy(IBO, base=2)\n",
    "    hABO=symbolEntropy(ABO, base=2)\n",
    "    hIABO=symbolEntropy(IABO, base=2)\n",
    "    #-H(B)+H(IB)+H(AB)+H(BO)-H(IAB)-H(IBO)-H(ABO)+H(IABO)\n",
    "    #print(hB,hIB,hAB,hBO,hIAB,hIBO,hABO,hIABO)\n",
    "    return-hB+hIB+hAB+hBO-hIAB-hIBO-hABO+hIABO\n",
    "\n",
    "# This function seems to analyze how information is processed or transmitted through a network, focusing on individual components (nodes) of the hidden states H.\n",
    "def singleShrinkingDecompositionInformation(I,H,O,width,iMult=2,oMult=2):\n",
    "    nodes = list(range(width))  # Initialize a list of node indices\n",
    "    cols = []  # To store subsets of nodes\n",
    "    colh = []  # To store corresponding information values\n",
    "    # Iteratively remove a node, compute information value, and record subsets and values\n",
    "    while len(nodes)>0:\n",
    "        infos=[]\n",
    "        for node in nodes:\n",
    "            subset=copy.deepcopy(nodes)\n",
    "            subset.remove(node)\n",
    "            maskA=0\n",
    "            for s in subset:\n",
    "                maskA+=1*(2**s)\n",
    "            maskA=int(maskA)\n",
    "            maskB=numpy.bitwise_and(numpy.bitwise_not(maskA),((2**width)-1))\n",
    "            h=computeTransmissionHfast(I,H,O,maskA,maskB,iMult=iMult,oMult=oMult)\n",
    "            infos.append(h)\n",
    "        nodeToDrop=nodes[infos.index(max(infos))]\n",
    "        nodes.remove(nodeToDrop)\n",
    "        cols.append(copy.deepcopy(nodes))\n",
    "        colh.append(max(infos))\n",
    "    return cols,colh\n",
    "\n",
    "\n",
    "# This function processes the output of a model given a dataset. It appears to involve some form of clustering (using KMeans) and then re-encoding the hidden states H.\n",
    "def getOutTaH(model,dataSet):\n",
    "    O, H = model.step(torch.Tensor(dataSet))  # Get output and hidden states from the model\n",
    "    # Transform H using clustering and re-encoding\n",
    "\n",
    "    #print(H.shape,H.min(),H.max())\n",
    "    #figure()\n",
    "    #hist(H.flatten())\n",
    "\n",
    "    H = H.transpose()  # Transpose H for processing\n",
    "    O = O.transpose()  # Transpose O for processing\n",
    "    B = numpy.zeros(H.shape)  # Initialize a matrix to store cluster labels for each hidden state\n",
    "    # Apply KMeans clustering to each hidden state\n",
    "    # Recompute H as a combination of cluster labels (B)\n",
    "    clusterNr=2\n",
    "    for i in range(B.shape[0]):\n",
    "        a=H[i].reshape(-1, 1)\n",
    "        x =len(numpy.unique(a))\n",
    "        if len(numpy.unique(a))==1:\n",
    "            who=numpy.random.randint(len(a))\n",
    "            a[who]=1-a[who]\n",
    "        kmeans = KMeans(n_clusters=clusterNr,n_init=10).fit(a)\n",
    "        B[i]=kmeans.labels_\n",
    "        #B[i]=1.0*(H[i]>numpy.median(H[i]))\n",
    "\n",
    "\n",
    "    H=numpy.zeros((H.shape))\n",
    "    for i in range(12):\n",
    "        H+=B[i]*(clusterNr**i)\n",
    "    H=H.astype((int))\n",
    "    return O,H\n",
    "\n",
    "# This function seems to integrate the previous functions to analyze how information flows through the network for different input-output pairs in a dataset.\n",
    "def shrinkingDecompositionInformation(model,width,dataSet,target,numbers=[0,1,2],whichTS=5,dsLength=8):\n",
    "    output, H = getOutTaH(model, dataSet)  # Get transformed outputs and hidden states from the model\n",
    "    # Slice output and H to process only specific timesteps\n",
    "    output=output.transpose()[whichTS::dsLength].transpose()\n",
    "\n",
    "    #print(\"target.shape\",target.shape,\"output.shape\",output.shape,\"H.shape\",H.shape,\"dataset.shape\",dataSet.shape)\n",
    "    H=H.transpose()[whichTS::dsLength].transpose()\n",
    "    #target=target.transpose()[whichTS::dsLength].transpose()\n",
    "    #print(H.shape,target.shape,numpy.array(range(512))[whichTS::dsLength])\n",
    "\n",
    "    collectorSet = dict()  # To store information about subsets of nodes (S)\n",
    "    collectorH = dict()    # To store information values (H)\n",
    "    # Compute shrinking decomposition information for selected inputs/outputs\n",
    "    for number in numbers:\n",
    "        I=target[number].astype(int)\n",
    "        O=(1.0*(output[number]>0.5)).astype(int)\n",
    "        #print(\"O\",O,\"T\",target[number])\n",
    "        #print(number,\"I.shape\",I.shape,\"O.shape\",O.shape,\"H.shape\",H.shape)\n",
    "        s,h=singleShrinkingDecompositionInformation(I,H,O,width)\n",
    "        collectorSet[number]=s\n",
    "        collectorH[number]=h\n",
    "    return collectorSet,collectorH\n",
    "\n",
    "\n",
    "# These functions convert the results of the shrinking decomposition into vector and matrix forms, which are likely used for further analysis or visualization.\n",
    "def removalIntoVec(res,width,H):\n",
    "    # Convert the shrinking decomposition results into a vector form\n",
    "\n",
    "    V = numpy.zeros(width)  # Initialize a vector\n",
    "    # Calculate values for V based on the difference in information values (H) as nodes are removed\n",
    "    #for i,r in enumerate(res):\n",
    "    #    for e in r:\n",
    "    #        V[e]+=H[0]-H[i]\n",
    "    fullSet=list(range(width))\n",
    "    nRes=copy.deepcopy(res)\n",
    "    nRes.insert(0,fullSet)\n",
    "\n",
    "    nodeList=[]\n",
    "    for i in range(width):\n",
    "        removedNode=list(set(nRes[i])-set(nRes[i+1]))[0]\n",
    "        nodeList.append(removedNode)\n",
    "    \n",
    "    for i,node in enumerate(nodeList):\n",
    "        V[node]=H[0]-H[i]\n",
    "\n",
    "    #V=sqrt(V)\n",
    "    if V.sum()==0:\n",
    "        return V\n",
    "    return V#/V.max()\n",
    "\n",
    "def removalIntoMatrix(res,width,H):\n",
    "    # Convert the shrinking decomposition results into a matrix form\n",
    "\n",
    "    M=[]\n",
    "    # Convert the shrinking decomposition results (S and H) into a matrix form\n",
    "    # This matrix can be used for visualization or further analysis\n",
    "    for i in range(len(res)):\n",
    "        M.append(removalIntoVec(res[i],width,H[i]))\n",
    "    return numpy.array(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d0873",
   "metadata": {},
   "source": [
    "## generateIOData on each song with its combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c74c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (42, 41, 8), Output (One-Hot) shape: (42, 41, 8), Output (Indices) shape: 42, Each output indices array length: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Output (One-Hot Encoded)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "songStrings = numpy.array([\n",
    "    \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "\n",
    "\n",
    "def generateIOData(songNr, songStrings):\n",
    "    notes = list(\"ABCDEFGH\")\n",
    "    source = []\n",
    "    target_one_hot = []\n",
    "    target_indices = []\n",
    "    \n",
    "    songString = songStrings[songNr]\n",
    "    \n",
    "    # Ensure the loop considers the possibility of wrapping around the song's end for a continuous cycle\n",
    "    for i in range(len(songString)):  # Allow wrapping to get a continuous sequence\n",
    "        input_one_hot = np.zeros((41, 8))\n",
    "        output_one_hot = np.zeros((41, 8))\n",
    "        current_target_indices = []\n",
    "        \n",
    "        for j in range(41):  # Build each input window\n",
    "            input_index = notes.index(songString[(i + j) % len(songString)])\n",
    "            input_one_hot[j][input_index] = 1.0\n",
    "            \n",
    "            if (i + j + 1) < len(songString) + i:  # Wrap around to start for output\n",
    "                next_char_index = notes.index(songString[(i + j + 1) % len(songString)])\n",
    "                output_one_hot[j][next_char_index] = 1.0\n",
    "                current_target_indices.append(next_char_index)\n",
    "            else:\n",
    "                current_target_indices.append(0)  # Append a placeholder if beyond song length\n",
    "\n",
    "        source.append(input_one_hot)\n",
    "        target_one_hot.append(output_one_hot)\n",
    "        target_indices.append(current_target_indices)\n",
    "        \n",
    "    return np.array(source), np.array(target_one_hot), np.array(target_indices)\n",
    "\n",
    "# Test the function with a specific song\n",
    "songNr = 1  # Choose the second song for example\n",
    "I, O_hot, O_indices = generateIOData(songNr, songStrings)\n",
    "\n",
    "print(f\"Input shape: {I.shape}, Output (One-Hot) shape: {O_hot.shape}, Output (Indices) shape: {len(O_indices)}, Each output indices array length: {len(O_indices[0])}\")\n",
    "\n",
    "# Display the first input and a portion of the output indices for visualization\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(I[0], aspect='auto')\n",
    "plt.title(\"Input (One-Hot Encoded)\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(O_hot[0], aspect='auto')\n",
    "plt.title(\"Output (One-Hot Encoded)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4fc09fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 41)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3664e",
   "metadata": {},
   "source": [
    "## Train RNNs on each song with its combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09f737cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, songStrings, number_of_Songs = 4):\n",
    "    L = []\n",
    "    A = []\n",
    "    songs = list(range(number_of_Songs))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(songs)\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        lo = np.zeros((number_of_Songs))\n",
    "        acc = np.zeros((number_of_Songs))\n",
    "        for songNr, song in enumerate(songs):\n",
    "            I, O_hot, O_indices = generateIOData(songNr, songStrings)\n",
    "            \n",
    "            # Prepare for shuffling\n",
    "            combined = list(zip(I, O_indices))\n",
    "            np.random.shuffle(combined)\n",
    "            I_shuffled, O_indices_shuffled = zip(*combined)\n",
    "            \n",
    "            # Convert back to numpy arrays if necessary and then to tensors\n",
    "            I_shuffled = np.array(I_shuffled)\n",
    "            O_indices_shuffled = np.array(O_indices_shuffled)\n",
    "            \n",
    "            inputs = torch.tensor(I_shuffled, dtype=torch.float)  # Inputs are already in the correct shape\n",
    "            targets = torch.tensor(O_indices_shuffled, dtype=torch.long)  # Use indices for CrossEntropyLoss\n",
    "            \n",
    "\n",
    "            # Assuming the model's output shape matches the targets shape\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, 8), targets.view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted_indices = torch.max(outputs, -1)\n",
    "            correct_predictions = predicted_indices == targets\n",
    "            accuracy = correct_predictions.float().mean().item()\n",
    "            acc[songNr] = accuracy\n",
    "            total_accuracy += accuracy\n",
    "            lo[songNr] = loss.item()\n",
    "        avg_loss = total_loss / number_of_Songs\n",
    "        avg_accuracy = total_accuracy / number_of_Songs\n",
    "\n",
    "        if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
    "            print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')\n",
    "            print(f'Epoch {epoch+1}, Loss: {np.mean(lo)}, Losses: {np.round(lo,2)}')\n",
    "            print(f'Epoch {epoch+1}, Accuracy: {np.mean(acc)}, Accuracies: {np.round(acc,2)}')\n",
    "        L.append(avg_loss)\n",
    "        A.append(avg_accuracy)\n",
    "\n",
    "        # Early stopping criteria (optional)\n",
    "        if len(A) > 5000 or avg_accuracy > 0.95:\n",
    "            print(\"Early stopping criteria met\")\n",
    "            break\n",
    "\n",
    "    return L, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cced8f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1219, Accuracy: 0.1237\n",
      "Epoch 1, Loss: 2.121948719024658, Losses: [2.14 2.11 2.18 2.05]\n",
      "Epoch 1, Accuracy: 0.12369337899144739, Accuracies: [0.01 0.16 0.12 0.21]\n",
      "Epoch 101, Loss: 1.8018, Accuracy: 0.1969\n",
      "Epoch 101, Loss: 1.8018265962600708, Losses: [1.82 1.79 1.78 1.82]\n",
      "Epoch 101, Accuracy: 0.19686411321163177, Accuracies: [0.23 0.17 0.3  0.08]\n",
      "Epoch 201, Loss: 1.5265, Accuracy: 0.4085\n",
      "Epoch 201, Loss: 1.5265251994132996, Losses: [1.62 1.07 1.57 1.84]\n",
      "Epoch 201, Accuracy: 0.4085365757346153, Accuracies: [0.35 0.65 0.33 0.3 ]\n",
      "Epoch 301, Loss: 1.1375, Accuracy: 0.5983\n",
      "Epoch 301, Loss: 1.1375225335359573, Losses: [1.08 0.47 1.37 1.63]\n",
      "Epoch 301, Accuracy: 0.5982868894934654, Accuracies: [0.6  0.97 0.45 0.37]\n",
      "Epoch 401, Loss: 0.9189, Accuracy: 0.7022\n",
      "Epoch 401, Loss: 0.9188747927546501, Losses: [0.76 0.31 1.17 1.44]\n",
      "Epoch 401, Accuracy: 0.702235758304596, Accuracies: [0.7  0.97 0.63 0.51]\n",
      "Epoch 501, Loss: 0.7527, Accuracy: 0.7625\n",
      "Epoch 501, Loss: 0.7526635937392712, Losses: [0.58 0.22 0.96 1.24]\n",
      "Epoch 501, Accuracy: 0.7624854743480682, Accuracies: [0.83 0.98 0.68 0.56]\n",
      "Epoch 601, Loss: 0.6076, Accuracy: 0.8389\n",
      "Epoch 601, Loss: 0.6076292172074318, Losses: [0.43 0.16 0.79 1.04]\n",
      "Epoch 601, Accuracy: 0.8388501852750778, Accuracies: [0.87 0.98 0.78 0.72]\n",
      "Epoch 701, Loss: 0.5043, Accuracy: 0.8635\n",
      "Epoch 701, Loss: 0.5043202638626099, Losses: [0.33 0.13 0.66 0.89]\n",
      "Epoch 701, Accuracy: 0.8635307848453522, Accuracies: [0.9  0.99 0.8  0.76]\n",
      "Epoch 801, Loss: 0.4270, Accuracy: 0.8849\n",
      "Epoch 801, Loss: 0.4270035997033119, Losses: [0.28 0.11 0.56 0.76]\n",
      "Epoch 801, Accuracy: 0.884872242808342, Accuracies: [0.93 0.99 0.83 0.79]\n",
      "Epoch 901, Loss: 0.3631, Accuracy: 0.9094\n",
      "Epoch 901, Loss: 0.36308231204748154, Losses: [0.24 0.1  0.48 0.64]\n",
      "Epoch 901, Accuracy: 0.9094076752662659, Accuracies: [0.94 0.99 0.87 0.84]\n",
      "Epoch 1001, Loss: 0.3143, Accuracy: 0.9213\n",
      "Epoch 1001, Loss: 0.3143060654401779, Losses: [0.22 0.08 0.42 0.54]\n",
      "Epoch 1001, Accuracy: 0.9213124364614487, Accuracies: [0.94 0.99 0.9  0.85]\n",
      "Epoch 1101, Loss: 0.2774, Accuracy: 0.9329\n",
      "Epoch 1101, Loss: 0.27742937579751015, Losses: [0.2  0.07 0.37 0.47]\n",
      "Epoch 1101, Accuracy: 0.932926818728447, Accuracies: [0.94 1.   0.94 0.86]\n",
      "Epoch 1201, Loss: 0.2474, Accuracy: 0.9358\n",
      "Epoch 1201, Loss: 0.24741661734879017, Losses: [0.18 0.06 0.32 0.42]\n",
      "Epoch 1201, Accuracy: 0.9358304291963577, Accuracies: [0.94 1.   0.95 0.86]\n",
      "Epoch 1301, Loss: 0.2238, Accuracy: 0.9386\n",
      "Epoch 1301, Loss: 0.22382680606096983, Losses: [0.17 0.06 0.29 0.37]\n",
      "Epoch 1301, Accuracy: 0.9385888427495956, Accuracies: [0.94 1.   0.95 0.86]\n",
      "Epoch 1401, Loss: 0.2028, Accuracy: 0.9444\n",
      "Epoch 1401, Loss: 0.20275624841451645, Losses: [0.16 0.05 0.26 0.34]\n",
      "Epoch 1401, Accuracy: 0.9443960636854172, Accuracies: [0.95 1.   0.95 0.88]\n",
      "Epoch 1501, Loss: 0.1884, Accuracy: 0.9564\n",
      "Epoch 1501, Loss: 0.18838737811893225, Losses: [0.15 0.05 0.24 0.31]\n",
      "Epoch 1501, Accuracy: 0.9564460068941116, Accuracies: [0.95 1.   0.95 0.93]\n",
      "Epoch 1601, Loss: 0.1703, Accuracy: 0.9607\n",
      "Epoch 1601, Loss: 0.170300398953259, Losses: [0.14 0.05 0.21 0.28]\n",
      "Epoch 1601, Accuracy: 0.9606562107801437, Accuracies: [0.94 1.   0.96 0.95]\n",
      "Epoch 1701, Loss: 0.1606, Accuracy: 0.9634\n",
      "Epoch 1701, Loss: 0.16056561563163996, Losses: [0.15 0.04 0.2  0.25]\n",
      "Epoch 1701, Accuracy: 0.9634146243333817, Accuracies: [0.95 1.   0.96 0.96]\n",
      "Epoch 1801, Loss: 0.1471, Accuracy: 0.9647\n",
      "Epoch 1801, Loss: 0.1470653135329485, Losses: [0.13 0.04 0.18 0.24]\n",
      "Epoch 1801, Accuracy: 0.9647212475538254, Accuracies: [0.95 1.   0.96 0.96]\n",
      "Epoch 1901, Loss: 0.1386, Accuracy: 0.9649\n",
      "Epoch 1901, Loss: 0.13855973351746798, Losses: [0.13 0.03 0.17 0.22]\n",
      "Epoch 1901, Accuracy: 0.964866429567337, Accuracies: [0.95 1.   0.96 0.96]\n",
      "Epoch 2001, Loss: 0.1308, Accuracy: 0.9678\n",
      "Epoch 2001, Loss: 0.1307969568297267, Losses: [0.13 0.03 0.16 0.21]\n",
      "Epoch 2001, Accuracy: 0.9677700400352478, Accuracies: [0.96 1.   0.96 0.96]\n",
      "Early stopping criteria met\n"
     ]
    }
   ],
   "source": [
    "model = RNNA()\n",
    "\n",
    "\n",
    "num_epochs = 3000\n",
    "number_of_Songs = 4\n",
    "L , A = train_model(model, num_epochs, songStrings= songStrings, number_of_Songs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1896692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN...\n",
      "Epoch 1, Loss: 2.1057, Accuracy: 0.1439\n",
      "Epoch 1, Loss: 2.1057199835777283, Losses: [2.1  2.11 2.08 2.13]\n",
      "Epoch 1, Accuracy: 0.14387340657413006, Accuracies: [0.05 0.17 0.29 0.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, Loss: 1.2441, Accuracy: 0.6032\n",
      "Epoch 101, Loss: 1.2440728545188904, Losses: [1.16 0.51 1.51 1.79]\n",
      "Epoch 101, Accuracy: 0.6032229959964752, Accuracies: [0.71 0.99 0.42 0.3 ]\n",
      "Epoch 201, Loss: 0.8126, Accuracy: 0.7487\n",
      "Epoch 201, Loss: 0.8125804215669632, Losses: [0.71 0.2  1.03 1.3 ]\n",
      "Epoch 201, Accuracy: 0.7486933916807175, Accuracies: [0.79 0.99 0.69 0.52]\n",
      "Epoch 301, Loss: 0.5657, Accuracy: 0.8300\n",
      "Epoch 301, Loss: 0.5656647384166718, Losses: [0.51 0.13 0.72 0.9 ]\n",
      "Epoch 301, Accuracy: 0.8299941867589951, Accuracies: [0.84 0.99 0.79 0.69]\n",
      "Epoch 401, Loss: 0.4199, Accuracy: 0.9056\n",
      "Epoch 401, Loss: 0.4198894537985325, Losses: [0.39 0.1  0.54 0.65]\n",
      "Epoch 401, Accuracy: 0.9056329876184464, Accuracies: [0.91 0.99 0.86 0.87]\n",
      "Epoch 501, Loss: 0.3261, Accuracy: 0.9303\n",
      "Epoch 501, Loss: 0.326123371720314, Losses: [0.31 0.08 0.41 0.5 ]\n",
      "Epoch 501, Accuracy: 0.9303135871887207, Accuracies: [0.92 0.99 0.9  0.91]\n",
      "Epoch 601, Loss: 0.2620, Accuracy: 0.9435\n",
      "Epoch 601, Loss: 0.2620092127472162, Losses: [0.26 0.07 0.33 0.39]\n",
      "Epoch 601, Accuracy: 0.9435249716043472, Accuracies: [0.93 0.99 0.93 0.92]\n",
      "Epoch 701, Loss: 0.2216, Accuracy: 0.9470\n",
      "Epoch 701, Loss: 0.2216131743043661, Losses: [0.22 0.06 0.28 0.33]\n",
      "Epoch 701, Accuracy: 0.9470092952251434, Accuracies: [0.93 1.   0.93 0.93]\n",
      "Early stopping criteria met\n",
      "Training RNNA...\n",
      "Epoch 1, Loss: 2.0862, Accuracy: 0.1263\n",
      "Epoch 1, Loss: 2.086192011833191, Losses: [2.11 2.08 2.07 2.08]\n",
      "Epoch 1, Accuracy: 0.12630662217270583, Accuracies: [0.   0.17 0.17 0.17]\n",
      "Epoch 101, Loss: 1.7582, Accuracy: 0.2616\n",
      "Epoch 101, Loss: 1.75816011428833, Losses: [1.81 1.66 1.74 1.83]\n",
      "Epoch 101, Accuracy: 0.2616144083440304, Accuracies: [0.19 0.33 0.31 0.21]\n",
      "Epoch 201, Loss: 1.4680, Accuracy: 0.4784\n",
      "Epoch 201, Loss: 1.4680197834968567, Losses: [1.72 0.73 1.6  1.82]\n",
      "Epoch 201, Accuracy: 0.4783681817352772, Accuracies: [0.25 0.98 0.43 0.26]\n",
      "Epoch 301, Loss: 1.0960, Accuracy: 0.6159\n",
      "Epoch 301, Loss: 1.0960157215595245, Losses: [1.   0.3  1.4  1.69]\n",
      "Epoch 301, Accuracy: 0.6158536672592163, Accuracies: [0.71 0.98 0.48 0.3 ]\n",
      "Epoch 401, Loss: 0.8779, Accuracy: 0.6966\n",
      "Epoch 401, Loss: 0.8779450617730618, Losses: [0.61 0.21 1.16 1.54]\n",
      "Epoch 401, Accuracy: 0.6965737640857697, Accuracies: [0.81 0.97 0.6  0.41]\n",
      "Epoch 501, Loss: 0.7372, Accuracy: 0.7141\n",
      "Epoch 501, Loss: 0.7371947765350342, Losses: [0.42 0.16 0.98 1.4 ]\n",
      "Epoch 501, Accuracy: 0.7141405344009399, Accuracies: [0.87 0.97 0.62 0.39]\n",
      "Epoch 601, Loss: 0.6281, Accuracy: 0.7519\n",
      "Epoch 601, Loss: 0.6281186994165182, Losses: [0.33 0.12 0.85 1.22]\n",
      "Epoch 601, Accuracy: 0.7518873512744904, Accuracies: [0.88 0.98 0.65 0.51]\n",
      "Epoch 701, Loss: 0.5336, Accuracy: 0.8050\n",
      "Epoch 701, Loss: 0.5336402952671051, Losses: [0.28 0.1  0.72 1.03]\n",
      "Epoch 701, Accuracy: 0.8050232231616974, Accuracies: [0.9  0.97 0.71 0.64]\n",
      "Epoch 801, Loss: 0.4445, Accuracy: 0.8553\n",
      "Epoch 801, Loss: 0.4445017911493778, Losses: [0.25 0.08 0.59 0.86]\n",
      "Epoch 801, Accuracy: 0.8552555292844772, Accuracies: [0.91 0.97 0.82 0.72]\n",
      "Epoch 901, Loss: 0.3632, Accuracy: 0.8955\n",
      "Epoch 901, Loss: 0.3631939999759197, Losses: [0.23 0.07 0.46 0.7 ]\n",
      "Epoch 901, Accuracy: 0.895470380783081, Accuracies: [0.91 0.98 0.87 0.82]\n",
      "Epoch 1001, Loss: 0.2996, Accuracy: 0.9159\n",
      "Epoch 1001, Loss: 0.29956522956490517, Losses: [0.22 0.05 0.35 0.57]\n",
      "Epoch 1001, Accuracy: 0.9159407615661621, Accuracies: [0.91 0.98 0.92 0.85]\n",
      "Epoch 1101, Loss: 0.2544, Accuracy: 0.9334\n",
      "Epoch 1101, Loss: 0.2544223079457879, Losses: [0.2  0.05 0.29 0.48]\n",
      "Epoch 1101, Accuracy: 0.9333623647689819, Accuracies: [0.91 0.98 0.95 0.89]\n",
      "Epoch 1201, Loss: 0.2231, Accuracy: 0.9393\n",
      "Epoch 1201, Loss: 0.22312121652066708, Losses: [0.19 0.04 0.26 0.41]\n",
      "Epoch 1201, Accuracy: 0.9393147528171539, Accuracies: [0.91 0.99 0.95 0.91]\n",
      "Epoch 1301, Loss: 0.1969, Accuracy: 0.9454\n",
      "Epoch 1301, Loss: 0.19689689669758081, Losses: [0.18 0.03 0.23 0.35]\n",
      "Epoch 1301, Accuracy: 0.9454123079776764, Accuracies: [0.91 0.99 0.95 0.92]\n",
      "Early stopping criteria met\n",
      "Training LSTM...\n",
      "Epoch 1, Loss: 2.0569, Accuracy: 0.1726\n",
      "Epoch 1, Loss: 2.0568637251853943, Losses: [2.12 2.04 2.05 2.02]\n",
      "Epoch 1, Accuracy: 0.1726190522313118, Accuracies: [0.19 0.17 0.17 0.17]\n",
      "Epoch 101, Loss: 1.5441, Accuracy: 0.5029\n",
      "Epoch 101, Loss: 1.5441219806671143, Losses: [1.59 1.21 1.65 1.73]\n",
      "Epoch 101, Accuracy: 0.5029036030173302, Accuracies: [0.42 0.81 0.4  0.37]\n",
      "Epoch 201, Loss: 1.2848, Accuracy: 0.5932\n",
      "Epoch 201, Loss: 1.2848077714443207, Losses: [1.29 0.73 1.44 1.68]\n",
      "Epoch 201, Accuracy: 0.5932055786252022, Accuracies: [0.52 0.98 0.51 0.36]\n",
      "Epoch 301, Loss: 1.0420, Accuracy: 0.6542\n",
      "Epoch 301, Loss: 1.0419977009296417, Losses: [0.96 0.47 1.2  1.53]\n",
      "Epoch 301, Accuracy: 0.6541811972856522, Accuracies: [0.72 0.99 0.57 0.34]\n",
      "Epoch 401, Loss: 0.8655, Accuracy: 0.7361\n",
      "Epoch 401, Loss: 0.8655263185501099, Losses: [0.77 0.35 1.   1.35]\n",
      "Epoch 401, Accuracy: 0.7360627204179764, Accuracies: [0.81 0.98 0.69 0.46]\n",
      "Epoch 501, Loss: 0.7381, Accuracy: 0.7898\n",
      "Epoch 501, Loss: 0.7380618527531624, Losses: [0.64 0.26 0.88 1.17]\n",
      "Epoch 501, Accuracy: 0.7897793352603912, Accuracies: [0.86 0.99 0.74 0.58]\n",
      "Epoch 601, Loss: 0.6408, Accuracy: 0.8304\n",
      "Epoch 601, Loss: 0.6408351249992847, Losses: [0.54 0.21 0.78 1.03]\n",
      "Epoch 601, Accuracy: 0.83042973279953, Accuracies: [0.9  0.98 0.79 0.65]\n",
      "Epoch 701, Loss: 0.5547, Accuracy: 0.8709\n",
      "Epoch 701, Loss: 0.5546638183295727, Losses: [0.48 0.17 0.69 0.87]\n",
      "Epoch 701, Accuracy: 0.8709349632263184, Accuracies: [0.9  0.99 0.84 0.76]\n",
      "Epoch 801, Loss: 0.4857, Accuracy: 0.8856\n",
      "Epoch 801, Loss: 0.48565277829766273, Losses: [0.44 0.15 0.6  0.76]\n",
      "Epoch 801, Accuracy: 0.8855981379747391, Accuracies: [0.9  0.99 0.85 0.8 ]\n",
      "Epoch 901, Loss: 0.4253, Accuracy: 0.9017\n",
      "Epoch 901, Loss: 0.4253421723842621, Losses: [0.4  0.13 0.5  0.67]\n",
      "Epoch 901, Accuracy: 0.9017131328582764, Accuracies: [0.9  1.   0.88 0.83]\n",
      "Epoch 1001, Loss: 0.3778, Accuracy: 0.9111\n",
      "Epoch 1001, Loss: 0.37784899584949017, Losses: [0.36 0.11 0.44 0.6 ]\n",
      "Epoch 1001, Accuracy: 0.9111498296260834, Accuracies: [0.9  1.   0.89 0.85]\n",
      "Epoch 1101, Loss: 0.3364, Accuracy: 0.9193\n",
      "Epoch 1101, Loss: 0.33642576448619366, Losses: [0.33 0.1  0.39 0.53]\n",
      "Epoch 1101, Accuracy: 0.9192799180746078, Accuracies: [0.91 1.   0.9  0.88]\n",
      "Epoch 1201, Loss: 0.3004, Accuracy: 0.9300\n",
      "Epoch 1201, Loss: 0.3003711458295584, Losses: [0.3  0.09 0.34 0.47]\n",
      "Epoch 1201, Accuracy: 0.9300232380628586, Accuracies: [0.92 1.   0.91 0.9 ]\n",
      "Epoch 1301, Loss: 0.2684, Accuracy: 0.9444\n",
      "Epoch 1301, Loss: 0.26841056533157825, Losses: [0.27 0.08 0.3  0.43]\n",
      "Epoch 1301, Accuracy: 0.9443960338830948, Accuracies: [0.94 0.99 0.92 0.92]\n",
      "Early stopping criteria met\n",
      "Training LSTMA...\n",
      "Epoch 1, Loss: 2.0715, Accuracy: 0.1369\n",
      "Epoch 1, Loss: 2.0714979767799377, Losses: [2.06 2.06 2.11 2.05]\n",
      "Epoch 1, Accuracy: 0.1369047649204731, Accuracies: [0.14 0.17 0.12 0.12]\n",
      "Epoch 101, Loss: 1.8693, Accuracy: 0.2089\n",
      "Epoch 101, Loss: 1.8692724108695984, Losses: [1.98 1.84 1.83 1.83]\n",
      "Epoch 101, Accuracy: 0.20891405642032623, Accuracies: [0.19 0.17 0.27 0.2 ]\n",
      "Epoch 201, Loss: 1.7962, Accuracy: 0.2014\n",
      "Epoch 201, Loss: 1.796170711517334, Losses: [1.79 1.8  1.79 1.8 ]\n",
      "Epoch 201, Accuracy: 0.2013646923005581, Accuracies: [0.24 0.17 0.19 0.21]\n",
      "Epoch 301, Loss: 1.6876, Accuracy: 0.3136\n",
      "Epoch 301, Loss: 1.6876113712787628, Losses: [1.77 1.6  1.72 1.67]\n",
      "Epoch 301, Accuracy: 0.31358885392546654, Accuracies: [0.24 0.34 0.3  0.37]\n",
      "Epoch 401, Loss: 1.5718, Accuracy: 0.4463\n",
      "Epoch 401, Loss: 1.571778565645218, Losses: [1.71 1.27 1.69 1.63]\n",
      "Epoch 401, Accuracy: 0.44628339260816574, Accuracies: [0.35 0.76 0.34 0.34]\n",
      "Epoch 501, Loss: 1.3855, Accuracy: 0.5341\n",
      "Epoch 501, Loss: 1.385457456111908, Losses: [1.23 1.04 1.65 1.62]\n",
      "Epoch 501, Accuracy: 0.5341172963380814, Accuracies: [0.62 0.84 0.3  0.37]\n",
      "Epoch 601, Loss: 1.2307, Accuracy: 0.5748\n",
      "Epoch 601, Loss: 1.2306651324033737, Losses: [0.84 0.87 1.59 1.62]\n",
      "Epoch 601, Accuracy: 0.5747677087783813, Accuracies: [0.75 0.82 0.34 0.39]\n",
      "Epoch 701, Loss: 1.1219, Accuracy: 0.6294\n",
      "Epoch 701, Loss: 1.12192203104496, Losses: [0.61 0.73 1.55 1.6 ]\n",
      "Epoch 701, Accuracy: 0.6293553933501244, Accuracies: [0.87 0.89 0.36 0.4 ]\n",
      "Epoch 801, Loss: 1.0393, Accuracy: 0.6717\n",
      "Epoch 801, Loss: 1.0392799004912376, Losses: [0.47 0.6  1.51 1.58]\n",
      "Epoch 801, Accuracy: 0.6717479601502419, Accuracies: [0.89 0.96 0.42 0.41]\n",
      "Epoch 901, Loss: 0.9567, Accuracy: 0.6944\n",
      "Epoch 901, Loss: 0.9566966444253922, Losses: [0.39 0.51 1.41 1.53]\n",
      "Epoch 901, Accuracy: 0.6943960636854172, Accuracies: [0.9  0.98 0.45 0.45]\n",
      "Epoch 1001, Loss: 0.8781, Accuracy: 0.7188\n",
      "Epoch 1001, Loss: 0.8781125694513321, Losses: [0.33 0.41 1.33 1.44]\n",
      "Epoch 1001, Accuracy: 0.7187862917780876, Accuracies: [0.91 0.98 0.48 0.51]\n",
      "Epoch 1101, Loss: 0.8094, Accuracy: 0.7400\n",
      "Epoch 1101, Loss: 0.8094117119908333, Losses: [0.29 0.33 1.25 1.36]\n",
      "Epoch 1101, Accuracy: 0.7399825900793076, Accuracies: [0.93 0.99 0.52 0.52]\n",
      "Epoch 1201, Loss: 0.7543, Accuracy: 0.7510\n",
      "Epoch 1201, Loss: 0.754258468747139, Losses: [0.25 0.28 1.19 1.3 ]\n",
      "Epoch 1201, Accuracy: 0.7510162740945816, Accuracies: [0.93 0.99 0.54 0.54]\n",
      "Epoch 1301, Loss: 0.7051, Accuracy: 0.7764\n",
      "Epoch 1301, Loss: 0.7050853073596954, Losses: [0.22 0.23 1.13 1.24]\n",
      "Epoch 1301, Accuracy: 0.776422768831253, Accuracies: [0.94 0.99 0.62 0.56]\n",
      "Epoch 1401, Loss: 0.6617, Accuracy: 0.7870\n",
      "Epoch 1401, Loss: 0.6616562940180302, Losses: [0.2  0.19 1.07 1.19]\n",
      "Epoch 1401, Accuracy: 0.7870209068059921, Accuracies: [0.94 1.   0.66 0.56]\n",
      "Epoch 1501, Loss: 0.6207, Accuracy: 0.7969\n",
      "Epoch 1501, Loss: 0.6207311116158962, Losses: [0.18 0.17 1.01 1.12]\n",
      "Epoch 1501, Accuracy: 0.7968931496143341, Accuracies: [0.94 1.   0.67 0.58]\n",
      "Epoch 1601, Loss: 0.5804, Accuracy: 0.8039\n",
      "Epoch 1601, Loss: 0.5804147012531757, Losses: [0.17 0.15 0.96 1.03]\n",
      "Epoch 1601, Accuracy: 0.8038617968559265, Accuracies: [0.94 1.   0.68 0.6 ]\n",
      "Epoch 1701, Loss: 0.5411, Accuracy: 0.8203\n",
      "Epoch 1701, Loss: 0.5411495789885521, Losses: [0.15 0.14 0.91 0.96]\n",
      "Epoch 1701, Accuracy: 0.8202671408653259, Accuracies: [0.95 1.   0.71 0.62]\n",
      "Epoch 1801, Loss: 0.5073, Accuracy: 0.8418\n",
      "Epoch 1801, Loss: 0.5073190368711948, Losses: [0.14 0.13 0.87 0.89]\n",
      "Epoch 1801, Accuracy: 0.8417537808418274, Accuracies: [0.95 1.   0.73 0.69]\n",
      "Epoch 1901, Loss: 0.4813, Accuracy: 0.8519\n",
      "Epoch 1901, Loss: 0.48130895011126995, Losses: [0.14 0.12 0.83 0.84]\n",
      "Epoch 1901, Accuracy: 0.8519163876771927, Accuracies: [0.95 1.   0.74 0.72]\n",
      "Epoch 2001, Loss: 0.4553, Accuracy: 0.8589\n",
      "Epoch 2001, Loss: 0.45532456412911415, Losses: [0.13 0.11 0.79 0.79]\n",
      "Epoch 2001, Accuracy: 0.8588850200176239, Accuracies: [0.95 1.   0.75 0.74]\n",
      "Epoch 2101, Loss: 0.4322, Accuracy: 0.8682\n",
      "Epoch 2101, Loss: 0.4322309922426939, Losses: [0.13 0.1  0.76 0.75]\n",
      "Epoch 2101, Accuracy: 0.8681765347719193, Accuracies: [0.95 1.   0.75 0.77]\n",
      "Epoch 2201, Loss: 0.4166, Accuracy: 0.8733\n",
      "Epoch 2201, Loss: 0.416620722040534, Losses: [0.13 0.09 0.72 0.72]\n",
      "Epoch 2201, Accuracy: 0.8732578456401825, Accuracies: [0.95 1.   0.76 0.79]\n",
      "Epoch 2301, Loss: 0.3923, Accuracy: 0.8811\n",
      "Epoch 2301, Loss: 0.39225752279162407, Losses: [0.12 0.08 0.69 0.68]\n",
      "Epoch 2301, Accuracy: 0.8810975551605225, Accuracies: [0.96 1.   0.77 0.8 ]\n",
      "Epoch 2401, Loss: 0.3675, Accuracy: 0.8952\n",
      "Epoch 2401, Loss: 0.36746728979051113, Losses: [0.12 0.08 0.63 0.64]\n",
      "Epoch 2401, Accuracy: 0.8951800167560577, Accuracies: [0.96 1.   0.82 0.8 ]\n",
      "Epoch 2501, Loss: 0.3483, Accuracy: 0.9024\n",
      "Epoch 2501, Loss: 0.34834148921072483, Losses: [0.12 0.07 0.6  0.61]\n",
      "Epoch 2501, Accuracy: 0.9024390280246735, Accuracies: [0.96 1.   0.84 0.81]\n",
      "Epoch 2601, Loss: 0.3306, Accuracy: 0.9053\n",
      "Epoch 2601, Loss: 0.3306261394172907, Losses: [0.11 0.06 0.56 0.58]\n",
      "Epoch 2601, Accuracy: 0.905342623591423, Accuracies: [0.95 1.   0.84 0.83]\n",
      "Epoch 2701, Loss: 0.3106, Accuracy: 0.9104\n",
      "Epoch 2701, Loss: 0.3106294358149171, Losses: [0.11 0.06 0.52 0.56]\n",
      "Epoch 2701, Accuracy: 0.9104239195585251, Accuracies: [0.96 1.   0.84 0.84]\n",
      "Epoch 2801, Loss: 0.2943, Accuracy: 0.9168\n",
      "Epoch 2801, Loss: 0.29428461752831936, Losses: [0.11 0.05 0.49 0.53]\n",
      "Epoch 2801, Accuracy: 0.9168118387460709, Accuracies: [0.97 1.   0.85 0.86]\n",
      "Epoch 2901, Loss: 0.2805, Accuracy: 0.9222\n",
      "Epoch 2901, Loss: 0.2804552437737584, Losses: [0.1  0.05 0.47 0.51]\n",
      "Epoch 2901, Accuracy: 0.9221835136413574, Accuracies: [0.96 1.   0.87 0.87]\n",
      "Epoch 3001, Loss: 0.2696, Accuracy: 0.9220\n",
      "Epoch 3001, Loss: 0.2695542387664318, Losses: [0.1  0.04 0.44 0.49]\n",
      "Epoch 3001, Accuracy: 0.9220383316278458, Accuracies: [0.97 1.   0.87 0.86]\n",
      "Epoch 3101, Loss: 0.2571, Accuracy: 0.9323\n",
      "Epoch 3101, Loss: 0.25710045639425516, Losses: [0.1  0.04 0.42 0.47]\n",
      "Epoch 3101, Accuracy: 0.9323461055755615, Accuracies: [0.96 1.   0.88 0.89]\n",
      "Epoch 3201, Loss: 0.2460, Accuracy: 0.9368\n",
      "Epoch 3201, Loss: 0.2459502937272191, Losses: [0.1  0.04 0.39 0.45]\n",
      "Epoch 3201, Accuracy: 0.9368466883897781, Accuracies: [0.96 1.   0.89 0.89]\n",
      "Epoch 3301, Loss: 0.2345, Accuracy: 0.9429\n",
      "Epoch 3301, Loss: 0.2345110233873129, Losses: [0.1  0.03 0.37 0.44]\n",
      "Epoch 3301, Accuracy: 0.9429442584514618, Accuracies: [0.96 1.   0.91 0.91]\n",
      "Epoch 3401, Loss: 0.2263, Accuracy: 0.9450\n",
      "Epoch 3401, Loss: 0.22626776108518243, Losses: [0.09 0.03 0.36 0.42]\n",
      "Epoch 3401, Accuracy: 0.9449767619371414, Accuracies: [0.96 1.   0.91 0.91]\n",
      "Epoch 3501, Loss: 0.2176, Accuracy: 0.9464\n",
      "Epoch 3501, Loss: 0.2175809545442462, Losses: [0.09 0.03 0.34 0.41]\n",
      "Epoch 3501, Accuracy: 0.946428582072258, Accuracies: [0.97 1.   0.91 0.91]\n",
      "Epoch 3601, Loss: 0.2106, Accuracy: 0.9483\n",
      "Epoch 3601, Loss: 0.21056795492768288, Losses: [0.09 0.03 0.33 0.39]\n",
      "Epoch 3601, Accuracy: 0.948315903544426, Accuracies: [0.96 1.   0.92 0.91]\n",
      "Epoch 3701, Loss: 0.2034, Accuracy: 0.9486\n",
      "Epoch 3701, Loss: 0.20335142640396953, Losses: [0.09 0.03 0.31 0.38]\n",
      "Epoch 3701, Accuracy: 0.9486062675714493, Accuracies: [0.96 1.   0.93 0.91]\n",
      "Early stopping criteria met\n",
      "Training GRU...\n",
      "Epoch 1, Loss: 2.0480, Accuracy: 0.1317\n",
      "Epoch 1, Loss: 2.048024147748947, Losses: [2.12 2.03 2.03 2.  ]\n",
      "Epoch 1, Accuracy: 0.13167828461155295, Accuracies: [0.03 0.17 0.17 0.17]\n",
      "Epoch 101, Loss: 1.3588, Accuracy: 0.5627\n",
      "Epoch 101, Loss: 1.3588497191667557, Losses: [1.39 0.76 1.48 1.8 ]\n",
      "Epoch 101, Accuracy: 0.5627177730202675, Accuracies: [0.56 0.98 0.45 0.26]\n",
      "Epoch 201, Loss: 0.9015, Accuracy: 0.7120\n",
      "Epoch 201, Loss: 0.9015234000980854, Losses: [0.87 0.23 1.08 1.43]\n",
      "Epoch 201, Accuracy: 0.7119628340005875, Accuracies: [0.74 0.98 0.67 0.45]\n",
      "Epoch 301, Loss: 0.5547, Accuracy: 0.8394\n",
      "Epoch 301, Loss: 0.5546931773424149, Losses: [0.52 0.13 0.69 0.89]\n",
      "Epoch 301, Accuracy: 0.8394308835268021, Accuracies: [0.86 0.98 0.83 0.68]\n",
      "Epoch 401, Loss: 0.3507, Accuracy: 0.9194\n",
      "Epoch 401, Loss: 0.3506864383816719, Losses: [0.32 0.09 0.45 0.54]\n",
      "Epoch 401, Accuracy: 0.9194250851869583, Accuracies: [0.93 0.98 0.89 0.87]\n",
      "Early stopping criteria met\n",
      "Training GRUA...\n",
      "Epoch 1, Loss: 2.1228, Accuracy: 0.1369\n",
      "Epoch 1, Loss: 2.122843384742737, Losses: [2.2  2.1  2.12 2.07]\n",
      "Epoch 1, Accuracy: 0.1369047649204731, Accuracies: [0.   0.17 0.17 0.21]\n",
      "Epoch 101, Loss: 1.7683, Accuracy: 0.2561\n",
      "Epoch 101, Loss: 1.7682947218418121, Losses: [1.77 1.74 1.78 1.78]\n",
      "Epoch 101, Accuracy: 0.25609756261110306, Accuracies: [0.24 0.33 0.23 0.23]\n",
      "Epoch 201, Loss: 1.3922, Accuracy: 0.5112\n",
      "Epoch 201, Loss: 1.3922082781791687, Losses: [1.19 0.96 1.62 1.79]\n",
      "Epoch 201, Accuracy: 0.5111788660287857, Accuracies: [0.58 0.82 0.39 0.25]\n",
      "Epoch 301, Loss: 0.9703, Accuracy: 0.6561\n",
      "Epoch 301, Loss: 0.9702565595507622, Losses: [0.81 0.35 1.17 1.55]\n",
      "Epoch 301, Accuracy: 0.6560685336589813, Accuracies: [0.68 0.98 0.62 0.35]\n",
      "Epoch 401, Loss: 0.6962, Accuracy: 0.7699\n",
      "Epoch 401, Loss: 0.6961819231510162, Losses: [0.63 0.17 0.79 1.21]\n",
      "Epoch 401, Accuracy: 0.7698896527290344, Accuracies: [0.75 0.98 0.81 0.53]\n",
      "Epoch 501, Loss: 0.5229, Accuracy: 0.8403\n",
      "Epoch 501, Loss: 0.5229323618113995, Losses: [0.55 0.11 0.55 0.88]\n",
      "Epoch 501, Accuracy: 0.840301975607872, Accuracies: [0.8  0.99 0.86 0.71]\n",
      "Epoch 601, Loss: 0.4240, Accuracy: 0.8705\n",
      "Epoch 601, Loss: 0.42398413829505444, Losses: [0.5  0.08 0.42 0.69]\n",
      "Epoch 601, Accuracy: 0.8704994171857834, Accuracies: [0.82 0.99 0.87 0.81]\n",
      "Epoch 701, Loss: 0.3508, Accuracy: 0.9052\n",
      "Epoch 701, Loss: 0.35077485628426075, Losses: [0.44 0.07 0.33 0.56]\n",
      "Epoch 701, Accuracy: 0.9051974415779114, Accuracies: [0.86 0.99 0.91 0.86]\n",
      "Epoch 801, Loss: 0.2935, Accuracy: 0.9257\n",
      "Epoch 801, Loss: 0.2934933854267001, Losses: [0.39 0.06 0.27 0.46]\n",
      "Epoch 801, Accuracy: 0.9256678372621536, Accuracies: [0.87 0.99 0.95 0.89]\n",
      "Epoch 901, Loss: 0.2518, Accuracy: 0.9374\n",
      "Epoch 901, Loss: 0.25178017653524876, Losses: [0.35 0.05 0.22 0.38]\n",
      "Epoch 901, Accuracy: 0.9374274164438248, Accuracies: [0.88 0.99 0.96 0.92]\n",
      "Epoch 1001, Loss: 0.2207, Accuracy: 0.9395\n",
      "Epoch 1001, Loss: 0.22068933863192797, Losses: [0.31 0.04 0.19 0.34]\n",
      "Epoch 1001, Accuracy: 0.9394599348306656, Accuracies: [0.89 0.99 0.96 0.92]\n",
      "Epoch 1101, Loss: 0.1970, Accuracy: 0.9466\n",
      "Epoch 1101, Loss: 0.19699085224419832, Losses: [0.27 0.04 0.17 0.3 ]\n",
      "Epoch 1101, Accuracy: 0.9465737491846085, Accuracies: [0.91 0.99 0.96 0.92]\n",
      "Early stopping criteria met\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RNN\": RNN(),\n",
    "    \"RNNA\": RNNA(),  \n",
    "    \"LSTM\": LSTM(),\n",
    "    \"LSTMA\": LSTMA(),  \n",
    "    \"GRU\": GRU(),\n",
    "    \"GRUA\": GRUA() \n",
    "    \n",
    "}\n",
    "num_epochs = 10000\n",
    "number_of_Songs = 4\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    L, A = train_model(model, num_epochs, songStrings, number_of_Songs)\n",
    "    results[model_name] = {\"Accuracy\": A, \"Loss\": L}\n",
    "    #torch.save(model, f'model_{model_name}_songs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e31f45e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RNN\n",
      "Final Accuracy: 0.9501\n",
      "Final Loss: 0.1971\n",
      "Number of Epoch: 798\n",
      "\n",
      "Model: RNNA\n",
      "Final Accuracy: 0.9502\n",
      "Final Loss: 0.1929\n",
      "Number of Epoch: 1322\n",
      "\n",
      "Model: LSTM\n",
      "Final Accuracy: 0.9501\n",
      "Final Loss: 0.2515\n",
      "Number of Epoch: 1366\n",
      "\n",
      "Model: LSTMA\n",
      "Final Accuracy: 0.9501\n",
      "Final Loss: 0.2019\n",
      "Number of Epoch: 3705\n",
      "\n",
      "Model: GRU\n",
      "Final Accuracy: 0.9502\n",
      "Final Loss: 0.2856\n",
      "Number of Epoch: 452\n",
      "\n",
      "Model: GRUA\n",
      "Final Accuracy: 0.9503\n",
      "Final Loss: 0.1900\n",
      "Number of Epoch: 1133\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Final Accuracy: {metrics['Accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Loss: {metrics['Loss'][-1]:.4f}\")\n",
    "    print(f\"Number of Epoch: {len(metrics['Accuracy'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3351a096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (expand_layer): Linear(in_features=8, out_features=20, bias=True)\n",
       "  (rnnLayer): RNN(20, 20, batch_first=True)\n",
       "  (outputLayer): Linear(in_features=20, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " models[\"RNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "16929fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 20)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "I, O_hot, O_indices = generateIOData(0, songStrings)\n",
    "\n",
    "S,H=shrinkingDecompositionInformation(model,20,I,O_indices.transpose(),numbers=[0,1,2,3,4,5,6,7],whichTS=40,dsLength=41)\n",
    "M=removalIntoMatrix(S,20,H)\n",
    "imshow(M)\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd0dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of M for song 1: (8, 20)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAF2CAYAAAA83m0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBeElEQVR4nO3de1zUVf7H8fcAMngDLQVFSdRMU1PLC5G5aqFo5qWrt9ZL5paLW0b7W3O7oLVJba3rloZlXtpaL2VppYYpK5WlaV4qK00LL5VAugmICTZzfn+4zDpykfkKzAy8no/HeTycM+d8z5kv3+Hx4fj5nq/NGGMEAAAAwCcEeHsCAAAAAP6HAB0AAADwIQToAAAAgA8hQAcAAAB8CAE6AAAA4EMI0AEAAAAfQoAOAAAA+BACdAAAAMCHEKADAAAAPoQAHaghpk+fLpvN5pWx+/Tpoz59+nhl7LLmceDAAdlsNi1evLhK5+GtcYu88sorateunWrVqqUGDRp4ZQ4AgNIRoAMVbPHixbLZbLLZbNq0aVOx940xioqKks1m04033mhpjJkzZ2rVqlUXOFNrsrOzFRQUpDvuuKPUNnl5eapdu7ZuvvnmKpyZ71myZIlmz57t7Wm42bNnj8aNG6fWrVtr/vz5evHFFyt9zE2bNmngwIFq1qyZQkJCdMkll2jw4MFasmRJpY99Id58800NHz5crVq1Up06ddS2bVs98MADOn78uLenBqCasxljjLcnAVQnixcv1vjx4xUSEqLx48fr+eefd3s/PT1dffv2ld1uV1xcnFavXu3xGPXq1dOtt97q0Qrsr7/+ql9//VUhISEej3eugQMHatOmTcrKylKdOnWKvf/yyy9r3LhxeuONN3TzzTersLBQkhQcHHzBY1+IotXz9PR0SWf+WCooKFCtWrUUGBhY4ePdeOON2r17tw4cOOBWX9njlmXevHmaNGmS9u3bp0svvbTSx3v99dc1fPhwdenSRSNGjFDDhg2VkZGhDz74QLVq1dLGjRsrfQ5WNWrUSJGRkRo2bJguueQSffHFF5o3b55atWqlHTt2qHbt2t6eIoBqKsjbEwCqqxtuuEGvv/66nn32WQUF/e+rtmTJEnXt2lVHjx6tknnk5+erbt26CgoKcpvHhRg9erRSU1P19ttva8SIEcXeX7JkicLCwjRo0CBJ3g/MS2Oz2SrkDxZ/GVc68z8gkio0teXkyZMl/qEmnUmtat++vbZs2VLsOiiai69asWJFsdSsrl27auzYsfrXv/6lu+66yzsTA1DtkeICVJKRI0fq2LFjWr9+vauusLBQK1as0KhRo0rs88wzz+iaa67RxRdfrNq1a6tr165asWKFWxubzab8/Hy9/PLLrlSacePGSfpfnvlXX32lUaNGqWHDhrr22mvd3iuyaNEi2Ww2LVy40O34M2fOlM1m09q1a0v9bDfddJPq1q1bYopCdna20tLSdOutt8put0sqOQf9ueeeU4cOHVSnTh01bNhQ3bp1czveuHHjFB0dXez4JeXSL1q0SNddd53Cw8Nlt9vVvn17paSklDr/Iufmgqenp7vO6bnl7Lm89dZbGjRokCIjI2W329W6dWs9/vjjcjgcrjZ9+vTRmjVrdPDgwWLHKC0H/d///rd69eqlunXrqkGDBho6dKi+/vrrEj///v37NW7cODVo0EBhYWEaP368Tp48WebnjY6OVlJSkiSpcePGstlsmj59uuv9559/Xh06dJDdbldkZKQSEhKKpXP06dNHHTt21Pbt2/Wb3/xGderU0Z///OdSx/z222/VvXv3Ev9ICw8Pd3udn5+vBx54QFFRUbLb7Wrbtq2eeeYZnfsfvTabTZMnT9aqVavUsWNH2e12dejQQampqcXGSE9PV7du3RQSEqLWrVvrhRdeKPf9GCXdN3HTTTdJUrGfCwBUJFbQgUoSHR2t2NhYLV26VAMHDpQkvfvuu8rJydGIESP07LPPFuvzj3/8Q0OGDNHo0aNVWFioZcuW6bbbbtPq1atdq9GvvPKK7rrrLvXo0UO/+93vJEmtW7d2O85tt92mNm3aaObMmcWCmyLjx4/Xm2++qcTERPXr109RUVH64osvNGPGDE2YMEE33HBDqZ+tbt26Gjp0qFasWKH//Oc/uuiii1zvLV++XA6HQ6NHjy61//z583Xvvffq1ltv1X333adTp07p888/1yeffFLqHy9lSUlJUYcOHTRkyBAFBQXpnXfe0e9//3s5nU4lJCSU+ziXX365XnnlFbe648ePKzEx0S2YXLx4serVq6fExETVq1dP//73v/Xoo48qNzdXTz/9tCTpoYceUk5Ojr7//nv9/e9/l3QmNak0GzZs0MCBA9WqVStNnz5dv/zyi5577jn17NlTO3bsKPbHyu23366WLVsqOTlZO3bs0EsvvaTw8HA99dRTpY4xe/Zs/fOf/9TKlSuVkpKievXqqVOnTpLOBP4zZsxQXFycJk2apL179yolJUXbtm3TRx99pFq1armOc+zYMQ0cOFAjRozQHXfcoYiIiFLHbNGihdLS0vT999+refPmpbYzxmjIkCHauHGjJkyYoC5dumjdunX6v//7P/3www+uc1hk06ZNevPNN/X73/9e9evX17PPPqtbbrlFhw4d0sUXXyxJ2rlzpwYMGKCmTZtqxowZcjgceuyxx9S4ceNS53E+mZmZks6kvwBApTEAKtSiRYuMJLNt2zYzZ84cU79+fXPy5EljjDG33Xab6du3rzHGmBYtWphBgwa59S1qV6SwsNB07NjRXHfddW71devWNWPHji02dlJSkpFkRo4cWep7Zzty5Ii56KKLTL9+/UxBQYG58sorzSWXXGJycnLO+znXrFljJJkXXnjBrf7qq682zZo1Mw6Hw1XXu3dv07t3b9froUOHmg4dOpR5/LFjx5oWLVqU63Oce96MMSY+Pt60atXKre7ceWRkZBhJZtGiRSXOwel0mhtvvNHUq1fPfPnll2WOd/fdd5s6deqYU6dOueoGDRpU4mcoadwuXbqY8PBwc+zYMVfdZ599ZgICAsyYMWNcdUWf/84773Q75k033WQuvvjiEj/H2Yr6//TTT6667OxsExwcbPr37+/2c5szZ46RZBYuXOiq6927t5Fk5s2bd96xjDFmwYIFRpIJDg42ffv2NY888oj58MMP3cYxxphVq1YZSeYvf/mLW/2tt95qbDab2b9/v6uu6Hhn13322WdGknnuuedcdYMHDzZ16tQxP/zwg6tu3759JigoqNg1VF4TJkwwgYGB5ptvvrHUHwDKgxQXoBLdfvvt+uWXX7R69Wrl5eVp9erVZa4Qn33T2c8//6ycnBz16tVLO3bs8Gjce+65p1ztmjRporlz52r9+vXq1auXdu3apYULFyo0NPS8ffv376/GjRu7paVkZGRoy5YtGjlypAICSv/10qBBA33//ffatm1bueZ5Pmeft5ycHB09elS9e/fWd999p5ycHMvHffzxx7V69WotXrxY7du3L3G8vLw8HT16VL169dLJkye1Z88ej8c5cuSIdu3apXHjxrn9b0SnTp3Ur1+/EtONzv0Z9+rVS8eOHVNubq7H42/YsEGFhYWaMmWK289t4sSJCg0N1Zo1a9za2+12jR8/vlzHvvPOO5Wamqo+ffpo06ZNevzxx9WrVy+1adNGH3/8savd2rVrFRgYqHvvvdet/wMPPCBjjN599123+ri4OLf/OerUqZNCQ0P13XffSZIcDoc2bNigYcOGKTIy0tXu0ksvdf2PlqeWLFmiBQsW6IEHHlCbNm0sHQMAyoMAHahEjRs3VlxcnJYsWaI333xTDodDt956a6ntV69erauvvlohISG66KKL1LhxY6WkpHgcZLZs2bLcbUeMGKFBgwZp69atmjhxoq6//vpy9QsKCtLw4cP14Ycf6ocffpAkV7BeVnqLJE2dOlX16tVTjx491KZNGyUkJOijjz4q95zP9dFHHykuLs6Vu924cWNXXrTVAD01NVUzZszQtGnTdMstt7i99+WXX+qmm25SWFiYQkND1bhxY9e2k1bGO3jwoCSpbdu2xd67/PLLdfToUeXn57vVX3LJJW6vGzZsKOnMH3YVNX5wcLBatWrler9Is2bNPLrxNz4+XuvWrdPx48f1wQcfKCEhQQcPHtSNN97oulH04MGDioyMVP369d36Xn755W5zLHLu55fOnIOiz5+dna1ffvmlxJ1qrOxe8+GHH2rChAmKj4/XE0884XF/APAEATpQyUaNGqV3331X8+bN08CBA0vdPePDDz/UkCFDFBISoueff15r167V+vXrNWrUqFLzyEvjyfZvx44d06effipJ+uqrr+R0Osvd94477pDT6dTSpUslSUuXLlX79u3VpUuXMvtdfvnl2rt3r5YtW6Zrr71Wb7zxhq699lrXDYySSr2J7+wbMaUzNyFef/31Onr0qGbNmqU1a9Zo/fr1uv/++yXJo89TJCMjQ6NHj1a/fv30l7/8xe2948ePq3fv3vrss8/02GOP6Z133tH69etdud9WxrOitO0ZPb1WrLC6vWCdOnXUq1cvzZkzRw8//LB+/vnnYivj5VWVn/+zzz7TkCFD1LFjR61YsaLCdkMCgNIQoAOV7KabblJAQIC2bNlSZnrLG2+8oZCQEK1bt0533nmnBg4cqLi4uBLbVuQTQRMSEpSXl6fk5GRt2rTJowfrxMTEqHXr1lqyZIk+++wzffnll+ddPS9St25dDR8+XIsWLdKhQ4c0aNAgPfHEEzp16pSkM6uhJT0Q5tyV1HfeeUcFBQV6++23dffdd+uGG25QXFyc5SDyl19+0c0336wGDRpo6dKlxVJ10tPTdezYMS1evFj33XefbrzxRsXFxblWsM9W3p9TixYtJEl79+4t9t6ePXvUqFEj1a1b18KnKZ/Sxi8sLFRGRobr/YrUrVs3SWfSe4rm8OOPPyovL8+tXVHKkKdzCA8PV0hIiPbv31/svZLqSvPtt99qwIABCg8P19q1a8u80RcAKgoBOlDJ6tWrp5SUFE2fPl2DBw8utV1gYKBsNpvbCvGBAwdKfGJo3bp1K+RphitWrNDy5cv15JNP6sEHH9SIESP08MMP65tvvin3MUaPHq2dO3cqKSlJNputXLuwHDt2zO11cHCw2rdvL2OMTp8+LenMzjQ5OTn6/PPPXe2OHDmilStXuvUtWkk9e+U0JydHixYtKvdnONs999yjb775RitXriwx6C5pvMLCwmIPpJLO/JzKk/LStGlTdenSRS+//LLbz3X37t167733ytxRpyLExcUpODhYzz77rNvnWrBggXJyclw7CFmRlpZWYn1RXn1RWs0NN9wgh8OhOXPmuLX7+9//LpvN5nHeeGBgoOLi4rRq1Sr9+OOPrvr9+/eXe9U+MzNT/fv3V0BAgNatW3dBu78AgCf4fzqgCowdO/a8bQYNGqRZs2ZpwIABGjVqlLKzszV37lxdeumlbkGqdOZhKRs2bNCsWbMUGRmpli1bKiYmxqM5ZWdna9KkSerbt68mT54sSZozZ442btyocePGadOmTWXe6Fnkjjvu0GOPPaa33npLPXv2LHHv8nP1799fTZo0Uc+ePRUREaGvv/5ac+bM0aBBg1w5yCNGjNDUqVN100036d5779XJkyeVkpKiyy67zO2m2f79+ys4OFiDBw/W3XffrRMnTmj+/PkKDw93rc6W15o1a/TPf/5Tt9xyiz7//HO3816vXj0NGzZM11xzjRo2bKixY8fq3nvvlc1m0yuvvFJiakXXrl21fPlyJSYmqnv37qpXr16pf6Q9/fTTGjhwoGJjYzVhwgTXNothYWFue5VXhsaNG2vatGmaMWOGBgwYoCFDhmjv3r16/vnn1b17d1d+vRVDhw5Vy5YtNXjwYLVu3Vr5+fnasGGD3nnnHXXv3t11PgYPHqy+ffvqoYce0oEDB9S5c2e99957euuttzRlypRiW4mWx/Tp0/Xee++pZ8+emjRpkusPgI4dO2rXrl3n7T9gwAB99913+tOf/qRNmzZp06ZNrvciIiLUr18/j+cEAOXitf1jgGrq7G0Wy1LSNosLFiwwbdq0MXa73bRr184sWrSoxG0F9+zZY37zm9+Y2rVrG0muLRdL2kKvyLnHufnmm039+vXNgQMH3Nq99dZbRpJ56qmnyv2Zu3fvbiSZ559/vsT3z93e8IUXXjC/+c1vzMUXX2zsdrtp3bq1+b//+79i2zu+9957pmPHjiY4ONi0bdvWvPrqqyWej7ffftt06tTJhISEmOjoaPPUU0+ZhQsXGkkmIyOj1Hmcu91h0c+upHL2dokfffSRufrqq03t2rVNZGSk+dOf/mTWrVtnJJmNGze62p04ccKMGjXKNGjQwO0YpW3vuGHDBtOzZ09Tu3ZtExoaagYPHmy++uortzal/YyL5n725y1JWdfInDlzTLt27UytWrVMRESEmTRpkvn555/d2vTu3fu8W2SebenSpWbEiBGmdevWpnbt2iYkJMS0b9/ePPTQQyY3N9etbV5enrn//vtNZGSkqVWrlmnTpo15+umnjdPpdGsnySQkJBQbq0WLFsW2H01LSzNXXnmlCQ4ONq1btzYvvfSSeeCBB0xISMh5517atSDJ7ToCgIpmM6YK7igCAMBHDBs2TF9++aX27dvn7akAQInIQQcAVFu//PKL2+t9+/Zp7dq16tOnj3cmBADlwAo6AKDaatq0qcaNG+fazz0lJUUFBQXauXMnDxsC4LO4SRQAUG0NGDBAS5cuVWZmpux2u2JjYzVz5kyCcwA+jRQXAEC1tWjRIh04cECnTp1STk6OUlNTddVVV3l7WgD8xAcffKDBgwcrMjJSNputxK2Pz5Wenq6rrrpKdrtdl156qRYvXuzxuAToAAAAQAny8/PVuXNnzZ07t1ztMzIyNGjQIPXt21e7du3SlClTdNddd2ndunUejUsOOgAAAHAeNptNK1eu1LBhw0ptM3XqVK1Zs0a7d+921Y0YMULHjx9Xampquceq8hx0p9OpH3/8UfXr16/Qx5UDAACgYhhjlJeXp8jIyHI9tK4qnTp1SoWFhZb7G2OKxaB2u112u/1Cp6bNmzcrLi7OrS4+Pl5Tpkzx6DhVHqD/+OOPioqKquphAQAA4KHDhw+refPm3p6Gy6lTp9SyRT1lZjssH6NevXo6ceKEW11SUlKFPLU5MzNTERERbnURERHKzc3VL7/8otq1a5frOFUeoBc9xvuaq/+koKAL/0vFUzktQ6p8zCKNPs722thHrwn32thhGae8NvZ//vDL+RtVksDVDb02tuPGn702NmqeRsN54A9Q3fyq09qkta64zVcUFhYqM9uhjO0tFFrf85X93DynWnY9qMOHDys0NNRVXxGr5xWpygP0ov9SCAqyKyio6oPlwGDvBehBgd774Xv1c3txM8/AOk7vje3Fc646vvWLBtVbkK2Wt6cAoKL99w5FX01HDq0fYClAd/UPDXUL0CtKkyZNlJWV5VaXlZWl0NDQcq+eS+yDDgAAAD/jME45LGxz4jCVu3AXGxurtWvXutWtX79esbGxHh3Ht7L+AQAAgPNwylgunjhx4oR27dqlXbt2STqzjeKuXbt06NAhSdK0adM0ZswYV/t77rlH3333nf70pz9pz549ev755/Xaa6/p/vvv92hcVtABAADgV5xyyspauKe9Pv30U/Xt29f1OjExUZI0duxYLV68WEeOHHEF65LUsmVLrVmzRvfff7/+8Y9/qHnz5nrppZcUHx/v0bgE6AAAAPArDmPksPAoH0/79OnTR2U9Mqikp4T26dNHO3fu9HRqbgjQAQAA4FespKsU9fMH5KADAAAAPoQVdAAAAPgVp4wc1XgFnQAdAAAAfqW6p7gQoAMAAMCvVNVNot5CgA4AAAC/4vxvsdLPH3CTKAAAAOBDWEEHAACAX3FYvEnUSh9vsLSCPnfuXEVHRyskJEQxMTHaunVrRc8LAAAAKJHDWC/+wOMAffny5UpMTFRSUpJ27Nihzp07Kz4+XtnZ2ZUxPwAAAMCN8wKKP/A4QJ81a5YmTpyo8ePHq3379po3b57q1KmjhQsXVsb8AAAAADdO2eSwUJyyeXvq5eJRgF5YWKjt27crLi7ufwcICFBcXJw2b95c4ZMDAAAAzuU01os/8Ogm0aNHj8rhcCgiIsKtPiIiQnv27CmxT0FBgQoKClyvc3NzLUwTAAAAqBkqfZvF5ORkhYWFuUpUVFRlDwkAAIBqzEp6S1HxBx4F6I0aNVJgYKCysrLc6rOystSkSZMS+0ybNk05OTmucvjwYeuzBQAAQI1HgH6W4OBgde3aVWlpaa46p9OptLQ0xcbGltjHbrcrNDTUrQAAAABWOY3NcvEHHj+oKDExUWPHjlW3bt3Uo0cPzZ49W/n5+Ro/fnxlzA8AAABwY3U13F9W0D0O0IcPH66ffvpJjz76qDIzM9WlSxelpqYWu3EUAAAAqAwOBchh4VZKRyXMpTJ4HKBL0uTJkzV58uSKngsAAABQ41kK0AEAAABvMRbzyU11zUEHAAAAvIkcdAAAAMCHOEyAHMZCDnp1fJIoAAAA4G1O2eS0cJOoU/4RoROgAwAAwK9U9xQXz//0AAAAAFBpWEEHAACAX7Geg06KCwAAAFDhzuSge56uYqWPNxCgAwAAwK84LT5JlJtEAQAAgEpAigsAAADgQ5wKqNbbLLKLCwAAAOBDvLaCfmLKCQXWPV3l427rsqjKxywSH9nFa2Nve/9Nr43ddfokr429o5v3ft7q5r2hvXnOvWn79BSvjX31rlu9NrYkhd2w36vjA0BVchibHMbCPugW+ngDKS4AAADwKw6LN4k6/CTFhQAdAAAAfsVpAuS0cJOok5tEAQAAgIrHCjoAAADgQ5yylk/urPipVAp2cQEAAAB8CCvoAAAA8CvW90H3j7VpAnQAAAD4FetPEiVABwAAACqcUzY5ZSUHnX3QAQAAgArHCjoAAADgQ6xvs+gfAbp/zBIAAACoIVhBBwAAgF9xGpucVvZBt9DHGwjQAQAA4FecFlNc2GYRAAAAqAROEyCnhRs+rfTxBgJ0AAAA+BWHbHJY2DLRSh9v8PjPiA8++ECDBw9WZGSkbDabVq1aVQnTAgAAAEpWtIJupfgDj2eZn5+vzp07a+7cuZUxHwAAAKBG8zjFZeDAgRo4cGBlzAUAAAA4L4espas4Kn4qlaLS1/kLCgqUm5vrVgAAAACrqjLFZe7cuYqOjlZISIhiYmK0devWMtvPnj1bbdu2Ve3atRUVFaX7779fp06d8mjMSg/Qk5OTFRYW5ipRUVGVPSQAAACqMYcJsFw8sXz5ciUmJiopKUk7duxQ586dFR8fr+zs7BLbL1myRA8++KCSkpL09ddfa8GCBVq+fLn+/Oc/ezRupQfo06ZNU05OjqscPny4socEAABANWZkk9NCMR6mxcyaNUsTJ07U+PHj1b59e82bN0916tTRwoULS2z/8ccfq2fPnho1apSio6PVv39/jRw58ryr7ueq9ADdbrcrNDTUrQAAAABWVcUKemFhobZv3664uDhXXUBAgOLi4rR58+YS+1xzzTXavn27KyD/7rvvtHbtWt1www0efT72QQcAAECNcu49kXa7XXa73a3u6NGjcjgcioiIcKuPiIjQnj17SjzuqFGjdPToUV177bUyxujXX3/VPffcU/kpLidOnNCuXbu0a9cuSVJGRoZ27dqlQ4cOeXooAAAAwGNOY7NcJCkqKsrtHsnk5OQKmVd6erpmzpyp559/Xjt27NCbb76pNWvW6PHHH/foOB6voH/66afq27ev63ViYqIkaezYsVq8eLGnhwMAAAA84lCAHBYytYv6HD582C3t+tzVc0lq1KiRAgMDlZWV5VaflZWlJk2alHj8Rx55RL/97W911113SZKuuOIK5efn63e/+50eeughBQSUb84eB+h9+vSRMcbTbgAAAECFOHs13NN+ksp1X2RwcLC6du2qtLQ0DRs27Ex/p1NpaWmaPHlyiX1OnjxZLAgPDAyUJI/iZ3LQAQAA4FecCpDTwgq6p30SExM1duxYdevWTT169NDs2bOVn5+v8ePHS5LGjBmjZs2auVJkBg8erFmzZunKK69UTEyM9u/fr0ceeUSDBw92BerlQYAOAAAAv+IwNjksrKB72mf48OH66aef9OijjyozM1NdunRRamqq68bRQ4cOua2YP/zww7LZbHr44Yf1ww8/qHHjxho8eLCeeOIJj8YlQAcAAABKMXny5FJTWtLT091eBwUFKSkpSUlJSRc0JgE6AAAA/MqF5qD7OgJ0AAAA+BVjAuT04KFDZ/fzBwToAAAA8CsO2eSQhRx0C328gQAdAAAAfsVprKWrOP1kp3ACdAAAAPgVp8UUFyt9vME/ZgkAAADUEKygAwAAwK84ZZPTQj65lT7eQIAOAAAAv1JVDyryFgJ0AAAA+JXqnoNOgF6F1v24y2tjd50+yWtjb5+e4rWxvSk+sovXxt7+I+e8yq313tAAUNM4ZfFBRaS4AAAAABXPWMxBN34SoPvHOj8AAABQQ7CCDgAAAL/iNBZTXLhJFAAAAKh43CQKAAAA+BBW0AEAAAAfwoOKAAAAAB9S3VfQ/SMRBwAAAKghWEEHAACAX6nuK+gE6AAAAPArBOgAAACADyFABwAAAHyIkbUdWUzFT6VScJMoAAAA4ENYQQcAAIBfqe4pLh6toCcnJ6t79+6qX7++wsPDNWzYMO3du7ey5gYAAAAUUxSgWyn+wKMA/f3331dCQoK2bNmi9evX6/Tp0+rfv7/y8/Mra34AAACAm+oeoHuU4pKamur2evHixQoPD9f27dv1m9/8pkInBgAAAJSkuqe4XFAOek5OjiTpoosuqpDJAAAAAOdjjE3GQrBtpY83WA7QnU6npkyZop49e6pjx46ltisoKFBBQYHrdW5urtUhAQAAgGrP8jaLCQkJ2r17t5YtW1Zmu+TkZIWFhblKVFSU1SEBAAAAOWWzXPyBpQB98uTJWr16tTZu3KjmzZuX2XbatGnKyclxlcOHD1uaKAAAACBxk6gbY4z+8Ic/aOXKlUpPT1fLli3P28dut8tut1ueIAAAAHA2ctDPkpCQoCVLluitt95S/fr1lZmZKUkKCwtT7dq1K2WCAAAAwNmq+y4uHqW4pKSkKCcnR3369FHTpk1dZfny5ZU1PwAAAMBN0Qq6leIPPE5xAQAAAFB5LmgfdAAAAKCqGYspLtVyBR0AAADwNiPJSmKHv+SCEKADAADArzhlk83Cnub+sg86AToAAAD8CtssAgAAAD7EaWyysc0iAAAAgKrACjoAAAD8ijEWbxL1k7tECdABAADgV8hBBwAAAHwIAToAAADgQ6r7TaIE6AAAAPAr1T0HnV1cAAAAAB/CCjoAAAD8ypkVdCs56JUwmUpAgA4AAAC/wk2iAAAAgA8x/y1W+vkDAnQAAAD4leq+gs5NogAAAPAv5gKKh+bOnavo6GiFhIQoJiZGW7duLbP98ePHlZCQoKZNm8put+uyyy7T2rVrPRqTFXQAAACgBMuXL1diYqLmzZunmJgYzZ49W/Hx8dq7d6/Cw8OLtS8sLFS/fv0UHh6uFStWqFmzZjp48KAaNGjg0bgE6AAAAPAvFlNc5GGfWbNmaeLEiRo/frwkad68eVqzZo0WLlyoBx98sFj7hQsX6j//+Y8+/vhj1apVS5IUHR3t8TRJcQEAAIBfKXpQkZUiSbm5uW6loKCg2BiFhYXavn274uLiXHUBAQGKi4vT5s2bS5zX22+/rdjYWCUkJCgiIkIdO3bUzJkz5XA4PPp8BOgAAADwK0U3iVopkhQVFaWwsDBXSU5OLjbG0aNH5XA4FBER4VYfERGhzMzMEuf13XffacWKFXI4HFq7dq0eeeQR/e1vf9Nf/vIXjz4fKS4AAADwL8bmcbqKq5+kw4cPKzQ01FVtt9srZFpOp1Ph4eF68cUXFRgYqK5du+qHH37Q008/raSkpHIfhwAdAAAAfuXsdBVP+0lSaGioW4BekkaNGikwMFBZWVlu9VlZWWrSpEmJfZo2bapatWopMDDQVXf55ZcrMzNThYWFCg4OLtc8SXEBAAAAzhEcHKyuXbsqLS3NVed0OpWWlqbY2NgS+/Ts2VP79++X0+l01X3zzTdq2rRpuYNziQAdAAAA/qaK9kFPTEzU/Pnz9fLLL+vrr7/WpEmTlJ+f79rVZcyYMZo2bZqr/aRJk/Sf//xH9913n7755hutWbNGM2fOVEJCgkfjkuICAAAAv1JVTxIdPny4fvrpJz366KPKzMxUly5dlJqa6rpx9NChQwoI+N96d1RUlNatW6f7779fnTp1UrNmzXTfffdp6tSpHo1LgA4AAAD/YyEH3YrJkydr8uTJJb6Xnp5erC42NlZbtmy5oDEJ0AEAAOBXqmoF3Vs8ykFPSUlRp06dXHe+xsbG6t13362suQEAAADFVVEOurd4FKA3b95cTz75pLZv365PP/1U1113nYYOHaovv/yysuYHAAAA1CgepbgMHjzY7fUTTzyhlJQUbdmyRR06dKjQiQEAAAAls/23WOnn+yznoDscDr3++uvKz88vdS9ISSooKFBBQYHrdW5urtUhAQAAAOvpKtUxxUWSvvjiC9WrV092u1333HOPVq5cqfbt25faPjk5WWFhYa4SFRV1QRMGAABADUcOuru2bdtq165d+uSTTzRp0iSNHTtWX331Vantp02bppycHFc5fPjwBU0YAAAANZyxWS9+wOMUl+DgYF166aWSpK5du2rbtm36xz/+oRdeeKHE9na7XXa7/cJmCQAAAPyXMWeKlX7+wOMV9HM5nU63HHMAAAAA1nm0gj5t2jQNHDhQl1xyifLy8rRkyRKlp6dr3bp1lTU/AAAAwF01v0nUowA9OztbY8aM0ZEjRxQWFqZOnTpp3bp16tevX2XNDwAAAHBnNZ+8OuagL1iwoLLmAQAAAJSLzZwpVvr5A8v7oAMAAABeQYoLAAAA4EOqeYrLBe/iAgAAAKDisIIOAAAA/0KKCwAAAOBDCNABAAAAH0KADgAAAPiQan6TKAE6AAAA/Ep13wedXVwAAAAAH8IKOgAAAPxLNc9BZwUdAAAA8CGsoAMAAMCv2GQxB73CZ1I5vBagN3wkUEGBgVU+bvyXXap8zCIzM7Z6bewXp/3Da2O3Trvba2O/du0LXht7/ytXem3s7QXeu9a8yZvfsSmJMV4bW5JmZizx2th/btnDa2MDqKHYxQUAAADwIeSgAwAAAKgqrKADAADAv1TzFXQCdAAAAPiV6v6gIgJ0AAAA+BdW0AEAAAAfQoAOAAAA+I7qnuLCLi4AAACAD2EFHQAAAP6FBxUBAAAAPoQcdAAAAMB3VPccdAJ0AAAA+JdqvoLOTaIAAACAD2EFHQAAAP7FYopLjVhBf/LJJ2Wz2TRlypQKmg4AAABwHuYCih+wvIK+bds2vfDCC+rUqVNFzgcAAAAoGznoxZ04cUKjR4/W/Pnz1bBhw4qeEwAAAFCqol1crBR/YClAT0hI0KBBgxQXF1fR8wEAAABqNI9TXJYtW6YdO3Zo27Zt5WpfUFCggoIC1+vc3FxPhwQAAABqDI9W0A8fPqz77rtP//rXvxQSElKuPsnJyQoLC3OVqKgoSxMFAAAAJFX7m0Q9CtC3b9+u7OxsXXXVVQoKClJQUJDef/99PfvsswoKCpLD4SjWZ9q0acrJyXGVw4cPV9jkAQAAUPNU9xx0j1Jcrr/+en3xxRdudePHj1e7du00depUBQYGFutjt9tlt9svbJYAAADA2fwk2LbCowC9fv366tixo1td3bp1dfHFFxerBwAAACpFNd9mkSeJAgAAwK9YTVeplikuJUlPT6+AaQAAAACQWEEHAACAv6nmKS6WHlQEAAAAeEtV7uIyd+5cRUdHKyQkRDExMdq6dWu5+i1btkw2m03Dhg3zeEwCdAAAAPiXKtoHffny5UpMTFRSUpJ27Nihzp07Kz4+XtnZ2WX2O3DggP74xz+qV69eng34XwToAAAA8C9VFKDPmjVLEydO1Pjx49W+fXvNmzdPderU0cKFC0vt43A4NHr0aM2YMUOtWrXy+KNJBOgAAADwMxea4pKbm+tWCgoKio1RWFio7du3Ky4uzlUXEBCguLg4bd68udS5PfbYYwoPD9eECRMsfz4CdAAAANQoUVFRCgsLc5Xk5ORibY4ePSqHw6GIiAi3+oiICGVmZpZ43E2bNmnBggWaP3/+Bc2PXVwAAADgXy5wF5fDhw8rNDTUVV0RT73Py8vTb3/7W82fP1+NGjW6oGMRoAMAAMC/XGCAHhoa6hagl6RRo0YKDAxUVlaWW31WVpaaNGlSrP23336rAwcOaPDgwa46p9MpSQoKCtLevXvVunXrck2TFBcAAAD4larYZjE4OFhdu3ZVWlqaq87pdCotLU2xsbHF2rdr105ffPGFdu3a5SpDhgxR3759tWvXLkVFRZV7bFbQAQAA4F+q6EFFiYmJGjt2rLp166YePXpo9uzZys/P1/jx4yVJY8aMUbNmzZScnKyQkBB17NjRrX+DBg0kqVj9+RCgAwAAwK9YfeiQp32GDx+un376SY8++qgyMzPVpUsXpaamum4cPXTokAICKj4hhQAdAAAAKMXkyZM1efLkEt9LT08vs+/ixYstjem1AH3FW28qtH7Vp8BfvevWKh+zyJ9bem1o5ay91Gtjf3v9Iq+N3XX6fV4b+9vpKV4b+7oxk7w2tjedTMzx2thb5r7gtbHPCPby+ABQhaooxcVbWEEHAACAfyFABwAAAHyH7b/FSj9/QIAOAAAA/8IKOgAAAOA7qmoXF2/hQUUAAACAD2EFHQAAAP6FFBcAAADAx/hJsG0FAToAAAD8SnXPQSdABwAAgH8hxQUAAADwHdV9BZ1dXAAAAAAfwgo6AAAA/AspLgAAAIDvqO4pLgToAAAA8C+soAMAAAA+pJoH6B7dJDp9+nTZbDa30q5du8qaGwAAAFBMUYqLleIPPF5B79ChgzZs2PC/AwSxCA8AAABUFI+j66CgIDVp0qQy5gIAAACcHyku7vbt26fIyEi1atVKo0eP1qFDh8psX1BQoNzcXLcCAAAAWGUzxnLxBx4F6DExMVq8eLFSU1OVkpKijIwM9erVS3l5eaX2SU5OVlhYmKtERUVd8KQBAABQg5kLKH7AowB94MCBuu2229SpUyfFx8dr7dq1On78uF577bVS+0ybNk05OTmucvjw4QueNAAAAGoubhItQ4MGDXTZZZdp//79pbax2+2y2+0XMgwAAADwP+Sgl+7EiRP69ttv1bRp04qaDwAAAFCjeRSg//GPf9T777+vAwcO6OOPP9ZNN92kwMBAjRw5srLmBwAAALghxeUs33//vUaOHKljx46pcePGuvbaa7VlyxY1bty4suYHAAAAuKvmKS4eBejLli2rrHkAAAAA5WJ1NbxarqADAAAAXscKOgAAAOBb/GU13IoL2sUFAAAAQMViBR0AAAD+xZgzxUo/P0CADgAAAL/CTaIAAACAL+EmUQAAAMB32JxnipV+/oAAHQAAAP6lmq+gs4sLAAAA4ENYQQcAAIBf4SZRAAAAwJewzSIAAADgO1hBryS9dt6swDr2Kh83cNVFVT6ma+w23rt12LGisdfGvurX4V4b++K9p7w29lWfeu9zB14S7LWxvanBU/W9NvZVD3jv5+1tjbXX21MAUNNU85tEWUEHAACAX6nuK+js4gIAAAD4EFbQAQAA4F+4SRQAAADwHdU9xYUAHQAAAP6Fm0QBAAAA38EKOgAAAOBLnOZMsdLPD7CLCwAAAOBDWEEHAACAfyEHHQAAAPAdNlnMQa/wmVQOUlwAAADgX4r2QbdSPDR37lxFR0crJCREMTEx2rp1a6lt58+fr169eqlhw4Zq2LCh4uLiymxfGgJ0AAAA+JWiXVysFE8sX75ciYmJSkpK0o4dO9S5c2fFx8crOzu7xPbp6ekaOXKkNm7cqM2bNysqKkr9+/fXDz/84NG4BOgAAABACWbNmqWJEydq/Pjxat++vebNm6c6depo4cKFJbb/17/+pd///vfq0qWL2rVrp5deeklOp1NpaWkejUuADgAAAP9iLqCUU2FhobZv3664uDhXXUBAgOLi4rR58+ZyHePkyZM6ffq0LrroovIPLAsB+g8//KA77rhDF198sWrXrq0rrrhCn376qaeHAQAAACyxGWO5SFJubq5bKSgoKDbG0aNH5XA4FBER4VYfERGhzMzMcs1z6tSpioyMdAvyy8OjAP3nn39Wz549VatWLb377rv66quv9Le//U0NGzb0aFAAAADAMucFFElRUVEKCwtzleTk5Aqf4pNPPqlly5Zp5cqVCgkJ8aivR9ssPvXUU4qKitKiRYtcdS1btvRoQAAAAOBCnL0a7mk/STp8+LBCQ0Nd9Xa7vVjbRo0aKTAwUFlZWW71WVlZatKkSZnjPPPMM3ryySe1YcMGderUyeN5erSC/vbbb6tbt2667bbbFB4eriuvvFLz58/3eFAAAADAsgvMQQ8NDXUrJQXowcHB6tq1q9sNnkU3fMbGxpY6tb/+9a96/PHHlZqaqm7duln6eB4F6N99951SUlLUpk0brVu3TpMmTdK9996rl19+udQ+BQUFxfJ8AAAAAF+XmJio+fPn6+WXX9bXX3+tSZMmKT8/X+PHj5ckjRkzRtOmTXO1f+qpp/TII49o4cKFio6OVmZmpjIzM3XixAmPxvUoxcXpdKpbt26aOXOmJOnKK6/U7t27NW/ePI0dO7bEPsnJyZoxY4ZHkwIAAABKZfGhQ572GT58uH766Sc9+uijyszMVJcuXZSamuq6cfTQoUMKCPjfendKSooKCwt16623uh0nKSlJ06dPL/e4HgXoTZs2Vfv27d3qLr/8cr3xxhul9pk2bZoSExNdr3NzcxUVFeXJsAAAAICLlYcOFfXz1OTJkzV58uQS30tPT3d7feDAAc8HKIFHAXrPnj21d+9et7pvvvlGLVq0KLWP3W4vMa8HAAAAsKSKVtC9xaMA/f7779c111yjmTNn6vbbb9fWrVv14osv6sUXX6ys+QEAAABubM4zxUo/f+DRTaLdu3fXypUrtXTpUnXs2FGPP/64Zs+erdGjR1fW/AAAAAB3RSvoVoof8GgFXZJuvPFG3XjjjZUxFwAAAKDG8zhABwAAALzqrD3NPe7nBwjQAQAA4Fcu9Emivo4AHQAAAP6FXVwAAAAAH2IkWdmRxT/icwJ0AAAA+JfqnuLi0TaLAAAAACoXK+gAAADwL0YWc9ArfCaVggAdAAAA/oWbRAEAAAAf4pRks9jPDxCgAwAAwK9U95tECdABAADgX6p5igu7uAAAAAA+xGsr6I2G71OQrZa3hvcKhxfHvmjfd94bfKH3hvamxu97ewaoSvy8AaAKVfMVdFJcAAAA4F8I0AEAAAAfwi4uAAAAgO9gFxcAAADAl1TzFBd2cQEAAAB8CCvoAAAA8C9OI9ksrIY7/WMFnQAdAAAA/qWap7gQoAMAAMDPWAzQRYAOAAAAVDxW0AEAAAAf4jSytBruJzno7OICAAAA+BBW0AEAAOBfjPNMsdLPDxCgAwAAwL+Qgw4AAAD4kGqeg06ADgAAAP9SzVfQPbpJNDo6WjabrVhJSEiorPkBAAAA7oz+F6R7VLw98fLxaAV927Ztcjgcrte7d+9Wv379dNttt1X4xAAAAICayKMAvXHjxm6vn3zySbVu3Vq9e/eu0EkBAAAAparmKS6Wc9ALCwv16quvKjExUTabrdR2BQUFKigocL3Ozc21OiQAAAAgOZ2SLGyZ6PSPbRYtP6ho1apVOn78uMaNG1dmu+TkZIWFhblKVFSU1SEBAAAAi/nnFlfdvcBygL5gwQINHDhQkZGRZbabNm2acnJyXOXw4cNWhwQAAACqfYBuKcXl4MGD2rBhg958883ztrXb7bLb7VaGAQAAAIqr5vugW1pBX7RokcLDwzVo0KCKng8AAABQo3m8gu50OrVo0SKNHTtWQUE85wgAAABVyxinjPH8hk8rfbzB4wh7w4YNOnTokO68887KmA8AAABQNmOspatU1xz0/v37y/jJhwMAAEA1ZCzmoPtJDEuOCgAAAPyL0ynZLKSrVNcUFwAAAMCrqvkKuuV90AEAAABUPFbQAQAA4FeM0yljIcWl2u7iAgAAAHhVNU9xIUAHAACAf3EayUaADgAAAPgGYyRZ2cWFAB0AAACocMZpZCysoPvLs3zYxQUAAAAoxdy5cxUdHa2QkBDFxMRo69atZbZ//fXX1a5dO4WEhOiKK67Q2rVrPR6TAB0AAAD+xTitFw8sX75ciYmJSkpK0o4dO9S5c2fFx8crOzu7xPYff/yxRo4cqQkTJmjnzp0aNmyYhg0bpt27d3s0rs1U8Vp/bm6uwsLC1EdDFWSrVZVDAwAAoBx+NaeVrreUk5Oj0NBQb0/HxRVH2m6yFEf+ak4r3aws9+eKiYlR9+7dNWfOHEmS0+lUVFSU/vCHP+jBBx8s1n748OHKz8/X6tWrXXVXX321unTponnz5pV7nlWeg17098CvOm1pdxwAAABUrl91WpLv5mz/ago8Xg2X/ve5cnNz3ertdrvsdrtbXWFhobZv365p06a56gICAhQXF6fNmzeXePzNmzcrMTHRrS4+Pl6rVq3yaJ5VHqDn5eVJkjbJ83wcAAAAVJ28vDyFhYV5exouwcHBatKkiTZlWo8j69Wrp6ioKLe6pKQkTZ8+3a3u6NGjcjgcioiIcKuPiIjQnj17Sjx2ZmZmie0zMzM9mmOVB+iRkZE6fPiw6tevL5vN5lHf3NxcRUVF6fDhwz713y2+jvPmOc6ZNZw3z3HOrOG8eY5zZk1NPW/GGOXl5SkyMtLbU3ETEhKijIwMFRYWWj6GMaZYDHru6rm3VXmAHhAQoObNm1/QMUJDQ2vUl6SicN48xzmzhvPmOc6ZNZw3z3HOrKmJ582XVs7PFhISopCQkEofp1GjRgoMDFRWVpZbfVZWlpo0aVJinyZNmnjUvjTs4gIAAACcIzg4WF27dlVaWpqrzul0Ki0tTbGxsSX2iY2NdWsvSevXry+1fWl4UBEAAABQgsTERI0dO1bdunVTjx49NHv2bOXn52v8+PGSpDFjxqhZs2ZKTk6WJN13333q3bu3/va3v2nQoEFatmyZPv30U7344osejetXAbrdbldSUpLP5Qn5Os6b5zhn1nDePMc5s4bz5jnOmTWct5pt+PDh+umnn/Too48qMzNTXbp0UWpqqutG0EOHDikg4H8JKddcc42WLFmihx9+WH/+85/Vpk0brVq1Sh07dvRo3CrfBx0AAABA6chBBwAAAHwIAToAAADgQwjQAQAAAB9CgA4AAAD4EJ8L0OfOnavo6GiFhIQoJiZGW7duLbP966+/rnbt2ikkJERXXHGF1q61/uhXf5ScnKzu3burfv36Cg8P17Bhw7R3794y+yxevFg2m82tVMWG/75i+vTpxT5/u3btyuxT068zSYqOji523mw2mxISEkpsXxOvsw8++ECDBw9WZGSkbDabVq1a5fa+MUaPPvqomjZtqtq1aysuLk779u0773E9/b3ob8o6b6dPn9bUqVN1xRVXqG7duoqMjNSYMWP0448/lnlMK99zf3K+a23cuHHFPv+AAQPOe9yafK1JKvF3nM1m09NPP13qMav7tQbv8KkAffny5UpMTFRSUpJ27Nihzp07Kz4+XtnZ2SW2//jjjzVy5EhNmDBBO3fu1LBhwzRs2DDt3r27imfuPe+//74SEhK0ZcsWrV+/XqdPn1b//v2Vn59fZr/Q0FAdOXLEVQ4ePFhFM/YNHTp0cPv8mzZtKrUt19kZ27Ztcztn69evlyTddtttpfapaddZfn6+OnfurLlz55b4/l//+lc9++yzmjdvnj755BPVrVtX8fHxOnXqVKnH9PT3oj8q67ydPHlSO3bs0COPPKIdO3bozTff1N69ezVkyJDzHteT77m/Od+1JkkDBgxw+/xLly4t85g1/VqT5Ha+jhw5ooULF8pms+mWW24p87jV+VqDlxgf0qNHD5OQkOB67XA4TGRkpElOTi6x/e23324GDRrkVhcTE2PuvvvuSp2nL8vOzjaSzPvvv19qm0WLFpmwsLCqm5SPSUpKMp07dy53e66zkt13332mdevWxul0lvh+Tb/OJJmVK1e6XjudTtOkSRPz9NNPu+qOHz9u7Ha7Wbp0aanH8fT3or8797yVZOvWrUaSOXjwYKltPP2e+7OSztnYsWPN0KFDPToO11pxQ4cONdddd12ZbWrStYaq4zMr6IWFhdq+fbvi4uJcdQEBAYqLi9PmzZtL7LN582a39pIUHx9favuaICcnR5J00UUXldnuxIkTatGihaKiojR06FB9+eWXVTE9n7Fv3z5FRkaqVatWGj16tA4dOlRqW66z4goLC/Xqq6/qzjvvlM1mK7VdTb/OzpaRkaHMzEy3ayksLEwxMTGlXktWfi/WBDk5ObLZbGrQoEGZ7Tz5nldH6enpCg8PV9u2bTVp0iQdO3as1LZca8VlZWVpzZo1mjBhwnnb1vRrDRXPZwL0o0ePyuFwuJ7MVCQiIkKZmZkl9snMzPSofXXndDo1ZcoU9ezZs8wnVrVt21YLFy7UW2+9pVdffVVOp1PXXHONvv/++yqcrffExMRo8eLFSk1NVUpKijIyMtSrVy/l5eWV2J7rrLhVq1bp+PHjGjduXKltavp1dq6i68WTa8nK78Xq7tSpU5o6dapGjhyp0NDQUtt5+j2vbgYMGKB//vOfSktL01NPPaX3339fAwcOlMPhKLE911pxL7/8surXr6+bb765zHY1/VpD5Qjy9gRQcRISErR79+7z5r7FxsYqNjbW9fqaa67R5ZdfrhdeeEGPP/54ZU/T6wYOHOj6d6dOnRQTE6MWLVrotddeK9dKCaQFCxZo4MCBioyMLLVNTb/OUPFOnz6t22+/XcYYpaSklNm2pn/PR4wY4fr3FVdcoU6dOql169ZKT0/X9ddf78WZ+Y+FCxdq9OjR5725vaZfa6gcPrOC3qhRIwUGBiorK8utPisrS02aNCmxT5MmTTxqX51NnjxZq1ev1saNG9W8eXOP+taqVUtXXnml9u/fX0mz820NGjTQZZddVurn5zpzd/DgQW3YsEF33XWXR/1q+nVWdL14ci1Z+b1YXRUF5wcPHtT69evLXD0vyfm+59Vdq1at1KhRo1I/P9eauw8//FB79+71+PecxLWGiuEzAXpwcLC6du2qtLQ0V53T6VRaWprbKtzZYmNj3dpL0vr160ttXx0ZYzR58mStXLlS//73v9WyZUuPj+FwOPTFF1+oadOmlTBD33fixAl9++23pX5+rjN3ixYtUnh4uAYNGuRRv5p+nbVs2VJNmjRxu5Zyc3P1ySeflHotWfm9WB0VBef79u3Thg0bdPHFF3t8jPN9z6u777//XseOHSv183OtuVuwYIG6du2qzp07e9y3pl9rqCDevkv1bMuWLTN2u90sXrzYfPXVV+Z3v/udadCggcnMzDTGGPPb3/7WPPjgg672H330kQkKCjLPPPOM+frrr01SUpKpVauW+eKLL7z1EarcpEmTTFhYmElPTzdHjhxxlZMnT7ranHveZsyYYdatW2e+/fZbs337djNixAgTEhJivvzyS298hCr3wAMPmPT0dJORkWE++ugjExcXZxo1amSys7ONMVxnZXE4HOaSSy4xU6dOLfYe15kxeXl5ZufOnWbnzp1Gkpk1a5bZuXOna7eRJ5980jRo0MC89dZb5vPPPzdDhw41LVu2NL/88ovrGNddd5157rnnXK/P93uxOijrvBUWFpohQ4aY5s2bm127drn9nisoKHAd49zzdr7vub8r65zl5eWZP/7xj2bz5s0mIyPDbNiwwVx11VWmTZs25tSpU65jcK0V/44aY0xOTo6pU6eOSUlJKfEYNe1ag3f4VIBujDHPPfecueSSS0xwcLDp0aOH2bJli+u93r17m7Fjx7q1f+2118xll11mgoODTYcOHcyaNWuqeMbeJanEsmjRIlebc8/blClTXOc4IiLC3HDDDWbHjh1VP3kvGT58uGnatKkJDg42zZo1M8OHDzf79+93vc91Vrp169YZSWbv3r3F3uM6M2bjxo0lfh+LzovT6TSPPPKIiYiIMHa73Vx//fXFzmWLFi1MUlKSW11Zvxerg7LOW0ZGRqm/5zZu3Og6xrnn7Xzfc39X1jk7efKk6d+/v2ncuLGpVauWadGihZk4cWKxQJtrrfh31BhjXnjhBVO7dm1z/PjxEo9R0641eIfNGGMqdYkeAAAAQLn5TA46AAAAAAJ0AAAAwKcQoAMAAAA+hAAdAAAA8CEE6AAAAIAPIUAHAAAAfAgBOgAAAOBDCNABAAAAH0KADgAAAPgQAnQAAADAhxCgAwAAAD6EAB0AAADwIf8PbRQo4ylsmoEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of M for song 2: (8, 20)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of M for song 3: (8, 20)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAF2CAYAAADjkBchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBdElEQVR4nO3deXxU1f3/8feEkAlbEpaEEAmrKJuAZSsgghKWgCwuCIgVkKKl5OuC9oe0lkVaA9VSFzAoZXFjqQugqEFAUFEQZFFBpGADBDFEUBIIkMDM+f2BmTBkIXOzTG7yej4e5/Fw7pxzz7mXO/GTk8854zDGGAEAAACwnQB/DwAAAACANQTzAAAAgE0RzAMAAAA2RTAPAAAA2BTBPAAAAGBTBPMAAACATRHMAwAAADZFMA8AAADYFME8AAAAYFME80AFMW3aNDkcDr/03bNnT/Xs2dMvfRc0joMHD8rhcGjx4sWlOg5/9Zvt1VdfVfPmzVW5cmWFhYX5ZQwAgOJBMA8Us8WLF8vhcMjhcGjTpk253jfGKDo6Wg6HQ7fccoulPp588kmtXLmyiCO1JjU1VYGBgbr77rvzrXPq1ClVqVJFt912WymOrOxZsmSJnnnmGX8Pw8t3332n0aNHq2nTppo/f75eeumlEu9z06ZNio2N1VVXXaXg4GA1aNBAAwcO1JIlS0q87+LUu3dvORwOxcXF+XsoAOAR6O8BAOVVcHCwlixZohtuuMHr+Mcff6wjR47I6XRaPveTTz6pO+64Q0OGDCl0m8cff1yPPfaY5T6zRUREqHfv3lq1apXOnDmjqlWr5qrz9ttv69y5c56A/8MPPyxyvyWhYcOGOnv2rCpXrlwi51+yZIl2796thx56qFT7LcjGjRvldrv17LPP6uqrry7x/t544w0NGzZM7dq104MPPqiaNWsqKSlJn3zyiebPn6+77rqrxMdQHN5++21t3rzZ38MAgFwI5oES0r9/f73xxht67rnnFBiY81FbsmSJ2rdvr+PHj5fKODIyMlStWjUFBgZ6jaMoRo4cqcTERL3zzjsaPnx4rveXLFmi0NBQDRgwQJIUFBRULP0WN4fDoeDg4ArTr3TxLyuSijW9Jr9f6qSL6V0tW7bUli1bcj0H2WMp686dO6dHHnlEkyZN0pQpU/w9HADwQpoNUEJGjBihEydOaO3atZ5jWVlZevPNN/OdjXz66afVtWtX1a5dW1WqVFH79u315ptvetVxOBzKyMjQyy+/7EnnGT16tKScvPhvv/1Wd911l2rWrOn5y8DlOfOLFi2Sw+HQwoULvc7/5JNPyuFw6P3338/32m699VZVq1YtzzSJ1NRUrV+/XnfccYfnrw955cw///zzatWqlapWraqaNWuqQ4cOXucbPXq0GjVqlOv8eeX+L1q0SDfffLMiIiLkdDrVsmVLJSQk5Dv+bJfnrm/cuNFzTy8vl45l1apVGjBggKKiouR0OtW0aVPNmDFDLpfLU6dnz5567733dOjQoVznyC9n/qOPPlL37t1VrVo1hYWFafDgwdq7d2+e13/gwAGNHj1aYWFhCg0N1ZgxY3TmzJkCr7dRo0aaOnWqJCk8PFwOh0PTpk3zvP/CCy+oVatWcjqdioqK0oQJE3Ty5Emvc/Ts2VOtW7fW9u3bdeONN6pq1ar685//nG+f33//vTp27JjnL3QRERFerzMyMvTII48oOjpaTqdT1157rZ5++mkZY7zqZae6rFy5Uq1bt5bT6VSrVq2UmJiYq4+NGzeqQ4cOCg4OVtOmTfXiiy/6vH7kH//4h9xutx599NFCtwGA0sLMPFBCGjVqpC5dumjp0qWKjY2VJH3wwQdKS0vT8OHD9dxzz+Vq8+yzz2rQoEEaOXKksrKytGzZMg0dOlSrV6/2zHK/+uqr+v3vf69OnTrpvvvukyQ1bdrU6zxDhw5Vs2bN9OSTT+YKhLKNGTNGb7/9tiZOnKjevXsrOjpa33zzjaZPn66xY8eqf//++V5btWrVNHjwYL355pv6+eefVatWLc97y5cvl8vl0siRI/NtP3/+fD3wwAO644479OCDD+rcuXP6+uuv9cUXX1hKu0hISFCrVq00aNAgBQYG6t1339Uf//hHud1uTZgwodDnadGihV599VWvYydPntTEiRO9As/FixerevXqmjhxoqpXr66PPvpIU6ZMUXp6up566ilJ0l/+8helpaXpyJEj+te//iVJql69er59r1u3TrGxsWrSpImmTZums2fP6vnnn1e3bt20Y8eOXL/Y3HnnnWrcuLHi4+O1Y8cO/fvf/1ZERIRmzZqVbx/PPPOMXnnlFa1YsUIJCQmqXr262rRpI+niLwnTp09XTEyMxo8fr3379ikhIUHbtm3TZ5995pUSdOLECcXGxmr48OG6++67Vbdu3Xz7bNiwodavX68jR46ofv36+dYzxmjQoEHasGGDxo4dq3bt2mnNmjX605/+pB9++MFzD7Nt2rRJb7/9tv74xz+qRo0aeu6553T77bfr8OHDql27tiRp586d6tevn+rVq6fp06fL5XLpiSeeUHh4eL7juNzhw4c1c+ZMLVy4UFWqVCl0OwAoNQZAsVq0aJGRZLZt22bmzJljatSoYc6cOWOMMWbo0KHmpptuMsYY07BhQzNgwACvttn1smVlZZnWrVubm2++2et4tWrVzKhRo3L1PXXqVCPJjBgxIt/3LvXjjz+aWrVqmd69e5vMzExz/fXXmwYNGpi0tLQrXud7771nJJkXX3zR6/hvf/tbc9VVVxmXy+U51qNHD9OjRw/P68GDB5tWrVoVeP5Ro0aZhg0bFuo6Lr9vxhjTt29f06RJE69jl48jKSnJSDKLFi3Kcwxut9vccsstpnr16mbPnj0F9nf//febqlWrmnPnznmODRgwIM9ryKvfdu3amYiICHPixAnPsa+++soEBASYe+65x3Ms+/rvvfder3Peeuutpnbt2nlex6Wy2//000+eY6mpqSYoKMj06dPH699tzpw5RpJZuHCh51iPHj2MJDNv3rwr9mWMMQsWLDCSTFBQkLnpppvMX//6V/Ppp5969WOMMStXrjSSzN/+9jev43fccYdxOBzmwIEDnmPZ57v02FdffWUkmeeff95zbODAgaZq1armhx9+8Bzbv3+/CQwMzPUM5eeOO+4wXbt29ep7woQJhWoLAKWBNBugBN155506e/asVq9erVOnTmn16tUFzjxfOvP3yy+/KC0tTd27d9eOHTt86vcPf/hDoepFRkZq7ty5Wrt2rbp3765du3Zp4cKFCgkJuWLbPn36KDw83Cs1JikpSVu2bNGIESMUEJD/j5ewsDAdOXJE27ZtK9Q4r+TS+5aWlqbjx4+rR48e+t///qe0tDTL550xY4ZWr16txYsXq2XLlnn2d+rUKR0/flzdu3fXmTNn9N133/ncz48//qhdu3Zp9OjRXn/laNOmjXr37p1nytPl/8bdu3fXiRMnlJ6e7nP/69atU1ZWlh566CGvf7dx48YpJCRE7733nld9p9OpMWPGFOrc9957rxITE9WzZ09t2rRJM2bMUPfu3dWsWTN9/vnnnnrvv/++KlWqpAceeMCr/SOPPCJjjD744AOv4zExMV5/kWrTpo1CQkL0v//9T5Lkcrm0bt06DRkyRFFRUZ56V199tecvZVeyYcMGvfXWW2VuRyIAuBTBPFCCwsPDFRMToyVLlujtt9+Wy+XSHXfckW/91atX67e//a2Cg4NVq1YthYeHKyEhweeAtHHjxoWuO3z4cA0YMEBbt27VuHHj1KtXr0K1CwwM1LBhw/Tpp5/qhx9+kCRPYF9Qio0kTZo0SdWrV1enTp3UrFkzTZgwQZ999lmhx3y5zz77TDExMZ5c8/DwcE8et9VgPjExUdOnT9fkyZN1++23e723Z88e3XrrrQoNDVVISIjCw8M9O/dY6e/QoUOSpGuvvTbXey1atNDx48eVkZHhdbxBgwZer2vWrCnp4i+BxdV/UFCQmjRp4nk/21VXXeXToua+fftqzZo1OnnypD755BNNmDBBhw4d0i233OJZBHvo0CFFRUWpRo0aXm1btGjhNcZsl1+/dPEeZF9/amqqzp49m+eOPYXZxefChQt64IEH9Lvf/U4dO3Ys3IUCgB8QzAMl7K677tIHH3ygefPmKTY2Nt9dRD799FMNGjRIwcHBeuGFF/T+++9r7dq1uuuuu/LNe8+PL7m9J06c0JdffilJ+vbbb+V2uwvd9u6775bb7dbSpUslSUuXLlXLli3Vrl27Atu1aNFC+/bt07Jly3TDDTforbfe0g033OBZnCkp3wWKly4ylS4usOzVq5eOHz+u2bNn67333tPatWv18MMPS5JP15MtKSlJI0eOVO/evfW3v/3N672TJ0+qR48e+uqrr/TEE0/o3Xff1dq1az256lb6s6JSpUp5Hvf1WbHCau541apV1b17d82ZM0ePP/64fvnll1wz7oVV0tf/yiuvaN++fbr//vt18OBBT5Eu/jXm4MGDV1xwDAClgWAeKGG33nqrAgICtGXLlgJTbN566y0FBwdrzZo1uvfeexUbG6uYmJg86xbnN7lOmDBBp06dUnx8vDZt2uRTSkHnzp3VtGlTLVmyRF999ZX27NlzxVn5bNWqVdOwYcO0aNEiHT58WAMGDNDf//53nTt3TtLFWdbLd1KRcs/Qvvvuu8rMzNQ777yj+++/X/3791dMTIzlgPPs2bO67bbbFBYWpqVLl+ZKF9q4caNOnDihxYsX68EHH9Qtt9yimJgYz8z4pQr779SwYUNJ0r59+3K9991336lOnTqqVq2ahaspnPz6z8rKUlJSkuf94tShQwdJF1OMssdw9OhRnTp1yqtedtqSr2OIiIhQcHCwDhw4kOu9vI5d7vDhwzp//ry6deumxo0be4p0MdBv3Lhxmf3+BAAVC8E8UMKqV6+uhIQETZs2TQMHDsy3XqVKleRwOLxmng8ePJjnN71Wq1Ytz0DXV2+++aaWL1+umTNn6rHHHtPw4cP1+OOP67///W+hzzFy5Ejt3LlTU6dOlcPhKNRuNCdOnPB6HRQUpJYtW8oYo/Pnz0u6uENPWlqavv76a0+9H3/8UStWrPBqmz1De+mMbFpamhYtWlToa7jUH/7wB/33v//VihUr8gzQ8+ovKytLL7zwQq661apVK1TaTb169dSuXTu9/PLLXv+uu3fv1ocffljgzkLFISYmRkFBQXruuee8rmvBggVKS0vz7KRkxfr16/M8nr0OIDu1p3///nK5XJozZ45XvX/9619yOByFznPPVqlSJcXExGjlypU6evSo5/iBAwcK9deA4cOHa8WKFblK9lhXrFihzp07+zQmACgJbE0JlIJRo0Zdsc6AAQM0e/Zs9evXT3fddZdSU1M1d+5cXX311V4BrSS1b99e69at0+zZsxUVFaXGjRv7HFikpqZq/PjxuummmzxfTz9nzhxt2LBBo0eP1qZNmwpcxJrt7rvv1hNPPKFVq1apW7duee4Nf7k+ffooMjJS3bp1U926dbV3717NmTNHAwYM8ORMDx8+XJMmTdKtt96qBx54QGfOnFFCQoKuueYarwXBffr0UVBQkAYOHKj7779fp0+f1vz58xUREeGZ9S2s9957T6+88opuv/12ff311173vXr16hoyZIi6du2qmjVratSoUXrggQfkcDj06quv5pne0b59ey1fvlwTJ05Ux44dVb169Xx/oXvqqacUGxurLl26aOzYsZ6tKUNDQ732gi8J4eHhmjx5sqZPn65+/fpp0KBB2rdvn1544QV17NjRsx7AisGDB6tx48YaOHCgmjZtqoyMDK1bt07vvvuuOnbs6LkfAwcO1E033aS//OUvOnjwoNq2basPP/xQq1at0kMPPZRr+9XCmDZtmj788EN169ZN48eP9/yy0Lp1a+3atavAts2bN1fz5s3zfK9x48Y+ffsyAJQov+2jA5RTl25NWZC8tqZcsGCBadasmXE6naZ58+Zm0aJFeW7F+N1335kbb7zRVKlSxUjybFOZ17aD2S4/z2233WZq1KhhDh486FVv1apVRpKZNWtWoa+5Y8eORpJ54YUX8nz/8i0hX3zxRXPjjTea2rVrG6fTaZo2bWr+9Kc/5doS88MPPzStW7c2QUFB5tprrzWvvfZanvfjnXfeMW3atDHBwcGmUaNGZtasWWbhwoVGkklKSsp3HJdvEZn9b5dXuXSLyc8++8z89re/NVWqVDFRUVHm//2//2fWrFljJJkNGzZ46p0+fdrcddddJiwszOsc+W2JuW7dOtOtWzdTpUoVExISYgYOHGi+/fZbrzr5/Rtnj/3S681LQc/InDlzTPPmzU3lypVN3bp1zfjx480vv/ziVadHjx5X3Fb0UkuXLjXDhw83TZs2NVWqVDHBwcGmZcuW5i9/+YtJT0/3qnvq1Cnz8MMPm6ioKFO5cmXTrFkz89RTTxm32+1VT/lsD9mwYcNcW7auX7/eXH/99SYoKMg0bdrU/Pvf/zaPPPKICQ4OLvQ1FKZvAPAXhzGlsFoKAIAyYsiQIdqzZ4/279/v76EAQJGRMw8AKLfOnj3r9Xr//v16//331bNnT/8MCACKGTPzAIByq169eho9erRnv/yEhARlZmZq586datasmb+HBwBFxgJYAEC51a9fPy1dulQpKSlyOp3q0qWLnnzySQJ5AOUGM/MAAACATZEzDwAAANgUwTwAAABgU6WeM+92u3X06FHVqFGjWL+SHgAAAMXDGKNTp04pKiqqUF8gWJrOnTunrKwsy+2DgoIUHBxcjCPyr1IP5o8eParo6OjS7hYAAAA+Sk5OVv369f09DI9z586pccPqSkl1WT5HZGSkkpKSyk1AX+rBfPZXtV//2h9UqaqztLtXjelVSr3PbN/fVd1vfTeZtM1vfR95tYXf+g7YGeK3viuf9lvXqr377JUrlZD/3VXJb31X/qmy3/qu+4X1/7EUhyrrvvJb3+bCBb/1DaBkXNB5bdL7nritrMjKylJKqktJ2xsqpIbvfzFIP+VW4/aHlJWVRTBvVXZqTaWqTgVWK/1gPrBS6feZLcCPD02gw39BTqWq/rvuAKf/+q5k/S+ARRYY6L9NqgKq+C+YDwj233MeWNm/wbw/P+OGlEmg/Pn1fyNlNSU6pEaApWC+PGKfeQAAANiKy7jlsjBv5TLu4h+MnxHMAwAAwFbcMnLL92jeSpuyjmAeAAAAtuKWW1bm2K21KtsI5gEAAGArLmPkMr7PsltpU9YRzAMAAMBWSLPJwTJgAAAAwKaYmQcAAICtuGXkYmZeEsE8AAAAbIY0mxwE8wAAALAVFsDmIJgHAACArbh/LVbalTcsgAUAAABsipl5AAAA2IrL4gJYK23KOksz83PnzlWjRo0UHByszp07a+vWrcU9LgAAACBPLmO9lDc+B/PLly/XxIkTNXXqVO3YsUNt27ZV3759lZqaWhLjAwAAALy4i1DKG5+D+dmzZ2vcuHEaM2aMWrZsqXnz5qlq1apauHBhSYwPAAAA8OKWQy4LxS2Hv4de7HwK5rOysrR9+3bFxMTknCAgQDExMdq8eXOxDw4AAAC4nNtYL+WNTwtgjx8/LpfLpbp163odr1u3rr777rs822RmZiozM9PzOj093cIwAQAAAFyuxLemjI+PV2hoqKdER0eXdJcAAAAox6yk2GSX8sanYL5OnTqqVKmSjh075nX82LFjioyMzLPN5MmTlZaW5inJycnWRwsAAIAKj2A+h0/BfFBQkNq3b6/169d7jrndbq1fv15dunTJs43T6VRISIhXAQAAAKxyG4flUt74/KVREydO1KhRo9ShQwd16tRJzzzzjDIyMjRmzJiSGB8AAADgxeose3mcmfc5mB82bJh++uknTZkyRSkpKWrXrp0SExNzLYoFAAAASoJLAXJZWPrpKoGx+JvPwbwkxcXFKS4urrjHAgAAAMAHloJ5AAAAwF+Mxfx3Q848AAAA4F/kzOcgmAcAAICtuEyAXMZCznxF/wZYAAAAwN/ccshtYQGsW+UvmieYBwAAgK2QZpPD919pAAAAAJQJBPMAAACwleyceSvFV3PnzlWjRo0UHByszp07a+vWrYVqt2zZMjkcDg0ZMsTnPn1BMA8AAABbuZgzb634Yvny5Zo4caKmTp2qHTt2qG3bturbt69SU1MLbHfw4EE9+uij6t69e1Eus1AI5gEAAGAr7l+/AdbX4uui2dmzZ2vcuHEaM2aMWrZsqXnz5qlq1apauHBhvm1cLpdGjhyp6dOnq0mTJkW91CsimAcAAICtFDXNJj093atkZmbm6iMrK0vbt29XTEyM51hAQIBiYmK0efPmfMf2xBNPKCIiQmPHji3+C88DwTwAAABsxf3rLLuVIknR0dEKDQ31lPj4+Fx9HD9+XC6XS3Xr1vU6XrduXaWkpOQ5rk2bNmnBggWaP39+8V90PtiaEgAAABVKcnKyQkJCPK+dTmeRz3nq1Cn97ne/0/z581WnTp0in6+w/BbMr239rkJqlP4fBh76d4dS7zPb6fj2fuv7fB//XXftJZX81vfrz/zDb30P3DHOb30fuirMb33rgstvXT899GW/9T351Gi/9S1JH7yw0W99j/79Q37rG0DJuHDhnLR+lb+HkS+XcchlLOwz/2ubkJAQr2A+L3Xq1FGlSpV07Ngxr+PHjh1TZGRkrvrff/+9Dh48qIEDB3qOud1uSVJgYKD27dunpk2b+jzmKyHNBgAAALZiZfFrdimsoKAgtW/fXuvXr/ccc7vdWr9+vbp06ZKrfvPmzfXNN99o165dnjJo0CDddNNN2rVrl6Kjo4vl2i9Hmg0AAABsxW0C5LawZ7zbGJ/qT5w4UaNGjVKHDh3UqVMnPfPMM8rIyNCYMWMkSffcc4+uuuoqxcfHKzg4WK1bt/ZqHxYWJkm5jhcngnkAAADYiq+z7DntfAvmhw0bpp9++klTpkxRSkqK2rVrp8TERM+i2MOHDysgwL+JLgTzAAAAsBW3ZCln3m2hr7i4OMXFxeX53saNGwtsu3jxYgs9+oaceQAAAMCmmJkHAACArVy6Z7yv7cobgnkAAADYyqXf5upru/KGYB4AAAC24pZDblnJmfe9TVlHMA8AAABbYWY+B8E8AAAAbMX61pTlL5gvf1cEAAAAVBDMzAMAAMBW3MYht5V95i20KesI5gEAAGArbotpNmxNCQAAAPiZ2wTIbWExq5U2ZR3BPAAAAGzFJYdcFraZtNKmrPP515NPPvlEAwcOVFRUlBwOh1auXFkCwwIAAADylj0zb6WUNz5fUUZGhtq2bau5c+eWxHgAAAAAFJLPaTaxsbGKjY0tibEAAAAAV+SStZQZV/EPxe9KPGc+MzNTmZmZntfp6ekl3SUAAADKMRbA5ijxK4qPj1doaKinREdHl3SXAAAAKMdcJsByKW9K/IomT56stLQ0T0lOTi7pLgEAAFCOGTnktlBMOdzNpsTTbJxOp5xOZ0l3AwAAgArC6iw7M/MAAAAAygyfZ+ZPnz6tAwcOeF4nJSVp165dqlWrlho0aFCsgwMAAAAu5zYOuY3vKTNW2pR1PgfzX375pW666SbP64kTJ0qSRo0apcWLFxfbwAAAAIC8uBQgl4UEEyttyjqfg/mePXvKGFMSYwEAAACuiJn5HCW+ABYAAAAoTm4FyG1hlt1Km7KOYB4AAAC24jIOuSzMsltpU9aVv19PAAAAgAqCmXkAAADYCjnzOQjmAQAAYCvGBMht4QugTDn80iiCeQAAANiKSw65ZCFn3kKbso5gHgAAALbiNtZSZtzlcHd1gnkAAADYittimo2VNmVd+bsiAAAAoIJgZh4AAAC24pZDbgv571balHUE8wAAALAVvjQqB8E8AAAAbIWc+Rx+C+YnHu2goOpBpd7v0TOhpd5ntmO3Zfqt7wsnS/9eZ2u80uW3vmNe+5Pf+m7yVrrf+s4Mv+C3vlM6VfZb33vPXeW3vq/amOG3viVpXMxwv/UddOKs3/oGUDICXP6LWQrDLYtfGkWaDQAAAOBfxmLOvCmHwXz5+1sDAAAAUEEwMw8AAABbcRuLaTYsgAUAAAD8iwWwOQjmAQAAYCvMzOcgmAcAAICt8KVROQjmAQAAYCvMzOcof4lDAAAAQAXBzDwAAABshZn5HATzAAAAsBWC+RwE8wAAALAVgvkcBPMAAACwFSNrO9OY4h+K37EAFgAAALApZuYBAABgK6TZ5PBpZj4+Pl4dO3ZUjRo1FBERoSFDhmjfvn0lNTYAAAAgl+xg3kopb3wK5j/++GNNmDBBW7Zs0dq1a3X+/Hn16dNHGRkZJTU+AAAAwAvBfA6f0mwSExO9Xi9evFgRERHavn27brzxxmIdGAAAAJAX0mxyFClnPi0tTZJUq1atYhkMAAAAcCXGOGQsBOZW2pR1loN5t9uthx56SN26dVPr1q3zrZeZmanMzEzP6/T0dKtdAgAAALiE5a0pJ0yYoN27d2vZsmUF1ouPj1doaKinREdHW+0SAAAAkFsOy8VXc+fOVaNGjRQcHKzOnTtr69at+dadP3++unfvrpo1a6pmzZqKiYkpsH5xsBTMx8XFafXq1dqwYYPq169fYN3JkycrLS3NU5KTky0NFAAAAJBKbwHs8uXLNXHiRE2dOlU7duxQ27Zt1bdvX6WmpuZZf+PGjRoxYoQ2bNigzZs3Kzo6Wn369NEPP/xQHJedJ5+CeWOM4uLitGLFCn300Udq3LjxFds4nU6FhIR4FQAAAMCq7Jx5K8UXs2fP1rhx4zRmzBi1bNlS8+bNU9WqVbVw4cI867/++uv64x//qHbt2ql58+b697//LbfbrfXr1xfHZefJp5z5CRMmaMmSJVq1apVq1KihlJQUSVJoaKiqVKlSIgMEAAAALlXU3WwuX8PpdDrldDq9jmVlZWn79u2aPHmy51hAQIBiYmK0efPmQvV35swZnT9/vkQ3i/FpZj4hIUFpaWnq2bOn6tWr5ynLly8vqfEBAAAAXoo6Mx8dHe21pjM+Pj5XH8ePH5fL5VLdunW9jtetW9czoX0lkyZNUlRUlGJiYop+0fnwaWbeGFNS4wAAAABKRXJyslfq9+Wz8sVh5syZWrZsmTZu3Kjg4OBiP3+2Iu0zDwAAAJQ2YzHNJntmvjDrOOvUqaNKlSrp2LFjXsePHTumyMjIAts+/fTTmjlzptatW6c2bdr4PE5fWN6aEgAAAPAHI8kYC8WHPoKCgtS+fXuvxavZi1m7dOmSb7t//OMfmjFjhhITE9WhQwfrF1lIzMwDAADAVtxyyGFhz3hf95mfOHGiRo0apQ4dOqhTp0565plnlJGRoTFjxkiS7rnnHl111VWenPtZs2ZpypQpWrJkiRo1auTJra9evbqqV6/u83gLg2AeAAAAtmJlm8nsdr4YNmyYfvrpJ02ZMkUpKSlq166dEhMTPYtiDx8+rICAnESXhIQEZWVl6Y477vA6z9SpUzVt2jSfx1sYBPMAAACwFbdxyFGErSl9ERcXp7i4uDzf27hxo9frgwcP+nz+oiJnHgAAALApZuYBAABgK9kLWq20K28I5gEAAGArpZUzbwcE8wAAALAVgvkcBPMAAACwldJcAFvWEcwDAADAVsiZz8FuNgAAAIBN+W1mPtKZpmBn5VLv9+DpWqXeZ7bQ9VX81ndmLf/9WelIT//9Gny+lstvfZ9uXDLf9FYYIROS/da3Pm7kt67f//NNfuu7UjX/PWuS9MvbDfzWd82amX7rG0DJuHDB3yMo2MWZeSs58yUwGD8jzQYAAAC2wgLYHATzAAAAsBXza7HSrrwhmAcAAICtMDOfg2AeAAAA9sLUvAe72QAAAAA2xcw8AAAA7MVimo1IswEAAAD8iy+NykEwDwAAAFthAWwOgnkAAADYi3FYS5khmAcAAAD8izSbHOxmAwAAANgUM/MAAACwF/aZ9yCYBwAAgK2wADYHwTwAAADspxzOsltBMA8AAABbYWY+h08LYBMSEtSmTRuFhIQoJCREXbp00QcffFBSYwMAAAByM0Uo5YxPwXz9+vU1c+ZMbd++XV9++aVuvvlmDR48WHv27Cmp8QEAAADIh09pNgMHDvR6/fe//10JCQnasmWLWrVqVawDAwAAAPLm+LVYaVe+WM6Zd7lceuONN5SRkaEuXbrkWy8zM1OZmZme1+np6Va7BAAAANia8hI+f2nUN998o+rVq8vpdOoPf/iDVqxYoZYtW+ZbPz4+XqGhoZ4SHR1dpAEDAACggiNn3sPnYP7aa6/Vrl279MUXX2j8+PEaNWqUvv3223zrT548WWlpaZ6SnJxcpAEDAACggjMO66Wc8TnNJigoSFdffbUkqX379tq2bZueffZZvfjii3nWdzqdcjqdRRslAAAA8CtjLhYr7cobn2fmL+d2u71y4gEAAACUDp9m5idPnqzY2Fg1aNBAp06d0pIlS7Rx40atWbOmpMYHAAAAeGMBrIdPwXxqaqruuece/fjjjwoNDVWbNm20Zs0a9e7du6TGBwAAAHizmv9e0XPmFyxYUFLjAAAAAArFYS4WK+3KG8v7zAMAAAB+QZqNB8E8AAAA7IU0G48i72YDAAAAwD+YmQcAAIC9kGbjQTAPAAAAeyGY9yCYBwAAgL0QzHsQzAMAAMBeWADrQTAPAAAAW2Gf+RzsZgMAAADYFDPzAAAAsBdy5j2YmQcAAABsipl5AAAA2IpDFnPmi30k/ue3YH7z8SYKPOss9X4Pf9yg1PvMdtX35/zW989BpX+vs9X/4Be/9e1+9rTf+k76OdpvfQc8U99vfTf5+ge/9Z3eLtJvfR++vZLf+paka6457Le+A3/v32sHUPwuuDP9PYSCsZuNBzPzAAAAsBdy5j3ImQcAAABsipl5AAAA2Asz8x4E8wAAALAVvjQqB8E8AAAA7IWZeQ+CeQAAANgLwbwHC2ABAABgK9lpNlaKr+bOnatGjRopODhYnTt31tatWwus/8Ybb6h58+YKDg7Wddddp/fff9/iVRYOwTwAAACQh+XLl2vixImaOnWqduzYobZt26pv375KTU3Ns/7nn3+uESNGaOzYsdq5c6eGDBmiIUOGaPfu3SU2RoJ5AAAA2Ev2l0ZZKT6YPXu2xo0bpzFjxqhly5aaN2+eqlatqoULF+ZZ/9lnn1W/fv30pz/9SS1atNCMGTP0m9/8RnPmzCmOq84TwTwAAADsxRShFFJWVpa2b9+umJgYz7GAgADFxMRo8+bNebbZvHmzV31J6tu3b771iwMLYAEAAGArRd2aMj093eu40+mU0+n0Onb8+HG5XC7VrVvX63jdunX13Xff5Xn+lJSUPOunpKT4PthCYmYeAAAA9lLEmfno6GiFhoZ6Snx8fGlfQbFhZh4AAAAVSnJyskJCQjyvL5+Vl6Q6deqoUqVKOnbsmNfxY8eOKTIyMs/zRkZG+lS/ODAzDwAAAHuxui3lrzPzISEhXiWvYD4oKEjt27fX+vXrPcfcbrfWr1+vLl265DmsLl26eNWXpLVr1+ZbvzgUKZifOXOmHA6HHnrooWIaDgAAAHAFpbAAVpImTpyo+fPn6+WXX9bevXs1fvx4ZWRkaMyYMZKke+65R5MnT/bUf/DBB5WYmKh//vOf+u677zRt2jR9+eWXiouLK9r1FsByms22bdv04osvqk2bNsU5HgAAAKBgpfQNsMOGDdNPP/2kKVOmKCUlRe3atVNiYqJnkevhw4cVEJAzN961a1ctWbJEjz/+uP785z+rWbNmWrlypVq3bm1hsIVjKZg/ffq0Ro4cqfnz5+tvf/tbcY8JAAAAyFdRd7PxRVxcXL4z6xs3bsx1bOjQoRo6dKjvHVlkKc1mwoQJGjBgQK59NAEAAACUHp9n5pctW6YdO3Zo27ZthaqfmZmpzMxMz+vL9/UEAAAAYI1PM/PJycl68MEH9frrrys4OLhQbeLj47328YyOjrY0UAAAAEBSqS2AtQOfgvnt27crNTVVv/nNbxQYGKjAwEB9/PHHeu655xQYGCiXy5WrzeTJk5WWluYpycnJxTZ4AAAAVDxWtqW0mmdf1vmUZtOrVy998803XsfGjBmj5s2ba9KkSapUqVKuNnl9PS4AAABQJOUwMLfCp2C+Ro0aubbWqVatmmrXrl2iW+4AAAAAHqW0NaUdWN5nHgAAAPCH0tyasqwrcjCf1/6aAAAAAEoeM/MAAACwF9JsPAjmAQAAYCuk2eQgmAcAAIC9MDPvQTAPAAAAeyGY9yCYBwAAgK2QZpPDp2+ABQAAAFB2MDMPAAAAeyHNxoNgHgAAAPZCMO9BMA8AAABbIWc+B8E8AAAA7IWZeQ+CeQAAANgKM/M52M0GAAAAsCm/zcxnnA9S4PmgUu+3/kdnSr3PbG5nJb/1fTrab13r3K21/NZ3zRfD/NZ3m//b77e+zywO9VvfGS0j/NZ38PEsv/XdvnWy3/qWpB1JDfzWd/PKaX7rG0DJMC6Xv4dQMNJsPEizAQAAgL0QzHsQzAMAAMBWHL8WK+3KG4J5AAAA2Asz8x4E8wAAALAVdrPJwW42AAAAgE0xMw8AAAB7Ic3Gg2AeAAAA9lMOA3MrCOYBAABgK+TM5yCYBwAAgL2QZuNBMA8AAABbYWY+B7vZAAAAADbFzDwAAADshTQbD4J5AAAA2AppNjkI5gEAAGAvzMx7EMwDAADAXgjmPXxaADtt2jQ5HA6v0rx585IaGwAAAJBLdpqNlVLe+Dwz36pVK61bty7nBIFM7gMAAAD+4HMkHhgYqMjIyJIYCwAAAHBlpNl4+LzP/P79+xUVFaUmTZpo5MiROnz4cIH1MzMzlZ6e7lUAAAAAqxzGWC7ljU/BfOfOnbV48WIlJiYqISFBSUlJ6t69u06dOpVvm/j4eIWGhnpKdHR0kQcNAACACswUoZQzPgXzsbGxGjp0qNq0aaO+ffvq/fff18mTJ/Wf//wn3zaTJ09WWlqapyQnJxd50AAAAKi4WACbo0irV8PCwnTNNdfowIED+dZxOp1yOp1F6QYAAADIQc68h88585c6ffq0vv/+e9WrV6+4xgMAAACgkHwK5h999FF9/PHHOnjwoD7//HPdeuutqlSpkkaMGFFS4wMAAAC8kGaTw6c0myNHjmjEiBE6ceKEwsPDdcMNN2jLli0KDw8vqfEBAAAA3kiz8fApmF+2bFlJjQMAAAAoFKuz7BV+Zh4AAADwO2bmPQjmAQAAYDvlcZbdiiLtZgMAAADAf5iZBwAAgL0Yc7FYaVfOEMwDAADAVlgAm4NgHgAAAPbCAlgPgnkAAADYisN9sVhpV96wABYAAAD2YopQSsjPP/+skSNHKiQkRGFhYRo7dqxOnz5dYP3/+7//07XXXqsqVaqoQYMGeuCBB5SWluZTvwTzAAAAQBGNHDlSe/bs0dq1a7V69Wp98sknuu+++/Ktf/ToUR09elRPP/20du/ercWLFysxMVFjx471qV/SbAAAAGArZW0B7N69e5WYmKht27apQ4cOkqTnn39e/fv319NPP62oqKhcbVq3bq233nrL87pp06b6+9//rrvvvlsXLlxQYGDhwnRm5gEAAGAv2VtTWiklYPPmzQoLC/ME8pIUExOjgIAAffHFF4U+T1pamkJCQgodyEvMzAMAAMBmijozn56e7nXc6XTK6XRaHk9KSooiIiK8jgUGBqpWrVpKSUkp1DmOHz+uGTNmFJiakxe/BfPHToQo4Gxwqfdb9ZHMUu/TY3OY//r248aqWSH+6zvlt37rWpXPVvdb30dHR1y5UgkJPu7wW98msLLf+j7vx39vSar+Ven/PM125Bb/9Q2gZLgyz0lz/D2KAhRxa8ro6Givw1OnTtW0adNyVX/sscc0a9asAk+5d+9eCwPxlp6ergEDBqhly5Z5jqMgzMwDAADAVoo6M5+cnKyQkBDP8fxm5R955BGNHj26wHM2adJEkZGRSk1N9Tp+4cIF/fzzz4qMjCyw/alTp9SvXz/VqFFDK1asUOXKvk1MEcwDAACgQgkJCfEK5vMTHh6u8PDwK9br0qWLTp48qe3bt6t9+/aSpI8++khut1udO3fOt116err69u0rp9Opd955R8HBvv+lkwWwAAAAsJcytgC2RYsW6tevn8aNG6etW7fqs88+U1xcnIYPH+7ZyeaHH35Q8+bNtXXrVkkXA/k+ffooIyNDCxYsUHp6ulJSUpSSkiKXy1XovpmZBwAAgK2Uta0pJen1119XXFycevXqpYCAAN1+++167rnnPO+fP39e+/bt05kzZyRJO3bs8Ox0c/XVV3udKykpSY0aNSpUvwTzAAAAsJciLoAtCbVq1dKSJUvyfb9Ro0Yyl/xloGfPnl6vrSKYBwAAgK2UxZl5fyGYBwAAgL24zcVipV05wwJYAAAAwKaYmQcAAIC9lMGceX8hmAcAAICtOGQxZ77YR+J/BPMAAACwF6t7xpfQPvP+RDAPAAAAW2E3mxwsgAUAAABsipl5AAAA2AsLYD18npn/4YcfdPfdd6t27dqqUqWKrrvuOn355ZclMTYAAAAgF4cxlkt549PM/C+//KJu3brppptu0gcffKDw8HDt379fNWvWLKnxAQAAAN7cvxYr7coZn4L5WbNmKTo6WosWLfIca9y4cbEPCgAAAMiP1Vn28jgz71OazTvvvKMOHTpo6NChioiI0PXXX6/58+eX1NgAAACA3EwRSjnjUzD/v//9TwkJCWrWrJnWrFmj8ePH64EHHtDLL7+cb5vMzEylp6d7FQAAAABF51OajdvtVocOHfTkk09Kkq6//nrt3r1b8+bN06hRo/JsEx8fr+nTpxd9pAAAAIDEl0ZdwqeZ+Xr16qlly5Zex1q0aKHDhw/n22by5MlKS0vzlOTkZGsjBQAAAJTzpVFWSnnj08x8t27dtG/fPq9j//3vf9WwYcN82zidTjmdTmujAwAAAC7HzLyHT8H8ww8/rK5du+rJJ5/UnXfeqa1bt+qll17SSy+9VFLjAwAAALw43BeLlXbljU9pNh07dtSKFSu0dOlStW7dWjNmzNAzzzyjkSNHltT4AAAAAG/ZM/NWSjnj08y8JN1yyy265ZZbSmIsAAAAAHzgczAPAAAA+JXVPePL38Q8wTwAAADshW+AzUEwDwAAAHthNxsPgnkAAADYi5FkZWea8hfLE8wDAADAXkizyeHT1pQAAAAAyg5m5gEAAGAvRhZz5ot9JH5HMA8AAAB7YQGsB8E8AAAA7MUtyWGxXTlDMA8AAABbYQFsDoJ5AAAA2AtpNh7sZgMAAADYlN9m5isdCVZAcHCp95up0u/TI8yPvw36seuA8/7rW+etJNQVj6Nf1vNb3/50rk75m/UoDL//e9eumPcdQMlwnyvjP1OYmfcgzQYAAAD2QjDvQTAPAAAAe2E3Gw+CeQAAANgKu9nkIJgHAACAvZBm48FuNgAAAIBNMTMPAAAAe3EbyWFhlt1d/mbmCeYBAABgL6TZeBDMAwAAwGYsBvP+/OKdEkIwDwAAAHthZt6DYB4AAAD24jayNMteDnPm2c0GAAAAsClm5gEAAGAvxn2xWGlXzhDMAwAAwF7ImfcgmAcAAIC9kDPvQTAPAAAAe2Fm3sOnBbCNGjWSw+HIVSZMmFBS4wMAAAC8GeUE9D4Vfw+8+Pk0M79t2za5XC7P6927d6t3794aOnRosQ8MAAAAQMF8CubDw8O9Xs+cOVNNmzZVjx49inVQAAAAQL5Is/GwnDOflZWl1157TRMnTpTD4ci3XmZmpjIzMz2v09PTrXYJAAAASG63JAvbTLrL39aUlr80auXKlTp58qRGjx5dYL34+HiFhoZ6SnR0tNUuAQAAAIv58hZn88s4y8H8ggULFBsbq6ioqALrTZ48WWlpaZ6SnJxstUsAAACAYP4SloL5Q4cOad26dfr9739/xbpOp1MhISFeBQAAALDMbayXEvLzzz9r5MiRCgkJUVhYmMaOHavTp08Xqq0xRrGxsXI4HFq5cqVP/VoK5hctWqSIiAgNGDDASnMAAACgXBk5cqT27NmjtWvXavXq1frkk0903333FartM888U+Aa1IL4vADW7XZr0aJFGjVqlAID+c4pAAAAlC5j3DLG98WsVtoUxt69e5WYmKht27apQ4cOkqTnn39e/fv319NPP11gWvquXbv0z3/+U19++aXq1avnc98+z8yvW7dOhw8f1r333utzZwAAAECRGYspNr/mzKenp3uVS3detGLz5s0KCwvzBPKSFBMTo4CAAH3xxRf5tjtz5ozuuusuzZ07V5GRkZb69jmY79Onj4wxuuaaayx1CAAAABRJERfARkdHe+22GB8fX6ThpKSkKCIiwutYYGCgatWqpZSUlHzbPfzww+ratasGDx5suW/yZAAAAGAvbrfksJAy82uaTXJystemLE6nM8/qjz32mGbNmlXgKffu3ev7OCS98847+uijj7Rz505L7bMRzAMAAMBejJFk/RtgC7vD4iOPPHLF71Rq0qSJIiMjlZqa6nX8woUL+vnnn/NNn/noo4/0/fffKywszOv47bffru7du2vjxo1XHJ9EMA8AAADkKTw8XOHh4Ves16VLF508eVLbt29X+/btJV0M1t1utzp37pxnm8ceeyzXNu/XXXed/vWvf2ngwIGFHiPBPAAAAGzFuN0yFtJsSmo3mxYtWqhfv34aN26c5s2bp/PnzysuLk7Dhw/37GTzww8/qFevXnrllVfUqVMnRUZG5jlr36BBAzVu3LjQfVv+BlgAAADAL8rgN8C+/vrrat68uXr16qX+/fvrhhtu0EsvveR5//z589q3b5/OnDlTrP0yMw8AAAB7cRvJYT1nviTUqlVLS5Ysyff9Ro0ayVyh/yu9nxeCeQAAANiLMZKs7GZTcsG8vxDMAwAAwFaM28hYmJm3MvNd1pEzDwAAANgUM/MAAACwF+OWtTSbktnNxp8I5gEAAGArpNnkKPVgPvsmujPPlXbXAAAAKITsOK2sBr8XTKalWfYLOl8Co/Evhynlf6UjR44oOjq6NLsEAACABcnJyapfv76/h+Fx7tw5NW7cWCkpKZbPERkZqaSkJAUHBxfjyPyn1IN5t9uto0ePqkaNGnI4HD61TU9PV3R0tJKTkxUSElJCIyx/uG++455Zw33zHffMGu6b77hn1lTU+2aM0alTpxQVFaWAgLK1X8q5c+eUlZVluX1QUFC5CeQlP6TZBAQEFPk3vJCQkAr1gSou3Dffcc+s4b75jntmDffNd9wzayrifQsNDfX3EPIUHBxcroLxoipbv2oBAAAAKDSCeQAAAMCmbBXMO51OTZ06VU6n099DsRXum++4Z9Zw33zHPbOG++Y77pk13DeUdaW+ABYAAABA8bDVzDwAAACAHATzAAAAgE0RzAMAAAA2RTAPAAAA2FSZC+bnzp2rRo0aKTg4WJ07d9bWrVsLrP/GG2+oefPmCg4O1nXXXaf333+/lEZaNsTHx6tjx46qUaOGIiIiNGTIEO3bt6/ANosXL5bD4fAqFenLF6ZNm5br+ps3b15gm4r+nElSo0aNct03h8OhCRMm5Fm/Ij5nn3zyiQYOHKioqCg5HA6tXLnS631jjKZMmaJ69eqpSpUqiomJ0f79+694Xl9/LtpNQfft/PnzmjRpkq677jpVq1ZNUVFRuueee3T06NECz2nlc24nV3rWRo8enev6+/Xrd8XzVuRnTVKeP+McDoeeeuqpfM9Z3p81lH1lKphfvny5Jk6cqKlTp2rHjh1q27at+vbtq9TU1Dzrf/755xoxYoTGjh2rnTt3asiQIRoyZIh2795dyiP3n48//lgTJkzQli1btHbtWp0/f159+vRRRkZGge1CQkL0448/esqhQ4dKacRlQ6tWrbyuf9OmTfnW5Tm7aNu2bV73bO3atZKkoUOH5tumoj1nGRkZatu2rebOnZvn+//4xz/03HPPad68efriiy9UrVo19e3bV+fOncv3nL7+XLSjgu7bmTNntGPHDv31r3/Vjh079Pbbb2vfvn0aNGjQFc/ry+fcbq70rElSv379vK5/6dKlBZ6zoj9rkrzu148//qiFCxfK4XDo9ttvL/C85flZgw2YMqRTp05mwoQJntcul8tERUWZ+Pj4POvfeeedZsCAAV7HOnfubO6///4SHWdZlpqaaiSZjz/+ON86ixYtMqGhoaU3qDJm6tSppm3btoWuz3OWtwcffNA0bdrUuN3uPN+v6M+ZJLNixQrPa7fbbSIjI81TTz3lOXby5EnjdDrN0qVL8z2Prz8X7e7y+5aXrVu3Gknm0KFD+dbx9XNuZ3nds1GjRpnBgwf7dB6etdwGDx5sbr755gLrVKRnDWVTmZmZz8rK0vbt2xUTE+M5FhAQoJiYGG3evDnPNps3b/aqL0l9+/bNt35FkJaWJkmqVatWgfVOnz6thg0bKjo6WoMHD9aePXtKY3hlxv79+xUVFaUmTZpo5MiROnz4cL51ec5yy8rK0muvvaZ7771XDocj33oV/Tm7VFJSklJSUryepdDQUHXu3DnfZ8nKz8WKIC0tTQ6HQ2FhYQXW8+VzXh5t3LhRERERuvbaazV+/HidOHEi37o8a7kdO3ZM7733nsaOHXvFuhX9WYN/lZlg/vjx43K5XKpbt67X8bp16yolJSXPNikpKT7VL+/cbrceeughdevWTa1bt8633rXXXquFCxdq1apVeu211+R2u9W1a1cdOXKkFEfrP507d9bixYuVmJiohIQEJSUlqXv37jp16lSe9XnOclu5cqVOnjyp0aNH51unoj9nl8t+Xnx5lqz8XCzvzp07p0mTJmnEiBEKCQnJt56vn/Pypl+/fnrllVe0fv16zZo1Sx9//LFiY2PlcrnyrM+zltvLL7+sGjVq6LbbbiuwXkV/1uB/gf4eAIrPhAkTtHv37ivm6nXp0kVdunTxvO7atatatGihF198UTNmzCjpYfpdbGys57/btGmjzp07q2HDhvrPf/5TqBkYSAsWLFBsbKyioqLyrVPRnzMUv/Pnz+vOO++UMUYJCQkF1q3on/Phw4d7/vu6665TmzZt1LRpU23cuFG9evXy48jsY+HChRo5cuQVF+5X9GcN/ldmZubr1KmjSpUq6dixY17Hjx07psjIyDzbREZG+lS/PIuLi9Pq1au1YcMG1a9f36e2lStX1vXXX68DBw6U0OjKtrCwMF1zzTX5Xj/PmbdDhw5p3bp1+v3vf+9Tu4r+nGU/L748S1Z+LpZX2YH8oUOHtHbt2gJn5fNypc95edekSRPVqVMn3+vnWfP26aefat++fT7/nJN41lD6ykwwHxQUpPbt22v9+vWeY263W+vXr/ea3btUly5dvOpL0tq1a/OtXx4ZYxQXF6cVK1boo48+UuPGjX0+h8vl0jfffKN69eqVwAjLvtOnT+v777/P9/p5zrwtWrRIERERGjBggE/tKvpz1rhxY0VGRno9S+np6friiy/yfZas/Fwsj7ID+f3792vdunWqXbu2z+e40ue8vDty5IhOnDiR7/XzrHlbsGCB2rdvr7Zt2/rctqI/a/ADf6/AvdSyZcuM0+k0ixcvNt9++6257777TFhYmElJSTHGGPO73/3OPPbYY576n332mQkMDDRPP/202bt3r5k6daqpXLmy+eabb/x1CaVu/PjxJjQ01GzcuNH8+OOPnnLmzBlPncvv2/Tp082aNWvM999/b7Zv326GDx9ugoODzZ49e/xxCaXukUceMRs3bjRJSUnms88+MzExMaZOnTomNTXVGMNzVhCXy2UaNGhgJk2alOs9njNjTp06ZXbu3Gl27txpJJnZs2ebnTt3enZdmTlzpgkLCzOrVq0yX3/9tRk8eLBp3LixOXv2rOccN998s3n++ec9r6/0c7E8KOi+ZWVlmUGDBpn69eubXbt2ef2cy8zM9Jzj8vt2pc+53RV0z06dOmUeffRRs3nzZpOUlGTWrVtnfvOb35hmzZqZc+fOec7Bs5b7M2qMMWlpaaZq1aomISEhz3NUtGcNZV+ZCuaNMeb55583DRo0MEFBQaZTp05my5Ytnvd69OhhRo0a5VX/P//5j7nmmmtMUFCQadWqlXnvvfdKecT+JSnPsmjRIk+dy+/bQw895LnHdevWNf379zc7duwo/cH7ybBhw0y9evVMUFCQueqqq8ywYcPMgQMHPO/znOVvzZo1RpLZt29frvd4zozZsGFDnp/H7PvidrvNX//6V1O3bl3jdDpNr169ct3Lhg0bmqlTp3odK+jnYnlQ0H1LSkrK9+fchg0bPOe4/L5d6XNudwXdszNnzpg+ffqY8PBwU7lyZdOwYUMzbty4XEE5z1ruz6gxxrz44oumSpUq5uTJk3meo6I9ayj7HMYYU6JT/wAAAABKRJnJmQcAAADgG4J5AAAAwKYI5gEAAACbIpgHAAAAbIpgHgAAALApgnkAAADApgjmAQAAAJsimAcAAABsimAeAAAAsCmCeQAAAMCmCOYBAAAAmyKYBwAAAGzq/wNpM9PsXNHICQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of M for song 4: (8, 20)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the existence of generateIOData, shrinkingDecompositionInformation, and removalIntoMatrix functions.\n",
    "for i in range(4):\n",
    "    \n",
    "    I, O_hot, O_indices = generateIOData(i, songStrings)\n",
    "    \n",
    "    # Assuming these functions return the necessary components for plotting\n",
    "    S, H = shrinkingDecompositionInformation(model, 20, I, O_indices.transpose(), numbers=[0,1,2,3,4,5,6,7], whichTS=40, dsLength=41)\n",
    "    M = removalIntoMatrix(S, 20, H)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))  # Adjust the figure size as necessary\n",
    "    plt.imshow(M, aspect='auto')  # 'auto' can adjust the aspect ratio based on array dimensions\n",
    "    plt.colorbar()  # Show color scale\n",
    "    plt.title(f'Matrix Visualization for Song {i+1}')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Shape of M for song {i+1}: {M.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f72ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 4, 2, 4, 1, 5, 2, 1, 1, 6, 1, 1, 4, 1, 4, 6, 4, 4, 4, 1, 2, 6, 1, 4,\n",
      "        1, 4, 1, 1, 2, 1, 4, 1, 2, 4, 1, 5, 5, 1, 1, 5, 6])\n",
      "tensor([4, 2, 4, 1, 5, 2, 1, 1, 6, 1, 1, 4, 1, 4, 6, 4, 4, 4, 1, 2, 6, 1, 4, 1,\n",
      "        4, 1, 1, 2, 1, 4, 1, 2, 4, 1, 5, 5, 1, 1, 5, 6, 4])\n",
      "tensor([2, 4, 1, 5, 2, 1, 1, 6, 1, 1, 4, 1, 4, 6, 4, 4, 4, 1, 2, 6, 1, 4, 1, 4,\n",
      "        1, 1, 2, 1, 4, 1, 2, 4, 1, 5, 5, 1, 1, 5, 6, 4, 5])\n",
      "tensor([4, 1, 5, 2, 1, 1, 6, 1, 1, 4, 1, 4, 6, 4, 4, 4, 1, 2, 6, 1, 4, 1, 4, 1,\n",
      "        1, 2, 1, 4, 1, 2, 4, 1, 5, 5, 1, 1, 5, 6, 4, 5, 4])\n",
      "(820, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "I, O_hot, O_indices = generateIOData(4, songStrings)\n",
    "songs =np.array([0,1,2,3])\n",
    "s,h=shrinkingDecompositionInformation(model,I,O_indices,songs,numbers=list(range(4)),width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771c087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M=removalIntoMatrix(s,20,h)\n",
    "imshow(M)\n",
    "print(M.max(),M.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755484cc",
   "metadata": {},
   "source": [
    "## generateIOData on all songs at once with its corresponding combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc6a8b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (168, 41, 8), Output (One-Hot) shape: (168, 41, 8), Output (Indices) shape: (168, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Output (One-Hot Encoded)')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGzCAYAAAASUAGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3XUlEQVR4nO3deVxU9f4/8NewDbINsciiiIiZK3YjRa6SG4loKonX0ko01Kvhym2Re/261PdGZSlaivbN1BZbXMu8Yq64m6KGbaSGggu4JANCDgif3x/+5lxHBhxm5jOAvZ6Px3ko55w55zMz75nXfM45nxmVEEKAiIjIyuzquwFERHR/YsAQEZEUDBgiIpKCAUNERFIwYIiISAoGDBERScGAISIiKRgwREQkBQOGiIik+FMGzJdffgkvLy/cuHGjvptCNtKyZUuMHj3aats7e/YsVCoVVq5cqcybMWMGIiIirLYPcwwYMADjxo2r1zaQ7ezevRsqlQq7d++22jbnzJkDlUql/F1RUYGgoCAsWbKkztuqU8CsXLkSKpUKR48erfOOZCgrK8OcOXPq9OBWVlZi9uzZmDx5Mtzc3AyWVVRUYNGiRejSpQvc3d3h5uaGLl26YNGiRaioqLBy602nL6K1a9caXT569Ohq98VUq1evRlpamsnrt2zZEiqVyujUv39/s9pgbT/++COeffZZNGvWDGq1GoGBgbhy5QquX79u0XZff/11bNy4scbl06ZNw/fff4+vv/7aov0AwIEDBzBnzhwUFRWZfJv9+/fj22+/xSuvvFJtWV5eHiZMmICWLVtCrVajadOmiIuLw/79+y1uqyXuVbsqlQqTJk2q83br+t6gf43VNH3++ed1bsP9wtHREcnJyfj3v/+Nmzdv1um2DpLaZBNlZWWYO3cuAKBXr14m3WbTpk3IycnB+PHjDeaXlpZi4MCByMzMxBNPPIHRo0fDzs4OGRkZmDp1KtavX4/NmzfD1dXV2nejXq1evRo//PADpk2bZvJtHn74YfzjH/+oNj8wMNCKLTPP+vXrMWLECHh5eSExMREhISE4e/YsUlNT8c0332DDhg148sknzdr266+/jmHDhiEuLs7ocn9/fwwZMgRvv/02Bg8ebMG9uB0wc+fOxejRo+Hp6WnSbebNm4e+ffuidevWBvP379+PAQMGAADGjh2L9u3bo6CgACtXrkRUVBQWLlyIyZMnW9Tehsac9wYAmDJlCrp06VJtfmRkpLWa1iiNGTMGM2bMwOrVq/H888+bfLtGHTDmWLFiBbp3745mzZoZzE9OTkZmZibeffddg09MEydOxOLFizFp0iS8+OKLSE9Pt3WTG5xmzZrh2Wefre9mVHPmzBk899xzaNWqFfbs2QNfX19l2cqVK1FSUoLnnnsO2dnZaNWqlZQ2DB8+HH/729/w22+/SduHMZcvX8bmzZuxdOlSg/nXr1/HsGHD0KRJE+zfvx+hoaHKsuTkZMTExGDatGkIDw/HX//6V5u1t6GKiorCsGHD6rsZDY6npyf69euHlStX1ilgLD4Ho+/iXrhwAXFxcXBzc4Ovry9efPFFVFZWKuvpj1m//fbbWLBgAYKDg9GkSRP07NkTP/zwg8E2e/XqZfRTx+jRo9GyZUtle/o3kLlz5ypd2Tlz5tTY1ps3byIjIwPR0dEG88+fP4/ly5ejT58+RrvjSUlJ6N27Nz744AOcP39ema/vvm/cuBEdO3aEWq1Ghw4dkJGRUW0bFy5cwPPPPw8/Pz9lvQ8//LDGtlrDkiVL0KFDB+UwUVJSksEhl169emHz5s04d+6c8vjpH19LmVoXAFBVVYWFCxeiU6dOcHZ2hq+vL/r3729wKPbWrVt47bXXEBoaCrVajZYtW+Kf//wndDqdss68efNQVlaG7t274y9/+QtcXFzQu3dv/Pjjj7C3t0e3bt1QWlqKt956CwBQVFSE9u3bw8HBAWq1Gq1bt8abb76Jqqoqg+PQRUVFUKlUKC0txapVq6BSqRASEqLsV7/uL7/8gk8++QRCCHTq1AlTp041OKRg7LyN3p21O2fOHLz00ksAgJCQEOW5OXv2bI2P9+bNm3Hr1q1qtb1s2TIUFBRg3rx5BuECAE2aNFHuz6uvvqrM1x8K379/P5KTk+Hr6wtXV1c8+eSTuHLlSrV9b9myBVFRUXB1dYW7uzsGDhyIH3/8sca2Wury5ctITEyEn58fnJ2d0blzZ6xatUpZbs57Q13U9XWfmJiIwMBAqNVqhISEYOLEiSgvL1fW+e233/C3v/0NXl5ecHFxQbdu3bB58+Zq2zp//jzi4uLg6uqKpk2bYvr06Qb1f6fDhw+jf//+0Gg0cHFxQc+ePY0eDt23bx+6dOkCZ2dnhIaGYtmyZTXe78cffxz79u3D77//bsrDBMBKPZjKykrExMQgIiICb7/9NrZv34533nkHoaGhmDhxosG6H330EUpKSpCUlISbN29i4cKF6NOnD06ePAk/Pz+T9+nr64v09HRMnDgRTz75JIYOHQoACAsLq/E2WVlZKC8vxyOPPGIwf8uWLaisrMSoUaNqvO2oUaOwa9cuZGRkYOzYscr8ffv2Yf369XjhhRfg7u6ORYsWIT4+Hnl5efD29gYAFBYWolu3bkph+vr6YsuWLUhMTERxcbHJh6dKSkpw9erVavONFdmcOXMwd+5cREdHY+LEicjJyUF6ejqOHDmC/fv3w9HREf/617+g1Wpx/vx5LFiwAABMOpdTUVFhtB2urq5o0qSJ8repdZGYmIiVK1ciNjYWY8eOxa1bt7B3714cOnQIjz76KIDbh3ZWrVqFYcOG4R//+AcOHz6M1NRU/Pzzz9iwYQOA24c/NRoNli9fjgEDBmDAgAE4duwY+vXrh/Lycvj7+6Nly5bYvHkzysrK0LNnT/z2229wc3PDm2++iQMHDiAlJQWXLl1SDksJITBkyBCoVCrY2dkp5zBKSkqQn59vcP+HDx+Oli1bwsfHBy4uLli0aBGuX7+Ojz766J6P6Z2GDh2KX3/9FZ999hkWLFgAHx8fADDokd3twIED8Pb2RnBwsMH8TZs2wdnZGcOHDzd6u5CQEPTo0QM7d+7EH3/8YfD8TZ48GQ888ABmz56Ns2fPIi0tDZMmTcIXX3yhrPPxxx8jISEBMTExePPNN1FWVob09HT06NEDx48fN/kDi7F6MuaPP/5Ar169cPr0aUyaNAkhISFYs2YNRo8ejaKiIkydOtWs9wa9ml5j3t7eBie+TXndX7x4EV27dkVRURHGjx+Ptm3b4sKFC1i7di3Kysrg5OSEwsJC/PWvf0VZWRmmTJkCb29vrFq1CoMHD8batWuVw7l//PEH+vbti7y8PEyZMgWBgYH4+OOPsXPnzmpt3blzJ2JjYxEeHo7Zs2fDzs4OK1asQJ8+fbB371507doVAHDy5En069cPvr6+mDNnDm7duoXZs2fX+D4cHh4OIQQOHDiAJ5544p6PJQBA1MGKFSsEAHHkyBFlXkJCggAgXn31VYN1//KXv4jw8HDl79zcXAFANGnSRJw/f16Zf/jwYQFATJ8+XZnXs2dP0bNnz2r7T0hIEMHBwcrfV65cEQDE7NmzTWr/Bx98IACIkydPGsyfNm2aACCOHz9e422PHTsmAIjk5GRlHgDh5OQkTp8+rcz7/vvvBQDx7rvvKvMSExNFQECAuHr1qsE2n376aaHRaERZWVmt7d61a5cAUOvk6uqqrH/58mXh5OQk+vXrJyorK5X57733ngAgPvzwQ2XewIEDDR7TewkODq6xDampqcp6ptbFzp07BQAxZcqUavuqqqoSQghx4sQJAUCMHTvWYPmLL74oAIidO3eKoqIiAUCoVCoxcOBA5bZCCPHPf/5TABAJCQli8ODBAoCYOXOmcHV1FU8++aTB/Z8xY4awt7dXamLjxo0CgHjrrbeEq6urSEhIELdu3RJRUVECgFixYoWYPXu2ACAGDx4shBCiX79+ol27duKFF14QAMT3338vhPjva2DFihXV7uvddTxv3jwBQOTm5tb+hPx/PXr0MHhc9Tw9PUXnzp1rve2UKVMEAJGdnS2E+O/rPDo62uBxnD59urC3txdFRUVCCCFKSkqEp6enGDdunMH2CgoKhEajqTbfGH2d1DYlJSUp66elpQkA4pNPPlHmlZeXi8jISOHm5iaKi4uFEHV/b7jXa+zSpUvKuqa+7keNGiXs7OwM3i/19I+rvs727t2rLCspKREhISGiZcuWyutXf7+//PJLZb3S0lLRunVrAUDs2rVL2e6DDz4oYmJiDJ67srIyERISIh5//HFlXlxcnHB2dhbnzp1T5v3000/C3t5eGIuGixcvCgDizTffvPcD+v9Z7TLlCRMmGPwdFRWF3377rdp6cXFxBuc/unbtioiICPznP/+xVlNqdO3aNQDAAw88YDC/pKQEAODu7l7jbfXLiouLDeZHR0cbHHoICwuDh4eHct+FEFi3bh0GDRoEIQSuXr2qTDExMdBqtTh27JhJ7Z81axa2bdtWberXr5/Betu3b0d5eTmmTZsGO7v/PsXjxo2Dh4eH0e53XURERBhtx4gRI6qte6+6WLduHVQqFWbPnl3ttvpPjPraSE5ONliuv9Bg8+bNynMohMDkyZMNPm3e2UPUP4/r1q1DVFQUnJycUFVVpTwn0dHRqKysxLlz55R9Ozg4GPS47O3tjZ4UT0pKAnC7vq5evaqsY6vavruugdu1XVtdAzXX9vjx4w0ex6ioKIPHZtu2bSgqKsKIESMM6tre3h4RERHYtWuXSW13dnY2Wk/btm2rtu5//vMf+Pv7G9Sao6MjpkyZghs3biAzM9OkfdakpteYl5eXwXr3et1XVVVh48aNGDRokNILv9Odtd21a1f06NFDWebm5obx48fj7Nmz+Omnn5T1AgICDM4Pubi4VLtY6cSJEzh16hRGjhyJa9euKc9JaWkp+vbtiz179qCqqgqVlZXYunUr4uLi0KJFC+X27dq1Q0xMjNHHRl9fpvY2ASsdItMfN7+7McYuC33wwQerzWvTpg2+/PJLazTFJOKuH/HUv8D0b1LG1BRCdz45enfe9ytXrqCoqAjvv/8+3n//faPbvnz5MgCgoKDAYL5GozE4ZNGpU6dqx9gB4JNPPjH4W/8G8NBDDxnMd3JyQqtWrZTl5vLx8THajruZUhdnzpxBYGBgtRfwnc6dOwc7O7tqV0f5+/vD09MT586dM3he7q4xX19f5cWhfx5zc3Px888/G6xzp9LSUmXfAQEB1Q4d3v3Y3rlfIQRUKhVCQ0NhZ2dX67kTa7q7roHb9VpbXQOm17b+MdQ/f6dOnQIA9OnTx+h2PTw8ANw+vKPVag2W+fv7K/+3t7c3qZ6A28/Hgw8+aPDBCbj9xqhfbomaXmN3M+V1X1xcjI4dO9a6nXPnzhkdO3Xn/enYsSPOnTuH1q1bGwQ+UL0O9c9JQkJCjfvUarXQ6XT4448/jL4fP/TQQ0Y/FOnr6+421MYqAWNvb2+NzShUKpXRF8vdJ4frSn9s9Pr162jevLkyX/9kZmdn4+GHHzZ62+zsbABA+/btDebXdN/17a+qqgIAPPvsszU+6fpjwwEBAQbzV6xYYdXBgbYmoy5qotFoTHozzc7ORrNmzXD16lU8/vjjUKlU+P7776uF9Ndff41vv/3WrHZev34dPj4+1dpbU/strWvgdm0b+0DXrl07HD9+HDqdDmq12uhts7Oz4ejoWO3NxtTa/vjjjw0CQ8/B4fbbyxdffIExY8YY3UZjda/Hpr7on5N58+bV+F7m5uZW48UBtdHXl/6coClsfpmyPmHv9OuvvxqcDHzggQeMHl67+9NJXZIUANq2bQvg9qfXTp06KfNjY2Nhb2+Pjz/+uMYT/R999BEcHBzqPJjQ19cX7u7uqKysvOcno7sPCXTo0KFO+9LTn+jNyckxuFS2vLwcubm5Bu2o62NobaGhodi6dSt+//33GnsxwcHBqKqqwqlTp5QPA8DtiyeKioqU+/voo49i165d2LBhg8E4Hf0gy8LCQpw9exZ///vfsXfvXty4cQPdunXD4cOHqz03+hPzwcHB2LFjB27cuGHwWOXk5FRr56lTpxASEoLc3Fx07twZp0+fRlVVlVLb+h7A3YMnjX3qNqe2161bV23+E088gYMHD2LNmjVGLy0/e/Ys9u7di+joaIPesin0h4iaNm1aa23HxMQYPdxljuDgYGRnZ6OqqsqgF/PLL78oy4H6r2tfX194eHhUu0L2bsHBwUZr6e77ExwcjB9++EHpHevdfVv9c+Lh4VHrc+Lr64smTZoYfT821h7g9vsmAIPX4L3Y/KtiNm7ciAsXLih/f/fddzh8+DBiY2OVeaGhofjll18MLon8/vvvq11m5+LiAqD6C7Ym4eHhcHJyqvZNBEFBQRgzZgy2b99udJzL0qVLsXPnTiQmJhr0fExhb2+P+Ph4rFu3zmix3Xkfo6OjDaa7ezSmio6OhpOTExYtWmTwiWr58uXQarUYOHCgMs/V1bXa4Qtbio+PhxBCGRR3J33b9YME7/7Ggfnz5wOAcn9SU1MB3L6C7s7jxPrbHTx4EC4uLnjppZcwfPhwHDx4EDqdDlqtVumhArdf3Por0wYMGIBbt24hPT0drq6uKCoqQmVlJd59991q7V28eDG0Wi3OnDmDv/71r8o6+tr28PCAj48P9uzZY3A7Y1/BoR/Qa2ptR0ZG4vr169U+mP39739H06ZN8dJLL1VbdvPmTYwZMwZCCMyaNcuk/dwpJiYGHh4eeP31141+04W+tgMCAqrVtrkGDBiAgoICgyvZbt26hXfffRdubm7o2bMngLq/N1ibnZ0d4uLisGnTJqPffHJnbX/33Xc4ePCgsqy0tBTvv/8+WrZsqRwxGTBgAC5evGjwbR5lZWXVDruHh4cjNDQUb7/9ttGvwtI/J/b29oiJicHGjRuRl5enLP/555+xdetWo/cpKysLKpWqToNObd6Dad26NXr06IGJEydCp9MhLS0N3t7eePnll5V1nn/+ecyfPx8xMTFITEzE5cuXsXTpUnTo0MHgRGSTJk3Qvn17fPHFF2jTpg28vLzQsWPHGo97Ojs7o1+/fti+fbvBdf8AsGDBAvzyyy944YUXkJGRofRUtm7diq+++go9e/bEO++8Y9Z9fuONN7Br1y5ERERg3LhxaN++PX7//XccO3YM27dvr9N15abw9fVFSkoK5s6di/79+2Pw4MHIycnBkiVL0KVLF4NPsuHh4fjiiy+QnJyMLl26wM3NDYMGDap1+xcuXKh2SAm43fWuaZR7TXr37o3nnnsOixYtwqlTp9C/f39UVVVh79696N27NyZNmoTOnTsjISEB77//PoqKitCzZ0989913WLVqFeLi4tC7d28Aty8+iIuLw8aNG9G8eXP07t0bpaWlOH78OOzs7FBSUoI1a9YgNDQUL730Er7++mssW7YMDg4O6Nu3L7p37478/HwcP34cnTp1QnZ2NgYNGoTu3btjxowZaN68ObZs2YK2bdsajGPQ0/cOhRDYs2cPvvrqK4wcORKdO3dW1hk7dizeeOMNjB07Fo8++ij27NmDX3/9tdq2wsPDAQD/+te/8PTTT8PR0RGDBg2q8ZskBg4cCAcHB2zfvt3gxK+3tzfWrl2LgQMH4pFHHqk2kv/06dNYuHChWYMsPTw8kJ6ejueeew6PPPIInn76afj6+iIvLw+bN29G9+7d8d5779V5u7UZP348li1bhtGjRyMrKwstW7bE2rVrsX//fqSlpSnnker63qC3d+9eo1+HEhYWZtJlznd6/fXX8e2336Jnz54YP3482rVrh0uXLmHNmjXYt28fPD09MWPGDHz22WeIjY3FlClT4OXlhVWrViE3Nxfr1q1Temnjxo3De++9h1GjRiErKwsBAQH4+OOPlSDVs7OzwwcffIDY2Fh06NABY8aMQbNmzXDhwgXs2rULHh4e2LRpE4DbY4QyMjIQFRWFF154QQnqDh06GHzg0tu2bRu6d++unGowicnXm4maL1O+8xJZPf2lm3r6SzTnzZsn3nnnHREUFCTUarWIiopSLuO80yeffCJatWolnJycxMMPPyy2bt1a7TJlIYQ4cOCACA8PF05OTiZdlrh+/XqhUqlEXl5etWU6nU4sWLBAhIeHC1dXV+Hi4iIeeeQRkZaWJsrLy6utj7suodQLDg4WCQkJBvMKCwtFUlKSCAoKEo6OjsLf31/07dtXvP/++7W2V4j/XkK5Zs0ao8treg7ee+890bZtW+Ho6Cj8/PzExIkTxfXr1w3WuXHjhhg5cqTw9PQUAO55yXJtlynfeVtT60IIIW7duiXmzZsn2rZtK5ycnISvr6+IjY0VWVlZyjoVFRVi7ty5IiQkRDg6OoqgoCCRkpIibt68abCtyspK8cILLwhnZ2flsmUfHx/h4uKiXEasV1JSIlJSUkRgYKBQqVTKZfQjR44UM2fOVNp57do18dxzzwlXV1dhb2+vXMaJuy5T/umnn0Tz5s2Fvb29eOCBB8SkSZPEH3/8YbDPsrIykZiYKDQajXB3dxfDhw8Xly9fNlq7r732mmjWrJmws7Mz6ZLlwYMHi759+xpdlpubK8aNGydatGghHB0dhY+Pjxg8eLDB5bF6xl7nQvy3DvWXxN45PyYmRmg0GuHs7CxCQ0PF6NGjxdGjR2ttrxA114mesddYYWGhGDNmjPDx8RFOTk6iU6dORi/9rst7w70uU77ztnV53Z87d06MGjVK+Pr6CrVaLVq1aiWSkpKETqdT1jlz5owYNmyY8PT0FM7OzqJr167im2++qbb9c+fOicGDBwsXFxfh4+Mjpk6dKjIyMow+J8ePHxdDhw4V3t7eQq1Wi+DgYDF8+HCxY8cOg/UyMzOVx6hVq1Zi6dKlRl+jRUVFwsnJSXzwwQc1PobG1ClgLHFnwNSnW7duiTZt2oiZM2fWazvo/qF/Qf7www/C2dlZbNy4sV7asWfPHmFnZyd+/fXXetk/3b8WLFggAgIC7jlm725/uq/rt7e3x6uvvorFixfz6/rJqpYtW4ZOnTphyJAh9bL/qKgo9OvXT/kqHCJrqKiowPz58zFz5sw6Xwjyp/uySwB46qmn8NRTT9V3M+g+M2vWrDpdwinDli1b6nX/dP9xdHQ0uBCgLv50PRgiIrINlRCNfMQTERE1SOzBEBGRFAwYIiKSokGf5K+qqsLFixfh7u5e71/9QI2XEAIlJSUIDAys9iWJsrB2yRrqo3atSsIl09W89957Ijg4WKjVatG1a1dx+PBhk26Xn59/z9+K4MTJ1Ck/P5+1y6lRTubUbkMgvQej/xqSpUuXIiIiAmlpaYiJiUFOTg6aNm1a6231X/vQAwPgAEfZTTXJhl9PWm1bT7bpdO+VyGK3UIF9+M89fxflbqzdmrF2bcPc2m0opAfM/PnzMW7cOOXrupcuXYrNmzfjww8/xIwZM2q9rf7QggMc4aBqGC9SD3frdVMbyn2674nb/9T1UBVrt2YN5T7d98ys3YZC6kG98vJyZGVlGXx7qp2dHaKjow2+PVRPp9OhuLjYYCKqD6xdIstJDZirV6+isrISfn5+BvP9/Pyq/XojcPvr1jUajTIFBQXJbB5RjVi7RJZrUJclpKSkQKvVKlN+fn59N4nIJKxdouqknoPx8fGBvb09CgsLDeYXFhYa/YlVtVpd48+6EtkSa5fIclJ7ME5OTggPD8eOHTuUeVVVVdixY0edfhWNyNZYu0SWk34VWXJyMhISEvDoo4+ia9euSEtLQ2lpqXJlDlFDdb/Vbkzgw/XdhAZv68UTVtsWH28bBMxTTz2FK1euYNasWSgoKMDDDz+MjIyMaidPiRoa1i6RZWzyVTGTJk3CpEmTbLErIqti7RKZr0FdRUZERPcPBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFA36Fy0bIg6eujcOViMigD0YIiKShAFDRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFBxoSSTRhl9PwsPdss9xHGxqO3ysrYs9GCIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIpGDBERCQFA4aIiKRgwBARkRSNYqAlB6s1LnysiQhgD4aIiCRhwBARkRQMGCIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIpGDBERCRFoxhoSdRYPdmmExxUjvXdDDLR1osnrLYtDjiW3IOZM2cOVCqVwdS2bVuZuySyCtYukeWk92A6dOiA7du3/3eHDuw0UePA2iWyjPRXjIODA/z9/WXvhsjqWLtElpF+kv/UqVMIDAxEq1at8MwzzyAvL6/GdXU6HYqLiw0movrC2iWyjNSAiYiIwMqVK5GRkYH09HTk5uYiKioKJSUlRtdPTU2FRqNRpqCgIJnNI6oRa5fIciohhLDVzoqKihAcHIz58+cjMTGx2nKdTgedTqf8XVxcjKCgIFz/tRW/rp/MdktUYDe+glarhYeHh1nbMLd2e2EIryJrRBraVWTWqN36ZNOzlp6enmjTpg1Onz5tdLlarYZarbZlk4hMwtolqjubDrS8ceMGzpw5g4CAAFvulshirF2iupPag3nxxRcxaNAgBAcH4+LFi5g9ezbs7e0xYsSIOm2Hg9Ual4Z2mMEc1qpdsg1r1RwPpVuX1IA5f/48RowYgWvXrsHX1xc9evTAoUOH4OvrK3O3RBZj7RJZTmrAfP755zI3TyQNa5fIcvyySyIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIpGDBERCQFf+CCFBysRkTWxB4MERFJwYAhIiIpGDBERCQFA4aIiKRgwBARkRQMGCIikoIBQ0REUjBgiIhICg60JKJ6w8G99zf2YIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFJwoOV9gIPViKghYg+GiIikYMAQEZEUDBgiIpKCAUNERFIwYIiISAoGDBERScGAISIiKRgwREQkBQdaElGdcXAvmcLsHsyePXswaNAgBAYGQqVSYePGjQbLhRCYNWsWAgIC0KRJE0RHR+PUqVOWtpfIKli/RPKZHTClpaXo3LkzFi9ebHT5W2+9hUWLFmHp0qU4fPgwXF1dERMTg5s3b5rdWCJrYf0SyWf2IbLY2FjExsYaXSaEQFpaGmbOnIkhQ4YAAD766CP4+flh48aNePrpp83dLZFVsH6J5JNykj83NxcFBQWIjo5W5mk0GkRERODgwYM13k6n06G4uNhgIrI1c+qXtUtUnZSAKSgoAAD4+fkZzPfz81OWGZOamgqNRqNMQUFBMppHVCtz6pe1S1Rdg7pMOSUlBVqtVpny8/Pru0lEJmHtElUnJWD8/f0BAIWFhQbzCwsLlWXGqNVqeHh4GExEtmZO/bJ2iaqTEjAhISHw9/fHjh07lHnFxcU4fPgwIiMjZeySyGpYv0TWYfZVZDdu3MDp06eVv3Nzc3HixAl4eXmhRYsWmDZtGv73f/8XDz74IEJCQvA///M/CAwMRFxcnDXafV/gYLX6w/olks/sgDl69Ch69+6t/J2cnAwASEhIwMqVK/Hyyy+jtLQU48ePR1FREXr06IGMjAw4Oztb3moiC7F+ieRTCSFEfTeiJsXFxdBoNOiFIXBQOdZ3c6yOPRjbuCUqsBtfQavV2uzcCGvXNKzd2tVH7VpTg7qKjIiI7h8MGCIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIp+IuWRH8S1rq0GODlxWQa9mCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSggFDRERScKBlHXGwGjVWrLd74+vbutiDISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFIwYIiISAoGDBERScGBlnXEwVP3xsFqRASwB0NERJIwYIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAy2JqNGz1uBeDuy1LvZgiIhICrMDZs+ePRg0aBACAwOhUqmwceNGg+WjR4+GSqUymPr3729pe4msgvVLJJ/ZAVNaWorOnTtj8eLFNa7Tv39/XLp0SZk+++wzc3dHZFWsXyL5zD4HExsbi9jY2FrXUavV8Pf3N3mbOp0OOp1O+bu4uNjc5hHVytr1y9olqk7qOZjdu3ejadOmeOihhzBx4kRcu3at1vVTU1Oh0WiUKSgoSGbziGpVl/pl7RJVJy1g+vfvj48++gg7duzAm2++iczMTMTGxqKysrLG26SkpECr1SpTfn6+rOYR1aqu9cvaJapO2mXKTz/9tPL/Tp06ISwsDKGhodi9ezf69u1r9DZqtRpqtVpWk4hMVtf6Ze0SVWezy5RbtWoFHx8fnD592la7JLIa1i9R3dlsoOX58+dx7do1BAQE2GqXVEccrFYz1i9R3ZkdMDdu3DD4NJebm4sTJ07Ay8sLXl5emDt3LuLj4+Hv748zZ87g5ZdfRuvWrRETE2OVhhNZgvVLJJ/ZAXP06FH07t1b+Ts5ORkAkJCQgPT0dGRnZ2PVqlUoKipCYGAg+vXrh9dee43HqalBYP0SyWd2wPTq1QtCiBqXb9261dxNE0nH+iWSj99FRkREUjBgiIhICgYMERFJwYAhIiIpGDBERCQFf9GSiOoNB/fe39iDISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFIwYIiISAoGDBERScGBlvcBDlYjooaIPRgiIpKCAUNERFIwYIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUHGhJRHXGwb1kCvZgiIhICgYMERFJwYAhIiIpGDBERCQFA4aIiKRgwBARkRQMGCIikoIBQ0REUnCgZT3iYDVqrO7XmrPWaxK4fx+jumAPhoiIpDA7YFJTU9GlSxe4u7ujadOmiIuLQ05OjsE6N2/eRFJSEry9veHm5ob4+HgUFhZa3GgiS7B2iWzD7IDJzMxEUlISDh06hG3btqGiogL9+vVDaWmpss706dOxadMmrFmzBpmZmbh48SKGDh1qlYYTmYu1S2QbZp+DycjIMPh75cqVaNq0KbKysvDYY49Bq9Vi+fLlWL16Nfr06QMAWLFiBdq1a4dDhw6hW7du1bap0+mg0+mUv4uLi81tHlGNWLtEtmG1czBarRYA4OXlBQDIyspCRUUFoqOjlXXatm2LFi1a4ODBg0a3kZqaCo1Go0xBQUHWah5RjVi7RHJYJWCqqqowbdo0dO/eHR07dgQAFBQUwMnJCZ6engbr+vn5oaCgwOh2UlJSoNVqlSk/P98azSOqEWuXSB6rXKaclJSEH374Afv27bNoO2q1Gmq12hpNIjIJa5dIHot7MJMmTcI333yDXbt2oXnz5sp8f39/lJeXo6ioyGD9wsJC+Pv7W7pbIouxdonkMrsHI4TA5MmTsWHDBuzevRshISEGy8PDw+Ho6IgdO3YgPj4eAJCTk4O8vDxERkZa1ur7xP06EKuhD1Zj7RLZhtkBk5SUhNWrV+Orr76Cu7u7cmxao9GgSZMm0Gg0SExMRHJyMry8vODh4YHJkycjMjLS6FU4RLbC2iWyDbMDJj09HQDQq1cvg/krVqzA6NGjAQALFiyAnZ0d4uPjodPpEBMTgyVLlpjdWCJrYO0S2YZFh8juxdnZGYsXL8bixYvN3Q2R1bF2iWyD30VGRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpOBPJhNRo8efH2+Y2IMhIiIpGDBERCQFA4aIiKRgwBARkRQMGCIikoIBQ0REUjBgiIhICgYMERFJwYGWpOBgNSKyJvZgiIhICgYMERFJwYAhIiIpGDBERCQFA4aIiKRgwBARkRQMGCIikoIBQ0REUnCgJRHVGw7uvb+xB0NERFIwYIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAy3vAxysRkQNkdk9mNTUVHTp0gXu7u5o2rQp4uLikJOTY7BOr169oFKpDKYJEyZY3GgiS7B2iWzD7IDJzMxEUlISDh06hG3btqGiogL9+vVDaWmpwXrjxo3DpUuXlOmtt96yuNFElmDtEtmG2YfIMjIyDP5euXIlmjZtiqysLDz22GPKfBcXF/j7+5vfQiIrY+0S2YbVTvJrtVoAgJeXl8H8Tz/9FD4+PujYsSNSUlJQVlZW4zZ0Oh2Ki4sNJiLZWLtEcljlJH9VVRWmTZuG7t27o2PHjsr8kSNHIjg4GIGBgcjOzsYrr7yCnJwcrF+/3uh2UlNTMXfuXGs0icgkrF0ieVRCCGHpRiZOnIgtW7Zg3759aN68eY3r7dy5E3379sXp06cRGhpabblOp4NOp1P+Li4uRlBQEHphCBxUjpY2877Fq8hqd0tUYDe+glarhYeHh8Ey1m79Yu3WrrbabQws7sFMmjQJ33zzDfbs2VPrCxQAIiIiAKDGF6larYZarba0SUQmYe0SyWV2wAghMHnyZGzYsAG7d+9GSEjIPW9z4sQJAEBAQIC5uyWyGGuXyDbMDpikpCSsXr0aX331Fdzd3VFQUAAA0Gg0aNKkCc6cOYPVq1djwIAB8Pb2RnZ2NqZPn47HHnsMYWFhVrsDRHXF2rUcD22RKcwOmPT0dAC3B6TdacWKFRg9ejScnJywfft2pKWlobS0FEFBQYiPj8fMmTMtajCRpVi7RLZh0SGy2gQFBSEzM9PczRNJw9olsg1+2SUREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSgr9oWY84WI1syVr1BrDmyDTswRARkRQMGCIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIpGDBERCQFA4aIiKTgQMs64mA1IiLTsAdDRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSggMtif4kOLD33jiQ2rrYgyEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSggFDRERSMGCIiEgKBgwREUnBgZZ1xMFT98bBakQEWNCDSU9PR1hYGDw8PODh4YHIyEhs2bJFWX7z5k0kJSXB29sbbm5uiI+PR2FhoVUaTWQJ1i6RbZgdMM2bN8cbb7yBrKwsHD16FH369MGQIUPw448/AgCmT5+OTZs2Yc2aNcjMzMTFixcxdOhQqzWcyFysXSLbUAkhhLU25uXlhXnz5mHYsGHw9fXF6tWrMWzYMADAL7/8gnbt2uHgwYPo1q2bSdsrLi6GRqNBLwyBg8rRWs0kyRraIbJbogK78RW0Wi08PDyMrsPaJaBx1m5DZpWT/JWVlfj8889RWlqKyMhIZGVloaKiAtHR0co6bdu2RYsWLXDw4MEat6PT6VBcXGwwEcnE2iWSx6KAOXnyJNzc3KBWqzFhwgRs2LAB7du3R0FBAZycnODp6Wmwvp+fHwoKCmrcXmpqKjQajTIFBQVZ0jyiGrF2ieSzKGAeeughnDhxAocPH8bEiRORkJCAn376yeztpaSkQKvVKlN+fr4lzSOqEWuXSD6LLlN2cnJC69atAQDh4eE4cuQIFi5ciKeeegrl5eUoKioy+CRYWFgIf3//GrenVquhVqstaRKRSVi7RPJZdaBlVVUVdDodwsPD4ejoiB07dijLcnJykJeXh8jISGvuksgqWLtE1md2DyYlJQWxsbFo0aIFSkpKsHr1auzevRtbt26FRqNBYmIikpOT4eXlBQ8PD0yePBmRkZEmX4VDJIsta3fDryfh4W7Z5zgONrUdPtbWZXbAXL58GaNGjcKlS5eg0WgQFhaGrVu34vHHHwcALFiwAHZ2doiPj4dOp0NMTAyWLFlitYYTmYu1S2QbVh0HY20cS9A4cSzBf2v3+q+t2IMhs3EcDBERkREMGCIikoIBQ0REUjBgiIhICgYMERFJwYAhIiIpGsUvWnKwWuPCx5qIAPZgiIhIEgYMERFJwYAhIiIpGDBERCQFA4aIiKRgwBARkRQMGCIikoIBQ0REUjSKgZZEjdWTbTrxt4wakYb2W0aNHXswREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFIwYIiISAoGDBERScGAISIiKRrFQEsOVmtcOFiNbM1aNcd6sy72YIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFI0ioGWZBscrEZE1mR2DyY9PR1hYWHw8PCAh4cHIiMjsWXLFmV5r169oFKpDKYJEyZYpdFElmDtEtmG2T2Y5s2b44033sCDDz4IIQRWrVqFIUOG4Pjx4+jQoQMAYNy4cXj11VeV27i4uFjeYiILsXaJbMPsgBk0aJDB3//+97+Rnp6OQ4cOKS9SFxcX+Pv7W9ZCIitj7RLZhlVO8ldWVuLzzz9HaWkpIiMjlfmffvopfHx80LFjR6SkpKCsrKzW7eh0OhQXFxtMRDKxdonksegk/8mTJxEZGYmbN2/Czc0NGzZsQPv27QEAI0eORHBwMAIDA5GdnY1XXnkFOTk5WL9+fY3bS01Nxdy5cy1pEpFJWLtE8qmEEMLcG5eXlyMvLw9arRZr167FBx98gMzMTOWFeqedO3eib9++OH36NEJDQ41uT6fTQafTKX8XFxcjKCgIvTCEX9dvA/frVWS3RAV24ytotVp4eHgAYO3eb/5MtduYWNSDcXJyQuvWrQEA4eHhOHLkCBYuXIhly5ZVWzciIgIAan2RqtVqqNVqS5pEZBLWLpF8Vh1oWVVVZfAp7k4nTpwAAAQEBFhzl0RWwdolsj6zezApKSmIjY1FixYtUFJSgtWrV2P37t3YunUrzpw5g9WrV2PAgAHw9vZGdnY2pk+fjsceewxhYWHWbD9RnbF2G4779dAW3WZ2wFy+fBmjRo3CpUuXoNFoEBYWhq1bt+Lxxx9Hfn4+tm/fjrS0NJSWliIoKAjx8fGYOXOmNdtOZBbWLpFtmB0wy5cvr3FZUFAQMjMzzd00kVSsXSLb4JddEhGRFAwYIiKSggFDRERSMGCIiEgKBgwREUnBgCEiIin4i5b3AQ5WI6KGiD0YIiKSggFDRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFBxoSUR1xsG9ZAr2YIiISAoGDBERScGAISIiKRgwREQkBQOGiIikYMAQEZEUDBgiIpKCAUNERFJwoGU94mA1IrqfsQdDRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSggMtif4krDWwF+DgXjKN1Xowb7zxBlQqFaZNm6bMu3nzJpKSkuDt7Q03NzfEx8ejsLDQWrsksgrWLpEcVgmYI0eOYNmyZQgLCzOYP336dGzatAlr1qxBZmYmLl68iKFDh1pjl0RWwdolksfigLlx4waeeeYZ/N///R8eeOABZb5Wq8Xy5csxf/589OnTB+Hh4VixYgUOHDiAQ4cOWbpbIouxdonksjhgkpKSMHDgQERHRxvMz8rKQkVFhcH8tm3bokWLFjh48KDRbel0OhQXFxtMRLKwdonksugk/+eff45jx47hyJEj1ZYVFBTAyckJnp6eBvP9/PxQUFBgdHupqamYO3euJU0iMglrl0g+s3sw+fn5mDp1Kj799FM4OztbpTEpKSnQarXKlJ+fb5XtEt2JtUtkG2YHTFZWFi5fvoxHHnkEDg4OcHBwQGZmJhYtWgQHBwf4+fmhvLwcRUVFBrcrLCyEv7+/0W2q1Wp4eHgYTETWxtolsg2zD5H17dsXJ0+eNJg3ZswYtG3bFq+88gqCgoLg6OiIHTt2ID4+HgCQk5ODvLw8REZGmrQPIQQA4BYqAGFuSxuu4pIqq2znlqiwynbuV7dw+/HR19OftXatVW8Aa85W7q7dRkdYUc+ePcXUqVOVvydMmCBatGghdu7cKY4ePSoiIyNFZGSkydvLz88XuP3y5MTJ4ik/P5+1y6lRTrXVbkMmdST/ggULYGdnh/j4eOh0OsTExGDJkiUm3z4wMBD5+flwd3eHSqUyuk5xcTGCgoKQn5/PwxI20BgfbyEESkpKEBgYaPJtWLv3n8b4eJtTuw2JSojG2ve6rbi4GBqNBlqtttEUTWPGx9t6+FjaFh9v2+OXXRIRkRQMGCIikqLRB4xarcbs2bOhVqvruyl/Cny8rYePpW3x8ba9Rn8OhoiIGqZG34MhIqKGiQFDRERSMGCIiEgKBgwREUnBgCEiIikafcAsXrwYLVu2hLOzMyIiIvDdd9/Vd5PuO3PmzIFKpTKY2rZtW9/NavRYu/KxdutXow6YL774AsnJyZg9ezaOHTuGzp07IyYmBpcvX67vpt13OnTogEuXLinTvn376rtJjRpr13ZYu/WnUQfM/PnzMW7cOIwZMwbt27fH0qVL4eLigg8//LC+m3bfcXBwgL+/vzL5+PjUd5MaNdau7bB260+jDZjy8nJkZWUZ/G66nZ0doqOja/zddDLfqVOnEBgYiFatWuGZZ55BXl5efTep0WLt2hZrt/402oC5evUqKisr4efnZzC/tt9NJ/NERERg5cqVyMjIQHp6OnJzcxEVFYWSkpL6blqjxNq1HdZu/ZL6ezB0f4iNjVX+HxYWhoiICAQHB+PLL79EYmJiPbaMqHas3frVaHswPj4+sLe3R2FhocH82n43nazD09MTbdq0wenTp+u7KY0Sa7f+sHZtq9EGjJOTE8LDw7Fjxw5lXlVVFXbs2GHy76aTeW7cuIEzZ84gICCgvpvSKLF26w9r17Ya9SGy5ORkJCQk4NFHH0XXrl2RlpaG0tJSjBkzpr6bdl958cUXMWjQIAQHB+PixYuYPXs27O3tMWLEiPpuWqPF2rUN1m79atQB89RTT+HKlSuYNWsWCgoK8PDDDyMjI6PayVOyzPnz5zFixAhcu3YNvr6+6NGjBw4dOgRfX9/6blqjxdq1DdZu/eLvwRARkRSN9hwMERE1bAwYIiKSggFDRERSMGCIiEgKBgwREUnBgCEiIikYMEREJAUDhoiIpGDAEBGRFAwYIiKSggFDRERS/D9Rz8TxBHRy5gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songStrings = numpy.array([\n",
    "    \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "\n",
    "def generateIOData(nrOfSongs,songStrings):\n",
    "    notes = list(\"ABCDEFGH\")\n",
    "    source = []\n",
    "    target_one_hot = []\n",
    "    target_indices = []\n",
    "    raw_target = []\n",
    "\n",
    "    for s in range(nrOfSongs):\n",
    "        for i in range(42):  # Adjust for loop to cover up to the second last character\n",
    "            input_one_hot = np.zeros((41, 8))\n",
    "            current_target_one_hot = np.zeros((41, 8))\n",
    "            current_target_indices = np.zeros(41, dtype=int)\n",
    "            for j in range(41):\n",
    "                if (i + j) < len(songStrings[s]):  # Ensure we don't exceed the song's length\n",
    "                    input_index = notes.index(songStrings[s][(i+j) % len(songStrings[s])])\n",
    "                    input_one_hot[j][input_index] = 1.0\n",
    "                    if (i + j + 1) < len(songStrings[s]):\n",
    "                        target_index = notes.index(songStrings[s][(i+j+1) % len(songStrings[s])])\n",
    "                        current_target_one_hot[j][target_index] = 1.0\n",
    "                        current_target_indices[j] = target_index\n",
    "            source.append(input_one_hot)\n",
    "            target_one_hot.append(current_target_one_hot)\n",
    "            target_indices.append(current_target_indices)  # Append the array of indices for this input window\n",
    "            raw_target.append(target_index)  # Keep track of the target indices\n",
    "    return np.array(source), np.array(target_one_hot), np.array(target_indices) , np.array(raw_target)\n",
    "\n",
    "I, O_hot, O_indices, songs = generateIOData(4,songStrings)\n",
    "print(f\"Input shape: {I.shape}, Output (One-Hot) shape: {O_hot.shape}, Output (Indices) shape: {O_indices.shape}\")\n",
    "\n",
    "# Display the first input and raw output for visualization\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(I[0], aspect='auto')\n",
    "plt.title(\"Input (One-Hot Encoded)\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(O_hot[0], aspect='auto')\n",
    "plt.title(\"Output (One-Hot Encoded)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3787b0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c2866e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, source, target):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    source = torch.tensor(source, dtype=torch.long)\n",
    "    target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        src = source.transpose(0, 1)  # Adjust for the expected input dimensions [sequence_length, batch_size]\n",
    "        tgt = target.transpose(0, 1)  # Same adjustment for the target\n",
    "        \n",
    "        output = model(src)  # Compute the output\n",
    "        \n",
    "        # The output is [sequence_length, batch_size, ntokens]. Get the most likely token predictions\n",
    "        predictions = output.argmax(dim=2)  # Get the index of the max log-probability\n",
    "        #print(predictions)\n",
    "        correct += (predictions == tgt).sum().item()  # Count how many predictions match the target\n",
    "        total += tgt.numel()  # Total number of predictions\n",
    "        \n",
    "    accuracy = correct / total  # Calculate the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ff013",
   "metadata": {},
   "source": [
    " ## Train Rnns on all songs at once with its corresponding combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec1416e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, songStrings, number_of_Songs):\n",
    "    L = []  # Losses\n",
    "    A = []  # Accuracies\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "    \n",
    "    # Assuming generateIOData has been adjusted to take only songStrings\n",
    "    I, _, O_indices, songs = generateIOData(number_of_Songs,songStrings)  # Use the full dataset\n",
    "    #print(f\"Input shape: {I.shape}, Output (Indices) shape: {O_indices.shape}\")\n",
    "    # Convert the dataset to tensors\n",
    "    inputs = torch.tensor(I, dtype=torch.float)\n",
    "    targets = torch.tensor(O_indices, dtype=torch.long)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()  # Zero the gradients at the start of each epoch\n",
    "        \n",
    "        # Shuffle dataset\n",
    "        indices = torch.randperm(inputs.size(0))\n",
    "        inputs_shuffled = inputs[indices]\n",
    "        targets_shuffled = targets[indices]\n",
    "        \n",
    "        # Assuming the model expects inputs of shape [seq_len, batch, feature]\n",
    "        src = inputs_shuffled\n",
    "        tgt = targets_shuffled\n",
    "        #print(f\"src shape: {src.shape}, tgt shape: {tgt.shape}\")\n",
    "        # Forward pass\n",
    "        outputs = model(src)\n",
    "        output_flat = outputs.view(-1, outputs.shape[-1])  # Flatten output for CrossEntropyLoss\n",
    "        loss = criterion(output_flat, tgt.view(-1))\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss = loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted_indices = torch.max(output_flat, 1)\n",
    "        print(f'predicted { predicted_indices}')\n",
    "        print(f'target {tgt.view(-1)}')\n",
    "        correct_predictions = (predicted_indices == tgt.view(-1)).sum().item()\n",
    "        total_accuracy = correct_predictions / tgt.numel()\n",
    "        \n",
    "        # Log the loss and accuracy\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {total_accuracy:.4f}')\n",
    "        \n",
    "        L.append(total_loss)\n",
    "        A.append(total_accuracy)\n",
    "\n",
    "        # Early stopping criteria (optional)\n",
    "        if total_accuracy >= 0.97:\n",
    "            print(\"Early stopping criteria met\")\n",
    "            break\n",
    "\n",
    "    return L, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b3d44c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted tensor([3, 2, 0,  ..., 2, 2, 2])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "Epoch 1, Loss: 2.0266, Accuracy: 0.0495\n",
      "predicted tensor([3, 2, 0,  ..., 2, 2, 2])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 2, 2, 2])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 2,  ..., 0, 2, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 5, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 1, 4, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 2, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 1, 4])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "Epoch 101, Loss: 1.3383, Accuracy: 0.5719\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 2, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 5, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 5, 0])\n",
      "target tensor([1, 4, 5,  ..., 2, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 5, 1])\n",
      "predicted tensor([0, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "Epoch 201, Loss: 0.9669, Accuracy: 0.6543\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 1, 4])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 5, 1])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 1, 2, 0])\n",
      "target tensor([4, 5, 0,  ..., 1, 4, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "Epoch 301, Loss: 0.7813, Accuracy: 0.7548\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 5,  ..., 5, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 5, 0, 0])\n",
      "predicted tensor([2, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 1, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 1, 2, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 3, 2, 0])\n",
      "target tensor([5, 4, 4,  ..., 3, 2, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 1,  ..., 2, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 2, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 5, 5,  ..., 2, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 2, 0, 0])\n",
      "predicted tensor([3, 1, 4,  ..., 3, 4, 5])\n",
      "target tensor([0, 3, 5,  ..., 3, 4, 5])\n",
      "Epoch 401, Loss: 0.6314, Accuracy: 0.7976\n",
      "predicted tensor([5, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 4, 5, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 5, 1])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 5, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 5, 1, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 4, 5, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 5, 1])\n",
      "predicted tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 2, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 6, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 2, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 4, 5])\n",
      "target tensor([4, 5, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 2, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 1, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 1, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 2, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 2, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "Epoch 501, Loss: 0.5224, Accuracy: 0.8261\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 3, 2, 0])\n",
      "target tensor([4, 3, 6,  ..., 3, 2, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 5, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 5, 1, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 4, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 4, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 1, 4])\n",
      "target tensor([4, 0, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "Epoch 601, Loss: 0.4370, Accuracy: 0.8688\n",
      "predicted tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 5, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 5, 1, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 5, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([6, 5, 1,  ..., 3, 3, 2])\n",
      "target tensor([0, 0, 6,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "target tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 6,  ..., 4, 5, 0])\n",
      "target tensor([0, 6, 5,  ..., 4, 5, 0])\n",
      "predicted tensor([4, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "target tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "Epoch 701, Loss: 0.3712, Accuracy: 0.8974\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 4, 5, 0])\n",
      "target tensor([2, 4, 5,  ..., 4, 5, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 3, 4, 5])\n",
      "target tensor([0, 2, 1,  ..., 3, 4, 5])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 2, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 2, 0, 0])\n",
      "predicted tensor([3, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "target tensor([4, 5, 4,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 1, 4])\n",
      "target tensor([3, 3, 2,  ..., 0, 1, 4])\n",
      "Epoch 801, Loss: 0.3176, Accuracy: 0.9104\n",
      "predicted tensor([3, 2, 3,  ..., 2, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 1, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 1, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 4, 5, 0])\n",
      "target tensor([2, 3, 4,  ..., 4, 5, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 5, 1, 0])\n",
      "target tensor([5, 4, 1,  ..., 5, 1, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 3, 3,  ..., 0, 5, 1])\n",
      "target tensor([4, 2, 1,  ..., 0, 5, 1])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 2,  ..., 1, 4, 0])\n",
      "target tensor([0, 1, 2,  ..., 1, 4, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 3, 3, 2])\n",
      "target tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([3, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "Epoch 901, Loss: 0.2734, Accuracy: 0.9292\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 5, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 5, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 4, 5, 0])\n",
      "target tensor([2, 3, 3,  ..., 4, 5, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 1, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 1, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 3, 2, 0])\n",
      "target tensor([1, 2, 5,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 1, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 1, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 1, 4])\n",
      "target tensor([5, 0, 1,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 1, 4])\n",
      "target tensor([0, 0, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 3,  ..., 3, 4, 5])\n",
      "target tensor([2, 0, 2,  ..., 3, 4, 5])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "Epoch 1001, Loss: 0.2397, Accuracy: 0.9384\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 1, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 1, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 2, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 2, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "target tensor([1, 5, 3,  ..., 1, 4, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 5, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 5, 0, 0])\n",
      "predicted tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 5, 1])\n",
      "target tensor([5, 0, 1,  ..., 0, 5, 1])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 1, 4])\n",
      "target tensor([3, 3, 2,  ..., 0, 1, 4])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 2,  ..., 3, 2, 0])\n",
      "target tensor([1, 0, 2,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 3, 4, 5])\n",
      "target tensor([2, 0, 3,  ..., 3, 4, 5])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 5, 1, 0])\n",
      "target tensor([2, 0, 3,  ..., 5, 1, 0])\n",
      "Epoch 1101, Loss: 0.2130, Accuracy: 0.9456\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 4, 5, 0])\n",
      "target tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 4, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 4, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 2, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 4,  ..., 2, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 5, 1, 0])\n",
      "target tensor([5, 4, 1,  ..., 5, 1, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "Epoch 1201, Loss: 0.1904, Accuracy: 0.9492\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 3, 3, 2])\n",
      "target tensor([2, 3, 4,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 5, 1])\n",
      "target tensor([6, 5, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 2, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 5, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 5, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "target tensor([0, 1, 4,  ..., 5, 1, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "target tensor([3, 4, 5,  ..., 4, 5, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 1, 4])\n",
      "target tensor([0, 1, 4,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 1, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 5, 1])\n",
      "target tensor([3, 2, 2,  ..., 0, 5, 1])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "Epoch 1301, Loss: 0.1730, Accuracy: 0.9538\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 2, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 2, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 3, 4, 5])\n",
      "target tensor([4, 5, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 3, 2, 0])\n",
      "target tensor([2, 5, 4,  ..., 3, 2, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 1,  ..., 3, 2, 0])\n",
      "target tensor([5, 0, 1,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "Epoch 1401, Loss: 0.1602, Accuracy: 0.9566\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 3, 3, 2])\n",
      "target tensor([2, 0, 3,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "target tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 1, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 1, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "Epoch 1501, Loss: 0.1500, Accuracy: 0.9582\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 4, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 4, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "target tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 5, 1, 0])\n",
      "target tensor([0, 0, 0,  ..., 5, 1, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 5, 1, 0])\n",
      "target tensor([6, 6, 0,  ..., 5, 1, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "target tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 6,  ..., 3, 3, 2])\n",
      "target tensor([0, 0, 6,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 4, 5, 0])\n",
      "target tensor([3, 4, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 4, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 4, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "Epoch 1601, Loss: 0.1418, Accuracy: 0.9604\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 2, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 2, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 5, 1, 0])\n",
      "target tensor([5, 3, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 0, 5, 1])\n",
      "target tensor([5, 4, 3,  ..., 0, 5, 1])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 1, 4])\n",
      "target tensor([1, 2, 3,  ..., 0, 1, 4])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 3, 2, 0])\n",
      "target tensor([3, 3, 2,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 4, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 4, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "Epoch 1701, Loss: 0.1348, Accuracy: 0.9615\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 4, 5, 0])\n",
      "target tensor([6, 6, 0,  ..., 4, 5, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 5, 1])\n",
      "target tensor([3, 4, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 1, 4, 0])\n",
      "target tensor([2, 0, 2,  ..., 1, 4, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 0,  ..., 4, 5, 0])\n",
      "target tensor([1, 5, 3,  ..., 4, 5, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 1, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 3,  ..., 5, 1, 0])\n",
      "target tensor([5, 4, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 3, 2, 0])\n",
      "target tensor([1, 0, 0,  ..., 3, 2, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 1, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 1, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "Epoch 1801, Loss: 0.1286, Accuracy: 0.9630\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "target tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 5, 1])\n",
      "target tensor([0, 5, 1,  ..., 0, 5, 1])\n",
      "predicted tensor([5, 2, 2,  ..., 5, 1, 0])\n",
      "target tensor([1, 0, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 3, 4, 5])\n",
      "target tensor([5, 0, 1,  ..., 3, 4, 5])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 2, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 5, 1])\n",
      "target tensor([0, 1, 2,  ..., 0, 5, 1])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 3, 3, 2])\n",
      "target tensor([3, 0, 5,  ..., 3, 3, 2])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 1, 4])\n",
      "target tensor([1, 2, 1,  ..., 0, 1, 4])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 3, 2, 0])\n",
      "target tensor([1, 2, 0,  ..., 3, 2, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 5, 1])\n",
      "target tensor([3, 4, 2,  ..., 0, 5, 1])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 3,  ..., 1, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 1, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 3, 4, 5])\n",
      "target tensor([2, 6, 6,  ..., 3, 4, 5])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "Epoch 1901, Loss: 0.1234, Accuracy: 0.9649\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 4, 5, 0])\n",
      "target tensor([5, 0, 3,  ..., 4, 5, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 4, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 4, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 1, 4])\n",
      "target tensor([2, 3, 4,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 5, 1])\n",
      "target tensor([2, 3, 4,  ..., 0, 5, 1])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 5, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 5, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 4, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "Epoch 2001, Loss: 0.1189, Accuracy: 0.9657\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 3, 4, 5])\n",
      "target tensor([3, 4, 5,  ..., 3, 4, 5])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 4, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 4, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "target tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 1, 4, 0])\n",
      "target tensor([0, 2, 1,  ..., 1, 4, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 1, 4])\n",
      "target tensor([1, 1, 2,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "target tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 3, 3, 2])\n",
      "target tensor([5, 3, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 1, 4])\n",
      "target tensor([1, 4, 5,  ..., 0, 1, 4])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 1, 4])\n",
      "target tensor([6, 6, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([1, 5, 5,  ..., 4, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 5, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 5, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "Epoch 2101, Loss: 0.1149, Accuracy: 0.9665\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 5, 1, 0])\n",
      "target tensor([0, 6, 5,  ..., 5, 1, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 3, 4, 5])\n",
      "target tensor([1, 4, 5,  ..., 3, 4, 5])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 1, 4, 0])\n",
      "target tensor([5, 0, 1,  ..., 1, 4, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 3, 2, 0])\n",
      "target tensor([5, 4, 5,  ..., 3, 2, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 3, 4, 5])\n",
      "target tensor([0, 0, 6,  ..., 3, 4, 5])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 3, 4, 5])\n",
      "target tensor([2, 5, 4,  ..., 3, 4, 5])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "Epoch 2201, Loss: 0.1114, Accuracy: 0.9668\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 5, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 5, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 1, 4, 0])\n",
      "target tensor([2, 0, 3,  ..., 1, 4, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 3, 3, 2])\n",
      "target tensor([3, 4, 5,  ..., 3, 3, 2])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "Epoch 2301, Loss: 0.1082, Accuracy: 0.9673\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 0,  ..., 3, 3, 2])\n",
      "target tensor([1, 4, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 2, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 3, 2, 0])\n",
      "target tensor([4, 4, 3,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 5, 1, 0])\n",
      "target tensor([3, 3, 2,  ..., 5, 1, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 5, 1])\n",
      "target tensor([4, 3, 2,  ..., 0, 5, 1])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 1, 4, 0])\n",
      "target tensor([5, 4, 4,  ..., 1, 4, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 4, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 4, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 1, 4, 0])\n",
      "target tensor([2, 3, 4,  ..., 1, 4, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 1, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 1, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "Epoch 2401, Loss: 0.1051, Accuracy: 0.9676\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 3, 3, 2])\n",
      "target tensor([1, 2, 3,  ..., 3, 3, 2])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 5, 1])\n",
      "target tensor([4, 3, 3,  ..., 0, 5, 1])\n",
      "predicted tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 3, 2, 0])\n",
      "target tensor([4, 2, 1,  ..., 3, 2, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 3, 4, 5])\n",
      "target tensor([0, 3, 5,  ..., 3, 4, 5])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 0,  ..., 3, 4, 5])\n",
      "target tensor([2, 1, 5,  ..., 3, 4, 5])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 1, 4])\n",
      "target tensor([0, 2, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 3, 4, 5])\n",
      "target tensor([0, 0, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 3, 4, 5])\n",
      "target tensor([5, 0, 1,  ..., 3, 4, 5])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "Epoch 2501, Loss: 0.1023, Accuracy: 0.9682\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 5, 1, 0])\n",
      "target tensor([4, 5, 0,  ..., 5, 1, 0])\n",
      "predicted tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 4,  ..., 3, 3, 2])\n",
      "target tensor([3, 0, 4,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "Epoch 2601, Loss: 0.0997, Accuracy: 0.9689\n",
      "predicted tensor([5, 4, 5,  ..., 0, 5, 1])\n",
      "target tensor([3, 4, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 3, 3, 2])\n",
      "target tensor([1, 2, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 3, 4, 5])\n",
      "target tensor([3, 5, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 2, 0])\n",
      "target tensor([4, 5, 0,  ..., 3, 2, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 5,  ..., 0, 5, 1])\n",
      "target tensor([3, 0, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 1, 4])\n",
      "target tensor([4, 5, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 2, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 2, 0])\n",
      "target tensor([4, 5, 4,  ..., 3, 2, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 5, 1, 0])\n",
      "target tensor([0, 1, 4,  ..., 5, 1, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 4, 5, 0])\n",
      "target tensor([0, 1, 2,  ..., 4, 5, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "Epoch 2701, Loss: 0.0974, Accuracy: 0.9691\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 5, 1])\n",
      "target tensor([1, 2, 5,  ..., 0, 5, 1])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "target tensor([4, 5, 0,  ..., 3, 3, 2])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 3, 3, 2])\n",
      "target tensor([0, 1, 2,  ..., 3, 3, 2])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 3, 3, 2])\n",
      "target tensor([1, 4, 5,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 1, 4])\n",
      "target tensor([4, 2, 1,  ..., 0, 1, 4])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "Epoch 2801, Loss: 0.0953, Accuracy: 0.9689\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 2,  ..., 1, 4, 0])\n",
      "target tensor([4, 0, 2,  ..., 1, 4, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 3, 3, 2])\n",
      "target tensor([5, 4, 2,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 3, 4, 5])\n",
      "target tensor([4, 5, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 3, 4, 5])\n",
      "target tensor([3, 4, 5,  ..., 3, 4, 5])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 5, 1, 0])\n",
      "target tensor([6, 6, 0,  ..., 5, 1, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 5, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 5, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 5, 1, 0])\n",
      "target tensor([5, 5, 4,  ..., 5, 1, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 4, 5, 0])\n",
      "target tensor([5, 0, 1,  ..., 4, 5, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 1, 4, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 4, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "Epoch 2901, Loss: 0.0935, Accuracy: 0.9692\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 4, 0, 0])\n",
      "target tensor([4, 5, 4,  ..., 4, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 1, 4])\n",
      "target tensor([5, 0, 3,  ..., 0, 1, 4])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 3, 2, 0])\n",
      "target tensor([0, 1, 2,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 3, 2, 0])\n",
      "target tensor([0, 3, 4,  ..., 3, 2, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 1, 4])\n",
      "target tensor([0, 6, 5,  ..., 0, 1, 4])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 3, 2, 0])\n",
      "target tensor([0, 1, 2,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 1, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 3, 2, 0])\n",
      "target tensor([1, 4, 0,  ..., 3, 2, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 1, 4, 0])\n",
      "target tensor([5, 4, 4,  ..., 1, 4, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "Epoch 3001, Loss: 0.0917, Accuracy: 0.9692\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 1, 4])\n",
      "target tensor([4, 5, 5,  ..., 0, 1, 4])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 1, 4, 0])\n",
      "target tensor([0, 1, 2,  ..., 1, 4, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 1, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([0, 1, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 1, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 2, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 2, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 2, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 2,  ..., 1, 4, 0])\n",
      "target tensor([5, 3, 2,  ..., 1, 4, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 3, 3, 2])\n",
      "target tensor([4, 3, 2,  ..., 3, 3, 2])\n",
      "predicted tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 6, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 4, 5, 0])\n",
      "target tensor([5, 5, 3,  ..., 4, 5, 0])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([0, 3, 0,  ..., 0, 0, 0])\n",
      "Epoch 3101, Loss: 0.0901, Accuracy: 0.9695\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 6,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([4, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 1, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 1, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 4, 0, 0])\n",
      "target tensor([5, 0, 0,  ..., 4, 0, 0])\n",
      "predicted tensor([0, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([3, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 3, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 5, 1, 0])\n",
      "target tensor([4, 0, 5,  ..., 5, 1, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 2, 0, 0])\n",
      "predicted tensor([4, 2, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 2, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 3, 4, 5])\n",
      "target tensor([1, 4, 0,  ..., 3, 4, 5])\n",
      "predicted tensor([1, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([2, 0, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 0, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 5, 1, 0])\n",
      "target tensor([5, 4, 4,  ..., 5, 1, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 4, 2,  ..., 1, 4, 0])\n",
      "target tensor([3, 4, 1,  ..., 1, 4, 0])\n",
      "predicted tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "target tensor([2, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 4, 5, 0])\n",
      "target tensor([6, 0, 0,  ..., 4, 5, 0])\n",
      "predicted tensor([3, 2, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([6, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 5, 1])\n",
      "target tensor([3, 2, 2,  ..., 0, 5, 1])\n",
      "predicted tensor([3, 4, 3,  ..., 1, 0, 0])\n",
      "target tensor([5, 5, 3,  ..., 1, 0, 0])\n",
      "predicted tensor([1, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 3, 1,  ..., 0, 0, 0])\n",
      "target tensor([2, 1, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 1, 1,  ..., 0, 0, 0])\n",
      "target tensor([1, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 2, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 0,  ..., 0, 1, 4])\n",
      "target tensor([1, 0, 0,  ..., 0, 1, 4])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "Epoch 3201, Loss: 0.0886, Accuracy: 0.9695\n",
      "predicted tensor([5, 0, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 2, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 1, 4])\n",
      "target tensor([0, 1, 2,  ..., 0, 1, 4])\n",
      "predicted tensor([6, 0, 6,  ..., 0, 0, 0])\n",
      "target tensor([0, 0, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 5, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 5, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "target tensor([2, 3, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 1, 5,  ..., 0, 0, 0])\n",
      "target tensor([0, 6, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 2, 5,  ..., 0, 0, 0])\n",
      "target tensor([2, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 6,  ..., 0, 0, 0])\n",
      "target tensor([3, 6, 6,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 1,  ..., 0, 0, 0])\n",
      "target tensor([5, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 2, 2,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([6, 0, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 3,  ..., 0, 0, 0])\n",
      "target tensor([4, 4, 3,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 4,  ..., 5, 1, 0])\n",
      "target tensor([2, 3, 4,  ..., 5, 1, 0])\n",
      "predicted tensor([1, 5, 5,  ..., 0, 0, 0])\n",
      "target tensor([6, 5, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 4,  ..., 0, 0, 0])\n",
      "target tensor([5, 4, 4,  ..., 0, 0, 0])\n",
      "predicted tensor([4, 5, 0,  ..., 0, 0, 0])\n",
      "target tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 4, 0,  ..., 0, 0, 0])\n",
      "target tensor([1, 0, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "target tensor([0, 1, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "predicted tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "target tensor([3, 4, 5,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 0, 1,  ..., 0, 0, 0])\n",
      "target tensor([4, 2, 1,  ..., 0, 0, 0])\n",
      "predicted tensor([5, 4, 2,  ..., 0, 0, 0])\n",
      "target tensor([3, 3, 2,  ..., 0, 0, 0])\n",
      "predicted tensor([2, 3, 0,  ..., 0, 0, 0])\n",
      "target tensor([5, 3, 0,  ..., 0, 0, 0])\n",
      "Early stopping criteria met\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "num_epochs = 7000\n",
    "number_of_Songs = 4\n",
    "L, A  = train_model(model, num_epochs, songStrings= songStrings, number_of_Songs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7261b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN...\n",
      "Epoch 1, Loss: 2.2120, Accuracy: 0.1161\n",
      "Epoch 101, Loss: 1.3491, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 0.9376, Accuracy: 0.6549\n",
      "Epoch 301, Loss: 0.7356, Accuracy: 0.7699\n",
      "Epoch 401, Loss: 0.6032, Accuracy: 0.8063\n",
      "Epoch 501, Loss: 0.5142, Accuracy: 0.8328\n",
      "Epoch 601, Loss: 0.4390, Accuracy: 0.8650\n",
      "Epoch 701, Loss: 0.3735, Accuracy: 0.8991\n",
      "Epoch 801, Loss: 0.3155, Accuracy: 0.9210\n",
      "Epoch 901, Loss: 0.2669, Accuracy: 0.9357\n",
      "Epoch 1001, Loss: 0.2323, Accuracy: 0.9441\n",
      "Epoch 1101, Loss: 0.2076, Accuracy: 0.9499\n",
      "Epoch 1201, Loss: 0.1887, Accuracy: 0.9519\n",
      "Epoch 1301, Loss: 0.1741, Accuracy: 0.9551\n",
      "Epoch 1401, Loss: 0.1623, Accuracy: 0.9567\n",
      "Epoch 1501, Loss: 0.1525, Accuracy: 0.9576\n",
      "Epoch 1601, Loss: 0.1443, Accuracy: 0.9599\n",
      "Epoch 1701, Loss: 0.1373, Accuracy: 0.9617\n",
      "Epoch 1801, Loss: 0.1313, Accuracy: 0.9627\n",
      "Epoch 1901, Loss: 0.1261, Accuracy: 0.9636\n",
      "Epoch 2001, Loss: 0.1215, Accuracy: 0.9639\n",
      "Epoch 2101, Loss: 0.1173, Accuracy: 0.9649\n",
      "Epoch 2201, Loss: 0.1135, Accuracy: 0.9657\n",
      "Epoch 2301, Loss: 0.1101, Accuracy: 0.9662\n",
      "Epoch 2401, Loss: 0.1070, Accuracy: 0.9666\n",
      "Epoch 2501, Loss: 0.1041, Accuracy: 0.9669\n",
      "Epoch 2601, Loss: 0.1014, Accuracy: 0.9676\n",
      "Epoch 2701, Loss: 0.0990, Accuracy: 0.9678\n",
      "Epoch 2801, Loss: 0.0968, Accuracy: 0.9682\n",
      "Epoch 2901, Loss: 0.0948, Accuracy: 0.9688\n",
      "Epoch 3001, Loss: 0.0930, Accuracy: 0.9695\n",
      "Early stopping criteria met\n",
      "Training RNNA...\n",
      "Epoch 1, Loss: 2.1424, Accuracy: 0.0258\n",
      "Epoch 101, Loss: 1.4228, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 1.2243, Accuracy: 0.5743\n",
      "Epoch 301, Loss: 1.0482, Accuracy: 0.5949\n",
      "Epoch 401, Loss: 1.0098, Accuracy: 0.5912\n",
      "Epoch 501, Loss: 1.1119, Accuracy: 0.5656\n",
      "Epoch 601, Loss: 0.9915, Accuracy: 0.5877\n",
      "Epoch 701, Loss: 0.9822, Accuracy: 0.5903\n",
      "Epoch 801, Loss: 0.9727, Accuracy: 0.5929\n",
      "Epoch 901, Loss: 0.9762, Accuracy: 0.6084\n",
      "Epoch 1001, Loss: 0.9412, Accuracy: 0.6105\n",
      "Epoch 1101, Loss: 0.9324, Accuracy: 0.6132\n",
      "Epoch 1201, Loss: 0.9239, Accuracy: 0.6208\n",
      "Epoch 1301, Loss: 0.9210, Accuracy: 0.6201\n",
      "Epoch 1401, Loss: 0.9146, Accuracy: 0.6298\n",
      "Epoch 1501, Loss: 0.9072, Accuracy: 0.6356\n",
      "Epoch 1601, Loss: 0.8978, Accuracy: 0.6405\n",
      "Epoch 1701, Loss: 0.8848, Accuracy: 0.6476\n",
      "Epoch 1801, Loss: 0.8642, Accuracy: 0.6611\n",
      "Epoch 1901, Loss: 0.8283, Accuracy: 0.6732\n",
      "Epoch 2001, Loss: 0.7833, Accuracy: 0.6940\n",
      "Epoch 2101, Loss: 0.7481, Accuracy: 0.7038\n",
      "Epoch 2201, Loss: 0.7359, Accuracy: 0.7056\n",
      "Epoch 2301, Loss: 0.7161, Accuracy: 0.7093\n",
      "Epoch 2401, Loss: 0.6932, Accuracy: 0.7224\n",
      "Epoch 2501, Loss: 0.6773, Accuracy: 0.7326\n",
      "Epoch 2601, Loss: 0.6624, Accuracy: 0.7451\n",
      "Epoch 2701, Loss: 0.6523, Accuracy: 0.7580\n",
      "Epoch 2801, Loss: 0.6362, Accuracy: 0.7744\n",
      "Epoch 2901, Loss: 0.6248, Accuracy: 0.7891\n",
      "Epoch 3001, Loss: 0.6141, Accuracy: 0.7933\n",
      "Epoch 3101, Loss: 0.6016, Accuracy: 0.8004\n",
      "Epoch 3201, Loss: 0.5897, Accuracy: 0.8065\n",
      "Epoch 3301, Loss: 0.5785, Accuracy: 0.8097\n",
      "Epoch 3401, Loss: 0.5656, Accuracy: 0.8130\n",
      "Epoch 3501, Loss: 0.5517, Accuracy: 0.8190\n",
      "Epoch 3601, Loss: 0.5382, Accuracy: 0.8220\n",
      "Epoch 3701, Loss: 0.5244, Accuracy: 0.8248\n",
      "Epoch 3801, Loss: 0.5121, Accuracy: 0.8252\n",
      "Epoch 3901, Loss: 0.5112, Accuracy: 0.8264\n",
      "Epoch 4001, Loss: 0.4920, Accuracy: 0.8300\n",
      "Epoch 4101, Loss: 0.4823, Accuracy: 0.8314\n",
      "Epoch 4201, Loss: 0.4731, Accuracy: 0.8325\n",
      "Epoch 4301, Loss: 0.4664, Accuracy: 0.8364\n",
      "Epoch 4401, Loss: 0.4712, Accuracy: 0.8349\n",
      "Epoch 4501, Loss: 0.4491, Accuracy: 0.8418\n",
      "Epoch 4601, Loss: 0.4407, Accuracy: 0.8451\n",
      "Epoch 4701, Loss: 0.4321, Accuracy: 0.8471\n",
      "Epoch 4801, Loss: 0.4234, Accuracy: 0.8490\n",
      "Epoch 4901, Loss: 0.4135, Accuracy: 0.8502\n",
      "Epoch 5001, Loss: 0.4148, Accuracy: 0.8524\n",
      "Epoch 5101, Loss: 0.3944, Accuracy: 0.8563\n",
      "Epoch 5201, Loss: 0.3837, Accuracy: 0.8628\n",
      "Epoch 5301, Loss: 0.3730, Accuracy: 0.8679\n",
      "Epoch 5401, Loss: 0.3621, Accuracy: 0.8728\n",
      "Epoch 5501, Loss: 0.3514, Accuracy: 0.8762\n",
      "Epoch 5601, Loss: 0.3652, Accuracy: 0.8753\n",
      "Epoch 5701, Loss: 0.3307, Accuracy: 0.8852\n",
      "Epoch 5801, Loss: 0.3207, Accuracy: 0.8878\n",
      "Epoch 5901, Loss: 0.3049, Accuracy: 0.8991\n",
      "Epoch 6001, Loss: 0.2912, Accuracy: 0.9039\n",
      "Epoch 6101, Loss: 0.2790, Accuracy: 0.9068\n",
      "Epoch 6201, Loss: 0.2668, Accuracy: 0.9110\n",
      "Epoch 6301, Loss: 0.2568, Accuracy: 0.9145\n",
      "Epoch 6401, Loss: 0.2476, Accuracy: 0.9177\n",
      "Epoch 6501, Loss: 0.2486, Accuracy: 0.9167\n",
      "Epoch 6601, Loss: 0.2336, Accuracy: 0.9231\n",
      "Epoch 6701, Loss: 0.2266, Accuracy: 0.9260\n",
      "Epoch 6801, Loss: 0.2203, Accuracy: 0.9286\n",
      "Epoch 6901, Loss: 0.2140, Accuracy: 0.9297\n",
      "Training LSTM...\n",
      "Epoch 1, Loss: 2.0480, Accuracy: 0.0000\n",
      "Epoch 101, Loss: 1.4333, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 1.1016, Accuracy: 0.5833\n",
      "Epoch 301, Loss: 0.9694, Accuracy: 0.6336\n",
      "Epoch 401, Loss: 0.8382, Accuracy: 0.6976\n",
      "Epoch 501, Loss: 0.7179, Accuracy: 0.7533\n",
      "Epoch 601, Loss: 0.6262, Accuracy: 0.8021\n",
      "Epoch 701, Loss: 0.5578, Accuracy: 0.8246\n",
      "Epoch 801, Loss: 0.5082, Accuracy: 0.8378\n",
      "Epoch 901, Loss: 0.4682, Accuracy: 0.8519\n",
      "Epoch 1001, Loss: 0.4330, Accuracy: 0.8628\n",
      "Epoch 1101, Loss: 0.4000, Accuracy: 0.8805\n",
      "Epoch 1201, Loss: 0.3682, Accuracy: 0.8959\n",
      "Epoch 1301, Loss: 0.3411, Accuracy: 0.9048\n",
      "Epoch 1401, Loss: 0.3182, Accuracy: 0.9158\n",
      "Epoch 1501, Loss: 0.2991, Accuracy: 0.9207\n",
      "Epoch 1601, Loss: 0.2826, Accuracy: 0.9261\n",
      "Epoch 1701, Loss: 0.2673, Accuracy: 0.9302\n",
      "Epoch 1801, Loss: 0.2531, Accuracy: 0.9326\n",
      "Epoch 1901, Loss: 0.2409, Accuracy: 0.9400\n",
      "Epoch 2001, Loss: 0.2305, Accuracy: 0.9438\n",
      "Epoch 2101, Loss: 0.2214, Accuracy: 0.9445\n",
      "Epoch 2201, Loss: 0.2132, Accuracy: 0.9456\n",
      "Epoch 2301, Loss: 0.2060, Accuracy: 0.9469\n",
      "Epoch 2401, Loss: 0.1992, Accuracy: 0.9470\n",
      "Epoch 2501, Loss: 0.1932, Accuracy: 0.9473\n",
      "Epoch 2601, Loss: 0.1875, Accuracy: 0.9480\n",
      "Epoch 2701, Loss: 0.1819, Accuracy: 0.9493\n",
      "Epoch 2801, Loss: 0.1761, Accuracy: 0.9528\n",
      "Epoch 2901, Loss: 0.1711, Accuracy: 0.9535\n",
      "Epoch 3001, Loss: 0.1663, Accuracy: 0.9541\n",
      "Epoch 3101, Loss: 0.1622, Accuracy: 0.9546\n",
      "Epoch 3201, Loss: 0.1584, Accuracy: 0.9562\n",
      "Epoch 3301, Loss: 0.1552, Accuracy: 0.9572\n",
      "Epoch 3401, Loss: 0.1522, Accuracy: 0.9583\n",
      "Epoch 3501, Loss: 0.1494, Accuracy: 0.9593\n",
      "Epoch 3601, Loss: 0.1465, Accuracy: 0.9595\n",
      "Epoch 3701, Loss: 0.1437, Accuracy: 0.9599\n",
      "Epoch 3801, Loss: 0.1410, Accuracy: 0.9611\n",
      "Epoch 3901, Loss: 0.1385, Accuracy: 0.9614\n",
      "Epoch 4001, Loss: 0.1359, Accuracy: 0.9614\n",
      "Epoch 4101, Loss: 0.1335, Accuracy: 0.9624\n",
      "Epoch 4201, Loss: 0.1311, Accuracy: 0.9631\n",
      "Epoch 4301, Loss: 0.1287, Accuracy: 0.9634\n",
      "Epoch 4401, Loss: 0.1264, Accuracy: 0.9636\n",
      "Epoch 4501, Loss: 0.1242, Accuracy: 0.9639\n",
      "Epoch 4601, Loss: 0.1222, Accuracy: 0.9647\n",
      "Epoch 4701, Loss: 0.1203, Accuracy: 0.9650\n",
      "Epoch 4801, Loss: 0.1186, Accuracy: 0.9647\n",
      "Epoch 4901, Loss: 0.1169, Accuracy: 0.9653\n",
      "Epoch 5001, Loss: 0.1154, Accuracy: 0.9656\n",
      "Epoch 5101, Loss: 0.1139, Accuracy: 0.9660\n",
      "Epoch 5201, Loss: 0.1126, Accuracy: 0.9665\n",
      "Epoch 5301, Loss: 0.1113, Accuracy: 0.9673\n",
      "Epoch 5401, Loss: 0.1102, Accuracy: 0.9678\n",
      "Epoch 5501, Loss: 0.1091, Accuracy: 0.9685\n",
      "Epoch 5601, Loss: 0.1134, Accuracy: 0.9670\n",
      "Epoch 5701, Loss: 0.1075, Accuracy: 0.9685\n",
      "Epoch 5801, Loss: 0.1067, Accuracy: 0.9685\n",
      "Epoch 5901, Loss: 0.1061, Accuracy: 0.9685\n",
      "Epoch 6001, Loss: 0.1054, Accuracy: 0.9686\n",
      "Epoch 6101, Loss: 0.1048, Accuracy: 0.9688\n",
      "Epoch 6201, Loss: 0.1042, Accuracy: 0.9688\n",
      "Epoch 6301, Loss: 0.1036, Accuracy: 0.9688\n",
      "Epoch 6401, Loss: 0.1029, Accuracy: 0.9689\n",
      "Epoch 6501, Loss: 0.1023, Accuracy: 0.9691\n",
      "Epoch 6601, Loss: 0.1016, Accuracy: 0.9691\n",
      "Epoch 6701, Loss: 0.1009, Accuracy: 0.9692\n",
      "Epoch 6801, Loss: 0.1002, Accuracy: 0.9692\n",
      "Epoch 6901, Loss: 0.0995, Accuracy: 0.9695\n",
      "Training LSTMA...\n",
      "Epoch 1, Loss: 2.0419, Accuracy: 0.0183\n",
      "Epoch 101, Loss: 1.5277, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 1.2628, Accuracy: 0.5719\n",
      "Epoch 301, Loss: 1.0756, Accuracy: 0.5944\n",
      "Epoch 401, Loss: 1.0267, Accuracy: 0.5855\n",
      "Epoch 501, Loss: 1.0078, Accuracy: 0.5859\n",
      "Epoch 601, Loss: 0.9976, Accuracy: 0.5873\n",
      "Epoch 701, Loss: 0.9898, Accuracy: 0.5889\n",
      "Epoch 801, Loss: 0.9836, Accuracy: 0.5916\n",
      "Epoch 901, Loss: 0.9784, Accuracy: 0.5945\n",
      "Epoch 1001, Loss: 0.9722, Accuracy: 0.5983\n",
      "Epoch 1101, Loss: 0.9604, Accuracy: 0.6108\n",
      "Epoch 1201, Loss: 0.9249, Accuracy: 0.6331\n",
      "Epoch 1301, Loss: 0.8923, Accuracy: 0.6417\n",
      "Epoch 1401, Loss: 0.8624, Accuracy: 0.6471\n",
      "Epoch 1501, Loss: 0.8281, Accuracy: 0.6712\n",
      "Epoch 1601, Loss: 0.7940, Accuracy: 0.6855\n",
      "Epoch 1701, Loss: 0.7590, Accuracy: 0.6986\n",
      "Epoch 1801, Loss: 0.7252, Accuracy: 0.7123\n",
      "Epoch 1901, Loss: 0.6923, Accuracy: 0.7494\n",
      "Epoch 2001, Loss: 0.6614, Accuracy: 0.7663\n",
      "Epoch 2101, Loss: 0.6288, Accuracy: 0.7893\n",
      "Epoch 2201, Loss: 0.5921, Accuracy: 0.8092\n",
      "Epoch 2301, Loss: 0.5565, Accuracy: 0.8211\n",
      "Epoch 2401, Loss: 0.5238, Accuracy: 0.8304\n",
      "Epoch 2501, Loss: 0.4914, Accuracy: 0.8445\n",
      "Epoch 2601, Loss: 0.4606, Accuracy: 0.8518\n",
      "Epoch 2701, Loss: 0.4331, Accuracy: 0.8582\n",
      "Epoch 2801, Loss: 0.4082, Accuracy: 0.8651\n",
      "Epoch 2901, Loss: 0.3861, Accuracy: 0.8721\n",
      "Epoch 3001, Loss: 0.3664, Accuracy: 0.8802\n",
      "Epoch 3101, Loss: 0.3484, Accuracy: 0.8878\n",
      "Epoch 3201, Loss: 0.3315, Accuracy: 0.8955\n",
      "Epoch 3301, Loss: 0.3148, Accuracy: 0.9035\n",
      "Epoch 3401, Loss: 0.3011, Accuracy: 0.9096\n",
      "Epoch 3501, Loss: 0.2885, Accuracy: 0.9138\n",
      "Epoch 3601, Loss: 0.2766, Accuracy: 0.9177\n",
      "Epoch 3701, Loss: 0.2653, Accuracy: 0.9209\n",
      "Epoch 3801, Loss: 0.2535, Accuracy: 0.9265\n",
      "Epoch 3901, Loss: 0.2433, Accuracy: 0.9307\n",
      "Epoch 4001, Loss: 0.2331, Accuracy: 0.9318\n",
      "Epoch 4101, Loss: 0.2236, Accuracy: 0.9370\n",
      "Epoch 4201, Loss: 0.2141, Accuracy: 0.9390\n",
      "Epoch 4301, Loss: 0.2050, Accuracy: 0.9416\n",
      "Epoch 4401, Loss: 0.1957, Accuracy: 0.9437\n",
      "Epoch 4501, Loss: 0.1868, Accuracy: 0.9483\n",
      "Epoch 4601, Loss: 0.1781, Accuracy: 0.9514\n",
      "Epoch 4701, Loss: 0.1695, Accuracy: 0.9550\n",
      "Epoch 4801, Loss: 0.1611, Accuracy: 0.9576\n",
      "Epoch 4901, Loss: 0.1534, Accuracy: 0.9608\n",
      "Epoch 5001, Loss: 0.1462, Accuracy: 0.9640\n",
      "Epoch 5101, Loss: 0.1394, Accuracy: 0.9659\n",
      "Epoch 5201, Loss: 0.1336, Accuracy: 0.9668\n",
      "Epoch 5301, Loss: 0.1281, Accuracy: 0.9684\n",
      "Early stopping criteria met\n",
      "Training GRU...\n",
      "Epoch 1, Loss: 2.1185, Accuracy: 0.0000\n",
      "Epoch 101, Loss: 1.3560, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 1.0347, Accuracy: 0.5900\n",
      "Epoch 301, Loss: 0.9389, Accuracy: 0.6540\n",
      "Epoch 401, Loss: 0.8024, Accuracy: 0.7436\n",
      "Epoch 501, Loss: 0.6453, Accuracy: 0.7957\n",
      "Epoch 601, Loss: 0.4973, Accuracy: 0.8290\n",
      "Epoch 701, Loss: 0.3725, Accuracy: 0.8875\n",
      "Epoch 801, Loss: 0.2790, Accuracy: 0.9361\n",
      "Epoch 901, Loss: 0.2210, Accuracy: 0.9419\n",
      "Epoch 1001, Loss: 0.1845, Accuracy: 0.9479\n",
      "Epoch 1101, Loss: 0.1605, Accuracy: 0.9551\n",
      "Epoch 1201, Loss: 0.1431, Accuracy: 0.9602\n",
      "Epoch 1301, Loss: 0.1305, Accuracy: 0.9634\n",
      "Epoch 1401, Loss: 0.1213, Accuracy: 0.9650\n",
      "Epoch 1501, Loss: 0.1141, Accuracy: 0.9669\n",
      "Epoch 1601, Loss: 0.1084, Accuracy: 0.9678\n",
      "Epoch 1701, Loss: 0.1037, Accuracy: 0.9682\n",
      "Epoch 1801, Loss: 0.0997, Accuracy: 0.9686\n",
      "Epoch 1901, Loss: 0.0961, Accuracy: 0.9689\n",
      "Epoch 2001, Loss: 0.0930, Accuracy: 0.9697\n",
      "Epoch 2101, Loss: 0.0902, Accuracy: 0.9699\n",
      "Early stopping criteria met\n",
      "Training GRUA...\n",
      "Epoch 1, Loss: 1.9651, Accuracy: 0.5719\n",
      "Epoch 101, Loss: 1.3687, Accuracy: 0.5719\n",
      "Epoch 201, Loss: 1.0900, Accuracy: 0.5906\n",
      "Epoch 301, Loss: 1.0118, Accuracy: 0.5906\n",
      "Epoch 401, Loss: 0.9905, Accuracy: 0.5913\n",
      "Epoch 501, Loss: 0.9827, Accuracy: 0.5909\n",
      "Epoch 601, Loss: 0.9779, Accuracy: 0.5907\n",
      "Epoch 701, Loss: 0.9747, Accuracy: 0.5909\n",
      "Epoch 801, Loss: 0.9721, Accuracy: 0.5902\n",
      "Epoch 901, Loss: 0.9698, Accuracy: 0.5903\n",
      "Epoch 1001, Loss: 0.9676, Accuracy: 0.5913\n",
      "Epoch 1101, Loss: 0.9693, Accuracy: 0.5920\n",
      "Epoch 1201, Loss: 0.9581, Accuracy: 0.5920\n",
      "Epoch 1301, Loss: 0.9475, Accuracy: 0.5997\n",
      "Epoch 1401, Loss: 0.9136, Accuracy: 0.6237\n",
      "Epoch 1501, Loss: 0.8902, Accuracy: 0.6375\n",
      "Epoch 1601, Loss: 0.8761, Accuracy: 0.6540\n",
      "Epoch 1701, Loss: 0.8604, Accuracy: 0.6642\n",
      "Epoch 1801, Loss: 0.8380, Accuracy: 0.6787\n",
      "Epoch 1901, Loss: 0.8118, Accuracy: 0.6886\n",
      "Epoch 2001, Loss: 0.7733, Accuracy: 0.6973\n",
      "Epoch 2101, Loss: 0.7276, Accuracy: 0.7243\n",
      "Epoch 2201, Loss: 0.7859, Accuracy: 0.7127\n",
      "Epoch 2301, Loss: 0.6751, Accuracy: 0.7403\n",
      "Epoch 2401, Loss: 0.6577, Accuracy: 0.7452\n",
      "Epoch 2501, Loss: 0.6404, Accuracy: 0.7548\n",
      "Epoch 2601, Loss: 0.6220, Accuracy: 0.7660\n",
      "Epoch 2701, Loss: 0.6043, Accuracy: 0.7760\n",
      "Epoch 2801, Loss: 0.5788, Accuracy: 0.7889\n",
      "Epoch 2901, Loss: 0.5549, Accuracy: 0.7969\n",
      "Epoch 3001, Loss: 0.5349, Accuracy: 0.8052\n",
      "Epoch 3101, Loss: 0.5157, Accuracy: 0.8133\n",
      "Epoch 3201, Loss: 0.4957, Accuracy: 0.8156\n",
      "Epoch 3301, Loss: 0.4754, Accuracy: 0.8240\n",
      "Epoch 3401, Loss: 0.4561, Accuracy: 0.8328\n",
      "Epoch 3501, Loss: 0.4383, Accuracy: 0.8429\n",
      "Epoch 3601, Loss: 0.4210, Accuracy: 0.8499\n",
      "Epoch 3701, Loss: 0.4034, Accuracy: 0.8600\n",
      "Epoch 3801, Loss: 0.3847, Accuracy: 0.8672\n",
      "Epoch 3901, Loss: 0.3653, Accuracy: 0.8734\n",
      "Epoch 4001, Loss: 0.3450, Accuracy: 0.8827\n",
      "Epoch 4101, Loss: 0.3224, Accuracy: 0.8897\n",
      "Epoch 4201, Loss: 0.2968, Accuracy: 0.8991\n",
      "Epoch 4301, Loss: 0.2716, Accuracy: 0.9096\n",
      "Epoch 4401, Loss: 0.2490, Accuracy: 0.9231\n",
      "Epoch 4501, Loss: 0.2292, Accuracy: 0.9328\n",
      "Epoch 4601, Loss: 0.2113, Accuracy: 0.9368\n",
      "Epoch 4701, Loss: 0.1944, Accuracy: 0.9405\n",
      "Epoch 4801, Loss: 0.1778, Accuracy: 0.9456\n",
      "Epoch 4901, Loss: 0.1606, Accuracy: 0.9515\n",
      "Epoch 5001, Loss: 0.1462, Accuracy: 0.9589\n",
      "Epoch 5101, Loss: 0.1349, Accuracy: 0.9623\n",
      "Epoch 5201, Loss: 0.1258, Accuracy: 0.9652\n",
      "Epoch 5301, Loss: 0.1175, Accuracy: 0.9675\n",
      "Epoch 5401, Loss: 0.1099, Accuracy: 0.9692\n",
      "Early stopping criteria met\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RNN\": RNN(),\n",
    "    \"RNNA\": RNNA(),  \n",
    "    \"LSTM\": LSTM(),\n",
    "    \"LSTMA\": LSTMA(),  \n",
    "    \"GRU\": GRU(),\n",
    "    \"GRUA\": GRUA() \n",
    "    \n",
    "}\n",
    "number_of_Songs = 4\n",
    "num_epochs = 7000\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    L , A = train_model(model, num_epochs, songStrings, number_of_Songs)\n",
    "    results[model_name] = {\"Accuracy\": A, \"Loss\": L}\n",
    "    #torch.save(model, f'model_{model_name}_songs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44c2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RNN\n",
      "Final Accuracy: 0.9702\n",
      "Number of Epoch: 3026\n",
      "Final Loss: 0.0926\n",
      "\n",
      "Model: RNNA\n",
      "Final Accuracy: 0.9310\n",
      "Number of Epoch: 7000\n",
      "Final Loss: 0.2078\n",
      "\n",
      "Model: LSTM\n",
      "Final Accuracy: 0.9697\n",
      "Number of Epoch: 7000\n",
      "Final Loss: 0.0989\n",
      "\n",
      "Model: LSTMA\n",
      "Final Accuracy: 0.9701\n",
      "Number of Epoch: 5399\n",
      "Final Loss: 0.1237\n",
      "\n",
      "Model: GRU\n",
      "Final Accuracy: 0.9701\n",
      "Number of Epoch: 2197\n",
      "Final Loss: 0.0878\n",
      "\n",
      "Model: GRUA\n",
      "Final Accuracy: 0.9701\n",
      "Number of Epoch: 5433\n",
      "Final Loss: 0.1076\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Final Accuracy: {metrics['Accuracy'][-1]:.4f}\")\n",
    "    print(f\"Number of Epoch: {len(metrics['Accuracy'])}\")\n",
    "    print(f\"Final Loss: {metrics['Loss'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d65ba9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 20)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.store[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b9a3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 41, 8)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I, _, O_indices, songs = generateIOData(number_of_Songs,songStrings)  # Use the full dataset\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e30155aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shrinkingDecompositionInformation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m I, O_hot, O_indices, songs \u001b[38;5;241m=\u001b[39m generateIOData(\u001b[38;5;241m4\u001b[39m, songStrings)\n\u001b[1;32m----> 2\u001b[0m S,H\u001b[38;5;241m=\u001b[39m\u001b[43mshrinkingDecompositionInformation\u001b[49m(model,\u001b[38;5;241m20\u001b[39m,source,target\u001b[38;5;241m.\u001b[39mtranspose(),numbers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m],whichTS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,dsLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m41\u001b[39m)\n\u001b[0;32m      3\u001b[0m M\u001b[38;5;241m=\u001b[39mremovalIntoMatrix(S,\u001b[38;5;241m20\u001b[39m,H)\n\u001b[0;32m      4\u001b[0m imshow(M)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shrinkingDecompositionInformation' is not defined"
     ]
    }
   ],
   "source": [
    "I, O_hot, O_indices, songs = generateIOData(4, songStrings)\n",
    "S,H=shrinkingDecompositionInformation(model,20,source,target.transpose(),numbers=[0,1,2,3,4,5,6,7],whichTS=40,dsLength=41)\n",
    "M=removalIntoMatrix(S,20,H)\n",
    "imshow(M)\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333cb072",
   "metadata": {},
   "source": [
    "## predict_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69708dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m who\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m\n\u001b[0;32m     25\u001b[0m I[who]\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msource\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwho\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     27\u001b[0m predicted_token_index \u001b[38;5;241m=\u001b[39m predict_next_token(model, source[who],verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted next token index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_token_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def predict_next_token(model, token_indices,verbose=False):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    \n",
    "    # Convert the list of token indices to a PyTorch tensor and add a batch dimension\n",
    "    src = torch.tensor(token_indices, dtype=torch.float).unsqueeze(1)  # Shape [sequence_length, 1] to match expected input\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(src,verbose)  # Get model output for the entire sequence\n",
    "\n",
    "    # Assuming output is [sequence_length, 1, ntokens] and we're interested in the last token's prediction\n",
    "    output_flat = output.view(-1, output.shape[-1])  # Flatten output for CrossEntropyLoss\n",
    "\n",
    "    _, predicted_indices = torch.max(output_flat, 1)\n",
    "    print(predicted_indices)\n",
    "    \n",
    "    last_token_logits = output[-1, 0, :]  # Get logits for the last token\n",
    "    predicted_token_index = last_token_logits.argmax().item()  # Find the index of the max log-probability\n",
    "    \n",
    "    return predicted_token_index\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a `model` instance and a sentence represented as a list of token indices\n",
    "# token_indices = [1, 2, 3, 2, 1, 2, 3, ...]\n",
    "who=40\n",
    "I[who]\n",
    "print(source[who].shape)\n",
    "predicted_token_index = predict_next_token(model, source[who],verbose=True)\n",
    "print(f'Predicted next token index: {predicted_token_index}')\n",
    "print(f\"original target {target[who][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "597f05d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4,\n",
       "       4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[who]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc0c38",
   "metadata": {},
   "source": [
    "## New shrinkingDecompositionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df1874b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolEntropy(D,base=2):\n",
    "    value,counts = numpy.unique(D, return_counts=True)\n",
    "    return entropy(counts,base=base)\n",
    "\n",
    "def computeTransmissionHfast(I,H,O,maskC,maskNC,iMult=2,oMult=2):\n",
    "    #print(\"I H O\",I.shape,H.shape,O.shape)\n",
    "    B=numpy.bitwise_and(H,maskNC)\n",
    "    IB=(B*iMult)+I\n",
    "    AB=H#numpy.bitwise_and(H,maskC+maskNC)\n",
    "    BO=(B*oMult)+O\n",
    "    IAB=(AB*iMult)+I\n",
    "    IBO=(B*(iMult*oMult))+(I*oMult)+O\n",
    "    ABO=(AB*oMult)+O\n",
    "    IABO=(AB*(iMult*oMult))+(I*oMult)+O\n",
    "    hB=symbolEntropy(B, base=2)\n",
    "    hIB=symbolEntropy(IB, base=2)\n",
    "    hAB=symbolEntropy(AB, base=2)\n",
    "    hBO=symbolEntropy(BO, base=2)\n",
    "    hIAB=symbolEntropy(IAB, base=2)\n",
    "    hIBO=symbolEntropy(IBO, base=2)\n",
    "    hABO=symbolEntropy(ABO, base=2)\n",
    "    hIABO=symbolEntropy(IABO, base=2)\n",
    "    #-H(B)+H(IB)+H(AB)+H(BO)-H(IAB)-H(IBO)-H(ABO)+H(IABO)\n",
    "    #print(hB,hIB,hAB,hBO,hIAB,hIBO,hABO,hIABO)\n",
    "    return-hB+hIB+hAB+hBO-hIAB-hIBO-hABO+hIABO\n",
    "\n",
    "def singleShrinkingDecompositionInformation(I,H,O,width,iMult=2,oMult=2):\n",
    "    nodes=list(range(width))\n",
    "    cols=[]\n",
    "    colh=[]\n",
    "    while len(nodes)>0:\n",
    "        infos=[]\n",
    "        for node in nodes:\n",
    "            subset=copy.deepcopy(nodes)\n",
    "            subset.remove(node)\n",
    "            maskA=0\n",
    "            for s in subset:\n",
    "                maskA+=1*(2**s)\n",
    "            maskA=int(maskA)\n",
    "            maskB=numpy.bitwise_and(numpy.bitwise_not(maskA),((2**width)-1))\n",
    "            h=computeTransmissionHfast(I,H,O,maskA,maskB,iMult=iMult,oMult=oMult)\n",
    "            infos.append(h)\n",
    "        nodeToDrop=nodes[infos.index(max(infos))]\n",
    "        nodes.remove(nodeToDrop)\n",
    "        cols.append(copy.deepcopy(nodes))\n",
    "        colh.append(max(infos))\n",
    "    return cols,colh\n",
    "\n",
    "def getAllIOH(model,source,target,songs,width=20):\n",
    "    I=[]\n",
    "    O=[]\n",
    "    H=[]\n",
    "    for i in range(len(songs)):\n",
    "        I.append(songs[i])\n",
    "        predicted_token_index = predict_next_token(model, source[i])\n",
    "        if predicted_token_index==target[i][-1]:\n",
    "            O.append(songs[i])\n",
    "        else:\n",
    "            O.append((songs[i]+1)%max(songs))\n",
    "        H.append(list(model.store[-1].flatten()))\n",
    "    H=numpy.array(H).transpose()\n",
    "    print(H.shape)\n",
    "    imshow(H)\n",
    "    B=numpy.zeros(H.shape)\n",
    "    clusterNr=2\n",
    "    for i in range(B.shape[0]):\n",
    "        a=H[i].reshape(-1, 1)\n",
    "        if len(numpy.unique(a))==1:\n",
    "            who=numpy.random.randint(len(a))\n",
    "            a[who]=1-a[who]\n",
    "        kmeans = KMeans(n_clusters=clusterNr,n_init=10).fit(a)\n",
    "        B[i]=kmeans.labels_\n",
    "    print(B.shape)\n",
    "    H=numpy.zeros((H.shape[1]))\n",
    "    for i in range(width):\n",
    "        H+=B[i]*(clusterNr**i)\n",
    "    H=H.astype((int))\n",
    "    return numpy.array(I),numpy.array(O),H\n",
    "\n",
    "def shrinkingDecompositionInformation(model,source,target,songs,numbers=[0,1,2,3],width=20):\n",
    "    allI,allO,H=getAllIOH(model,source,target,songs,width=width)\n",
    "    collectorSet=dict()\n",
    "    collectorH=dict()\n",
    "    for number in numbers:\n",
    "        I=(1*(songs==number)).astype(int)\n",
    "        O=(1*(allO==number)).astype(int)\n",
    "        s,h=singleShrinkingDecompositionInformation(I,H,O,width)\n",
    "        collectorSet[number]=s\n",
    "        collectorH[number]=h\n",
    "    return collectorSet,collectorH\n",
    "\n",
    "def removalIntoVec(res,width,H):\n",
    "    V=numpy.zeros(width)\n",
    "    #for i,r in enumerate(res):\n",
    "    #    for e in r:\n",
    "    #        V[e]+=H[0]-H[i]\n",
    "    fullSet=list(range(width))\n",
    "    nRes=copy.deepcopy(res)\n",
    "    nRes.insert(0,fullSet)\n",
    "    nodeList=[]\n",
    "    for i in range(width):\n",
    "        removedNode=list(set(nRes[i])-set(nRes[i+1]))[0]\n",
    "        nodeList.append(removedNode)\n",
    "    for i,node in enumerate(nodeList):\n",
    "        V[node]=H[0]-H[i]\n",
    "    #V=sqrt(V)\n",
    "    if V.sum()==0:\n",
    "        return V\n",
    "    return V#/V.max()\n",
    "\n",
    "def removalIntoMatrix(res,width,H):\n",
    "    M=[]\n",
    "    for i in range(len(res)):\n",
    "        M.append(removalIntoVec(res[i],width,H[i]))\n",
    "    return numpy.array(M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, O_hot, target, songs = generateIOData(4, songStrings)\n",
    "\n",
    "s,h=shrinkingDecompositionInformation(model,source,target,songs,numbers=list(range(4)),width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62a70d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=removalIntoMatrix(s,20,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f6136c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(M)\n",
    "print(M.max(),M.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1576888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n",
      "(820, 168)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    \"RNN\": RNN(),\n",
    "    \"RNNA\": RNNA(),  \n",
    "    \"LSTM\": LSTM(),\n",
    "    \"LSTMA\": LSTMA(),  \n",
    "    \"GRU\": GRU(),\n",
    "    \"GRUA\": GRUA() \n",
    "    \n",
    "}\n",
    "source, O_hot, target, songs = generateIOData(4, songStrings)\n",
    "fig, axs = plt.subplots(len(models), 1, figsize=(10, 20))\n",
    "\n",
    "# For each model, process the data and plot the resulting matrix\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    s, h = shrinkingDecompositionInformation(model, source, target, songs, numbers=list(range(4)), width=20)\n",
    "    M = removalIntoMatrix(s, 20, h)\n",
    "    \n",
    "    ax = axs[i]\n",
    "    cax = ax.imshow(M)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f\"{model_name}: Max={M.max()}, Min={M.min()}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "62ebe9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "51c07259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6,\n",
       "       5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0ce4dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "48f4ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateIODataV2(songStrings, num_songs, seq_length=42):\n",
    "    notes = list(\"ABCDEFGH\")  # List of unique notes\n",
    "    source = []\n",
    "    target = []\n",
    "    raw = []\n",
    "    for s in range(num_songs):  # Loop through the specified number of songs\n",
    "        song = songStrings[s]\n",
    "        for i in range(len(song) - seq_length + 1):\n",
    "            # Generate input sequence and the corresponding target sequence\n",
    "            input_seq = [notes.index(note) for note in song[i:i+seq_length]]\n",
    "            target_seq = [notes.index(note) for note in song[i+1:i+seq_length+1]]\n",
    "            source.append(input_seq)\n",
    "            target.append(target_seq)\n",
    "            raw.append(s)\n",
    "    # Convert input sequences to one-hot encoding\n",
    "    source_one_hot = np.zeros((len(source), seq_length, len(notes)), dtype=np.float32)\n",
    "    for i, seq in enumerate(source):\n",
    "        for j, note_index in enumerate(seq):\n",
    "            source_one_hot[i, j, note_index] = 1.0\n",
    "\n",
    "    target_array = np.array(target)  # Convert target sequences to a NumPy array\n",
    "\n",
    "    return source_one_hot, target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1e389da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, input_dim = 42, hidden_dim =20, output_dim = 41, num_layers=1):\n",
    "        super(Seq2SeqRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.outputLayer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.outputLayer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b88261cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, inputs, targets, num_epochs=1000, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs_reshaped = outputs.reshape(-1, outputs.shape[2])\n",
    "        targets_reshaped = targets.reshape(-1)\n",
    "        loss = criterion(outputs_reshaped, targets_reshaped)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item()}')\n",
    "    \n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "54ed06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generateIODataV2(songStrings, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3fa5f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 42, 8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6997a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: nan\n",
      "Epoch 100/1000, Loss: nan\n",
      "Epoch 200/1000, Loss: nan\n",
      "Epoch 300/1000, Loss: nan\n",
      "Epoch 400/1000, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m Seq2SeqRNN(input_dim, hidden_dim, output_dim, num_layers)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[92], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, inputs, targets, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m targets_reshaped \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs_reshaped, targets_reshaped)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     15\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = len(\"ABCDEFGH\")  # Number of unique notes\n",
    "hidden_dim = 64  # Adjust based on performance\n",
    "output_dim = input_dim  # Same as input because of one-hot encoding\n",
    "num_layers = 1  # Can be adjusted for model complexity\n",
    "\n",
    "# Prepare data\n",
    "inputs, targets = generateIODataV2(songStrings, 4)\n",
    "inputs_tensor = torch.tensor(inputs, dtype=torch.float)\n",
    "targets_tensor = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# Initialize model\n",
    "model = Seq2SeqRNN(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Train model\n",
    "trained_model = train_model(model, inputs_tensor, targets_tensor, num_epochs=1000, learning_rate=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
