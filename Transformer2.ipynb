{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/magics/pylab.py:162: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [5], [4], [2], [3], [2], [2], [1], [5], [1], [4], [3], [3], [4], [0], [0], [3], [4], [4], [5], [5], [2], [5], [3], [3], [1], [3], [1], [2], [1], [1], [5], [1], [3], [3], [0], [0], [3], [2], [3], [2], [0]]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "songString = \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\"\n",
    "notes=list(unique(list(songString)))\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5]]\n",
    "DaisyBell=list()\n",
    "DaisyBellMatrix=[]\n",
    "for note in list(songString):\n",
    "    row=[0]*6\n",
    "    row[notes.index(note)]=1\n",
    "    DaisyBellMatrix.append(row)\n",
    "    DaisyBell.append(chord[notes.index(note)])\n",
    "print(DaisyBell)\n",
    "DaisyBellMatrix=numpy.array(DaisyBellMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [1], [1], [5], [5], [5], [4], [4], [4], [4], [2], [2], [5], [1], [1], [4], [4], [2], [2], [2], [0], [0], [4], [4], [1], [1], [2], [1], [1], [5], [5], [5], [5], [5], [4], [4], [3], [3], [2], [2], [1]]\n"
     ]
    }
   ],
   "source": [
    "HotDogsongString = \"AACCGGGFFFFDDGCCFFDDDAAFFCCDCCGGGGGFFEEDDC\"\n",
    "notes=list(unique(list(songString)))\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5]]\n",
    "HotDog=list()\n",
    "HotDogMatrix=[]\n",
    "for note in list(HotDogsongString):\n",
    "    row=[0]*6\n",
    "    row[notes.index(note)]=1\n",
    "    HotDogMatrix.append(row)\n",
    "    HotDog.append(chord[notes.index(note)])\n",
    "print(HotDog)\n",
    "HotDogMatrix=numpy.array(HotDogMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
      "[[2], [5], [0], [2], [7], [5], [3], [5], [4], [4], [3], [7], [4], [6], [1], [5], [7], [0], [2], [6], [0], [7], [0], [4], [1], [7], [2], [1], [1], [5], [6], [3], [7], [6], [3], [1], [1], [2], [0], [1], [7], [2]]\n",
      "[[2], [2], [6], [6], [0], [0], [6], [5], [5], [4], [4], [3], [3], [2], [6], [6], [5], [5], [4], [4], [3], [6], [6], [5], [5], [4], [4], [3], [2], [2], [6], [6], [0], [0], [6], [5], [5], [4], [4], [3], [3], [2]]\n",
      "[[0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5]]\n",
      "[[0], [1], [0], [2], [0], [3], [0], [4], [0], [5], [0], [1], [4], [5], [0], [3], [4], [2], [1], [0], [1], [2], [5], [4], [3], [4], [5], [0], [1], [2], [0], [3], [4], [1], [0], [2], [0], [3], [5], [0], [1], [4]]\n",
      "[[3], [1], [2], [0], [2], [1], [2], [5], [5], [3], [2], [4], [5], [5], [4], [5], [2], [3], [3], [4], [5], [4], [1], [4], [0], [2], [5], [4], [2], [1], [1], [1], [2], [1], [4], [2], [1], [5], [3], [0], [5], [1]]\n",
      "[[0], [1], [4], [1], [2], [0], [4], [5], [2], [3], [5], [5], [1], [2], [1], [3], [1], [1], [1], [2], [4], [3], [2], [1], [5], [1], [5], [5], [4], [2], [1], [2], [4], [1], [2], [0], [0], [5], [5], [0], [3], [1]]\n",
      "[[1], [4], [4], [5], [1], [0], [5], [3], [0], [4], [0], [0], [4], [5], [3], [1], [3], [5], [3], [4], [5], [2], [0], [2], [4], [1], [2], [2], [3], [0], [2], [4], [0], [2], [0], [2], [4], [4], [3], [1], [0], [0]]\n",
      "[[1], [5], [4], [1], [5], [4], [4], [1], [3], [1], [2], [5], [4], [0], [0], [2], [0], [0], [0], [5], [3], [5], [2], [1], [5], [1], [5], [4], [0], [0], [2], [5], [5], [2], [0], [0], [1], [2], [4], [3], [3], [2]]\n",
      "[[1], [0], [3], [3], [5], [5], [4], [0], [3], [1], [4], [3], [5], [3], [5], [1], [4], [1], [2], [2], [0], [3], [4], [5], [3], [4], [0], [1], [1], [5], [3], [4], [5], [5], [4], [1], [4], [4], [5], [3], [4], [5]]\n",
      "[[0], [1], [5], [5], [4], [3], [1], [3], [1], [5], [4], [2], [4], [3], [4], [0], [4], [1], [1], [4], [4], [2], [5], [3], [3], [0], [4], [3], [2], [3], [1], [1], [5], [2], [0], [3], [0], [3], [1], [1], [2], [5]]\n",
      "[[3], [5], [1], [2], [4], [1], [3], [0], [0], [3], [0], [0], [5], [2], [3], [0], [2], [0], [3], [3], [0], [5], [5], [0], [2], [3], [2], [5], [2], [2], [3], [3], [3], [2], [5], [1], [4], [1], [1], [3], [4], [3]]\n",
      "[[2], [2], [5], [1], [4], [5], [3], [3], [2], [1], [5], [3], [0], [3], [3], [1], [5], [1], [2], [2], [4], [4], [0], [1], [0], [5], [0], [0], [0], [4], [3], [2], [3], [2], [4], [0], [4], [5], [1], [5], [2], [3]]\n",
      "[[4], [1], [0], [3], [5], [5], [0], [0], [5], [0], [3], [3], [3], [0], [1], [4], [0], [1], [1], [3], [5], [3], [2], [0], [5], [1], [2], [3], [4], [4], [1], [1], [1], [4], [2], [3], [3], [5], [4], [4], [0], [4]]\n",
      "[[0], [5], [0], [3], [3], [5], [4], [5], [0], [3], [3], [1], [2], [3], [2], [5], [4], [4], [5], [2], [0], [4], [4], [4], [3], [5], [5], [4], [3], [1], [2], [0], [3], [1], [1], [3], [1], [0], [4], [5], [2], [3]]\n"
     ]
    }
   ],
   "source": [
    "songStrings = numpy.array([\n",
    "    \"CFACHFDFEEDHEGBFHACGAHAEBHCBBFGDHGDBBCABHC\",\n",
    "    \"CCGGAAGFFEEDDCGGFFEEDGGFFEEDCCGGAAGFFEEDDC\",\n",
    "    \"ABCDEFABCDEFABCDEFABCDEFABCDEFABCDEFABCDEF\",\n",
    "    \"ABACADAEAFABEFADECBABCFEDEFABCADEBACADFABE\",\n",
    "    \"DBCACBCFFDCEFFEFCDDEFEBEACFECBBBCBECBFDAFB\",\n",
    "    \"ABEBCAEFCDFFBCBDBBBCEDCBFBFFECBCEBCAAFFADB\",\n",
    "    \"BEEFBAFDAEAAEFDBDFDEFCACEBCCDACEACACEEDBAA\",\n",
    "    \"BFEBFEEBDBCFEAACAAAFDFCBFBFEAACFFCAABCEDDC\",\n",
    "    \"BADDFFEADBEDFDFBEBCCADEFDEABBFDEFFEBEEFDEF\",\n",
    "    \"ABFFEDBDBFECEDEAEBBEECFDDAEDCDBBFCADADBBCF\",\n",
    "    \"DFBCEBDAADAAFCDACADDAFFACDCFCCDDDCFBEBBDED\",\n",
    "    \"CCFBEFDDCBFDADDBFBCCEEABAFAAAEDCDCEAEFBFCD\",\n",
    "    \"EBADFFAAFADDDABEABBDFDCAFBCDEEBBBECDDFEEAE\",\n",
    "    \"AFADDFEFADDBCDCFEEFCAEEEDFFEDBCADBBDBAEFCD\"])\n",
    "notes=list(\"ABCDEFGH\")\n",
    "print(notes)\n",
    "chord=[[0],\n",
    "       [1],\n",
    "       [2],\n",
    "       [3],\n",
    "       [4],\n",
    "       [5],\n",
    "       [6],\n",
    "       [7]]\n",
    "allSongs=list()\n",
    "for songString in songStrings:\n",
    "    song=[]\n",
    "    for note in list(songString):\n",
    "        row=[0]*8\n",
    "        row[notes.index(note)]=1\n",
    "        song.append(chord[notes.index(note)])\n",
    "    allSongs.append(song)\n",
    "for song in allSongs:\n",
    "    print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, song_index, bptt=42):\n",
    "    data=[]\n",
    "    target=[]\n",
    "    for pos in range(i,i+bptt):\n",
    "        data.append(source[song_index][pos%len(source[song_index])])\n",
    "        target+=source[song_index][(pos+1)%len(source[song_index])]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor, verbose=False) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        if verbose:\n",
    "            print(src.shape)\n",
    "            figure()\n",
    "            imshow(src.detach().numpy().reshape((42,20)))\n",
    "        src = self.pos_encoder(src)\n",
    "        if verbose:\n",
    "            print(src.shape)\n",
    "            figure()\n",
    "            imshow(src.detach().numpy().reshape((42,20)))\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "            figure()\n",
    "            imshow(output.detach().numpy().reshape((42,20)))\n",
    "        output = self.decoder(output)\n",
    "        if verbose:\n",
    "            print(output.shape)\n",
    "            figure()\n",
    "            imshow(output.detach().numpy().reshape((42,6)))\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): Embedding(6, 64)\n",
      "  (decoder): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(ntoken=8, d_model=64, nhead=4, d_hid=256, nlayers=2, dropout=0.0)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  6.8156e-01,  ...,  1.0000e+00,\n",
       "                         1.3335e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.9748e-01,  ...,  1.0000e+00,\n",
       "                         2.6670e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.5625e-01, -2.9254e-01,  6.4315e-01,  ...,  6.3049e-01,\n",
       "                         6.1813e-01,  7.8608e-01]],\n",
       "              \n",
       "                      [[ 2.7050e-01, -9.6272e-01, -5.1133e-02,  ...,  6.3036e-01,\n",
       "                         6.1823e-01,  7.8599e-01]],\n",
       "              \n",
       "                      [[-6.6395e-01, -7.4778e-01, -7.1816e-01,  ...,  6.3022e-01,\n",
       "                         6.1834e-01,  7.8591e-01]]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1423, -0.0435, -0.0043,  ..., -0.0760, -0.0993, -0.0375],\n",
       "                      [ 0.1088, -0.1340,  0.0929,  ...,  0.0007,  0.0346,  0.0880],\n",
       "                      [-0.1062, -0.1453,  0.1109,  ..., -0.0625,  0.1007, -0.1018],\n",
       "                      ...,\n",
       "                      [-0.0185,  0.0388, -0.0438,  ..., -0.1264,  0.1132,  0.0941],\n",
       "                      [-0.0221, -0.1436,  0.0325,  ..., -0.0799,  0.1140, -0.0266],\n",
       "                      [ 0.1327, -0.0523, -0.1238,  ..., -0.1274, -0.0825,  0.1153]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0131,  0.0963,  0.1092,  ..., -0.0606, -0.0165,  0.0403],\n",
       "                      [ 0.0308, -0.0241,  0.1153,  ..., -0.0674, -0.1044,  0.1230],\n",
       "                      [-0.0311,  0.1215, -0.0081,  ...,  0.0569,  0.0974, -0.1179],\n",
       "                      ...,\n",
       "                      [ 0.0848,  0.0274,  0.1214,  ..., -0.1158,  0.1187,  0.0441],\n",
       "                      [ 0.0630,  0.1166,  0.0415,  ..., -0.0233,  0.0017,  0.0205],\n",
       "                      [-0.0118,  0.0737,  0.1171,  ...,  0.0827, -0.1143,  0.0870]])),\n",
       "             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.linear1.weight',\n",
       "              tensor([[-0.1014, -0.1200,  0.0932,  ..., -0.0360, -0.0106, -0.0803],\n",
       "                      [ 0.0908, -0.0360,  0.1241,  ...,  0.0951, -0.0738,  0.0950],\n",
       "                      [-0.0741, -0.0989,  0.0033,  ...,  0.0696, -0.0003, -0.0571],\n",
       "                      ...,\n",
       "                      [-0.0802, -0.0530, -0.0064,  ..., -0.0359,  0.0291, -0.0315],\n",
       "                      [-0.0843,  0.0359, -0.1152,  ..., -0.0916, -0.1224, -0.1044],\n",
       "                      [ 0.0459,  0.0192,  0.0233,  ...,  0.0345,  0.0211, -0.0105]])),\n",
       "             ('transformer_encoder.layers.0.linear1.bias',\n",
       "              tensor([ 0.1174,  0.0641, -0.0511,  0.1019, -0.0353, -0.0023, -0.0657,  0.0233,\n",
       "                      -0.1092,  0.0848,  0.1250,  0.0803,  0.0315,  0.0977,  0.0509,  0.1171,\n",
       "                      -0.0562, -0.0858, -0.0658,  0.1019, -0.0978, -0.0790,  0.0394,  0.0833,\n",
       "                      -0.0453,  0.0323,  0.0581, -0.0775, -0.1216,  0.0454,  0.0649,  0.0830,\n",
       "                      -0.0430, -0.0110,  0.0568,  0.1114,  0.0856, -0.0337, -0.0531, -0.0311,\n",
       "                       0.1045, -0.0160,  0.0565,  0.1207,  0.0931, -0.1075,  0.0351,  0.0906,\n",
       "                      -0.0859, -0.0960, -0.0970, -0.0535, -0.0358, -0.1075,  0.0700,  0.0294,\n",
       "                      -0.0655, -0.1005,  0.0192,  0.0738,  0.0856, -0.0590, -0.1175,  0.1093,\n",
       "                      -0.1101,  0.0440,  0.1157,  0.1156,  0.0553,  0.1202, -0.0553,  0.0765,\n",
       "                       0.0151, -0.0560,  0.0548,  0.1140, -0.0574, -0.0597,  0.0314, -0.0744,\n",
       "                       0.0141, -0.0676, -0.0673,  0.0925, -0.0180, -0.0834,  0.0218,  0.1155,\n",
       "                      -0.0399,  0.0572, -0.1092, -0.0193, -0.0089, -0.0437,  0.0439, -0.0980,\n",
       "                       0.0039,  0.0044,  0.1139,  0.0374,  0.0837,  0.0510, -0.0611,  0.0417,\n",
       "                       0.0334,  0.1094,  0.0741, -0.0656, -0.0633,  0.1243,  0.0010,  0.0048,\n",
       "                       0.1012, -0.0343,  0.1127,  0.0435,  0.1177, -0.1031, -0.0408,  0.0658,\n",
       "                       0.0622, -0.0097,  0.0629, -0.0028,  0.0427,  0.0879,  0.0457, -0.0921,\n",
       "                      -0.0724,  0.1116,  0.0377, -0.0434,  0.0986,  0.0003, -0.0664,  0.0560,\n",
       "                       0.0991, -0.1210, -0.0311,  0.1002,  0.0386, -0.0285, -0.1174, -0.0175,\n",
       "                       0.0411,  0.0963,  0.1065,  0.0115,  0.0504,  0.0510, -0.0643,  0.0057,\n",
       "                       0.0805,  0.0632,  0.0718, -0.0389,  0.0026,  0.0994,  0.0451, -0.0544,\n",
       "                       0.0059,  0.0903,  0.0773, -0.0923,  0.0031, -0.1182, -0.0590,  0.0746,\n",
       "                       0.0211,  0.0201, -0.0734, -0.0410, -0.0414,  0.0985,  0.1139,  0.0392,\n",
       "                       0.0542, -0.0305, -0.0087,  0.0070,  0.1068, -0.0088,  0.0377, -0.1170,\n",
       "                      -0.0387,  0.1114,  0.0053, -0.0143,  0.1050, -0.0913,  0.0065,  0.0019,\n",
       "                       0.1042,  0.0613, -0.0972,  0.0179,  0.0797, -0.0036, -0.1027,  0.1079,\n",
       "                       0.0532, -0.0688, -0.0581,  0.0369, -0.0270, -0.0487, -0.0905, -0.0814,\n",
       "                       0.0232,  0.1226,  0.0553,  0.0468,  0.0679,  0.1181, -0.0022,  0.1221,\n",
       "                       0.0967, -0.0873,  0.1103, -0.1220,  0.0118, -0.0413, -0.0112, -0.0237,\n",
       "                       0.0653,  0.0349, -0.0249, -0.0119,  0.0160,  0.0869, -0.0077,  0.0103,\n",
       "                       0.0045,  0.1226, -0.0192, -0.0009, -0.0064,  0.0269, -0.0507, -0.1196,\n",
       "                       0.0808, -0.0726, -0.0051, -0.1064, -0.0355, -0.1005, -0.0871, -0.1160,\n",
       "                       0.0103,  0.0064,  0.0501,  0.0928, -0.0844,  0.0858, -0.0094, -0.0176])),\n",
       "             ('transformer_encoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0154, -0.0440,  0.0019,  ...,  0.0376, -0.0174, -0.0526],\n",
       "                      [-0.0564,  0.0064,  0.0348,  ..., -0.0311, -0.0580, -0.0200],\n",
       "                      [-0.0603, -0.0546, -0.0614,  ...,  0.0121,  0.0604,  0.0561],\n",
       "                      ...,\n",
       "                      [ 0.0209,  0.0192,  0.0366,  ..., -0.0003, -0.0140, -0.0250],\n",
       "                      [-0.0540, -0.0076, -0.0466,  ..., -0.0193,  0.0573, -0.0370],\n",
       "                      [ 0.0410, -0.0091, -0.0177,  ..., -0.0343, -0.0449, -0.0373]])),\n",
       "             ('transformer_encoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0165,  0.0063,  0.0569, -0.0591,  0.0485,  0.0546, -0.0523, -0.0510,\n",
       "                      -0.0492,  0.0383,  0.0610,  0.0454, -0.0308, -0.0300, -0.0257,  0.0329,\n",
       "                      -0.0156, -0.0140, -0.0455, -0.0250,  0.0264,  0.0191,  0.0432,  0.0221,\n",
       "                       0.0288,  0.0020,  0.0422, -0.0207,  0.0551, -0.0180,  0.0208, -0.0072,\n",
       "                       0.0228, -0.0149,  0.0526,  0.0065, -0.0376, -0.0042,  0.0618,  0.0186,\n",
       "                       0.0437, -0.0125, -0.0262, -0.0476,  0.0391,  0.0549, -0.0335,  0.0414,\n",
       "                      -0.0180,  0.0363, -0.0170, -0.0020,  0.0322,  0.0447, -0.0260, -0.0383,\n",
       "                       0.0432, -0.0585, -0.0384,  0.0240,  0.0610, -0.0331, -0.0255,  0.0142])),\n",
       "             ('transformer_encoder.layers.0.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.0.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.0.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1423, -0.0435, -0.0043,  ..., -0.0760, -0.0993, -0.0375],\n",
       "                      [ 0.1088, -0.1340,  0.0929,  ...,  0.0007,  0.0346,  0.0880],\n",
       "                      [-0.1062, -0.1453,  0.1109,  ..., -0.0625,  0.1007, -0.1018],\n",
       "                      ...,\n",
       "                      [-0.0185,  0.0388, -0.0438,  ..., -0.1264,  0.1132,  0.0941],\n",
       "                      [-0.0221, -0.1436,  0.0325,  ..., -0.0799,  0.1140, -0.0266],\n",
       "                      [ 0.1327, -0.0523, -0.1238,  ..., -0.1274, -0.0825,  0.1153]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0131,  0.0963,  0.1092,  ..., -0.0606, -0.0165,  0.0403],\n",
       "                      [ 0.0308, -0.0241,  0.1153,  ..., -0.0674, -0.1044,  0.1230],\n",
       "                      [-0.0311,  0.1215, -0.0081,  ...,  0.0569,  0.0974, -0.1179],\n",
       "                      ...,\n",
       "                      [ 0.0848,  0.0274,  0.1214,  ..., -0.1158,  0.1187,  0.0441],\n",
       "                      [ 0.0630,  0.1166,  0.0415,  ..., -0.0233,  0.0017,  0.0205],\n",
       "                      [-0.0118,  0.0737,  0.1171,  ...,  0.0827, -0.1143,  0.0870]])),\n",
       "             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.linear1.weight',\n",
       "              tensor([[-0.1014, -0.1200,  0.0932,  ..., -0.0360, -0.0106, -0.0803],\n",
       "                      [ 0.0908, -0.0360,  0.1241,  ...,  0.0951, -0.0738,  0.0950],\n",
       "                      [-0.0741, -0.0989,  0.0033,  ...,  0.0696, -0.0003, -0.0571],\n",
       "                      ...,\n",
       "                      [-0.0802, -0.0530, -0.0064,  ..., -0.0359,  0.0291, -0.0315],\n",
       "                      [-0.0843,  0.0359, -0.1152,  ..., -0.0916, -0.1224, -0.1044],\n",
       "                      [ 0.0459,  0.0192,  0.0233,  ...,  0.0345,  0.0211, -0.0105]])),\n",
       "             ('transformer_encoder.layers.1.linear1.bias',\n",
       "              tensor([ 0.1174,  0.0641, -0.0511,  0.1019, -0.0353, -0.0023, -0.0657,  0.0233,\n",
       "                      -0.1092,  0.0848,  0.1250,  0.0803,  0.0315,  0.0977,  0.0509,  0.1171,\n",
       "                      -0.0562, -0.0858, -0.0658,  0.1019, -0.0978, -0.0790,  0.0394,  0.0833,\n",
       "                      -0.0453,  0.0323,  0.0581, -0.0775, -0.1216,  0.0454,  0.0649,  0.0830,\n",
       "                      -0.0430, -0.0110,  0.0568,  0.1114,  0.0856, -0.0337, -0.0531, -0.0311,\n",
       "                       0.1045, -0.0160,  0.0565,  0.1207,  0.0931, -0.1075,  0.0351,  0.0906,\n",
       "                      -0.0859, -0.0960, -0.0970, -0.0535, -0.0358, -0.1075,  0.0700,  0.0294,\n",
       "                      -0.0655, -0.1005,  0.0192,  0.0738,  0.0856, -0.0590, -0.1175,  0.1093,\n",
       "                      -0.1101,  0.0440,  0.1157,  0.1156,  0.0553,  0.1202, -0.0553,  0.0765,\n",
       "                       0.0151, -0.0560,  0.0548,  0.1140, -0.0574, -0.0597,  0.0314, -0.0744,\n",
       "                       0.0141, -0.0676, -0.0673,  0.0925, -0.0180, -0.0834,  0.0218,  0.1155,\n",
       "                      -0.0399,  0.0572, -0.1092, -0.0193, -0.0089, -0.0437,  0.0439, -0.0980,\n",
       "                       0.0039,  0.0044,  0.1139,  0.0374,  0.0837,  0.0510, -0.0611,  0.0417,\n",
       "                       0.0334,  0.1094,  0.0741, -0.0656, -0.0633,  0.1243,  0.0010,  0.0048,\n",
       "                       0.1012, -0.0343,  0.1127,  0.0435,  0.1177, -0.1031, -0.0408,  0.0658,\n",
       "                       0.0622, -0.0097,  0.0629, -0.0028,  0.0427,  0.0879,  0.0457, -0.0921,\n",
       "                      -0.0724,  0.1116,  0.0377, -0.0434,  0.0986,  0.0003, -0.0664,  0.0560,\n",
       "                       0.0991, -0.1210, -0.0311,  0.1002,  0.0386, -0.0285, -0.1174, -0.0175,\n",
       "                       0.0411,  0.0963,  0.1065,  0.0115,  0.0504,  0.0510, -0.0643,  0.0057,\n",
       "                       0.0805,  0.0632,  0.0718, -0.0389,  0.0026,  0.0994,  0.0451, -0.0544,\n",
       "                       0.0059,  0.0903,  0.0773, -0.0923,  0.0031, -0.1182, -0.0590,  0.0746,\n",
       "                       0.0211,  0.0201, -0.0734, -0.0410, -0.0414,  0.0985,  0.1139,  0.0392,\n",
       "                       0.0542, -0.0305, -0.0087,  0.0070,  0.1068, -0.0088,  0.0377, -0.1170,\n",
       "                      -0.0387,  0.1114,  0.0053, -0.0143,  0.1050, -0.0913,  0.0065,  0.0019,\n",
       "                       0.1042,  0.0613, -0.0972,  0.0179,  0.0797, -0.0036, -0.1027,  0.1079,\n",
       "                       0.0532, -0.0688, -0.0581,  0.0369, -0.0270, -0.0487, -0.0905, -0.0814,\n",
       "                       0.0232,  0.1226,  0.0553,  0.0468,  0.0679,  0.1181, -0.0022,  0.1221,\n",
       "                       0.0967, -0.0873,  0.1103, -0.1220,  0.0118, -0.0413, -0.0112, -0.0237,\n",
       "                       0.0653,  0.0349, -0.0249, -0.0119,  0.0160,  0.0869, -0.0077,  0.0103,\n",
       "                       0.0045,  0.1226, -0.0192, -0.0009, -0.0064,  0.0269, -0.0507, -0.1196,\n",
       "                       0.0808, -0.0726, -0.0051, -0.1064, -0.0355, -0.1005, -0.0871, -0.1160,\n",
       "                       0.0103,  0.0064,  0.0501,  0.0928, -0.0844,  0.0858, -0.0094, -0.0176])),\n",
       "             ('transformer_encoder.layers.1.linear2.weight',\n",
       "              tensor([[ 0.0154, -0.0440,  0.0019,  ...,  0.0376, -0.0174, -0.0526],\n",
       "                      [-0.0564,  0.0064,  0.0348,  ..., -0.0311, -0.0580, -0.0200],\n",
       "                      [-0.0603, -0.0546, -0.0614,  ...,  0.0121,  0.0604,  0.0561],\n",
       "                      ...,\n",
       "                      [ 0.0209,  0.0192,  0.0366,  ..., -0.0003, -0.0140, -0.0250],\n",
       "                      [-0.0540, -0.0076, -0.0466,  ..., -0.0193,  0.0573, -0.0370],\n",
       "                      [ 0.0410, -0.0091, -0.0177,  ..., -0.0343, -0.0449, -0.0373]])),\n",
       "             ('transformer_encoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0165,  0.0063,  0.0569, -0.0591,  0.0485,  0.0546, -0.0523, -0.0510,\n",
       "                      -0.0492,  0.0383,  0.0610,  0.0454, -0.0308, -0.0300, -0.0257,  0.0329,\n",
       "                      -0.0156, -0.0140, -0.0455, -0.0250,  0.0264,  0.0191,  0.0432,  0.0221,\n",
       "                       0.0288,  0.0020,  0.0422, -0.0207,  0.0551, -0.0180,  0.0208, -0.0072,\n",
       "                       0.0228, -0.0149,  0.0526,  0.0065, -0.0376, -0.0042,  0.0618,  0.0186,\n",
       "                       0.0437, -0.0125, -0.0262, -0.0476,  0.0391,  0.0549, -0.0335,  0.0414,\n",
       "                      -0.0180,  0.0363, -0.0170, -0.0020,  0.0322,  0.0447, -0.0260, -0.0383,\n",
       "                       0.0432, -0.0585, -0.0384,  0.0240,  0.0610, -0.0331, -0.0255,  0.0142])),\n",
       "             ('transformer_encoder.layers.1.norm1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('transformer_encoder.layers.1.norm2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('transformer_encoder.layers.1.norm2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.weight',\n",
       "              tensor([[-1.2444e-03,  5.9936e-02,  1.6982e-02, -1.5952e-03,  7.6201e-02,\n",
       "                       -3.1631e-02,  9.3127e-02,  3.7070e-02,  7.2296e-02,  8.2055e-02,\n",
       "                        8.2883e-02,  5.1648e-02,  3.0874e-02, -4.1175e-02, -4.0016e-02,\n",
       "                        8.7745e-02,  4.7457e-02, -5.2626e-02,  2.1914e-02,  7.6464e-02,\n",
       "                        5.7091e-02, -6.8699e-02, -7.8204e-02,  4.1760e-02, -9.8264e-02,\n",
       "                        2.4091e-02, -7.6426e-02,  1.2650e-02,  8.1527e-02,  4.0288e-02,\n",
       "                       -7.0935e-02, -1.8472e-02,  3.9257e-02, -2.2594e-02, -9.6210e-02,\n",
       "                        9.5417e-02,  2.8536e-02, -2.5925e-02,  4.0441e-02, -2.9216e-02,\n",
       "                        3.6171e-03, -9.8117e-02,  5.8863e-02, -7.4239e-02, -2.7541e-03,\n",
       "                       -4.1689e-02, -8.9300e-02, -3.8927e-02,  9.9643e-03, -8.2693e-02,\n",
       "                       -2.2929e-02, -2.6107e-03,  1.8724e-02, -5.6004e-02,  3.3332e-02,\n",
       "                        5.6742e-03, -1.2438e-02, -2.5053e-02,  2.9587e-04,  9.4959e-02,\n",
       "                       -2.0428e-02,  5.8163e-02, -6.4637e-02, -9.1844e-02],\n",
       "                      [ 1.5149e-02, -7.9572e-02,  3.1861e-02,  2.9045e-02, -1.8095e-03,\n",
       "                       -9.2473e-02, -7.4245e-02,  3.5424e-02, -4.0994e-02,  8.0730e-02,\n",
       "                       -1.8152e-02, -3.9287e-02,  9.5508e-02,  2.0359e-02,  6.1455e-02,\n",
       "                       -5.1761e-02,  3.7027e-02,  9.1186e-02,  3.8808e-02,  6.8757e-02,\n",
       "                        6.4315e-02, -1.5803e-02, -3.9403e-02, -8.2073e-02,  5.4257e-02,\n",
       "                        1.5650e-02, -7.7695e-02,  1.9935e-02,  4.2155e-02, -3.9490e-02,\n",
       "                       -3.5187e-02,  7.9179e-02, -1.0854e-02, -7.7170e-02, -4.0567e-02,\n",
       "                       -3.9597e-02, -1.7608e-02, -9.6000e-02,  1.4978e-02, -8.9233e-03,\n",
       "                       -6.5239e-02, -6.4660e-02, -9.7835e-05, -7.3829e-02, -7.0331e-03,\n",
       "                       -9.8332e-02, -6.7412e-04, -8.1438e-02, -9.7784e-03,  7.6205e-02,\n",
       "                        6.9847e-02, -7.5842e-02,  6.1713e-02, -4.1939e-02, -7.6494e-02,\n",
       "                        4.2455e-02,  7.5522e-02, -7.7868e-02, -6.9578e-02, -4.9334e-02,\n",
       "                        4.8470e-02,  7.3504e-02,  5.1336e-02,  9.3358e-02],\n",
       "                      [ 4.9106e-02,  9.0342e-02, -9.2284e-02,  9.5492e-02,  2.9552e-02,\n",
       "                        8.4228e-02,  4.5627e-02, -2.2189e-02, -4.8352e-02, -3.8690e-02,\n",
       "                       -8.1651e-02,  8.5613e-02, -5.6014e-02,  8.8470e-02, -4.6432e-02,\n",
       "                        7.2058e-02,  7.7654e-02, -6.9096e-02, -6.4582e-02,  2.9398e-02,\n",
       "                       -5.4657e-02, -8.9848e-02, -5.8150e-02, -6.0277e-02,  2.7300e-02,\n",
       "                        1.4745e-02,  2.6927e-03,  8.0283e-03,  3.5890e-03,  9.4929e-02,\n",
       "                        2.9017e-02, -6.6290e-02,  7.1810e-02,  4.7738e-02,  5.5453e-03,\n",
       "                       -6.4204e-02,  6.5095e-02,  4.4200e-02,  3.0753e-02, -7.4808e-02,\n",
       "                        4.5852e-02, -9.8356e-03,  2.3913e-02,  2.3165e-02,  6.4269e-02,\n",
       "                        4.0601e-02,  1.3593e-02,  4.2812e-02,  6.0982e-02, -4.2910e-02,\n",
       "                        8.7930e-02, -4.9606e-02, -6.3211e-02, -8.6833e-03, -7.4327e-02,\n",
       "                        2.0667e-02,  8.5052e-02,  9.0760e-02, -2.0947e-02, -4.2025e-03,\n",
       "                        8.2945e-02, -2.8001e-02,  2.6824e-03, -7.2150e-03],\n",
       "                      [ 7.9467e-02, -7.6631e-02, -3.8144e-02, -3.9876e-02,  2.2195e-02,\n",
       "                        8.4513e-02,  9.0744e-03, -8.7340e-03,  2.8879e-02, -7.6637e-02,\n",
       "                       -5.0254e-02,  1.6691e-02, -8.1840e-02, -8.7609e-02,  1.0516e-02,\n",
       "                        6.9705e-02,  4.8775e-02,  7.1884e-02,  2.5262e-02, -8.1111e-02,\n",
       "                        6.2516e-02,  5.8583e-02, -6.5473e-02,  2.1046e-02,  6.4506e-02,\n",
       "                       -6.8215e-02,  9.2540e-02, -3.3000e-02, -2.4190e-03, -7.2171e-02,\n",
       "                       -4.7493e-02, -7.0934e-02, -2.5803e-02, -8.0414e-02, -8.3988e-02,\n",
       "                        7.2974e-02, -8.4961e-02, -1.8759e-02,  7.5646e-02, -7.9625e-02,\n",
       "                       -2.0180e-03,  5.3291e-02, -1.1317e-02,  9.5838e-02,  5.4777e-02,\n",
       "                        6.7913e-02,  2.2348e-02,  5.8887e-02,  8.2949e-02, -5.1631e-02,\n",
       "                       -6.4882e-02,  4.2953e-02, -1.6824e-02,  9.7472e-02, -4.5308e-02,\n",
       "                       -5.5821e-02, -7.7668e-02, -9.6814e-03,  3.2969e-03, -4.7869e-02,\n",
       "                        8.2813e-02,  5.0010e-02, -9.6613e-03,  1.4755e-02],\n",
       "                      [-1.6937e-02, -5.2947e-02, -8.4822e-02,  7.8934e-02, -7.6745e-02,\n",
       "                       -2.0239e-02,  2.2991e-02,  8.9225e-02, -7.4641e-02,  4.7162e-02,\n",
       "                       -7.5625e-03,  9.5151e-02,  3.4452e-02, -4.5804e-02,  6.3685e-02,\n",
       "                       -6.7663e-02,  7.1767e-03, -6.2032e-02,  4.1961e-02, -1.2353e-02,\n",
       "                        6.2252e-02, -5.0484e-02,  7.5273e-02,  9.5040e-02, -7.4047e-02,\n",
       "                       -3.1904e-02, -9.7871e-03, -8.4044e-02, -6.6997e-02, -5.3443e-02,\n",
       "                       -7.6091e-02, -1.0882e-02,  2.4526e-02,  8.2566e-02,  4.5424e-02,\n",
       "                       -4.2125e-02,  3.5624e-02, -9.9193e-02,  1.6004e-02, -7.6098e-02,\n",
       "                       -9.0678e-02,  4.2380e-02, -9.9885e-02,  3.4789e-02, -6.6905e-02,\n",
       "                        7.7429e-02, -4.3361e-02,  7.9436e-02, -9.8702e-02, -2.2307e-02,\n",
       "                        2.1742e-03, -1.9683e-02, -5.2591e-02, -1.7307e-02, -9.4305e-02,\n",
       "                        5.4562e-02, -3.8726e-02,  4.1276e-02,  8.3338e-02, -3.6690e-02,\n",
       "                       -8.0224e-02,  2.3537e-02,  8.8436e-03,  2.7097e-02],\n",
       "                      [ 2.2188e-02,  2.7744e-02,  4.0624e-02,  1.0689e-02, -9.8370e-02,\n",
       "                        1.1239e-03,  5.0973e-02, -5.9091e-02,  4.7273e-02, -7.9074e-02,\n",
       "                       -6.9127e-02, -2.3762e-02,  2.3025e-02,  4.7252e-02, -8.8109e-02,\n",
       "                        5.8442e-02,  4.4980e-02,  7.6001e-02,  7.5654e-02, -2.8291e-02,\n",
       "                       -8.4567e-02,  2.8395e-02,  5.5518e-02,  1.2281e-02, -6.6445e-02,\n",
       "                        5.5165e-02,  3.1455e-02, -7.0049e-02, -9.0800e-02, -9.6766e-02,\n",
       "                       -4.0177e-02,  5.7401e-02, -5.1123e-02,  7.7884e-02,  2.8105e-02,\n",
       "                       -3.5532e-02, -8.5683e-02,  3.5470e-02, -4.2905e-02, -5.6771e-02,\n",
       "                        2.7684e-02,  9.4053e-02,  3.6268e-02, -8.1305e-02,  5.4659e-02,\n",
       "                       -4.4225e-02,  1.5174e-02,  4.5584e-02, -5.8932e-03, -8.3471e-02,\n",
       "                        1.1783e-02,  4.0615e-02, -2.3022e-03, -7.7736e-02, -9.7090e-03,\n",
       "                        8.4052e-02, -1.4519e-02,  2.1389e-02,  1.1204e-03,  6.2018e-02,\n",
       "                       -5.5478e-02, -9.3274e-02, -1.7276e-02, -8.5862e-02]])),\n",
       "             ('decoder.weight',\n",
       "              tensor([[-0.0631,  0.0688,  0.0646, -0.0940, -0.0926,  0.0055, -0.0916,  0.0551,\n",
       "                       -0.0814,  0.0220, -0.0881, -0.0131,  0.0949,  0.0730, -0.0113,  0.0743,\n",
       "                       -0.0543, -0.0643, -0.0371,  0.0487, -0.0832, -0.0438, -0.0051,  0.0449,\n",
       "                        0.0856,  0.0730,  0.0051, -0.0304,  0.0730, -0.0497, -0.0724, -0.0415,\n",
       "                        0.0996,  0.0718,  0.0265,  0.0590,  0.0298, -0.0840,  0.0685,  0.0820,\n",
       "                       -0.0910, -0.0531, -0.0263, -0.0474, -0.0610, -0.0185, -0.0327, -0.0772,\n",
       "                        0.0667, -0.0335, -0.0005,  0.0589,  0.0619, -0.0472, -0.0271,  0.0989,\n",
       "                       -0.0708,  0.0187,  0.0709, -0.0874,  0.0997,  0.0620,  0.0407,  0.0354],\n",
       "                      [ 0.0186, -0.0686, -0.0568, -0.0284,  0.0019, -0.0456, -0.0884,  0.0084,\n",
       "                       -0.0089, -0.0281,  0.0884,  0.0305, -0.0479, -0.0336,  0.0810,  0.0688,\n",
       "                        0.0601, -0.0329,  0.0439, -0.0833, -0.0107,  0.0700,  0.0347, -0.0848,\n",
       "                       -0.0721, -0.0281, -0.0610,  0.0602, -0.0546,  0.0262,  0.0834, -0.0303,\n",
       "                        0.0490, -0.0170, -0.0600, -0.0112,  0.0591, -0.0402, -0.0814, -0.0170,\n",
       "                        0.0943,  0.0959, -0.0245,  0.0268,  0.0480,  0.0324, -0.0389, -0.0736,\n",
       "                        0.0877, -0.0157, -0.0539, -0.0411, -0.0736,  0.0513,  0.0796, -0.0679,\n",
       "                        0.0946, -0.0069, -0.0903,  0.0782,  0.0039, -0.0114, -0.0058,  0.0793],\n",
       "                      [ 0.0839, -0.0497,  0.0132,  0.0668, -0.0089, -0.0823,  0.0312, -0.0960,\n",
       "                       -0.0740, -0.0026, -0.0307,  0.0138,  0.0221,  0.0526, -0.0247, -0.0162,\n",
       "                        0.0971,  0.0508, -0.0207,  0.0742, -0.0910, -0.0563, -0.0632, -0.0976,\n",
       "                       -0.0946, -0.0180, -0.0626,  0.0399,  0.0142,  0.0344,  0.0242, -0.0480,\n",
       "                        0.0033, -0.0982, -0.0044,  0.0734,  0.0551, -0.0657,  0.0292,  0.0927,\n",
       "                        0.0344,  0.0652,  0.0529, -0.0134,  0.0372, -0.0583, -0.0969,  0.0611,\n",
       "                       -0.0812, -0.0036,  0.0254,  0.0977, -0.0387, -0.0781,  0.0731,  0.0131,\n",
       "                        0.0213, -0.0533, -0.0922, -0.0878,  0.0049, -0.0486,  0.0331, -0.0626],\n",
       "                      [-0.0297, -0.0557,  0.0006, -0.0828, -0.0975, -0.0425,  0.0438,  0.0751,\n",
       "                        0.0471,  0.0019, -0.0601,  0.0711, -0.0537,  0.0522,  0.0207,  0.0117,\n",
       "                       -0.0373, -0.0003,  0.0757,  0.0021, -0.0834, -0.0273,  0.0516,  0.0902,\n",
       "                        0.0774,  0.0476, -0.0009,  0.0187,  0.0292, -0.0719,  0.0738, -0.0353,\n",
       "                        0.0138, -0.0841,  0.0649, -0.0575, -0.0544, -0.0468,  0.0635,  0.0213,\n",
       "                       -0.0440, -0.0700, -0.0567,  0.0154, -0.0371, -0.0373, -0.0112, -0.0735,\n",
       "                        0.0350,  0.0150,  0.0627,  0.0239, -0.0545,  0.0911, -0.0121,  0.0427,\n",
       "                        0.0265, -0.0422,  0.0462, -0.0257, -0.0795,  0.0675,  0.0422,  0.0470],\n",
       "                      [-0.0908,  0.0413,  0.0168,  0.0083,  0.0096, -0.0139, -0.0193, -0.0683,\n",
       "                        0.0074, -0.0045, -0.0841, -0.0149,  0.0113, -0.0791, -0.0026,  0.0679,\n",
       "                        0.0739, -0.0471, -0.0726,  0.0990,  0.0273,  0.0436,  0.0086, -0.0868,\n",
       "                       -0.0456, -0.0757,  0.0229, -0.0415, -0.0489, -0.0841, -0.0561,  0.0287,\n",
       "                       -0.0536, -0.0911,  0.0305,  0.0803, -0.0396,  0.0709, -0.0816, -0.0891,\n",
       "                       -0.0336, -0.0834, -0.0494, -0.0139, -0.0603, -0.0993, -0.0863, -0.0786,\n",
       "                       -0.0357, -0.0691,  0.0707, -0.0035,  0.0098, -0.0344,  0.0935, -0.0350,\n",
       "                       -0.0614, -0.0956,  0.0548,  0.0121, -0.0132,  0.0561, -0.0572,  0.0224],\n",
       "                      [-0.0788, -0.0049,  0.0482, -0.0743, -0.0590,  0.0049,  0.0871,  0.0662,\n",
       "                        0.0840,  0.0493,  0.0117,  0.0595,  0.0019,  0.0970,  0.0735, -0.0680,\n",
       "                        0.0694,  0.0980, -0.0226, -0.0781,  0.0028,  0.0921, -0.0327, -0.0896,\n",
       "                        0.0117,  0.0214, -0.0410, -0.0425,  0.0096,  0.0243, -0.0723,  0.0922,\n",
       "                        0.0335, -0.0270,  0.0008, -0.0005,  0.0982, -0.0501,  0.0008,  0.0566,\n",
       "                        0.0018,  0.0860,  0.0863, -0.0479,  0.0931,  0.0083, -0.0510,  0.0986,\n",
       "                       -0.0337,  0.0400, -0.0835,  0.0500, -0.0173,  0.0004, -0.0147,  0.0786,\n",
       "                        0.0918,  0.0023, -0.0881,  0.0623, -0.0937, -0.0550, -0.0546,  0.0213]])),\n",
       "             ('decoder.bias', tensor([0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, songs, optimizer, criterion, bptt=42, device='cpu'):\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    batches = numpy.array(list(range(bptt)))\n",
    "    numpy.random.shuffle(batches)\n",
    "    for song_index, song in enumerate(songs):\n",
    "        num_batches = len(song) // bptt\n",
    "        for batch, i in enumerate(batches):\n",
    "            #print(f\"batch {batch} of {num_batches}\")\n",
    "            #print(f\"i {i}\")\n",
    "            data, targets = get_batch(songs, i, song_index, bptt)\n",
    "            seq_len = len(data)\n",
    "            if seq_len != bptt:  # only on last batch\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(torch.tensor(data,dtype=torch.long), src_mask)\n",
    "            loss = criterion(output.view(-1, ntokens), torch.tensor(targets,dtype=torch.long))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if batch % log_interval == 0 and batch > 0:\n",
    "                lr = scheduler.get_last_lr()[0]\n",
    "                ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "                cur_loss = total_loss / log_interval\n",
    "                ppl = math.exp(cur_loss)\n",
    "                print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                    f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                    f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "\n",
    "def evaluate(model, songs, criterion, bptt=42, device='cpu'):    \n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for song_index, song in enumerate(songs):\n",
    "            for i in range(0, len(song) - 1, bptt):\n",
    "                data, targets = get_batch(songs, i, song_index, bptt)\n",
    "                seq_len = len(data)\n",
    "                if seq_len != bptt:\n",
    "                    src_mask = src_mask[:seq_len, :seq_len]\n",
    "                output = model(torch.tensor(data,dtype=torch.long), src_mask)\n",
    "                output_flat = output.view(-1, ntokens)\n",
    "                total_loss += seq_len * criterion(output_flat, torch.tensor(targets,dtype=torch.long)).item()\n",
    "    avg_loss = total_loss / sum(len(song) for song in songs)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2], [5], [0], [2], [7], [5], [3], [5], [4], [4], [3], [7], [4], [6], [1], [5], [7], [0], [2], [6], [0], [7], [0], [4], [1], [7], [2], [1], [1], [5], [6], [3], [7], [6], [3], [1], [1], [2], [0], [1], [7], [2]], [[2], [2], [6], [6], [0], [0], [6], [5], [5], [4], [4], [3], [3], [2], [6], [6], [5], [5], [4], [4], [3], [6], [6], [5], [5], [4], [4], [3], [2], [2], [6], [6], [0], [0], [6], [5], [5], [4], [4], [3], [3], [2]], [[0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5], [0], [1], [2], [3], [4], [5]], [[0], [1], [0], [2], [0], [3], [0], [4], [0], [5], [0], [1], [4], [5], [0], [3], [4], [2], [1], [0], [1], [2], [5], [4], [3], [4], [5], [0], [1], [2], [0], [3], [4], [1], [0], [2], [0], [3], [5], [0], [1], [4]], [[3], [1], [2], [0], [2], [1], [2], [5], [5], [3], [2], [4], [5], [5], [4], [5], [2], [3], [3], [4], [5], [4], [1], [4], [0], [2], [5], [4], [2], [1], [1], [1], [2], [1], [4], [2], [1], [5], [3], [0], [5], [1]]]\n"
     ]
    }
   ],
   "source": [
    "#songs = [DaisyBell, hotDog]\n",
    "#songs = [DaisyBell]\n",
    "songs = allSongs[:5]\n",
    "print(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "for song in songs:\n",
    "    print(len(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ntokens = 6  # size of vocabulary\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 120  # embedding dimension\n",
    "d_hid = 120  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.0  # dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pnb9p7_n30s29gprj1gbqbbm0000gn/T/ipykernel_29870/4199152564.py:53: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  avg_loss = total_loss / sum(len(song) for song in songs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| End of epoch   1 | Validation Loss: 2.61 | Validation Perplexity:    13.56\n",
      "| End of epoch   2 | Validation Loss: 2.69 | Validation Perplexity:    14.73\n",
      "| End of epoch   3 | Validation Loss: 2.38 | Validation Perplexity:    10.77\n",
      "| End of epoch   4 | Validation Loss: 2.58 | Validation Perplexity:    13.19\n",
      "| End of epoch   5 | Validation Loss: 2.57 | Validation Perplexity:    13.12\n",
      "| End of epoch   6 | Validation Loss: 2.66 | Validation Perplexity:    14.23\n",
      "| End of epoch   7 | Validation Loss: 2.52 | Validation Perplexity:    12.37\n",
      "| End of epoch   8 | Validation Loss: 2.61 | Validation Perplexity:    13.60\n",
      "| End of epoch   9 | Validation Loss: 2.86 | Validation Perplexity:    17.45\n",
      "| End of epoch  10 | Validation Loss: 2.65 | Validation Perplexity:    14.12\n",
      "| End of epoch  11 | Validation Loss: 2.77 | Validation Perplexity:    15.90\n",
      "| End of epoch  12 | Validation Loss: 3.01 | Validation Perplexity:    20.34\n",
      "| End of epoch  13 | Validation Loss: 2.77 | Validation Perplexity:    16.01\n",
      "| End of epoch  14 | Validation Loss: 2.45 | Validation Perplexity:    11.63\n",
      "| End of epoch  15 | Validation Loss: 2.62 | Validation Perplexity:    13.73\n",
      "| End of epoch  16 | Validation Loss: 2.88 | Validation Perplexity:    17.85\n",
      "| End of epoch  17 | Validation Loss: 2.45 | Validation Perplexity:    11.54\n",
      "| End of epoch  18 | Validation Loss: 2.69 | Validation Perplexity:    14.67\n",
      "| End of epoch  19 | Validation Loss: 2.42 | Validation Perplexity:    11.20\n",
      "| End of epoch  20 | Validation Loss: 2.44 | Validation Perplexity:    11.50\n",
      "| End of epoch  21 | Validation Loss: 2.52 | Validation Perplexity:    12.44\n",
      "| End of epoch  22 | Validation Loss: 2.59 | Validation Perplexity:    13.31\n",
      "| End of epoch  23 | Validation Loss: 2.58 | Validation Perplexity:    13.17\n",
      "| End of epoch  24 | Validation Loss: 2.52 | Validation Perplexity:    12.38\n",
      "| End of epoch  25 | Validation Loss: 2.30 | Validation Perplexity:    10.01\n",
      "| End of epoch  26 | Validation Loss: 2.43 | Validation Perplexity:    11.36\n",
      "| End of epoch  27 | Validation Loss: 2.46 | Validation Perplexity:    11.73\n",
      "| End of epoch  28 | Validation Loss: 2.27 | Validation Perplexity:     9.72\n",
      "| End of epoch  29 | Validation Loss: 2.47 | Validation Perplexity:    11.88\n",
      "| End of epoch  30 | Validation Loss: 2.30 | Validation Perplexity:    10.01\n",
      "| End of epoch  31 | Validation Loss: 2.31 | Validation Perplexity:    10.04\n",
      "| End of epoch  32 | Validation Loss: 2.60 | Validation Perplexity:    13.40\n",
      "| End of epoch  33 | Validation Loss: 2.43 | Validation Perplexity:    11.38\n",
      "| End of epoch  34 | Validation Loss: 2.15 | Validation Perplexity:     8.60\n",
      "| End of epoch  35 | Validation Loss: 2.22 | Validation Perplexity:     9.20\n",
      "| End of epoch  36 | Validation Loss: 2.45 | Validation Perplexity:    11.54\n",
      "| End of epoch  37 | Validation Loss: 2.20 | Validation Perplexity:     9.06\n",
      "| End of epoch  38 | Validation Loss: 2.43 | Validation Perplexity:    11.41\n",
      "| End of epoch  39 | Validation Loss: 2.02 | Validation Perplexity:     7.51\n",
      "| End of epoch  40 | Validation Loss: 2.05 | Validation Perplexity:     7.77\n",
      "| End of epoch  41 | Validation Loss: 2.01 | Validation Perplexity:     7.46\n",
      "| End of epoch  42 | Validation Loss: 1.93 | Validation Perplexity:     6.92\n",
      "| End of epoch  43 | Validation Loss: 1.78 | Validation Perplexity:     5.92\n",
      "| End of epoch  44 | Validation Loss: 1.98 | Validation Perplexity:     7.25\n",
      "| End of epoch  45 | Validation Loss: 1.69 | Validation Perplexity:     5.41\n",
      "| End of epoch  46 | Validation Loss: 1.95 | Validation Perplexity:     7.04\n",
      "| End of epoch  47 | Validation Loss: 1.86 | Validation Perplexity:     6.44\n",
      "| End of epoch  48 | Validation Loss: 1.92 | Validation Perplexity:     6.79\n",
      "| End of epoch  49 | Validation Loss: 1.75 | Validation Perplexity:     5.78\n",
      "| End of epoch  50 | Validation Loss: 1.79 | Validation Perplexity:     5.98\n",
      "| End of epoch  51 | Validation Loss: 1.84 | Validation Perplexity:     6.27\n",
      "| End of epoch  52 | Validation Loss: 1.71 | Validation Perplexity:     5.54\n",
      "| End of epoch  53 | Validation Loss: 1.85 | Validation Perplexity:     6.37\n",
      "| End of epoch  54 | Validation Loss: 1.72 | Validation Perplexity:     5.59\n",
      "| End of epoch  55 | Validation Loss: 1.62 | Validation Perplexity:     5.04\n",
      "| End of epoch  56 | Validation Loss: 1.63 | Validation Perplexity:     5.10\n",
      "| End of epoch  57 | Validation Loss: 1.58 | Validation Perplexity:     4.86\n",
      "| End of epoch  58 | Validation Loss: 1.75 | Validation Perplexity:     5.77\n",
      "| End of epoch  59 | Validation Loss: 1.46 | Validation Perplexity:     4.33\n",
      "| End of epoch  60 | Validation Loss: 1.52 | Validation Perplexity:     4.59\n",
      "| End of epoch  61 | Validation Loss: 1.50 | Validation Perplexity:     4.46\n",
      "| End of epoch  62 | Validation Loss: 1.47 | Validation Perplexity:     4.35\n",
      "| End of epoch  63 | Validation Loss: 1.39 | Validation Perplexity:     4.02\n",
      "| End of epoch  64 | Validation Loss: 1.39 | Validation Perplexity:     4.03\n",
      "| End of epoch  65 | Validation Loss: 1.00 | Validation Perplexity:     2.73\n",
      "| End of epoch  66 | Validation Loss: 1.15 | Validation Perplexity:     3.15\n",
      "| End of epoch  67 | Validation Loss: 1.13 | Validation Perplexity:     3.08\n",
      "| End of epoch  68 | Validation Loss: 1.01 | Validation Perplexity:     2.74\n",
      "| End of epoch  69 | Validation Loss: 0.91 | Validation Perplexity:     2.49\n",
      "| End of epoch  70 | Validation Loss: 0.89 | Validation Perplexity:     2.44\n",
      "| End of epoch  71 | Validation Loss: 0.71 | Validation Perplexity:     2.04\n",
      "| End of epoch  72 | Validation Loss: 0.66 | Validation Perplexity:     1.93\n",
      "| End of epoch  73 | Validation Loss: 0.67 | Validation Perplexity:     1.95\n",
      "| End of epoch  74 | Validation Loss: 0.61 | Validation Perplexity:     1.84\n",
      "| End of epoch  75 | Validation Loss: 0.68 | Validation Perplexity:     1.97\n",
      "| End of epoch  76 | Validation Loss: 0.53 | Validation Perplexity:     1.69\n",
      "| End of epoch  77 | Validation Loss: 0.54 | Validation Perplexity:     1.72\n",
      "| End of epoch  78 | Validation Loss: 0.52 | Validation Perplexity:     1.69\n",
      "| End of epoch  79 | Validation Loss: 0.45 | Validation Perplexity:     1.57\n",
      "| End of epoch  80 | Validation Loss: 0.43 | Validation Perplexity:     1.53\n",
      "| End of epoch  81 | Validation Loss: 0.44 | Validation Perplexity:     1.55\n",
      "| End of epoch  82 | Validation Loss: 0.44 | Validation Perplexity:     1.56\n",
      "| End of epoch  83 | Validation Loss: 0.35 | Validation Perplexity:     1.41\n",
      "| End of epoch  84 | Validation Loss: 0.34 | Validation Perplexity:     1.40\n",
      "| End of epoch  85 | Validation Loss: 0.34 | Validation Perplexity:     1.41\n",
      "| End of epoch  86 | Validation Loss: 0.30 | Validation Perplexity:     1.35\n",
      "| End of epoch  87 | Validation Loss: 0.29 | Validation Perplexity:     1.34\n",
      "| End of epoch  88 | Validation Loss: 0.28 | Validation Perplexity:     1.32\n",
      "| End of epoch  89 | Validation Loss: 0.25 | Validation Perplexity:     1.29\n",
      "| End of epoch  90 | Validation Loss: 0.28 | Validation Perplexity:     1.32\n",
      "| End of epoch  91 | Validation Loss: 0.24 | Validation Perplexity:     1.27\n",
      "| End of epoch  92 | Validation Loss: 0.22 | Validation Perplexity:     1.24\n",
      "| End of epoch  93 | Validation Loss: 0.21 | Validation Perplexity:     1.23\n",
      "| End of epoch  94 | Validation Loss: 0.22 | Validation Perplexity:     1.24\n",
      "| End of epoch  95 | Validation Loss: 0.21 | Validation Perplexity:     1.23\n",
      "| End of epoch  96 | Validation Loss: 0.19 | Validation Perplexity:     1.21\n",
      "| End of epoch  97 | Validation Loss: 0.18 | Validation Perplexity:     1.20\n",
      "| End of epoch  98 | Validation Loss: 0.17 | Validation Perplexity:     1.19\n",
      "| End of epoch  99 | Validation Loss: 0.17 | Validation Perplexity:     1.18\n",
      "| End of epoch 100 | Validation Loss: 0.16 | Validation Perplexity:     1.17\n",
      "| End of epoch 101 | Validation Loss: 0.15 | Validation Perplexity:     1.16\n",
      "| End of epoch 102 | Validation Loss: 0.14 | Validation Perplexity:     1.15\n",
      "| End of epoch 103 | Validation Loss: 0.14 | Validation Perplexity:     1.15\n",
      "| End of epoch 104 | Validation Loss: 0.14 | Validation Perplexity:     1.15\n",
      "| End of epoch 105 | Validation Loss: 0.13 | Validation Perplexity:     1.14\n",
      "| End of epoch 106 | Validation Loss: 0.13 | Validation Perplexity:     1.13\n",
      "| End of epoch 107 | Validation Loss: 0.12 | Validation Perplexity:     1.13\n",
      "| End of epoch 108 | Validation Loss: 0.12 | Validation Perplexity:     1.13\n",
      "| End of epoch 109 | Validation Loss: 0.11 | Validation Perplexity:     1.12\n",
      "| End of epoch 110 | Validation Loss: 0.11 | Validation Perplexity:     1.12\n",
      "| End of epoch 111 | Validation Loss: 0.11 | Validation Perplexity:     1.11\n",
      "| End of epoch 112 | Validation Loss: 0.10 | Validation Perplexity:     1.11\n",
      "| End of epoch 113 | Validation Loss: 0.10 | Validation Perplexity:     1.11\n",
      "| End of epoch 114 | Validation Loss: 0.10 | Validation Perplexity:     1.11\n",
      "| End of epoch 115 | Validation Loss: 0.10 | Validation Perplexity:     1.11\n",
      "| End of epoch 116 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "| End of epoch 117 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "| End of epoch 118 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "| End of epoch 119 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "| End of epoch 120 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 121 | Validation Loss: 0.10 | Validation Perplexity:     1.10\n",
      "| End of epoch 122 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 123 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 124 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 125 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 126 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 127 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 128 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 129 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 130 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 131 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 132 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 133 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 134 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 135 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 136 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 137 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 138 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 139 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 140 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 141 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 142 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 143 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 144 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 145 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 146 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 147 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 148 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 149 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 150 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 151 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 152 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 153 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 154 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 155 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 156 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 157 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 158 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 159 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 160 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 161 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 162 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 163 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 164 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 165 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 166 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 167 | Validation Loss: 0.09 | Validation Perplexity:     1.10\n",
      "| End of epoch 168 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 169 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 170 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 171 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 172 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 173 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 174 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 175 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 176 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 177 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 178 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 179 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 180 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 181 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 182 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 183 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 184 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 185 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 186 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 187 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 188 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 189 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 190 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 191 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 192 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 193 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 194 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 195 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 196 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 197 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 198 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 199 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n",
      "| End of epoch 200 | Validation Loss: 0.09 | Validation Perplexity:     1.09\n"
     ]
    }
   ],
   "source": [
    "bptt = 42\n",
    "\n",
    "#ntokens = 6  # size of vocabulary\n",
    "ntokens = 8  # size of vocabulary\n",
    "emsize = 64  # embedding dimension\n",
    "d_hid = 256  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.0  # dropout probability\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "\n",
    "epochs=200\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, songs, optimizer, criterion)\n",
    "    # Evaluate on the validation dataset\n",
    "    val_loss = evaluate(model, songs, criterion)  # Replace `songs` with your validation dataset if available\n",
    "    \n",
    "    # Calculate and print the validation perplexity\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    print(f'| End of epoch {epoch:3d} | Validation Loss: {val_loss:.2f} | Validation Perplexity: {val_ppl:8.2f}')\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for song 1, batch 0: 0.95\n",
      "target notes:    [5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2]\n",
      "predicted notes: [3, 4, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2]\n",
      "Accuracy for song 1, batch 1: 0.98\n",
      "target notes:    [0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5]\n",
      "predicted notes: [0, 1, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5]\n",
      "Accuracy for song 1, batch 2: 0.98\n",
      "target notes:    [2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0]\n",
      "predicted notes: [1, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0]\n",
      "Accuracy for song 1, batch 3: 0.98\n",
      "target notes:    [7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2]\n",
      "predicted notes: [3, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2]\n",
      "Accuracy for song 1, batch 4: 0.98\n",
      "target notes:    [5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7]\n",
      "predicted notes: [0, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7]\n",
      "Accuracy for song 1, batch 5: 0.95\n",
      "target notes:    [3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5]\n",
      "predicted notes: [0, 2, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5]\n",
      "Accuracy for song 1, batch 6: 0.98\n",
      "target notes:    [5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3]\n",
      "predicted notes: [4, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3]\n",
      "Accuracy for song 1, batch 7: 0.95\n",
      "target notes:    [4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5]\n",
      "predicted notes: [0, 4, 3, 3, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5]\n",
      "Accuracy for song 1, batch 8: 0.93\n",
      "target notes:    [4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4]\n",
      "predicted notes: [5, 5, 3, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4]\n",
      "Accuracy for song 1, batch 9: 0.95\n",
      "target notes:    [3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4]\n",
      "predicted notes: [5, 2, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4]\n",
      "Accuracy for song 1, batch 10: 0.98\n",
      "target notes:    [7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3]\n",
      "predicted notes: [4, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3]\n",
      "Accuracy for song 1, batch 11: 0.98\n",
      "target notes:    [4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7]\n",
      "predicted notes: [0, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7]\n",
      "Accuracy for song 1, batch 12: 0.98\n",
      "target notes:    [6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4]\n",
      "predicted notes: [5, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4]\n",
      "Accuracy for song 1, batch 13: 0.98\n",
      "target notes:    [1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6]\n",
      "predicted notes: [5, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6]\n",
      "Accuracy for song 1, batch 14: 0.95\n",
      "target notes:    [5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1]\n",
      "predicted notes: [2, 6, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1]\n",
      "Accuracy for song 1, batch 15: 0.98\n",
      "target notes:    [7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5]\n",
      "predicted notes: [0, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5]\n",
      "Accuracy for song 1, batch 16: 0.98\n",
      "target notes:    [0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7]\n",
      "predicted notes: [0, 4, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7]\n",
      "Accuracy for song 1, batch 17: 0.95\n",
      "target notes:    [2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0]\n",
      "predicted notes: [1, 7, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0]\n",
      "Accuracy for song 1, batch 18: 0.95\n",
      "target notes:    [6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2]\n",
      "predicted notes: [3, 0, 6, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2]\n",
      "Accuracy for song 1, batch 19: 0.95\n",
      "target notes:    [0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6]\n",
      "predicted notes: [5, 6, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6]\n",
      "Accuracy for song 1, batch 20: 0.98\n",
      "target notes:    [7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0]\n",
      "predicted notes: [1, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0]\n",
      "Accuracy for song 1, batch 21: 1.00\n",
      "target notes:    [0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7]\n",
      "predicted notes: [0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7]\n",
      "Accuracy for song 1, batch 22: 0.98\n",
      "target notes:    [4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0]\n",
      "predicted notes: [1, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0]\n",
      "Accuracy for song 1, batch 23: 0.98\n",
      "target notes:    [1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4]\n",
      "predicted notes: [5, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4]\n",
      "Accuracy for song 1, batch 24: 0.98\n",
      "target notes:    [7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1]\n",
      "predicted notes: [2, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1]\n",
      "Accuracy for song 1, batch 25: 0.95\n",
      "target notes:    [2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7]\n",
      "predicted notes: [0, 2, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7]\n",
      "Accuracy for song 1, batch 26: 0.95\n",
      "target notes:    [1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2]\n",
      "predicted notes: [3, 1, 4, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2]\n",
      "Accuracy for song 1, batch 27: 0.95\n",
      "target notes:    [1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1]\n",
      "predicted notes: [2, 2, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1]\n",
      "Accuracy for song 1, batch 28: 0.98\n",
      "target notes:    [5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1]\n",
      "predicted notes: [2, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1]\n",
      "Accuracy for song 1, batch 29: 0.98\n",
      "target notes:    [6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5]\n",
      "predicted notes: [0, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5]\n",
      "Accuracy for song 1, batch 30: 0.98\n",
      "target notes:    [3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6]\n",
      "predicted notes: [5, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6]\n",
      "Accuracy for song 1, batch 31: 0.95\n",
      "target notes:    [7, 6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3]\n",
      "predicted notes: [4, 4, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3]\n",
      "Accuracy for song 1, batch 32: 0.98\n",
      "target notes:    [6, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7]\n",
      "predicted notes: [0, 3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7]\n",
      "Accuracy for song 1, batch 33: 0.95\n",
      "target notes:    [3, 1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6]\n",
      "predicted notes: [5, 7, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6]\n",
      "Accuracy for song 1, batch 34: 0.95\n",
      "target notes:    [1, 1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3]\n",
      "predicted notes: [4, 2, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3]\n",
      "Accuracy for song 1, batch 35: 0.95\n",
      "target notes:    [1, 2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1]\n",
      "predicted notes: [2, 2, 1, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1]\n",
      "Accuracy for song 1, batch 36: 0.98\n",
      "target notes:    [2, 0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1]\n",
      "predicted notes: [2, 3, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1]\n",
      "Accuracy for song 1, batch 37: 0.95\n",
      "target notes:    [0, 1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2]\n",
      "predicted notes: [3, 3, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2]\n",
      "Accuracy for song 1, batch 38: 0.98\n",
      "target notes:    [1, 7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0]\n",
      "predicted notes: [1, 2, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0]\n",
      "Accuracy for song 1, batch 39: 0.95\n",
      "target notes:    [7, 2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1]\n",
      "predicted notes: [2, 2, 1, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1]\n",
      "Accuracy for song 1, batch 40: 0.98\n",
      "target notes:    [2, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7]\n",
      "predicted notes: [0, 2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7]\n",
      "Accuracy for song 1, batch 41: 0.95\n",
      "target notes:    [2, 5, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2]\n",
      "predicted notes: [3, 3, 0, 2, 7, 5, 3, 5, 4, 4, 3, 7, 4, 6, 1, 5, 7, 0, 2, 6, 0, 7, 0, 4, 1, 7, 2, 1, 1, 5, 6, 3, 7, 6, 3, 1, 1, 2, 0, 1, 7, 2]\n",
      "Accuracy for song 2, batch 0: 0.95\n",
      "target notes:    [2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2]\n",
      "predicted notes: [3, 3, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2]\n",
      "Accuracy for song 2, batch 1: 0.93\n",
      "target notes:    [6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2]\n",
      "predicted notes: [3, 0, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2]\n",
      "Accuracy for song 2, batch 2: 0.95\n",
      "target notes:    [6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6]\n",
      "predicted notes: [5, 5, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6]\n",
      "Accuracy for song 2, batch 3: 0.95\n",
      "target notes:    [0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6]\n",
      "predicted notes: [5, 6, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6]\n",
      "Accuracy for song 2, batch 4: 0.93\n",
      "target notes:    [0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0]\n",
      "predicted notes: [1, 1, 5, 5, 4, 4, 3, 3, 2, 2, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0]\n",
      "Accuracy for song 2, batch 5: 0.95\n",
      "target notes:    [6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0]\n",
      "predicted notes: [1, 5, 5, 4, 4, 3, 3, 2, 2, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0]\n",
      "Accuracy for song 2, batch 6: 0.98\n",
      "target notes:    [5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6]\n",
      "predicted notes: [5, 5, 4, 4, 3, 2, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6]\n",
      "Accuracy for song 2, batch 7: 0.93\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5]\n",
      "predicted notes: [0, 0, 4, 4, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5]\n",
      "Accuracy for song 2, batch 8: 0.98\n",
      "target notes:    [4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5]\n",
      "predicted notes: [0, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5]\n",
      "Accuracy for song 2, batch 9: 0.95\n",
      "target notes:    [4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4]\n",
      "predicted notes: [5, 5, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4]\n",
      "Accuracy for song 2, batch 10: 0.95\n",
      "target notes:    [3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4]\n",
      "predicted notes: [5, 2, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4]\n",
      "Accuracy for song 2, batch 11: 0.95\n",
      "target notes:    [3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3]\n",
      "predicted notes: [4, 4, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3]\n",
      "Accuracy for song 2, batch 12: 0.95\n",
      "target notes:    [2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3]\n",
      "predicted notes: [4, 2, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3]\n",
      "Accuracy for song 2, batch 13: 0.93\n",
      "target notes:    [6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [3, 0, 0, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2]\n",
      "Accuracy for song 2, batch 14: 0.98\n",
      "target notes:    [6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6]\n",
      "predicted notes: [5, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6]\n",
      "Accuracy for song 2, batch 15: 0.98\n",
      "target notes:    [5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6]\n",
      "predicted notes: [5, 5, 4, 4, 3, 2, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6]\n",
      "Accuracy for song 2, batch 16: 0.90\n",
      "target notes:    [5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5]\n",
      "predicted notes: [0, 0, 4, 4, 3, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5]\n",
      "Accuracy for song 2, batch 17: 0.95\n",
      "target notes:    [4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5]\n",
      "predicted notes: [0, 4, 3, 3, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5]\n",
      "Accuracy for song 2, batch 18: 0.93\n",
      "target notes:    [4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4]\n",
      "predicted notes: [5, 5, 3, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4]\n",
      "Accuracy for song 2, batch 19: 0.95\n",
      "target notes:    [3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4]\n",
      "predicted notes: [5, 2, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4]\n",
      "Accuracy for song 2, batch 20: 0.98\n",
      "target notes:    [6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3]\n",
      "predicted notes: [4, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3]\n",
      "Accuracy for song 2, batch 21: 0.95\n",
      "target notes:    [6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6]\n",
      "predicted notes: [5, 5, 5, 4, 4, 3, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6]\n",
      "Accuracy for song 2, batch 22: 1.00\n",
      "target notes:    [5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6]\n",
      "predicted notes: [5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6]\n",
      "Accuracy for song 2, batch 23: 0.90\n",
      "target notes:    [5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5]\n",
      "predicted notes: [0, 0, 4, 4, 3, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5]\n",
      "Accuracy for song 2, batch 24: 0.95\n",
      "target notes:    [4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5]\n",
      "predicted notes: [0, 4, 3, 3, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5]\n",
      "Accuracy for song 2, batch 25: 0.93\n",
      "target notes:    [4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4]\n",
      "predicted notes: [5, 5, 3, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4]\n",
      "Accuracy for song 2, batch 26: 0.98\n",
      "target notes:    [3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4]\n",
      "predicted notes: [5, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4]\n",
      "Accuracy for song 2, batch 27: 0.98\n",
      "target notes:    [2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3]\n",
      "predicted notes: [4, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3]\n",
      "Accuracy for song 2, batch 28: 0.93\n",
      "target notes:    [2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2]\n",
      "predicted notes: [3, 3, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2]\n",
      "Accuracy for song 2, batch 29: 0.95\n",
      "target notes:    [6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2]\n",
      "predicted notes: [3, 0, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2]\n",
      "Accuracy for song 2, batch 30: 0.93\n",
      "target notes:    [6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6]\n",
      "predicted notes: [5, 5, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6]\n",
      "Accuracy for song 2, batch 31: 0.93\n",
      "target notes:    [0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6]\n",
      "predicted notes: [5, 6, 6, 5, 5, 4, 4, 3, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6]\n",
      "Accuracy for song 2, batch 32: 0.95\n",
      "target notes:    [0, 6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0]\n",
      "predicted notes: [1, 1, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0]\n",
      "Accuracy for song 2, batch 33: 0.98\n",
      "target notes:    [6, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0]\n",
      "predicted notes: [1, 5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0]\n",
      "Accuracy for song 2, batch 34: 0.95\n",
      "target notes:    [5, 5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6]\n",
      "predicted notes: [5, 5, 4, 4, 3, 2, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6]\n",
      "Accuracy for song 2, batch 35: 0.90\n",
      "target notes:    [5, 4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5]\n",
      "predicted notes: [0, 0, 4, 4, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5]\n",
      "Accuracy for song 2, batch 36: 0.95\n",
      "target notes:    [4, 4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5]\n",
      "predicted notes: [0, 4, 3, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5]\n",
      "Accuracy for song 2, batch 37: 0.93\n",
      "target notes:    [4, 3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4]\n",
      "predicted notes: [5, 5, 3, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4]\n",
      "Accuracy for song 2, batch 38: 0.93\n",
      "target notes:    [3, 3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4]\n",
      "predicted notes: [5, 2, 2, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4]\n",
      "Accuracy for song 2, batch 39: 0.93\n",
      "target notes:    [3, 2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3]\n",
      "predicted notes: [4, 4, 6, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3]\n",
      "Accuracy for song 2, batch 40: 0.95\n",
      "target notes:    [2, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3]\n",
      "predicted notes: [4, 2, 6, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3]\n",
      "Accuracy for song 2, batch 41: 0.90\n",
      "target notes:    [2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2]\n",
      "predicted notes: [3, 3, 3, 6, 6, 0, 6, 5, 5, 4, 4, 3, 3, 2, 6, 6, 5, 5, 4, 4, 3, 6, 6, 5, 5, 4, 4, 3, 2, 2, 6, 6, 0, 0, 6, 5, 5, 4, 4, 3, 3, 2]\n",
      "Accuracy for song 3, batch 0: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 1: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 2: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 3: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 4: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 5: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 6: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 7: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 8: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 9: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 10: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 11: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 12: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 13: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 14: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 15: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 16: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 17: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 18: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 19: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 20: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 21: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 22: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 23: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 24: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 25: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 26: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 27: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 28: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 29: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 30: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 31: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 32: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 33: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 34: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 35: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 3, batch 36: 1.00\n",
      "target notes:    [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
      "Accuracy for song 3, batch 37: 1.00\n",
      "target notes:    [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 3, batch 38: 1.00\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 3, batch 39: 1.00\n",
      "target notes:    [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3]\n",
      "Accuracy for song 3, batch 40: 1.00\n",
      "target notes:    [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
      "Accuracy for song 3, batch 41: 1.00\n",
      "target notes:    [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n",
      "Accuracy for song 4, batch 0: 0.98\n",
      "target notes:    [1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0]\n",
      "predicted notes: [1, 2, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0]\n",
      "Accuracy for song 4, batch 1: 0.98\n",
      "target notes:    [0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1]\n",
      "predicted notes: [2, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1]\n",
      "Accuracy for song 4, batch 2: 0.93\n",
      "target notes:    [2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0]\n",
      "predicted notes: [1, 7, 3, 5, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0]\n",
      "Accuracy for song 4, batch 3: 0.95\n",
      "target notes:    [0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2]\n",
      "predicted notes: [3, 3, 5, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2]\n",
      "Accuracy for song 4, batch 4: 0.95\n",
      "target notes:    [3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0]\n",
      "predicted notes: [1, 4, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0]\n",
      "Accuracy for song 4, batch 5: 0.95\n",
      "target notes:    [0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3]\n",
      "predicted notes: [4, 5, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3]\n",
      "Accuracy for song 4, batch 6: 0.95\n",
      "target notes:    [4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0]\n",
      "predicted notes: [1, 1, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0]\n",
      "Accuracy for song 4, batch 7: 0.95\n",
      "target notes:    [0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4]\n",
      "predicted notes: [5, 2, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4]\n",
      "Accuracy for song 4, batch 8: 0.95\n",
      "target notes:    [5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0]\n",
      "predicted notes: [1, 1, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0]\n",
      "Accuracy for song 4, batch 9: 0.98\n",
      "target notes:    [0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5]\n",
      "predicted notes: [0, 1, 2, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5]\n",
      "Accuracy for song 4, batch 10: 0.95\n",
      "target notes:    [1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0]\n",
      "predicted notes: [1, 2, 0, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0]\n",
      "Accuracy for song 4, batch 11: 0.95\n",
      "target notes:    [4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1]\n",
      "predicted notes: [2, 0, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1]\n",
      "Accuracy for song 4, batch 12: 0.98\n",
      "target notes:    [5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4]\n",
      "predicted notes: [5, 0, 1, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4]\n",
      "Accuracy for song 4, batch 13: 0.98\n",
      "target notes:    [0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5]\n",
      "predicted notes: [0, 1, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5]\n",
      "Accuracy for song 4, batch 14: 0.95\n",
      "target notes:    [3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0]\n",
      "predicted notes: [1, 4, 1, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0]\n",
      "Accuracy for song 4, batch 15: 0.98\n",
      "target notes:    [4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3]\n",
      "predicted notes: [4, 5, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3]\n",
      "Accuracy for song 4, batch 16: 0.95\n",
      "target notes:    [2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4]\n",
      "predicted notes: [5, 1, 1, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4]\n",
      "Accuracy for song 4, batch 17: 0.95\n",
      "target notes:    [1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2]\n",
      "predicted notes: [3, 1, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2]\n",
      "Accuracy for song 4, batch 18: 0.95\n",
      "target notes:    [0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1]\n",
      "predicted notes: [2, 2, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1]\n",
      "Accuracy for song 4, batch 19: 0.98\n",
      "target notes:    [1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0]\n",
      "predicted notes: [1, 2, 3, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0]\n",
      "Accuracy for song 4, batch 20: 0.93\n",
      "target notes:    [2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1]\n",
      "predicted notes: [2, 3, 5, 2, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1]\n",
      "Accuracy for song 4, batch 21: 0.95\n",
      "target notes:    [5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2]\n",
      "predicted notes: [3, 4, 2, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2]\n",
      "Accuracy for song 4, batch 22: 0.93\n",
      "target notes:    [4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5]\n",
      "predicted notes: [0, 4, 2, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5]\n",
      "Accuracy for song 4, batch 23: 0.95\n",
      "target notes:    [3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4]\n",
      "predicted notes: [5, 2, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4]\n",
      "Accuracy for song 4, batch 24: 0.98\n",
      "target notes:    [4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3]\n",
      "predicted notes: [4, 5, 0, 1, 2, 3, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3]\n",
      "Accuracy for song 4, batch 25: 0.98\n",
      "target notes:    [5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4]\n",
      "predicted notes: [5, 0, 1, 2, 3, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4]\n",
      "Accuracy for song 4, batch 26: 0.98\n",
      "target notes:    [0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5]\n",
      "predicted notes: [0, 1, 2, 3, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5]\n",
      "Accuracy for song 4, batch 27: 0.98\n",
      "target notes:    [1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0]\n",
      "predicted notes: [1, 2, 3, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0]\n",
      "Accuracy for song 4, batch 28: 0.95\n",
      "target notes:    [2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1]\n",
      "predicted notes: [2, 3, 1, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1]\n",
      "Accuracy for song 4, batch 29: 0.95\n",
      "target notes:    [0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2]\n",
      "predicted notes: [3, 3, 5, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2]\n",
      "Accuracy for song 4, batch 30: 0.98\n",
      "target notes:    [3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0]\n",
      "predicted notes: [1, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0]\n",
      "Accuracy for song 4, batch 31: 0.98\n",
      "target notes:    [4, 1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3]\n",
      "predicted notes: [4, 5, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3]\n",
      "Accuracy for song 4, batch 32: 0.93\n",
      "target notes:    [1, 0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4]\n",
      "predicted notes: [5, 7, 2, 0, 3, 5, 0, 1, 4, 0, 1, 2, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4]\n",
      "Accuracy for song 4, batch 33: 0.95\n",
      "target notes:    [0, 2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1]\n",
      "predicted notes: [2, 2, 0, 3, 0, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1]\n",
      "Accuracy for song 4, batch 34: 0.95\n",
      "target notes:    [2, 0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0]\n",
      "predicted notes: [1, 7, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0]\n",
      "Accuracy for song 4, batch 35: 0.98\n",
      "target notes:    [0, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2]\n",
      "predicted notes: [3, 3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2]\n",
      "Accuracy for song 4, batch 36: 0.95\n",
      "target notes:    [3, 5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0]\n",
      "predicted notes: [1, 4, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0]\n",
      "Accuracy for song 4, batch 37: 0.95\n",
      "target notes:    [5, 0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3]\n",
      "predicted notes: [4, 4, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3]\n",
      "Accuracy for song 4, batch 38: 0.95\n",
      "target notes:    [0, 1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5]\n",
      "predicted notes: [0, 1, 2, 5, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5]\n",
      "Accuracy for song 4, batch 39: 0.98\n",
      "target notes:    [1, 4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0]\n",
      "predicted notes: [1, 2, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0]\n",
      "Accuracy for song 4, batch 40: 0.95\n",
      "target notes:    [4, 0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1]\n",
      "predicted notes: [2, 0, 2, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1]\n",
      "Accuracy for song 4, batch 41: 0.95\n",
      "target notes:    [0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4]\n",
      "predicted notes: [5, 2, 0, 2, 0, 3, 0, 4, 0, 5, 0, 1, 4, 5, 0, 3, 4, 2, 1, 0, 1, 2, 5, 4, 3, 4, 5, 0, 1, 2, 0, 3, 4, 1, 0, 2, 0, 3, 5, 0, 1, 4]\n",
      "Accuracy for song 5, batch 0: 0.98\n",
      "target notes:    [1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3]\n",
      "predicted notes: [4, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3]\n",
      "Accuracy for song 5, batch 1: 0.95\n",
      "target notes:    [2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1]\n",
      "predicted notes: [2, 3, 1, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1]\n",
      "Accuracy for song 5, batch 2: 0.95\n",
      "target notes:    [0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2]\n",
      "predicted notes: [3, 3, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2]\n",
      "Accuracy for song 5, batch 3: 0.95\n",
      "target notes:    [2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0]\n",
      "predicted notes: [1, 7, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0]\n",
      "Accuracy for song 5, batch 4: 0.93\n",
      "target notes:    [1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2]\n",
      "predicted notes: [3, 1, 3, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2]\n",
      "Accuracy for song 5, batch 5: 0.98\n",
      "target notes:    [2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1]\n",
      "predicted notes: [2, 3, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1]\n",
      "Accuracy for song 5, batch 6: 0.95\n",
      "target notes:    [5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2]\n",
      "predicted notes: [3, 4, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2]\n",
      "Accuracy for song 5, batch 7: 0.95\n",
      "target notes:    [5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5]\n",
      "predicted notes: [0, 0, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5]\n",
      "Accuracy for song 5, batch 8: 0.98\n",
      "target notes:    [3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5]\n",
      "predicted notes: [0, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5]\n",
      "Accuracy for song 5, batch 9: 0.93\n",
      "target notes:    [2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3]\n",
      "predicted notes: [4, 2, 5, 0, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3]\n",
      "Accuracy for song 5, batch 10: 0.98\n",
      "target notes:    [4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2]\n",
      "predicted notes: [3, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2]\n",
      "Accuracy for song 5, batch 11: 0.98\n",
      "target notes:    [5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4]\n",
      "predicted notes: [5, 0, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4]\n",
      "Accuracy for song 5, batch 12: 0.93\n",
      "target notes:    [5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5]\n",
      "predicted notes: [0, 0, 4, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5]\n",
      "Accuracy for song 5, batch 13: 0.95\n",
      "target notes:    [4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5]\n",
      "predicted notes: [0, 4, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5]\n",
      "Accuracy for song 5, batch 14: 0.98\n",
      "target notes:    [5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4]\n",
      "predicted notes: [5, 0, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4]\n",
      "Accuracy for song 5, batch 15: 0.98\n",
      "target notes:    [2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5]\n",
      "predicted notes: [0, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5]\n",
      "Accuracy for song 5, batch 16: 0.98\n",
      "target notes:    [3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2]\n",
      "predicted notes: [3, 4, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2]\n",
      "Accuracy for song 5, batch 17: 0.98\n",
      "target notes:    [3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3]\n",
      "predicted notes: [4, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3]\n",
      "Accuracy for song 5, batch 18: 0.98\n",
      "target notes:    [4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3]\n",
      "predicted notes: [4, 5, 0, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3]\n",
      "Accuracy for song 5, batch 19: 0.98\n",
      "target notes:    [5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4]\n",
      "predicted notes: [5, 0, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4]\n",
      "Accuracy for song 5, batch 20: 0.95\n",
      "target notes:    [4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5]\n",
      "predicted notes: [0, 4, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5]\n",
      "Accuracy for song 5, batch 21: 0.95\n",
      "target notes:    [1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4]\n",
      "predicted notes: [5, 7, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4]\n",
      "Accuracy for song 5, batch 22: 0.98\n",
      "target notes:    [4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1]\n",
      "predicted notes: [2, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1]\n",
      "Accuracy for song 5, batch 23: 0.98\n",
      "target notes:    [0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4]\n",
      "predicted notes: [5, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4]\n",
      "Accuracy for song 5, batch 24: 0.95\n",
      "target notes:    [2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0]\n",
      "predicted notes: [1, 7, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0]\n",
      "Accuracy for song 5, batch 25: 0.98\n",
      "target notes:    [5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2]\n",
      "predicted notes: [3, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2]\n",
      "Accuracy for song 5, batch 26: 0.95\n",
      "target notes:    [4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5]\n",
      "predicted notes: [0, 4, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5]\n",
      "Accuracy for song 5, batch 27: 0.95\n",
      "target notes:    [2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4]\n",
      "predicted notes: [5, 1, 1, 5, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4]\n",
      "Accuracy for song 5, batch 28: 0.95\n",
      "target notes:    [1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2]\n",
      "predicted notes: [3, 1, 4, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2]\n",
      "Accuracy for song 5, batch 29: 0.95\n",
      "target notes:    [1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1]\n",
      "predicted notes: [2, 2, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1]\n",
      "Accuracy for song 5, batch 30: 0.98\n",
      "target notes:    [1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1]\n",
      "predicted notes: [2, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1]\n",
      "Accuracy for song 5, batch 31: 0.98\n",
      "target notes:    [2, 1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1]\n",
      "predicted notes: [2, 3, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1]\n",
      "Accuracy for song 5, batch 32: 0.95\n",
      "target notes:    [1, 4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2]\n",
      "predicted notes: [3, 1, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2]\n",
      "Accuracy for song 5, batch 33: 0.95\n",
      "target notes:    [4, 2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1]\n",
      "predicted notes: [2, 0, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1]\n",
      "Accuracy for song 5, batch 34: 0.95\n",
      "target notes:    [2, 1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4]\n",
      "predicted notes: [5, 1, 1, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4]\n",
      "Accuracy for song 5, batch 35: 0.95\n",
      "target notes:    [1, 5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2]\n",
      "predicted notes: [3, 1, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2]\n",
      "Accuracy for song 5, batch 36: 0.95\n",
      "target notes:    [5, 3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1]\n",
      "predicted notes: [2, 6, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1]\n",
      "Accuracy for song 5, batch 37: 0.95\n",
      "target notes:    [3, 0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5]\n",
      "predicted notes: [0, 2, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5]\n",
      "Accuracy for song 5, batch 38: 0.98\n",
      "target notes:    [0, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3]\n",
      "predicted notes: [4, 5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3]\n",
      "Accuracy for song 5, batch 39: 0.98\n",
      "target notes:    [5, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0]\n",
      "predicted notes: [1, 1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0]\n",
      "Accuracy for song 5, batch 40: 0.98\n",
      "target notes:    [1, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5]\n",
      "predicted notes: [0, 3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5]\n",
      "Accuracy for song 5, batch 41: 0.98\n",
      "target notes:    [3, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1]\n",
      "predicted notes: [2, 1, 2, 0, 2, 1, 2, 5, 5, 3, 2, 4, 5, 5, 4, 5, 2, 3, 3, 4, 5, 4, 1, 4, 0, 2, 5, 4, 2, 1, 1, 1, 2, 1, 4, 2, 1, 5, 3, 0, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "for i ,song in enumerate(songs):\n",
    "    for j in range(bptt):\n",
    "        data,target=get_batch(songs,j, i)\n",
    "        # Convert the input notes to a tensor and add an extra dimension\n",
    "\n",
    "        # Create a mask for the input\n",
    "        src_mask = generate_square_subsequent_mask(len(data)).to(device)\n",
    "\n",
    "        # Run the model on the input tensor\n",
    "        output = model(torch.tensor(data,dtype=torch.long),src_mask)\n",
    "\n",
    "        # Detach the output from the computation graph and convert to numpy array\n",
    "        output_array = output.detach().numpy()\n",
    "\n",
    "        # Get the predicted notes by finding the index of the maximum value in each output vector\n",
    "        predicted_notes = np.argmax(output_array, axis=-1)\n",
    "\n",
    "        predicted_notes_list = [note for sublist in predicted_notes for note in sublist]  # Flattening the list\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(np.array(predicted_notes_list) == np.array(target))\n",
    "        print(f'Accuracy for song {i + 1}, batch {j}: {accuracy:.2f}')\n",
    "        print(f'target notes:    {target}')\n",
    "        print(f'predicted notes: {predicted_notes_list}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
