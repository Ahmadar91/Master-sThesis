{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pickle\n",
    "import numpy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.pyplot import figure, subplots, imshow, xticks, yticks, title\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from statistics import mean\n",
    "from scipy.stats import entropy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim**0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted\n",
    "\n",
    "\n",
    "class NetRNNWithAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=12, inp=3):\n",
    "        super(NetRNNWithAttention, self).__init__()\n",
    "        self.attention = SelfAttention(inp)  # Attention layer with input dimension\n",
    "        self.rnnLayer = nn.RNN(inp, hidden_dim, batch_first=True)\n",
    "        self.outputLayer = nn.Linear(hidden_dim, 1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.resetHidden()\n",
    "        self.inp = inp\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applying attention first\n",
    "        attn_out = self.attention(x)\n",
    "        # Feeding the output of the attention layer into the RNN\n",
    "        h0 = torch.zeros(1, x.shape[0], self.hidden_dim)\n",
    "        rnn_out, _ = self.rnnLayer(attn_out, h0)\n",
    "        rnn_out = torch.tanh(rnn_out)\n",
    "\n",
    "        # Applying the final output layer\n",
    "        out = torch.sigmoid(self.outputLayer(rnn_out[:, -1, :])).squeeze()\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.zeros(1, 1, self.hidden_dim)\n",
    "            for i in range(x.shape[1]):\n",
    "                # Applying attention to each timestep\n",
    "                attn_out = self.attention(x[l][i].reshape((1, 1, self.inp)))\n",
    "\n",
    "                # Feeding the output of the attention layer into the RNN\n",
    "                out, h0 = self.rnnLayer(attn_out, h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "\n",
    "                out = torch.tanh(out)\n",
    "                out = torch.sigmoid(self.outputLayer(out[:, -1, :]))\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "\n",
    "        return np.array(O), np.array(H)\n",
    "\n",
    "\n",
    "model = NetRNNWithAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=12, inp=3):\n",
    "        super(NetRNN, self).__init__()\n",
    "        self.rnnLayer = nn.RNN(inp, hidden_dim, batch_first=True)\n",
    "        self.outputLayer = nn.Linear(hidden_dim, 1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.resetHidden()\n",
    "        self.inp = inp\n",
    "\n",
    "    def resetHidden(self):\n",
    "        self.hidden = list()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.h0 = torch.Tensor(numpy.zeros((1, x.shape[0], self.hidden_dim)))\n",
    "        out, self.h0 = self.rnnLayer(x, self.h0)\n",
    "        out = torch.tanh(out)\n",
    "        self.hidden.append(copy.deepcopy(self.h0.detach().numpy()))\n",
    "        out = torch.sigmoid(self.outputLayer(out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "    def step(self, x):\n",
    "        O = []\n",
    "        H = []\n",
    "        for l in range(x.shape[0]):\n",
    "            h0 = torch.Tensor(numpy.zeros((1, 1, self.hidden_dim)))\n",
    "            for i in range(x.shape[1]):\n",
    "                out, h0 = self.rnnLayer(x[l][i].reshape((1, 1, self.inp)), h0)\n",
    "                H.append(out.detach().numpy().flatten())\n",
    "                # print(out.detach().numpy().flatten().shape)\n",
    "            out = torch.tanh(out)\n",
    "            out = torch.sigmoid(self.outputLayer(out[:, -1, :]))\n",
    "            for i in range(x.shape[1]):\n",
    "                O.append(out.detach().numpy().flatten())\n",
    "                # print(out.detach().numpy().flatten().shape)\n",
    "        return numpy.array(O), numpy.array(H)\n",
    "\n",
    "\n",
    "model = NetRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainData(num_samples, min_length, max_length):\n",
    "    s = []  # Sequences (list of arrays)\n",
    "    t = []  # Targets (list of labels)\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomized common length between min_length and max_length\n",
    "        common_length = np.random.randint(min_length, max_length + 1)\n",
    "\n",
    "        # Given arrays\n",
    "        array_A = np.full(common_length, 0.5)\n",
    "        array_B = np.full(common_length, 0.5)\n",
    "        array_C = np.full(common_length, 0.5)\n",
    "\n",
    "        # Random index for array A\n",
    "        index_A = np.random.randint(common_length)\n",
    "        value_A = np.random.choice([0, 1])\n",
    "        array_A[index_A] = value_A\n",
    "\n",
    "        # Different random index for array B\n",
    "        indices_B = np.delete(\n",
    "            np.arange(common_length), index_A\n",
    "        )  # Removing the index used in Array A\n",
    "        index_B = np.random.choice(indices_B)\n",
    "        value_B = np.random.choice([0, 1])\n",
    "        array_B[index_B] = value_B\n",
    "\n",
    "        # Setting the last index of array C to either 0 or 1\n",
    "        value_C = np.random.choice([0, 1])\n",
    "        array_C[-1] = value_C\n",
    "\n",
    "        # Generating label based on value_C\n",
    "        label = int((value_A != value_B) if value_C == 0 else (value_A == value_B))\n",
    "        label_arr = [label]\n",
    "        # Combine arrays\n",
    "        combined_array = np.vstack([array_A, array_B, array_C]).T\n",
    "\n",
    "        s.append(combined_array)\n",
    "        t.append(label_arr)\n",
    "\n",
    "    return s, numpy.array(t)  # Returning as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0.5, 0.5, 0.5],\n",
       "         [0.5, 0. , 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0. , 0.5, 0.5],\n",
       "         [0.5, 0.5, 1. ]]),\n",
       "  array([[0.5, 0.5, 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [1. , 0.5, 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0.5, 0. , 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0.5, 0.5, 0.5],\n",
       "         [0.5, 0.5, 1. ]])],\n",
       " array([[1],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seq = 2\n",
    "array_min_length = 5\n",
    "array_max_length = 10\n",
    "sequences, labels = generateTrainData(num_seq, array_min_length, array_max_length)\n",
    "sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "NetRNNWithAttention(\n",
      "  (attention): SelfAttention(\n",
      "    (query): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (key): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (value): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      "  (rnnLayer): RNN(3, 12, batch_first=True)\n",
      "  (outputLayer): Linear(in_features=12, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NetRNNWithAttention()\n",
    "sequences, labels = generateTrainData(100, 10, 10)\n",
    "output = model(torch.Tensor(sequences))\n",
    "print(output.shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming sequences and labels are already generated using generateTrainData\n",
    "num_samples = len(sequences)  # Number of samples to display\n",
    "\n",
    "# Plotting\n",
    "# Adjust the figure size to accommodate horizontal layout\n",
    "plt.figure(figsize=(3 * num_samples, 15))\n",
    "\n",
    "for i, (seq, label) in enumerate(zip(sequences, labels)):\n",
    "    # Reshape each sequence for visualization\n",
    "    reshaped_sequence = seq  # Use the sequence as it is\n",
    "\n",
    "    # Add a subplot for each sequence in a horizontal layout\n",
    "    ax = plt.subplot(1, num_samples, i + 1)\n",
    "    img = ax.imshow(reshaped_sequence, cmap=\"gray\", vmin=0.0, vmax=1.0)\n",
    "\n",
    "    # Determine the operation title based on the label\n",
    "    operation_title = \"XOR\" if label == 0 else \"XNOR\"\n",
    "\n",
    "    # Setting the title with the operation label\n",
    "    ax.set_title(f\"Sequence {i+1} - Operation: {operation_title}, {label}\")\n",
    "\n",
    "    # Setting labels for features (X-axis) and detailed time points (Y-axis)\n",
    "    ax.set_xlabel(\"Arrays (A, B, C)\")\n",
    "    ax.set_ylabel(\"Time Points\")\n",
    "\n",
    "    # Setting tick marks for each array on the X-axis\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_xticklabels([\"A\", \"B\", \"C\"])\n",
    "\n",
    "    # Setting tick marks for each time point on the Y-axis\n",
    "    # Here, the number of ticks should be equal to the length of the sequence (number of rows)\n",
    "    ax.set_yticks(range(reshaped_sequence.shape[0]))\n",
    "    ax.set_yticklabels([f\"{j+1}\" for j in range(reshaped_sequence.shape[0])])\n",
    "\n",
    "# Adding a colorbar as the key, placed at the side\n",
    "# cbar_ax = plt.gcf().add_axes([0.93, 0.15, 0.02, 0.7])  # Adjust these values as needed for positioning\n",
    "# cbar = plt.colorbar(img, cax=cbar_ax)\n",
    "# cbar.set_ticks([0, 1])\n",
    "# cbar.set_ticklabels(['0 (Black)', '1 (White)'])\n",
    "\n",
    "# Adjust the main figure to make room for the colorbar\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, target in test_data:\n",
    "            seq_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)\n",
    "            target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "            output = model(seq_tensor)\n",
    "            loss = criterion(output, target_tensor)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            predictions = (output >= 0.5).float()\n",
    "            total_correct += (predictions == target_tensor).sum().item()\n",
    "            total_samples += target_tensor.numel()\n",
    "\n",
    "    avg_loss = test_loss / len(test_data)\n",
    "    avg_accuracy = total_correct / total_samples\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pnb9p7_n30s29gprj1gbqbbm0000gn/T/ipykernel_69101/4171570184.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sequences = numpy.array(sequences)  # Convert to numpy array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5084411138296128\n",
      "acc: 0.4955152106285095\n",
      "acc: 0.4986448657512665\n",
      "acc: 0.5020590135455132\n",
      "acc: 0.49611291736364366\n",
      "acc: 0.499186604321003\n",
      "acc: 0.5028960201144218\n",
      "acc: 0.5002873572707176\n",
      "acc: 0.4981431496143341\n",
      "acc: 0.4988619673252106\n",
      "acc: 0.49853614866733553\n",
      "acc: 0.5035735249519349\n",
      "acc: 0.5042756316065788\n",
      "acc: 0.5019648438692093\n",
      "acc: 0.5027036035060882\n",
      "acc: 0.4976484704017639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb#X32sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss \u001b[39m=\u001b[39m error(output, target_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb#X32sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb#X32sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb#X32sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m div \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy() \u001b[39m-\u001b[39m target_tensor\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/Master-sThesis/Attention.ipynb#X32sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m divs\u001b[39m.\u001b[39mappend(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39mabs\u001b[39m(div)\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collectorA = dict()\n",
    "array_min_length = 17  # Define the min length of Arrays A, B, C\n",
    "array_max_length = 25  # Define the max length of Arrays A, B, C\n",
    "num_samples = 100\n",
    "for rep in range(1):\n",
    "    for kind in [\"NetRNNWithAttention\" ,\"RNN\"]:\n",
    "        if kind == \"RNN\":\n",
    "            model = NetRNN(hidden_dim=12, inp=3)\n",
    "        if kind == \"NetRNNWithAttention\":\n",
    "            model = NetRNNWithAttention(hidden_dim=12, inp=3)\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        error = nn.MSELoss()\n",
    "        acc = 0.0\n",
    "        W = []\n",
    "        A = []\n",
    "\n",
    "        while acc < 0.97:\n",
    "            model.resetHidden()\n",
    "            sequences, targets = generateTrainData(\n",
    "                num_samples, array_min_length, array_max_length\n",
    "            )\n",
    "            sequences = numpy.array(sequences)  # Convert to numpy array\n",
    "\n",
    "            divs = []\n",
    "            for seq, target in zip(sequences, targets):\n",
    "                optimizer.zero_grad()\n",
    "                # Process each sequence individually\n",
    "                seq_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(\n",
    "                    0\n",
    "                )  # Add batch dimension\n",
    "                target_tensor = torch.tensor(\n",
    "                    target, dtype=torch.float32\n",
    "                )  # Add batch dimension\n",
    "                # seq_tensor =torch.Tensor(seq.reshape(1, seq.shape[0], 3))\n",
    "                output = model(seq_tensor)\n",
    "                loss = error(output, target_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                div = output.detach().numpy() - target_tensor.numpy()\n",
    "                divs.append(1.0 - abs(div).mean())\n",
    "\n",
    "            W.append(loss.item())\n",
    "            acc = mean(divs)\n",
    "            A.append(acc)\n",
    "            print(f\"acc: {acc}\")\n",
    "\n",
    "            # Restart training if not converging\n",
    "            if acc < 0.97 and len(A) > 2000:\n",
    "                if kind == \"RNN\":\n",
    "                    model = NetRNN(hidden_dim=12, inp=3)\n",
    "                if kind == \"NetRNNWithAttention\":\n",
    "                    model = NetRNNWithAttention(hidden_dim=12, inp=3)\n",
    "                optimizer = optim.Adam(model.parameters())\n",
    "                acc = 0.0\n",
    "                W = []\n",
    "                A = []\n",
    "                print(\"repeat\")\n",
    "\n",
    "        # torch.save(model, f\"model{rep}.pth\")\n",
    "        collectorA[\"{0} {1}\".format(kind, rep)] = A\n",
    "        torch.save(model, \"models/model_{0}_{1}.model\".format(kind, rep))\n",
    "        print(\"{0} {1}\".format(kind, rep), len(A))\n",
    "        print(f\"RNN {rep}\", len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_min_length = 5\n",
    "array_max_length = 10\n",
    "analysis_interval = 500  # Interval for performing analysis\n",
    "\n",
    "# Training Loop\n",
    "for rep in range(1):\n",
    "    model = NetRNNWithAttention(hidden_dim=12)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    error = nn.MSELoss()\n",
    "    acc = 0.0\n",
    "    W = []  # To store loss values\n",
    "    A = []  # To store accuracy values\n",
    "\n",
    "    iteration = 0\n",
    "    while acc < 0.97:\n",
    "        model.resetHidden()\n",
    "        sequences, targets = generateTrainData(2, array_min_length, array_max_length)\n",
    "\n",
    "        divs = []\n",
    "        for seq, target in zip(sequences, targets):\n",
    "            optimizer.zero_grad()\n",
    "            seq_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)\n",
    "            target_tensor = torch.tensor([target], dtype=torch.float32)\n",
    "\n",
    "            output = model(seq_tensor)\n",
    "            loss = error(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            div = output.detach().numpy() - target_tensor.numpy()\n",
    "            divs.append(1.0 - abs(div).mean())\n",
    "\n",
    "        W.append(loss.item())\n",
    "        acc = mean(divs)\n",
    "        A.append(acc)\n",
    "        # print(f\"acc: {acc}\")\n",
    "\n",
    "        # Analysis Part\n",
    "        if iteration % analysis_interval == 0:\n",
    "            analysis_sequences, _ = generateTrainData(\n",
    "                1, array_min_length, array_max_length\n",
    "            )\n",
    "            analysis_seq_tensor = torch.tensor(\n",
    "                analysis_sequences[0], dtype=torch.float32\n",
    "            ).unsqueeze(0)\n",
    "            analysis_outputs, analysis_hidden_states = model.step(analysis_seq_tensor)\n",
    "\n",
    "            # Logging\n",
    "            # mean_outputs = analysis_outputs.mean(axis=0)\n",
    "            # std_outputs = analysis_outputs.std(axis=0)\n",
    "            # print(f\"Analysis - Step Function Outputs: Mean = {mean_outputs}, Std Dev = {std_outputs}\")\n",
    "\n",
    "            # mean_hidden_states = analysis_hidden_states.mean(axis=0)\n",
    "            # std_hidden_states = analysis_hidden_states.std(axis=0)\n",
    "            # print(f\"Analysis - Step Function Hidden States: Mean = {mean_hidden_states}, Std Dev = {std_hidden_states}\")\n",
    "\n",
    "            # Visualization\n",
    "            # plt.figure(figsize=(12, 4))\n",
    "            # plt.subplot(1, 2, 1)\n",
    "            # plt.plot(analysis_outputs)\n",
    "            # plt.title(\"Step Function Outputs Over Time\")\n",
    "            # plt.xlabel(\"Timestep\")\n",
    "            # plt.ylabel(\"Output\")\n",
    "\n",
    "            # plt.subplot(1, 2, 2)\n",
    "            # plt.plot(analysis_hidden_states)\n",
    "            # plt.title(\"Hidden States Over Time\")\n",
    "            # plt.xlabel(\"Timestep\")\n",
    "            # plt.ylabel(\"Hidden State Value\")\n",
    "\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "        # Restart training if not converging\n",
    "        if acc < 0.97 and len(A) > 2000:\n",
    "            model = NetRNNWithAttention(hidden_dim=12)\n",
    "            optimizer = optim.Adam(model.parameters())\n",
    "            acc = 0.0\n",
    "            W = []\n",
    "            A = []\n",
    "            print(\"repeat\")\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    print(f\"RNN {rep}\", len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolEntropy(D, base=2):\n",
    "    value, counts = numpy.unique(D, return_counts=True)\n",
    "    return entropy(counts, base=base)\n",
    "\n",
    "\n",
    "def computeTransmissionHfast(I, H, O, maskC, maskNC, iMult=2, oMult=2):\n",
    "    # print(\"I H O\",I.shape,H.shape,O.shape)\n",
    "    B = numpy.bitwise_and(H, maskNC)\n",
    "    IB = (B * iMult) + I\n",
    "    AB = H  # numpy.bitwise_and(H,maskC+maskNC)\n",
    "    BO = (B * oMult) + O\n",
    "    IAB = (AB * iMult) + I\n",
    "    IBO = (B * (iMult * oMult)) + (I * oMult) + O\n",
    "    ABO = (AB * oMult) + O\n",
    "    IABO = (AB * (iMult * oMult)) + (I * oMult) + O\n",
    "    hB = symbolEntropy(B, base=2)\n",
    "    hIB = symbolEntropy(IB, base=2)\n",
    "    hAB = symbolEntropy(AB, base=2)\n",
    "    hBO = symbolEntropy(BO, base=2)\n",
    "    hIAB = symbolEntropy(IAB, base=2)\n",
    "    hIBO = symbolEntropy(IBO, base=2)\n",
    "    hABO = symbolEntropy(ABO, base=2)\n",
    "    hIABO = symbolEntropy(IABO, base=2)\n",
    "    # -H(B)+H(IB)+H(AB)+H(BO)-H(IAB)-H(IBO)-H(ABO)+H(IABO)\n",
    "    # print(hB,hIB,hAB,hBO,hIAB,hIBO,hABO,hIABO)\n",
    "    return -hB + hIB + hAB + hBO - hIAB - hIBO - hABO + hIABO\n",
    "\n",
    "\n",
    "def singleShrinkingDecompositionInformation(I, H, O, width, iMult=2, oMult=2):\n",
    "    nodes = list(range(width))\n",
    "    cols = []\n",
    "    colh = []\n",
    "    while len(nodes) > 0:\n",
    "        infos = []\n",
    "        for node in nodes:\n",
    "            subset = copy.deepcopy(nodes)\n",
    "            subset.remove(node)\n",
    "            maskA = 0\n",
    "            for s in subset:\n",
    "                maskA += 1 * (2**s)\n",
    "            maskA = int(maskA)\n",
    "            maskB = numpy.bitwise_and(numpy.bitwise_not(maskA), ((2**width) - 1))\n",
    "            h = computeTransmissionHfast(\n",
    "                I, H, O, maskA, maskB, iMult=iMult, oMult=oMult\n",
    "            )\n",
    "            infos.append(h)\n",
    "        nodeToDrop = nodes[infos.index(max(infos))]\n",
    "        nodes.remove(nodeToDrop)\n",
    "        cols.append(copy.deepcopy(nodes))\n",
    "        colh.append(max(infos))\n",
    "    return cols, colh\n",
    "\n",
    "\n",
    "def getOutTaH(model, dataSet):\n",
    "    O, H = model.step(torch.Tensor(dataSet))\n",
    "    # print(H.shape,H.min(),H.max())\n",
    "    # figure()\n",
    "    # hist(H.flatten())\n",
    "    H = H.transpose()\n",
    "    O = O.transpose()\n",
    "    B = numpy.zeros(H.shape)\n",
    "    clusterNr = 2\n",
    "    for i in range(B.shape[0]):\n",
    "        a = H[i].reshape(-1, 1)\n",
    "        if len(numpy.unique(a)) == 1:\n",
    "            who = numpy.random.randint(len(a))\n",
    "            a[who] = 1 - a[who]\n",
    "        kmeans = KMeans(n_clusters=clusterNr).fit(a)\n",
    "        B[i] = kmeans.labels_\n",
    "        # B[i]=1.0*(H[i]>numpy.median(H[i]))\n",
    "\n",
    "    H = numpy.zeros((H.shape))\n",
    "    for i in range(12):\n",
    "        H += B[i] * (clusterNr**i)\n",
    "    H = H.astype((int))\n",
    "    return O, H\n",
    "\n",
    "\n",
    "def shrinkingDecompositionInformation(\n",
    "    model, width, dataSet, target, numbers=[0, 1, 2], whichTS=5, dsLength=8\n",
    "):\n",
    "    output, H = getOutTaH(model, dataSet)\n",
    "    output = output.transpose()[whichTS::dsLength].transpose()\n",
    "    # print(\"target.shape\",target.shape,\"output.shape\",output.shape,\"H.shape\",H.shape,\"dataset.shape\",dataSet.shape)\n",
    "    H = H.transpose()[whichTS::dsLength].transpose()\n",
    "    # target=target.transpose()[whichTS::dsLength].transpose()\n",
    "    # print(H.shape,target.shape,numpy.array(range(512))[whichTS::dsLength])\n",
    "    collectorSet = dict()\n",
    "    collectorH = dict()\n",
    "    for number in numbers:\n",
    "        I = target[number].astype(int)\n",
    "        O = (1.0 * (output[number] > 0.5)).astype(int)\n",
    "        # print(\"O\",O,\"T\",target[number])\n",
    "        # print(number,\"I.shape\",I.shape,\"O.shape\",O.shape,\"H.shape\",H.shape)\n",
    "        s, h = singleShrinkingDecompositionInformation(I, H, O, width)\n",
    "        collectorSet[number] = s\n",
    "        collectorH[number] = h\n",
    "    return collectorSet, collectorH\n",
    "\n",
    "\n",
    "def removalIntoVec(res, width, H):\n",
    "    V = numpy.zeros(width)\n",
    "    # for i,r in enumerate(res):\n",
    "    #    for e in r:\n",
    "    #        V[e]+=H[0]-H[i]\n",
    "    fullSet = list(range(width))\n",
    "    nRes = copy.deepcopy(res)\n",
    "    nRes.insert(0, fullSet)\n",
    "    nodeList = []\n",
    "    for i in range(width):\n",
    "        removedNode = list(set(nRes[i]) - set(nRes[i + 1]))[0]\n",
    "        nodeList.append(removedNode)\n",
    "    for i, node in enumerate(nodeList):\n",
    "        V[node] = H[0] - H[i]\n",
    "    # V=sqrt(V)\n",
    "    if V.sum() == 0:\n",
    "        return V\n",
    "    return V  # /V.max()\n",
    "\n",
    "\n",
    "def removalIntoMatrix(res, width, H):\n",
    "    M = []\n",
    "    for i in range(len(res)):\n",
    "        M.append(removalIntoVec(res[i], width, H[i]))\n",
    "    return numpy.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy: 52.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = torch.load(\"./Models/model_NetRNNWithAttention_0.model\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    # Ensure predictions and targets are the same shape\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    # Round predictions to the nearest integer (0 or 1)\n",
    "    predictions = predictions.round()\n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    correct = (predictions == targets).float()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = correct.sum() / correct.numel()  # Use numel() instead of len()\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "# Generate test data\n",
    "sequences, targets = generateTrainData(\n",
    "    100, array_min_length, array_max_length\n",
    ")  # You can use a different function for test data\n",
    "\n",
    "# Convert sequences and targets to tensors and pad sequences\n",
    "seq_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in sequences]\n",
    "padded_seq_tensors = pad_sequence(seq_tensors, batch_first=True)\n",
    "target_tensors = torch.tensor(targets, dtype=torch.float32).squeeze()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "with torch.no_grad():\n",
    "    total_acc = 0.0\n",
    "    for seq_tensor, target_tensor in zip(padded_seq_tensors, target_tensors):\n",
    "        output = model(seq_tensor.unsqueeze(0))  # Add batch dimension\n",
    "        acc = calculate_accuracy(output, target_tensor)\n",
    "        total_acc += acc\n",
    "\n",
    "    # Calculate average accuracy\n",
    "    avg_acc = total_acc / len(padded_seq_tensors)\n",
    "    print(f\"Average Test Accuracy: {avg_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
